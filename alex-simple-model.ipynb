{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "if torch.backends.mps.is_available():  # Check for Apple Silicon GPU availability (requires PyTorch 1.12 or later)\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():  # Check for NVIDIA GPU availability\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fall back to CPU\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy = pd.read_parquet('train.parquet')\n",
    "test = pd.read_parquet('test.parquet')\n",
    "validate = pd.read_parquet('validate.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect all texts to one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('AllTexts.txt', 'w') as f:\n",
    "#     pass  # This just creates the file, immediately closing it\n",
    "\n",
    "# with open('AllTexts.txt', 'a') as f:  # Open file in append mode\n",
    "#     for _, row in train.iterrows():\n",
    "#         concatenated = '\\n'.join(row['passages']['passage_text'])\n",
    "#         concatenated = '\\n'.join([concatenated, '\\n'.join(row['answers'])])\n",
    "#         concatenated = '\\n'.join([concatenated, row['query']])\n",
    "#         f.write(concatenated.lower() + '\\n')\n",
    "#     for _, row in test.iterrows():\n",
    "#         concatenated = '\\n'.join(row['passages']['passage_text'])\n",
    "#         concatenated = '\\n'.join([concatenated, '\\n'.join(row['answers'])])\n",
    "#         concatenated = '\\n'.join([concatenated, row['query']])\n",
    "#         f.write(concatenated.lower() + '\\n')\n",
    "#     for _, row in validate.iterrows():\n",
    "#         concatenated = '\\n'.join(row['passages']['passage_text'])\n",
    "#         concatenated = '\\n'.join([concatenated, '\\n'.join(row['answers'])])\n",
    "#         concatenated = '\\n'.join([concatenated, row['query']])\n",
    "#         f.write(concatenated.lower() + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train tokanizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spm.SentencePieceTrainer.train(\n",
    "#     input = 'AllTexts.txt',\n",
    "#     model_prefix='spm_AllTexts', \n",
    "#     vocab_size=30000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokanizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('spm_AllTexts.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_file(file_path, sp_processor):\n",
    "    tokenized_sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Assuming each line in the file is a separate sentence or paragraph\n",
    "            # Tokenize the line and add the list of tokens to the tokenized_sentences list\n",
    "            tokenized_sentences.append(sp_processor.encode_as_pieces(line.strip()))\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokinize all the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokinized_sentences = tokenize_file(\"AllTexts.txt\", sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export tokens to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"Tokens_AllText.json\", 'w', encoding='utf-8') as file:\n",
    "#     json.dump(tokinized_sentences, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    min_count  =20,\n",
    "    window     =10,\n",
    "    vector_size=vector_size,\n",
    "    sample     =6e-5, \n",
    "    alpha      = 0.03, \n",
    "    min_alpha  = 0.0007, \n",
    "    negative   = 20,\n",
    "    workers    = multiprocessing.cpu_count() - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(tokinized_sentences))\n",
    "# w2v_model.build_vocab(tokinized_sentences)\n",
    "# w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"word2vec_vocab.txt\", 'w') as vocab_file:\n",
    "#     for word in w2v_model.wv.key_to_index.keys():\n",
    "#         vocab_file.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model.train(tokinized_sentences, total_examples=w2v_model.corpus_count, epochs=20, report_delay=1)\n",
    "# w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('▁cyber', 0.5855585336685181), ('▁hack', 0.5675662159919739), ('▁malicious', 0.5665103197097778), ('▁malware', 0.5581293106079102)]\n",
      "[('▁cyber', 0.5855585336685181), ('▁hack', 0.5675662159919739), ('▁malicious', 0.5665103197097778), ('▁malware', 0.5581293106079102), ('▁scam', 0.5384910702705383), ('▁spyware', 0.5197509527206421), ('▁legitimate', 0.5031879544258118), ('▁adware', 0.4846465289592743), ('▁pretend', 0.469952255487442), ('▁insider', 0.46461066603660583)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = w2v_model.wv.most_similar('▁hacker', topn=4)\n",
    "print(similar_words)\n",
    "print(w2v_model.wv.most_similar(sp.encode_as_pieces('Hacker'.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_w2v_embedding(sp, text):\n",
    "#     tokens = sp.encode_as_pieces(text.lower())\n",
    "\n",
    "#     embeddings = []\n",
    "#     for token in tokens:\n",
    "#         if (token in w2v_model.wv): \n",
    "#             embeddings.append(w2v_model.wv[token])\n",
    "\n",
    "#     return np.stack(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triples for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTriplesTokens(dataframe):\n",
    "    triples = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        available_indices = list(dataframe.index)\n",
    "        available_indices.remove(index)\n",
    "        \n",
    "        for relevant in row['passages']['passage_text']:\n",
    "            random_index = np.random.choice(available_indices)\n",
    "            random_doc_index = np.random.choice(\n",
    "                list(\n",
    "                    range(\n",
    "                        len(dataframe.iloc[random_index]['passages']['passage_text'])\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "            irrelevant = dataframe.iloc[random_index]['passages']['passage_text'][random_doc_index]\n",
    "\n",
    "            triples.append([\n",
    "                row['query'],\n",
    "                relevant,\n",
    "                irrelevant,\n",
    "            ])\n",
    "\n",
    "    return triples\n",
    "\n",
    "# train_triplets = prepareTriplesTokens(train)\n",
    "# test_triplets = prepareTriplesTokens(test)\n",
    "# validate_triplets = prepareTriplesTokens(validate)\n",
    "\n",
    "train_triplets = pd.read_parquet('train_triplets.parquet')\n",
    "test_triplets = pd.read_parquet('test_triplets.parquet')\n",
    "validate_triplets = pd.read_parquet('validate_triplets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         query                                           relevant  \\\n",
      "0  what is rba  Since 2007, the RBA's outstanding reputation h...   \n",
      "1  what is rba  The Reserve Bank of Australia (RBA) came into ...   \n",
      "2  what is rba  RBA Recognized with the 2014 Microsoft US Regi...   \n",
      "\n",
      "                                          irrelevant  \n",
      "0  This report describes the typical weather at t...  \n",
      "1  1. district, community the vicar of a small pa...  \n",
      "2  They have tried to make Panda Express prices c...  \n"
     ]
    }
   ],
   "source": [
    "print(train_triplets[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the list of triples to a DataFrame\n",
    "# columns = ['query', 'relevant', 'irrelevant']\n",
    "# train_triplets = pd.DataFrame(train_triplets, columns=columns)\n",
    "# test_triplets = pd.DataFrame(test_triplets, columns=columns)\n",
    "# validate_triplets = pd.DataFrame(validate_triplets, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_triplets_embeddings = pd.DataFrame()\n",
    "\n",
    "# test_triplets_embeddings['query_embeddings'] = test_triplets['query'].apply(lambda x: to_w2v_embedding(sp, x))\n",
    "# test_triplets_embeddings['relevant_embeddings'] = test_triplets['relevant'].apply(lambda x: to_w2v_embedding(sp, x))\n",
    "# test_triplets_embeddings['irrelevant_embeddings'] = test_triplets['irrelevant'].apply(lambda x: to_w2v_embedding(sp, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DataFrame size: 134.55 MB\n"
     ]
    }
   ],
   "source": [
    "# Calculate the memory usage of each column in bytes, then sum them up, and convert to megabytes\n",
    "# total_memory_mb = test_triplets_embeddings.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "# print(f'Total DataFrame size: {total_memory_mb:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_triplets_embeddings = pd.DataFrame()\n",
    "# train_triplets_embeddings['query_embeddings'] = train_triplets['query'].apply(lambda x: to_w2v_embedding(sp, x))\n",
    "# train_triplets_embeddings['relevant_embeddings'] = train_triplets['relevant'].apply(lambda x: to_w2v_embedding(sp, x))\n",
    "# train_triplets_embeddings['irrelevant_embeddings'] = train_triplets['irrelevant'].apply(lambda x: to_w2v_embedding(sp, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DataFrame size: 1150.24 MB\n"
     ]
    }
   ],
   "source": [
    "# Calculate the memory usage of each column in bytes, then sum them up, and convert to megabytes\n",
    "# total_memory_mb = train_triplets_embeddings.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "# print(f'Total DataFrame size: {total_memory_mb:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [[-0.38117662, -1.751613, 0.118526, -4.4650145...\n",
      "Name: query_embeddings, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print(test_triplets_embeddings['query_embeddings'].head(1))\n",
    "\n",
    "# train_triplets_embeddings.to_parquet('train_triplets_with_embedings.parquet', engine='pyarrow') \n",
    "# test_triplets_embeddings.to_parquet('test_triplets_with_embedings.parquet', engine='pyarrow') \n",
    "# validate_triplets.to_parquet('validate_triplets_with_embedings.parquet', engine='pyarrow') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryDocsDataset(Dataset):\n",
    "    def __init__(self, sp, queries, relevant_docs, irrelevant_docs, device):\n",
    "        self.queries = queries\n",
    "        self.relevant_docs = relevant_docs\n",
    "        self.irrelevant_docs = irrelevant_docs\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def to_w2v_embedding(self, sp, text):\n",
    "        tokens = sp.encode_as_pieces(text.lower())\n",
    "\n",
    "        embeddings = []\n",
    "        for token in tokens:\n",
    "            if (token in w2v_model.wv): \n",
    "                embeddings.append(w2v_model.wv[token])\n",
    "\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'query': torch.tensor(self.to_w2v_embedding(sp, self.queries[idx]), dtype=torch.float, device=self.device),\n",
    "            'relevant': torch.tensor(self.to_w2v_embedding(sp, self.relevant_docs[idx]), dtype=torch.float, device=self.device),\n",
    "            'irrelevant': torch.tensor(self.to_w2v_embedding(sp, self.irrelevant_docs[idx]), dtype=torch.float, device=self.device),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingDataset = QueryDocsDataset(sp, train_triplets['query'], train_triplets['relevant'], train_triplets['irrelevant'], device)\n",
    "TestingDataset = QueryDocsDataset(sp, test_triplets['query'], test_triplets['relevant'], test_triplets['irrelevant'], device)\n",
    "ValidationDataset = QueryDocsDataset(sp, validate_triplets['query'], validate_triplets['relevant'], validate_triplets['irrelevant'], device)\n",
    "\n",
    "# TrainingDataset = QueryDocsDataset(sp, train_triplets_embeddings['query_embeddings'], train_triplets_embeddings['relevant_embeddings'], train_triplets_embeddings['irrelevant_embeddings'])\n",
    "# TestingDataset = QueryDocsDataset(sp, test_triplets_embeddings['query_embeddings'], test_triplets_embeddings['relevant_embeddings'], test_triplets_embeddings['irrelevant_embeddings'])\n",
    "# ValidationDataset = QueryDocsDataset(sp, validate_triplets_embeddings['query'], validate_triplets_embeddings['relevant'], validate_triplets_embeddings['irrelevant'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(QueryRNNCell, self).__init__()\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.weight_ih = nn.Parameter(torch.randn(input_size, hidden_size, device=self.device))  # Input to hidden weights\n",
    "        self.weight_hh = nn.Parameter(torch.randn(hidden_size, hidden_size, device=self.device))  # Hidden to hidden weights\n",
    "        \n",
    "        self.bias_hh = nn.Parameter(torch.randn(hidden_size, device=self.device))  # Bias\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        return torch.tanh(\n",
    "            torch.mm(input, self.weight_ih) + torch.mm(hidden, self.weight_hh) + self.bias_hh\n",
    "        )\n",
    "    \n",
    "class QueryRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(QueryRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_cell = QueryRNNCell(input_size, hidden_size, device)\n",
    "        self.rnn_cell.to(device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Assuming input is of shape (batch, seq_len, input_size)\n",
    "        batch_size, seq_len, _ = input.shape\n",
    "        hidden = torch.zeros(batch_size, self.hidden_size, device=self.device)  # Initial hidden state\n",
    "        for i in range(seq_len):\n",
    "            \n",
    "            mask = torch.any(input[:, i, :] != 0, dim=1).float().unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "            current_input = input[:, i, :]  \n",
    "            \n",
    "            current_hidden = self.rnn_cell(current_input, hidden)\n",
    "            \n",
    "            # Apply mask: Only update hidden state for non-padded inputs\n",
    "            hidden = mask * current_hidden + (1 - mask) * hidden\n",
    "            \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, device):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.queryEncoder = QueryRNN(embedding_size, hidden_size, device)\n",
    "        self.queryEncoder.to(device)\n",
    "        self.docEncoder = QueryRNN(embedding_size, hidden_size, device)\n",
    "        self.docEncoder.to(device)\n",
    "\n",
    "    def forward(self, query, relevant, irrelevant):\n",
    "        query_embedding = self.queryEncoder(query)\n",
    "        relevant_embedding = self.docEncoder(relevant)\n",
    "        irrelevant_embedding = self.docEncoder(irrelevant)\n",
    "        return query_embedding, relevant_embedding, irrelevant_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lose Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def triplet_loss_function_cosine(query, relevant_doc, irrelevant_doc, margin):\n",
    "    # Compute cosine similarity (the output ranges from -1 to 1)\n",
    "    relevant_similarity = F.cosine_similarity(query, relevant_doc)\n",
    "    irrelevant_similarity = F.cosine_similarity(query, irrelevant_doc)\n",
    "    \n",
    "    # Convert similarities to distances (ranges from 0 to 2)\n",
    "    relevant_distance = 1 - relevant_similarity\n",
    "    irrelevant_distance = 1 - irrelevant_similarity\n",
    "    \n",
    "    # Compute the triplet loss\n",
    "    triplet_loss = torch.clamp(margin + relevant_distance - irrelevant_distance, min=0)\n",
    "    return triplet_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Extract lists of tensors for 'query', 'relevant', and 'irrelevant' from the batch\n",
    "    query_tensors = [item['query'] for item in batch]\n",
    "    relevant_tensors = [item['relevant'] for item in batch]\n",
    "    irrelevant_tensors = [item['irrelevant'] for item in batch]\n",
    "    \n",
    "    # Pad sequences within each list to the same length\n",
    "    query_padded = pad_sequence(query_tensors, batch_first=True, padding_value=0)\n",
    "    relevant_padded = pad_sequence(relevant_tensors, batch_first=True, padding_value=0)\n",
    "    irrelevant_padded = pad_sequence(irrelevant_tensors, batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Return a dictionary with padded sequences\n",
    "    return {\n",
    "        'query': query_padded,\n",
    "        'relevant': relevant_padded,\n",
    "        'irrelevant': irrelevant_padded\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[51, 92, 14, 71],\n",
      "         [60, 20, 82, 86],\n",
      "         [74, 74, 87, 99],\n",
      "         [23,  2, 21, 52],\n",
      "         [ 1, 87, 29, 37],\n",
      "         [ 0,  0,  0,  0]],\n",
      "\n",
      "        [[51, 92, 14, 71],\n",
      "         [60, 20, 82, 86],\n",
      "         [74, 74, 87, 99],\n",
      "         [23,  2, 21, 52],\n",
      "         [ 1, 87, 29, 37],\n",
      "         [60, 20, 82, 86]]])\n"
     ]
    }
   ],
   "source": [
    "# Convert the numpy array to a PyTorch tensor\n",
    "tensors =[ \n",
    "    torch.tensor([\n",
    "        [51, 92, 14, 71],\n",
    "        [60, 20, 82, 86],\n",
    "        [74, 74, 87, 99],\n",
    "        [23,  2, 21, 52],\n",
    "        [ 1, 87, 29, 37],\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        [51, 92, 14, 71],\n",
    "        [60, 20, 82, 86],\n",
    "        [74, 74, 87, 99],\n",
    "        [23,  2, 21, 52],\n",
    "        [ 1, 87, 29, 37],\n",
    "        [60, 20, 82, 86],\n",
    "    ]),\n",
    "]\n",
    "dump = pad_sequence(tensors, batch_first=True)\n",
    "\n",
    "print(dump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "hidden_size = 16\n",
    "margin = 1.0\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "\n",
    "# TrainingDataloader = DataLoader(TrainingDataset, batch_size, shuffle=False)\n",
    "# TestingDataloader = DataLoader(TestingDataset, batch_size, shuffle=False)\n",
    "\n",
    "TrainingDataloader = DataLoader(TrainingDataset, batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "TestingDataloader = DataLoader(TestingDataset, batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "ValidatingDataloader = DataLoader(ValidationDataset, batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Instantiate the model\n",
    "Towers = TwoTowerModel(embedding_size, hidden_size, device)\n",
    "Towers.to(device)\n",
    "optimizer = torch.optim.Adam(Towers.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recheck the padding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10, 128])\n",
      "torch.Size([100, 137, 128])\n",
      "torch.Size([100, 183, 128])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mirrelevant\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape) \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, last row of 7:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "for batch in TestingDataloader:\n",
    "    print(batch['query'].shape)        # Shape: (batch_size, max_seq_length_query, feature_dim)\n",
    "    print(batch['relevant'].shape)     # Shape: (batch_size, max_seq_length_relevant, feature_dim)\n",
    "    print(batch['irrelevant'].shape) \n",
    "\n",
    "    for i in range(batch['query'].size(0)):\n",
    "        print(f\"Element {i+1}, last row of 7:\\n{batch['query'][i, -1, :].numpy()}\\n\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch: 10, Train Loss: 0.9766\n",
      "Epoch [1/10], Batch: 20, Train Loss: 1.0061\n",
      "Epoch [1/10], Batch: 30, Train Loss: 0.9594\n",
      "Epoch [1/10], Batch: 40, Train Loss: 1.0156\n",
      "Epoch [1/10], Batch: 50, Train Loss: 1.0344\n",
      "Epoch [1/10], Batch: 60, Train Loss: 0.9772\n",
      "Epoch [1/10], Batch: 70, Train Loss: 1.0357\n",
      "Epoch [1/10], Batch: 80, Train Loss: 1.0218\n",
      "Epoch [1/10], Batch: 90, Train Loss: 0.9434\n",
      "Epoch [1/10], Batch: 100, Train Loss: 1.0047\n",
      "Epoch [1/10], Batch: 110, Train Loss: 1.0164\n",
      "Epoch [1/10], Batch: 120, Train Loss: 0.9788\n",
      "Epoch [1/10], Batch: 130, Train Loss: 0.9703\n",
      "Epoch [1/10], Batch: 140, Train Loss: 0.9520\n",
      "Epoch [1/10], Batch: 150, Train Loss: 0.9897\n",
      "Epoch [1/10], Batch: 160, Train Loss: 1.0113\n",
      "Epoch [1/10], Batch: 170, Train Loss: 0.9122\n",
      "Epoch [1/10], Batch: 180, Train Loss: 1.0138\n",
      "Epoch [1/10], Batch: 190, Train Loss: 1.0163\n",
      "Epoch [1/10], Batch: 200, Train Loss: 0.9997\n",
      "Epoch [1/10], Batch: 210, Train Loss: 0.9810\n",
      "Epoch [1/10], Batch: 220, Train Loss: 1.0054\n",
      "Epoch [1/10], Batch: 230, Train Loss: 0.9946\n",
      "Epoch [1/10], Batch: 240, Train Loss: 1.0190\n",
      "Epoch [1/10], Batch: 250, Train Loss: 1.0295\n",
      "Epoch [1/10], Batch: 260, Train Loss: 0.9726\n",
      "Epoch [1/10], Batch: 270, Train Loss: 1.0111\n",
      "Epoch [1/10], Batch: 280, Train Loss: 0.9900\n",
      "Epoch [1/10], Batch: 290, Train Loss: 1.0378\n",
      "Epoch [1/10], Batch: 300, Train Loss: 1.0302\n",
      "Epoch [1/10], Batch: 310, Train Loss: 0.9371\n",
      "Epoch [1/10], Batch: 320, Train Loss: 0.9110\n",
      "Epoch [1/10], Batch: 330, Train Loss: 0.9936\n",
      "Epoch [1/10], Batch: 340, Train Loss: 0.9961\n",
      "Epoch [1/10], Batch: 350, Train Loss: 1.0144\n",
      "Epoch [1/10], Batch: 360, Train Loss: 0.9755\n",
      "Epoch [1/10], Batch: 370, Train Loss: 0.9801\n",
      "Epoch [1/10], Batch: 380, Train Loss: 0.8994\n",
      "Epoch [1/10], Batch: 390, Train Loss: 1.0402\n",
      "Epoch [1/10], Batch: 400, Train Loss: 0.9829\n",
      "Epoch [1/10], Batch: 410, Train Loss: 1.0124\n",
      "Epoch [1/10], Batch: 420, Train Loss: 0.9239\n",
      "Epoch [1/10], Batch: 430, Train Loss: 0.9731\n",
      "Epoch [1/10], Batch: 440, Train Loss: 1.0118\n",
      "Epoch [1/10], Batch: 450, Train Loss: 1.0137\n",
      "Epoch [1/10], Batch: 460, Train Loss: 0.9782\n",
      "Epoch [1/10], Batch: 470, Train Loss: 0.9847\n",
      "Epoch [1/10], Batch: 480, Train Loss: 1.0167\n",
      "Epoch [1/10], Batch: 490, Train Loss: 0.9589\n",
      "Epoch [1/10], Batch: 500, Train Loss: 0.9949\n",
      "Epoch [1/10], Batch: 510, Train Loss: 1.0028\n",
      "Epoch [1/10], Batch: 520, Train Loss: 1.0443\n",
      "Epoch [1/10], Batch: 530, Train Loss: 1.0575\n",
      "Epoch [1/10], Batch: 540, Train Loss: 0.9873\n",
      "Epoch [1/10], Batch: 550, Train Loss: 0.9794\n",
      "Epoch [1/10], Batch: 560, Train Loss: 0.9755\n",
      "Epoch [1/10], Batch: 570, Train Loss: 0.9860\n",
      "Epoch [1/10], Batch: 580, Train Loss: 1.0178\n",
      "Epoch [1/10], Batch: 590, Train Loss: 0.9813\n",
      "Epoch [1/10], Batch: 600, Train Loss: 1.0253\n",
      "Epoch [1/10], Batch: 610, Train Loss: 1.0023\n",
      "Epoch [1/10], Batch: 620, Train Loss: 0.9451\n",
      "Epoch [1/10], Batch: 630, Train Loss: 0.9955\n",
      "Epoch [1/10], Batch: 640, Train Loss: 1.0201\n",
      "Epoch [1/10], Batch: 650, Train Loss: 0.9887\n",
      "Epoch [1/10], Batch: 660, Train Loss: 1.0256\n",
      "Epoch [1/10], Batch: 670, Train Loss: 0.9703\n",
      "Epoch [1/10], Batch: 680, Train Loss: 1.0269\n",
      "Epoch [1/10], Batch: 690, Train Loss: 1.0230\n",
      "Epoch [1/10], Batch: 700, Train Loss: 1.0415\n",
      "Epoch [1/10], Batch: 710, Train Loss: 0.9442\n",
      "Epoch [1/10], Batch: 720, Train Loss: 0.9724\n",
      "Epoch [1/10], Batch: 730, Train Loss: 0.9793\n",
      "Epoch [1/10], Batch: 740, Train Loss: 1.0172\n",
      "Epoch [1/10], Batch: 750, Train Loss: 0.9920\n",
      "Epoch [1/10], Batch: 760, Train Loss: 1.0307\n",
      "Epoch [1/10], Batch: 770, Train Loss: 1.0524\n",
      "Epoch [1/10], Batch: 780, Train Loss: 0.9605\n",
      "Epoch [1/10], Batch: 790, Train Loss: 1.0238\n",
      "Epoch [1/10], Batch: 800, Train Loss: 0.9870\n",
      "Epoch [1/10], Batch: 810, Train Loss: 0.9661\n",
      "Epoch [1/10], Batch: 820, Train Loss: 0.9627\n",
      "Epoch [1/10], Batch: 830, Train Loss: 0.9971\n",
      "Epoch [1/10], Batch: 840, Train Loss: 1.0303\n",
      "Epoch [1/10], Batch: 850, Train Loss: 0.9564\n",
      "Epoch [1/10], Batch: 860, Train Loss: 0.9368\n",
      "Epoch [1/10], Batch: 870, Train Loss: 0.9798\n",
      "Epoch [1/10], Batch: 880, Train Loss: 0.9984\n",
      "Epoch [1/10], Batch: 890, Train Loss: 0.9654\n",
      "Epoch [1/10], Batch: 900, Train Loss: 0.9795\n",
      "Epoch [1/10], Batch: 910, Train Loss: 1.0041\n",
      "Epoch [1/10], Batch: 920, Train Loss: 1.0278\n",
      "Epoch [1/10], Batch: 930, Train Loss: 1.0071\n",
      "Epoch [1/10], Batch: 940, Train Loss: 0.9317\n",
      "Epoch [1/10], Batch: 950, Train Loss: 0.9532\n",
      "Epoch [1/10], Batch: 960, Train Loss: 0.9583\n",
      "Epoch [1/10], Batch: 970, Train Loss: 1.0329\n",
      "Epoch [1/10], Batch: 980, Train Loss: 1.0131\n",
      "Epoch [1/10], Batch: 990, Train Loss: 0.9750\n",
      "Epoch [1/10], Batch: 1000, Train Loss: 1.0109\n",
      "Epoch [1/10], Batch: 1010, Train Loss: 0.9526\n",
      "Epoch [1/10], Batch: 1020, Train Loss: 1.0567\n",
      "Epoch [1/10], Batch: 1030, Train Loss: 1.0036\n",
      "Epoch [1/10], Batch: 1040, Train Loss: 0.9609\n",
      "Epoch [1/10], Batch: 1050, Train Loss: 0.9742\n",
      "Epoch [1/10], Batch: 1060, Train Loss: 0.9821\n",
      "Epoch [1/10], Batch: 1070, Train Loss: 1.0387\n",
      "Epoch [1/10], Batch: 1080, Train Loss: 0.9603\n",
      "Epoch [1/10], Batch: 1090, Train Loss: 0.9927\n",
      "Epoch [1/10], Batch: 1100, Train Loss: 0.9836\n",
      "Epoch [1/10], Batch: 1110, Train Loss: 1.0227\n",
      "Epoch [1/10], Batch: 1120, Train Loss: 0.9601\n",
      "Epoch [1/10], Batch: 1130, Train Loss: 0.9780\n",
      "Epoch [1/10], Batch: 1140, Train Loss: 0.9788\n",
      "Epoch [1/10], Batch: 1150, Train Loss: 0.9366\n",
      "Epoch [1/10], Batch: 1160, Train Loss: 0.9160\n",
      "Epoch [1/10], Batch: 1170, Train Loss: 0.9561\n",
      "Epoch [1/10], Batch: 1180, Train Loss: 0.9640\n",
      "Epoch [1/10], Batch: 1190, Train Loss: 0.9989\n",
      "Epoch [1/10], Batch: 1200, Train Loss: 1.0401\n",
      "Epoch [1/10], Batch: 1210, Train Loss: 0.9294\n",
      "Epoch [1/10], Batch: 1220, Train Loss: 0.9867\n",
      "Epoch [1/10], Batch: 1230, Train Loss: 0.9920\n",
      "Epoch [1/10], Batch: 1240, Train Loss: 0.9948\n",
      "Epoch [1/10], Batch: 1250, Train Loss: 1.0023\n",
      "Epoch [1/10], Batch: 1260, Train Loss: 1.0315\n",
      "Epoch [1/10], Batch: 1270, Train Loss: 0.9987\n",
      "Epoch [1/10], Batch: 1280, Train Loss: 0.9820\n",
      "Epoch [1/10], Batch: 1290, Train Loss: 0.9780\n",
      "Epoch [1/10], Batch: 1300, Train Loss: 0.9900\n",
      "Epoch [1/10], Batch: 1310, Train Loss: 0.9723\n",
      "Epoch [1/10], Batch: 1320, Train Loss: 1.0297\n",
      "Epoch [1/10], Batch: 1330, Train Loss: 1.0128\n",
      "Epoch [1/10], Batch: 1340, Train Loss: 1.0132\n",
      "Epoch [1/10], Batch: 1350, Train Loss: 0.9789\n",
      "Epoch [1/10], Batch: 1360, Train Loss: 1.0243\n",
      "Epoch [1/10], Batch: 1370, Train Loss: 0.9837\n",
      "Epoch [1/10], Batch: 1380, Train Loss: 0.9269\n",
      "Epoch [1/10], Batch: 1390, Train Loss: 1.0365\n",
      "Epoch [1/10], Batch: 1400, Train Loss: 0.9688\n",
      "Epoch [1/10], Batch: 1410, Train Loss: 1.0208\n",
      "Epoch [1/10], Batch: 1420, Train Loss: 0.9994\n",
      "Epoch [1/10], Batch: 1430, Train Loss: 1.0061\n",
      "Epoch [1/10], Batch: 1440, Train Loss: 0.9460\n",
      "Epoch [1/10], Batch: 1450, Train Loss: 1.0055\n",
      "Epoch [1/10], Batch: 1460, Train Loss: 0.9741\n",
      "Epoch [1/10], Batch: 1470, Train Loss: 1.0339\n",
      "Epoch [1/10], Batch: 1480, Train Loss: 0.9335\n",
      "Epoch [1/10], Batch: 1490, Train Loss: 0.9362\n",
      "Epoch [1/10], Batch: 1500, Train Loss: 1.0311\n",
      "Epoch [1/10], Batch: 1510, Train Loss: 1.0099\n",
      "Epoch [1/10], Batch: 1520, Train Loss: 0.9998\n",
      "Epoch [1/10], Batch: 1530, Train Loss: 0.9194\n",
      "Epoch [1/10], Batch: 1540, Train Loss: 0.9932\n",
      "Epoch [1/10], Batch: 1550, Train Loss: 0.9874\n",
      "Epoch [1/10], Batch: 1560, Train Loss: 0.9711\n",
      "Epoch [1/10], Batch: 1570, Train Loss: 1.0053\n",
      "Epoch [1/10], Batch: 1580, Train Loss: 1.0340\n",
      "Epoch [1/10], Batch: 1590, Train Loss: 0.9393\n",
      "Epoch [1/10], Batch: 1600, Train Loss: 1.0116\n",
      "Epoch [1/10], Batch: 1610, Train Loss: 0.9790\n",
      "Epoch [1/10], Batch: 1620, Train Loss: 0.9735\n",
      "Epoch [1/10], Batch: 1630, Train Loss: 0.9954\n",
      "Epoch [1/10], Batch: 1640, Train Loss: 0.9741\n",
      "Epoch [1/10], Batch: 1650, Train Loss: 1.0214\n",
      "Epoch [1/10], Batch: 1660, Train Loss: 1.0368\n",
      "Epoch [1/10], Batch: 1670, Train Loss: 1.0503\n",
      "Epoch [1/10], Batch: 1680, Train Loss: 0.9826\n",
      "Epoch [1/10], Batch: 1690, Train Loss: 0.9922\n",
      "Epoch [1/10], Batch: 1700, Train Loss: 1.0087\n",
      "Epoch [1/10], Batch: 1710, Train Loss: 0.9601\n",
      "Epoch [1/10], Batch: 1720, Train Loss: 0.9948\n",
      "Epoch [1/10], Batch: 1730, Train Loss: 1.0108\n",
      "Epoch [1/10], Batch: 1740, Train Loss: 0.9567\n",
      "Epoch [1/10], Batch: 1750, Train Loss: 0.9750\n",
      "Epoch [1/10], Batch: 1760, Train Loss: 0.9811\n",
      "Epoch [1/10], Batch: 1770, Train Loss: 1.0102\n",
      "Epoch [1/10], Batch: 1780, Train Loss: 1.0115\n",
      "Epoch [1/10], Batch: 1790, Train Loss: 0.9240\n",
      "Epoch [1/10], Batch: 1800, Train Loss: 1.0243\n",
      "Epoch [1/10], Batch: 1810, Train Loss: 1.0368\n",
      "Epoch [1/10], Batch: 1820, Train Loss: 0.9487\n",
      "Epoch [1/10], Batch: 1830, Train Loss: 0.9724\n",
      "Epoch [1/10], Batch: 1840, Train Loss: 0.9950\n",
      "Epoch [1/10], Batch: 1850, Train Loss: 0.9509\n",
      "Epoch [1/10], Batch: 1860, Train Loss: 0.9487\n",
      "Epoch [1/10], Batch: 1870, Train Loss: 1.0616\n",
      "Epoch [1/10], Batch: 1880, Train Loss: 0.9571\n",
      "Epoch [1/10], Batch: 1890, Train Loss: 1.0147\n",
      "Epoch [1/10], Batch: 1900, Train Loss: 0.9445\n",
      "Epoch [1/10], Batch: 1910, Train Loss: 0.9416\n",
      "Epoch [1/10], Batch: 1920, Train Loss: 0.9766\n",
      "Epoch [1/10], Batch: 1930, Train Loss: 0.9660\n",
      "Epoch [1/10], Batch: 1940, Train Loss: 0.9751\n",
      "Epoch [1/10], Batch: 1950, Train Loss: 0.9389\n",
      "Epoch [1/10], Batch: 1960, Train Loss: 0.9307\n",
      "Epoch [1/10], Batch: 1970, Train Loss: 1.0251\n",
      "Epoch [1/10], Batch: 1980, Train Loss: 0.9429\n",
      "Epoch [1/10], Batch: 1990, Train Loss: 0.9961\n",
      "Epoch [1/10], Batch: 2000, Train Loss: 0.9724\n",
      "Epoch [1/10], Batch: 2010, Train Loss: 0.9252\n",
      "Epoch [1/10], Batch: 2020, Train Loss: 0.9761\n",
      "Epoch [1/10], Batch: 2030, Train Loss: 0.9369\n",
      "Epoch [1/10], Batch: 2040, Train Loss: 0.9591\n",
      "Epoch [1/10], Batch: 2050, Train Loss: 1.0083\n",
      "Epoch [1/10], Batch: 2060, Train Loss: 0.9607\n",
      "Epoch [1/10], Batch: 2070, Train Loss: 0.9781\n",
      "Epoch [1/10], Batch: 2080, Train Loss: 1.0152\n",
      "Epoch [1/10], Batch: 2090, Train Loss: 1.0052\n",
      "Epoch [1/10], Batch: 2100, Train Loss: 0.9557\n",
      "Epoch [1/10], Batch: 2110, Train Loss: 1.0226\n",
      "Epoch [1/10], Batch: 2120, Train Loss: 0.9898\n",
      "Epoch [1/10], Batch: 2130, Train Loss: 0.9922\n",
      "Epoch [1/10], Batch: 2140, Train Loss: 1.0434\n",
      "Epoch [1/10], Batch: 2150, Train Loss: 0.9951\n",
      "Epoch [1/10], Batch: 2160, Train Loss: 1.0019\n",
      "Epoch [1/10], Batch: 2170, Train Loss: 0.9816\n",
      "Epoch [1/10], Batch: 2180, Train Loss: 1.0619\n",
      "Epoch [1/10], Batch: 2190, Train Loss: 0.9648\n",
      "Epoch [1/10], Batch: 2200, Train Loss: 0.9663\n",
      "Epoch [1/10], Batch: 2210, Train Loss: 1.0191\n",
      "Epoch [1/10], Batch: 2220, Train Loss: 0.9902\n",
      "Epoch [1/10], Batch: 2230, Train Loss: 0.9694\n",
      "Epoch [1/10], Batch: 2240, Train Loss: 0.9561\n",
      "Epoch [1/10], Batch: 2250, Train Loss: 0.9794\n",
      "Epoch [1/10], Batch: 2260, Train Loss: 0.9846\n",
      "Epoch [1/10], Batch: 2270, Train Loss: 0.9680\n",
      "Epoch [1/10], Batch: 2280, Train Loss: 1.0133\n",
      "Epoch [1/10], Batch: 2290, Train Loss: 0.9931\n",
      "Epoch [1/10], Batch: 2300, Train Loss: 0.9705\n",
      "Epoch [1/10], Batch: 2310, Train Loss: 0.9769\n",
      "Epoch [1/10], Batch: 2320, Train Loss: 1.0289\n",
      "Epoch [1/10], Batch: 2330, Train Loss: 0.9701\n",
      "Epoch [1/10], Batch: 2340, Train Loss: 1.0019\n",
      "Epoch [1/10], Batch: 2350, Train Loss: 1.0217\n",
      "Epoch [1/10], Batch: 2360, Train Loss: 1.0167\n",
      "Epoch [1/10], Batch: 2370, Train Loss: 0.9638\n",
      "Epoch [1/10], Batch: 2380, Train Loss: 1.0023\n",
      "Epoch [1/10], Batch: 2390, Train Loss: 0.9318\n",
      "Epoch [1/10], Batch: 2400, Train Loss: 0.9927\n",
      "Epoch [1/10], Batch: 2410, Train Loss: 0.9260\n",
      "Epoch [1/10], Batch: 2420, Train Loss: 0.9823\n",
      "Epoch [1/10], Batch: 2430, Train Loss: 0.9877\n",
      "Epoch [1/10], Batch: 2440, Train Loss: 1.0139\n",
      "Epoch [1/10], Batch: 2450, Train Loss: 0.9662\n",
      "Epoch [1/10], Batch: 2460, Train Loss: 1.0042\n",
      "Epoch [1/10], Batch: 2470, Train Loss: 1.0644\n",
      "Epoch [1/10], Batch: 2480, Train Loss: 0.9199\n",
      "Epoch [1/10], Batch: 2490, Train Loss: 0.9725\n",
      "Epoch [1/10], Batch: 2500, Train Loss: 0.9719\n",
      "Epoch [1/10], Batch: 2510, Train Loss: 1.0529\n",
      "Epoch [1/10], Batch: 2520, Train Loss: 0.9389\n",
      "Epoch [1/10], Batch: 2530, Train Loss: 1.0480\n",
      "Epoch [1/10], Batch: 2540, Train Loss: 0.9795\n",
      "Epoch [1/10], Batch: 2550, Train Loss: 0.9906\n",
      "Epoch [1/10], Batch: 2560, Train Loss: 0.9594\n",
      "Epoch [1/10], Batch: 2570, Train Loss: 0.9686\n",
      "Epoch [1/10], Batch: 2580, Train Loss: 0.9645\n",
      "Epoch [1/10], Batch: 2590, Train Loss: 1.0597\n",
      "Epoch [1/10], Batch: 2600, Train Loss: 0.9777\n",
      "Epoch [1/10], Batch: 2610, Train Loss: 1.0166\n",
      "Epoch [1/10], Batch: 2620, Train Loss: 1.0337\n",
      "Epoch [1/10], Batch: 2630, Train Loss: 0.9732\n",
      "Epoch [1/10], Batch: 2640, Train Loss: 0.9484\n",
      "Epoch [1/10], Batch: 2650, Train Loss: 0.9571\n",
      "Epoch [1/10], Batch: 2660, Train Loss: 0.9550\n",
      "Epoch [1/10], Batch: 2670, Train Loss: 0.9490\n",
      "Epoch [1/10], Batch: 2680, Train Loss: 0.9683\n",
      "Epoch [1/10], Batch: 2690, Train Loss: 1.0229\n",
      "Epoch [1/10], Batch: 2700, Train Loss: 0.9813\n",
      "Epoch [1/10], Batch: 2710, Train Loss: 0.9543\n",
      "Epoch [1/10], Batch: 2720, Train Loss: 1.0466\n",
      "Epoch [1/10], Batch: 2730, Train Loss: 0.9664\n",
      "Epoch [1/10], Batch: 2740, Train Loss: 1.0293\n",
      "Epoch [1/10], Batch: 2750, Train Loss: 0.9788\n",
      "Epoch [1/10], Batch: 2760, Train Loss: 0.9278\n",
      "Epoch [1/10], Batch: 2770, Train Loss: 1.0110\n",
      "Epoch [1/10], Batch: 2780, Train Loss: 0.9394\n",
      "Epoch [1/10], Batch: 2790, Train Loss: 0.9919\n",
      "Epoch [1/10], Batch: 2800, Train Loss: 0.9627\n",
      "Epoch [1/10], Batch: 2810, Train Loss: 0.9982\n",
      "Epoch [1/10], Batch: 2820, Train Loss: 1.0188\n",
      "Epoch [1/10], Batch: 2830, Train Loss: 0.9818\n",
      "Epoch [1/10], Batch: 2840, Train Loss: 0.9218\n",
      "Epoch [1/10], Batch: 2850, Train Loss: 0.9925\n",
      "Epoch [1/10], Batch: 2860, Train Loss: 1.0182\n",
      "Epoch [1/10], Batch: 2870, Train Loss: 0.8984\n",
      "Epoch [1/10], Batch: 2880, Train Loss: 1.0508\n",
      "Epoch [1/10], Batch: 2890, Train Loss: 0.9796\n",
      "Epoch [1/10], Batch: 2900, Train Loss: 1.0200\n",
      "Epoch [1/10], Batch: 2910, Train Loss: 0.9704\n",
      "Epoch [1/10], Batch: 2920, Train Loss: 0.9488\n",
      "Epoch [1/10], Batch: 2930, Train Loss: 0.9562\n",
      "Epoch [1/10], Batch: 2940, Train Loss: 1.0227\n",
      "Epoch [1/10], Batch: 2950, Train Loss: 0.9888\n",
      "Epoch [1/10], Batch: 2960, Train Loss: 1.0133\n",
      "Epoch [1/10], Batch: 2970, Train Loss: 0.9691\n",
      "Epoch [1/10], Batch: 2980, Train Loss: 0.9177\n",
      "Epoch [1/10], Batch: 2990, Train Loss: 0.9948\n",
      "Epoch [1/10], Batch: 3000, Train Loss: 0.9973\n",
      "Epoch [1/10], Batch: 3010, Train Loss: 0.9601\n",
      "Epoch [1/10], Batch: 3020, Train Loss: 0.9818\n",
      "Epoch [1/10], Batch: 3030, Train Loss: 0.9480\n",
      "Epoch [1/10], Batch: 3040, Train Loss: 0.9395\n",
      "Epoch [1/10], Batch: 3050, Train Loss: 0.9978\n",
      "Epoch [1/10], Batch: 3060, Train Loss: 0.9250\n",
      "Epoch [1/10], Batch: 3070, Train Loss: 1.0610\n",
      "Epoch [1/10], Batch: 3080, Train Loss: 1.0108\n",
      "Epoch [1/10], Batch: 3090, Train Loss: 0.9839\n",
      "Epoch [1/10], Batch: 3100, Train Loss: 0.9383\n",
      "Epoch [1/10], Batch: 3110, Train Loss: 0.9007\n",
      "Epoch [1/10], Batch: 3120, Train Loss: 1.0029\n",
      "Epoch [1/10], Batch: 3130, Train Loss: 0.9703\n",
      "Epoch [1/10], Batch: 3140, Train Loss: 0.9321\n",
      "Epoch [1/10], Batch: 3150, Train Loss: 0.9785\n",
      "Epoch [1/10], Batch: 3160, Train Loss: 1.0681\n",
      "Epoch [1/10], Batch: 3170, Train Loss: 0.9864\n",
      "Epoch [1/10], Batch: 3180, Train Loss: 0.9228\n",
      "Epoch [1/10], Batch: 3190, Train Loss: 0.9875\n",
      "Epoch [1/10], Batch: 3200, Train Loss: 1.0018\n",
      "Epoch [1/10], Batch: 3210, Train Loss: 1.0714\n",
      "Epoch [1/10], Batch: 3220, Train Loss: 0.9629\n",
      "Epoch [1/10], Batch: 3230, Train Loss: 0.9076\n",
      "Epoch [1/10], Batch: 3240, Train Loss: 0.9388\n",
      "Epoch [1/10], Batch: 3250, Train Loss: 1.0031\n",
      "Epoch [1/10], Batch: 3260, Train Loss: 0.9370\n",
      "Epoch [1/10], Batch: 3270, Train Loss: 1.0032\n",
      "Epoch [1/10], Batch: 3280, Train Loss: 0.9783\n",
      "Epoch [1/10], Batch: 3290, Train Loss: 1.0257\n",
      "Epoch [1/10], Batch: 3300, Train Loss: 1.0167\n",
      "Epoch [1/10], Batch: 3310, Train Loss: 1.0192\n",
      "Epoch [1/10], Batch: 3320, Train Loss: 1.0350\n",
      "Epoch [1/10], Batch: 3330, Train Loss: 0.9005\n",
      "Epoch [1/10], Batch: 3340, Train Loss: 0.9317\n",
      "Epoch [1/10], Batch: 3350, Train Loss: 0.9830\n",
      "Epoch [1/10], Batch: 3360, Train Loss: 0.9118\n",
      "Epoch [1/10], Batch: 3370, Train Loss: 0.9880\n",
      "Epoch [1/10], Batch: 3380, Train Loss: 0.9961\n",
      "Epoch [1/10], Batch: 3390, Train Loss: 0.9454\n",
      "Epoch [1/10], Batch: 3400, Train Loss: 0.9542\n",
      "Epoch [1/10], Batch: 3410, Train Loss: 0.9942\n",
      "Epoch [1/10], Batch: 3420, Train Loss: 0.9194\n",
      "Epoch [1/10], Batch: 3430, Train Loss: 0.9715\n",
      "Epoch [1/10], Batch: 3440, Train Loss: 1.0602\n",
      "Epoch [1/10], Batch: 3450, Train Loss: 1.0106\n",
      "Epoch [1/10], Batch: 3460, Train Loss: 0.9912\n",
      "Epoch [1/10], Batch: 3470, Train Loss: 0.9825\n",
      "Epoch [1/10], Batch: 3480, Train Loss: 0.9737\n",
      "Epoch [1/10], Batch: 3490, Train Loss: 0.9975\n",
      "Epoch [1/10], Batch: 3500, Train Loss: 0.9828\n",
      "Epoch [1/10], Batch: 3510, Train Loss: 0.9834\n",
      "Epoch [1/10], Batch: 3520, Train Loss: 0.9912\n",
      "Epoch [1/10], Batch: 3530, Train Loss: 0.9402\n",
      "Epoch [1/10], Batch: 3540, Train Loss: 0.9552\n",
      "Epoch [1/10], Batch: 3550, Train Loss: 0.9514\n",
      "Epoch [1/10], Batch: 3560, Train Loss: 0.9856\n",
      "Epoch [1/10], Batch: 3570, Train Loss: 0.9777\n",
      "Epoch [1/10], Batch: 3580, Train Loss: 0.9680\n",
      "Epoch [1/10], Batch: 3590, Train Loss: 1.0496\n",
      "Epoch [1/10], Batch: 3600, Train Loss: 0.9376\n",
      "Epoch [1/10], Batch: 3610, Train Loss: 0.8784\n",
      "Epoch [1/10], Batch: 3620, Train Loss: 0.9983\n",
      "Epoch [1/10], Batch: 3630, Train Loss: 0.9604\n",
      "Epoch [1/10], Batch: 3640, Train Loss: 0.9760\n",
      "Epoch [1/10], Batch: 3650, Train Loss: 0.9450\n",
      "Epoch [1/10], Batch: 3660, Train Loss: 0.9609\n",
      "Epoch [1/10], Batch: 3670, Train Loss: 0.9960\n",
      "Epoch [1/10], Batch: 3680, Train Loss: 0.9296\n",
      "Epoch [1/10], Batch: 3690, Train Loss: 0.9772\n",
      "Epoch [1/10], Batch: 3700, Train Loss: 1.0307\n",
      "Epoch [1/10], Batch: 3710, Train Loss: 1.0517\n",
      "Epoch [1/10], Batch: 3720, Train Loss: 0.9716\n",
      "Epoch [1/10], Batch: 3730, Train Loss: 1.0220\n",
      "Epoch [1/10], Batch: 3740, Train Loss: 0.9669\n",
      "Epoch [1/10], Batch: 3750, Train Loss: 0.9514\n",
      "Epoch [1/10], Batch: 3760, Train Loss: 0.9227\n",
      "Epoch [1/10], Batch: 3770, Train Loss: 0.9979\n",
      "Epoch [1/10], Batch: 3780, Train Loss: 1.0327\n",
      "Epoch [1/10], Batch: 3790, Train Loss: 1.0327\n",
      "Epoch [1/10], Batch: 3800, Train Loss: 0.9621\n",
      "Epoch [1/10], Batch: 3810, Train Loss: 0.8938\n",
      "Epoch [1/10], Batch: 3820, Train Loss: 0.9167\n",
      "Epoch [1/10], Batch: 3830, Train Loss: 0.9092\n",
      "Epoch [1/10], Batch: 3840, Train Loss: 0.9911\n",
      "Epoch [1/10], Batch: 3850, Train Loss: 0.9758\n",
      "Epoch [1/10], Batch: 3860, Train Loss: 1.0160\n",
      "Epoch [1/10], Batch: 3870, Train Loss: 0.9941\n",
      "Epoch [1/10], Batch: 3880, Train Loss: 0.9416\n",
      "Epoch [1/10], Batch: 3890, Train Loss: 0.9705\n",
      "Epoch [1/10], Batch: 3900, Train Loss: 0.9676\n",
      "Epoch [1/10], Batch: 3910, Train Loss: 1.0301\n",
      "Epoch [1/10], Batch: 3920, Train Loss: 0.9607\n",
      "Epoch [1/10], Batch: 3930, Train Loss: 0.9528\n",
      "Epoch [1/10], Batch: 3940, Train Loss: 0.9434\n",
      "Epoch [1/10], Batch: 3950, Train Loss: 0.9650\n",
      "Epoch [1/10], Batch: 3960, Train Loss: 1.0251\n",
      "Epoch [1/10], Batch: 3970, Train Loss: 0.9935\n",
      "Epoch [1/10], Batch: 3980, Train Loss: 0.9877\n",
      "Epoch [1/10], Batch: 3990, Train Loss: 1.0243\n",
      "Epoch [1/10], Batch: 4000, Train Loss: 0.9180\n",
      "Epoch [1/10], Batch: 4010, Train Loss: 0.9457\n",
      "Epoch [1/10], Batch: 4020, Train Loss: 0.9315\n",
      "Epoch [1/10], Batch: 4030, Train Loss: 0.9794\n",
      "Epoch [1/10], Batch: 4040, Train Loss: 1.0050\n",
      "Epoch [1/10], Batch: 4050, Train Loss: 0.8658\n",
      "Epoch [1/10], Batch: 4060, Train Loss: 1.0257\n",
      "Epoch [1/10], Batch: 4070, Train Loss: 0.9699\n",
      "Epoch [1/10], Batch: 4080, Train Loss: 1.0064\n",
      "Epoch [1/10], Batch: 4090, Train Loss: 0.9769\n",
      "Epoch [1/10], Batch: 4100, Train Loss: 0.9649\n",
      "Epoch [1/10], Batch: 4110, Train Loss: 0.9905\n",
      "Epoch [1/10], Batch: 4120, Train Loss: 0.9692\n",
      "Epoch [1/10], Batch: 4130, Train Loss: 1.0135\n",
      "Epoch [1/10], Batch: 4140, Train Loss: 0.9451\n",
      "Epoch [1/10], Batch: 4150, Train Loss: 1.0027\n",
      "Epoch [1/10], Batch: 4160, Train Loss: 0.9552\n",
      "Epoch [1/10], Batch: 4170, Train Loss: 0.9532\n",
      "Epoch [1/10], Batch: 4180, Train Loss: 0.9774\n",
      "Epoch [1/10], Batch: 4190, Train Loss: 0.9723\n",
      "Epoch [1/10], Batch: 4200, Train Loss: 0.9246\n",
      "Epoch [1/10], Batch: 4210, Train Loss: 0.9955\n",
      "Epoch [1/10], Batch: 4220, Train Loss: 0.9875\n",
      "Epoch [1/10], Batch: 4230, Train Loss: 0.9844\n",
      "Epoch [1/10], Batch: 4240, Train Loss: 1.0520\n",
      "Epoch [1/10], Batch: 4250, Train Loss: 0.9757\n",
      "Epoch [1/10], Batch: 4260, Train Loss: 0.9753\n",
      "Epoch [1/10], Batch: 4270, Train Loss: 1.0304\n",
      "Epoch [1/10], Batch: 4280, Train Loss: 0.9469\n",
      "Epoch [1/10], Batch: 4290, Train Loss: 0.9436\n",
      "Epoch [1/10], Batch: 4300, Train Loss: 0.9704\n",
      "Epoch [1/10], Batch: 4310, Train Loss: 0.9426\n",
      "Epoch [1/10], Batch: 4320, Train Loss: 0.9751\n",
      "Epoch [1/10], Batch: 4330, Train Loss: 0.9941\n",
      "Epoch [1/10], Batch: 4340, Train Loss: 0.9465\n",
      "Epoch [1/10], Batch: 4350, Train Loss: 0.9361\n",
      "Epoch [1/10], Batch: 4360, Train Loss: 1.0051\n",
      "Epoch [1/10], Batch: 4370, Train Loss: 0.9367\n",
      "Epoch [1/10], Batch: 4380, Train Loss: 0.9498\n",
      "Epoch [1/10], Batch: 4390, Train Loss: 0.9796\n",
      "Epoch [1/10], Batch: 4400, Train Loss: 0.9790\n",
      "Epoch [1/10], Batch: 4410, Train Loss: 0.9310\n",
      "Epoch [1/10], Batch: 4420, Train Loss: 1.0311\n",
      "Epoch [1/10], Batch: 4430, Train Loss: 0.9746\n",
      "Epoch [1/10], Batch: 4440, Train Loss: 0.9890\n",
      "Epoch [1/10], Batch: 4450, Train Loss: 0.9601\n",
      "Epoch [1/10], Batch: 4460, Train Loss: 0.9390\n",
      "Epoch [1/10], Batch: 4470, Train Loss: 1.0069\n",
      "Epoch [1/10], Batch: 4480, Train Loss: 1.0012\n",
      "Epoch [1/10], Batch: 4490, Train Loss: 0.9679\n",
      "Epoch [1/10], Batch: 4500, Train Loss: 1.0518\n",
      "Epoch [1/10], Batch: 4510, Train Loss: 0.9889\n",
      "Epoch [1/10], Batch: 4520, Train Loss: 0.9194\n",
      "Epoch [1/10], Batch: 4530, Train Loss: 0.9680\n",
      "Epoch [1/10], Batch: 4540, Train Loss: 0.9231\n",
      "Epoch [1/10], Batch: 4550, Train Loss: 1.0171\n",
      "Epoch [1/10], Batch: 4560, Train Loss: 0.9908\n",
      "Epoch [1/10], Batch: 4570, Train Loss: 0.9460\n",
      "Epoch [1/10], Batch: 4580, Train Loss: 0.9224\n",
      "Epoch [1/10], Batch: 4590, Train Loss: 0.9097\n",
      "Epoch [1/10], Batch: 4600, Train Loss: 0.9492\n",
      "Epoch [1/10], Batch: 4610, Train Loss: 0.9010\n",
      "Epoch [1/10], Batch: 4620, Train Loss: 0.9724\n",
      "Epoch [1/10], Batch: 4630, Train Loss: 0.9282\n",
      "Epoch [1/10], Batch: 4640, Train Loss: 0.9780\n",
      "Epoch [1/10], Batch: 4650, Train Loss: 1.0313\n",
      "Epoch [1/10], Batch: 4660, Train Loss: 0.9657\n",
      "Epoch [1/10], Batch: 4670, Train Loss: 0.9787\n",
      "Epoch [1/10], Batch: 4680, Train Loss: 0.9777\n",
      "Epoch [1/10], Batch: 4690, Train Loss: 1.0296\n",
      "Epoch [1/10], Batch: 4700, Train Loss: 1.0155\n",
      "Epoch [1/10], Batch: 4710, Train Loss: 0.9137\n",
      "Epoch [1/10], Batch: 4720, Train Loss: 1.0628\n",
      "Epoch [1/10], Batch: 4730, Train Loss: 0.9798\n",
      "Epoch [1/10], Batch: 4740, Train Loss: 0.9442\n",
      "Epoch [1/10], Batch: 4750, Train Loss: 0.9825\n",
      "Epoch [1/10], Batch: 4760, Train Loss: 0.9782\n",
      "Epoch [1/10], Batch: 4770, Train Loss: 0.9131\n",
      "Epoch [1/10], Batch: 4780, Train Loss: 0.8872\n",
      "Epoch [1/10], Batch: 4790, Train Loss: 0.9779\n",
      "Epoch [1/10], Batch: 4800, Train Loss: 0.9207\n",
      "Epoch [1/10], Batch: 4810, Train Loss: 0.9400\n",
      "Epoch [1/10], Batch: 4820, Train Loss: 0.9678\n",
      "Epoch [1/10], Batch: 4830, Train Loss: 0.9992\n",
      "Epoch [1/10], Batch: 4840, Train Loss: 0.9791\n",
      "Epoch [1/10], Batch: 4850, Train Loss: 0.9213\n",
      "Epoch [1/10], Batch: 4860, Train Loss: 0.9719\n",
      "Epoch [1/10], Batch: 4870, Train Loss: 0.9221\n",
      "Epoch [1/10], Batch: 4880, Train Loss: 0.9811\n",
      "Epoch [1/10], Batch: 4890, Train Loss: 1.0181\n",
      "Epoch [1/10], Batch: 4900, Train Loss: 0.9867\n",
      "Epoch [1/10], Batch: 4910, Train Loss: 0.9344\n",
      "Epoch [1/10], Batch: 4920, Train Loss: 0.9338\n",
      "Epoch [1/10], Batch: 4930, Train Loss: 0.8904\n",
      "Epoch [1/10], Batch: 4940, Train Loss: 0.9042\n",
      "Epoch [1/10], Batch: 4950, Train Loss: 0.9388\n",
      "Epoch [1/10], Batch: 4960, Train Loss: 1.0117\n",
      "Epoch [1/10], Batch: 4970, Train Loss: 1.0120\n",
      "Epoch [1/10], Batch: 4980, Train Loss: 0.9805\n",
      "Epoch [1/10], Batch: 4990, Train Loss: 0.9450\n",
      "Epoch [1/10], Batch: 5000, Train Loss: 0.8916\n",
      "Epoch [1/10], Batch: 5010, Train Loss: 0.9842\n",
      "Epoch [1/10], Batch: 5020, Train Loss: 0.9974\n",
      "Epoch [1/10], Batch: 5030, Train Loss: 0.9250\n",
      "Epoch [1/10], Batch: 5040, Train Loss: 1.0176\n",
      "Epoch [1/10], Batch: 5050, Train Loss: 1.0527\n",
      "Epoch [1/10], Batch: 5060, Train Loss: 0.9295\n",
      "Epoch [1/10], Batch: 5070, Train Loss: 0.9585\n",
      "Epoch [1/10], Batch: 5080, Train Loss: 0.9970\n",
      "Epoch [1/10], Batch: 5090, Train Loss: 0.9984\n",
      "Epoch [1/10], Batch: 5100, Train Loss: 1.0033\n",
      "Epoch [1/10], Batch: 5110, Train Loss: 0.9098\n",
      "Epoch [1/10], Batch: 5120, Train Loss: 0.9060\n",
      "Epoch [1/10], Batch: 5130, Train Loss: 0.9423\n",
      "Epoch [1/10], Batch: 5140, Train Loss: 0.9108\n",
      "Epoch [1/10], Batch: 5150, Train Loss: 0.9198\n",
      "Epoch [1/10], Batch: 5160, Train Loss: 1.0648\n",
      "Epoch [1/10], Batch: 5170, Train Loss: 0.9196\n",
      "Epoch [1/10], Batch: 5180, Train Loss: 1.0024\n",
      "Epoch [1/10], Batch: 5190, Train Loss: 0.9442\n",
      "Epoch [1/10], Batch: 5200, Train Loss: 0.9879\n",
      "Epoch [1/10], Batch: 5210, Train Loss: 0.9898\n",
      "Epoch [1/10], Batch: 5220, Train Loss: 0.9558\n",
      "Epoch [1/10], Batch: 5230, Train Loss: 0.9327\n",
      "Epoch [1/10], Batch: 5240, Train Loss: 0.9926\n",
      "Epoch [1/10], Batch: 5250, Train Loss: 0.9762\n",
      "Epoch [1/10], Batch: 5260, Train Loss: 0.9045\n",
      "Epoch [1/10], Batch: 5270, Train Loss: 0.9930\n",
      "Epoch [1/10], Batch: 5280, Train Loss: 1.0295\n",
      "Epoch [1/10], Batch: 5290, Train Loss: 0.9778\n",
      "Epoch [1/10], Batch: 5300, Train Loss: 0.9053\n",
      "Epoch [1/10], Batch: 5310, Train Loss: 1.0235\n",
      "Epoch [1/10], Batch: 5320, Train Loss: 0.9073\n",
      "Epoch [1/10], Batch: 5330, Train Loss: 0.9089\n",
      "Epoch [1/10], Batch: 5340, Train Loss: 0.9875\n",
      "Epoch [1/10], Batch: 5350, Train Loss: 0.9164\n",
      "Epoch [1/10], Batch: 5360, Train Loss: 0.9801\n",
      "Epoch [1/10], Batch: 5370, Train Loss: 0.9626\n",
      "Epoch [1/10], Batch: 5380, Train Loss: 0.8860\n",
      "Epoch [1/10], Batch: 5390, Train Loss: 0.9913\n",
      "Epoch [1/10], Batch: 5400, Train Loss: 1.0573\n",
      "Epoch [1/10], Batch: 5410, Train Loss: 0.9569\n",
      "Epoch [1/10], Batch: 5420, Train Loss: 0.8905\n",
      "Epoch [1/10], Batch: 5430, Train Loss: 0.9383\n",
      "Epoch [1/10], Batch: 5440, Train Loss: 0.9417\n",
      "Epoch [1/10], Batch: 5450, Train Loss: 0.9085\n",
      "Epoch [1/10], Batch: 5460, Train Loss: 0.8758\n",
      "Epoch [1/10], Batch: 5470, Train Loss: 1.0005\n",
      "Epoch [1/10], Batch: 5480, Train Loss: 0.9543\n",
      "Epoch [1/10], Batch: 5490, Train Loss: 0.9257\n",
      "Epoch [1/10], Batch: 5500, Train Loss: 1.0224\n",
      "Epoch [1/10], Batch: 5510, Train Loss: 1.0314\n",
      "Epoch [1/10], Batch: 5520, Train Loss: 0.9734\n",
      "Epoch [1/10], Batch: 5530, Train Loss: 1.0567\n",
      "Epoch [1/10], Batch: 5540, Train Loss: 0.9714\n",
      "Epoch [1/10], Batch: 5550, Train Loss: 0.9672\n",
      "Epoch [1/10], Batch: 5560, Train Loss: 0.9906\n",
      "Epoch [1/10], Batch: 5570, Train Loss: 0.9608\n",
      "Epoch [1/10], Batch: 5580, Train Loss: 0.8814\n",
      "Epoch [1/10], Batch: 5590, Train Loss: 0.9655\n",
      "Epoch [1/10], Batch: 5600, Train Loss: 0.9047\n",
      "Epoch [1/10], Batch: 5610, Train Loss: 0.8982\n",
      "Epoch [1/10], Batch: 5620, Train Loss: 1.0276\n",
      "Epoch [1/10], Batch: 5630, Train Loss: 0.9075\n",
      "Epoch [1/10], Batch: 5640, Train Loss: 0.9283\n",
      "Epoch [1/10], Batch: 5650, Train Loss: 0.9454\n",
      "Epoch [1/10], Batch: 5660, Train Loss: 1.0086\n",
      "Epoch [1/10], Batch: 5670, Train Loss: 0.9674\n",
      "Epoch [1/10], Batch: 5680, Train Loss: 0.9641\n",
      "Epoch [1/10], Batch: 5690, Train Loss: 0.9498\n",
      "Epoch [1/10], Batch: 5700, Train Loss: 0.9339\n",
      "Epoch [1/10], Batch: 5710, Train Loss: 1.0094\n",
      "Epoch [1/10], Batch: 5720, Train Loss: 1.0128\n",
      "Epoch [1/10], Batch: 5730, Train Loss: 1.0018\n",
      "Epoch [1/10], Batch: 5740, Train Loss: 0.9815\n",
      "Epoch [1/10], Batch: 5750, Train Loss: 0.9629\n",
      "Epoch [1/10], Batch: 5760, Train Loss: 0.9920\n",
      "Epoch [1/10], Batch: 5770, Train Loss: 1.0489\n",
      "Epoch [1/10], Batch: 5780, Train Loss: 0.9646\n",
      "Epoch [1/10], Batch: 5790, Train Loss: 0.8925\n",
      "Epoch [1/10], Batch: 5800, Train Loss: 0.9981\n",
      "Epoch [1/10], Batch: 5810, Train Loss: 1.0079\n",
      "Epoch [1/10], Batch: 5820, Train Loss: 1.0363\n",
      "Epoch [1/10], Batch: 5830, Train Loss: 0.9872\n",
      "Epoch [1/10], Batch: 5840, Train Loss: 0.9891\n",
      "Epoch [1/10], Batch: 5850, Train Loss: 0.9943\n",
      "Epoch [1/10], Batch: 5860, Train Loss: 0.9234\n",
      "Epoch [1/10], Batch: 5870, Train Loss: 0.9409\n",
      "Epoch [1/10], Batch: 5880, Train Loss: 1.0075\n",
      "Epoch [1/10], Batch: 5890, Train Loss: 0.9958\n",
      "Epoch [1/10], Batch: 5900, Train Loss: 0.9647\n",
      "Epoch [1/10], Batch: 5910, Train Loss: 0.9482\n",
      "Epoch [1/10], Batch: 5920, Train Loss: 0.9374\n",
      "Epoch [1/10], Batch: 5930, Train Loss: 1.0167\n",
      "Epoch [1/10], Batch: 5940, Train Loss: 0.8964\n",
      "Epoch [1/10], Batch: 5950, Train Loss: 0.8823\n",
      "Epoch [1/10], Batch: 5960, Train Loss: 0.9445\n",
      "Epoch [1/10], Batch: 5970, Train Loss: 0.9782\n",
      "Epoch [1/10], Batch: 5980, Train Loss: 0.9400\n",
      "Epoch [1/10], Batch: 5990, Train Loss: 0.9757\n",
      "Epoch [1/10], Batch: 6000, Train Loss: 0.8177\n",
      "Epoch [1/10], Batch: 6010, Train Loss: 0.9853\n",
      "Epoch [1/10], Batch: 6020, Train Loss: 0.9578\n",
      "Epoch [1/10], Batch: 6030, Train Loss: 0.9014\n",
      "Epoch [1/10], Batch: 6040, Train Loss: 0.9875\n",
      "Epoch [1/10], Batch: 6050, Train Loss: 0.9058\n",
      "Epoch [1/10], Batch: 6060, Train Loss: 0.9889\n",
      "Epoch [1/10], Batch: 6070, Train Loss: 0.9528\n",
      "Epoch [1/10], Batch: 6080, Train Loss: 0.8563\n",
      "Epoch [1/10], Batch: 6090, Train Loss: 0.8915\n",
      "Epoch [1/10], Batch: 6100, Train Loss: 0.9750\n",
      "Epoch [1/10], Batch: 6110, Train Loss: 0.9281\n",
      "Epoch [1/10], Batch: 6120, Train Loss: 0.9302\n",
      "Epoch [1/10], Batch: 6130, Train Loss: 0.9885\n",
      "Epoch [1/10], Batch: 6140, Train Loss: 1.0201\n",
      "Epoch [1/10], Batch: 6150, Train Loss: 1.0216\n",
      "Epoch [1/10], Batch: 6160, Train Loss: 0.9314\n",
      "Epoch [1/10], Batch: 6170, Train Loss: 0.9747\n",
      "Epoch [1/10], Batch: 6180, Train Loss: 0.9474\n",
      "Epoch [1/10], Batch: 6190, Train Loss: 1.0342\n",
      "Epoch [1/10], Batch: 6200, Train Loss: 0.9179\n",
      "Epoch [1/10], Batch: 6210, Train Loss: 0.9096\n",
      "Epoch [1/10], Batch: 6220, Train Loss: 0.8948\n",
      "Epoch [1/10], Batch: 6230, Train Loss: 0.9055\n",
      "Epoch [1/10], Batch: 6240, Train Loss: 0.9710\n",
      "Epoch [1/10], Batch: 6250, Train Loss: 0.9547\n",
      "Epoch [1/10], Batch: 6260, Train Loss: 1.0224\n",
      "Epoch [1/10], Batch: 6270, Train Loss: 0.9635\n",
      "Epoch [1/10], Batch: 6280, Train Loss: 0.9666\n",
      "Epoch [1/10], Batch: 6290, Train Loss: 0.9348\n",
      "Epoch [1/10], Batch: 6300, Train Loss: 0.9201\n",
      "Epoch [1/10], Batch: 6310, Train Loss: 0.9334\n",
      "Epoch [1/10], Batch: 6320, Train Loss: 0.9660\n",
      "Epoch [1/10], Batch: 6330, Train Loss: 0.9403\n",
      "Epoch [1/10], Batch: 6340, Train Loss: 0.9642\n",
      "Epoch [1/10], Batch: 6350, Train Loss: 0.9737\n",
      "Epoch [1/10], Batch: 6360, Train Loss: 1.0191\n",
      "Epoch [1/10], Batch: 6370, Train Loss: 0.9947\n",
      "Epoch [1/10], Batch: 6380, Train Loss: 0.9149\n",
      "Epoch [1/10], Batch: 6390, Train Loss: 0.9421\n",
      "Epoch [1/10], Batch: 6400, Train Loss: 1.0097\n",
      "Epoch [1/10], Batch: 6410, Train Loss: 0.9454\n",
      "Epoch [1/10], Batch: 6420, Train Loss: 0.9565\n",
      "Epoch [1/10], Batch: 6430, Train Loss: 0.8422\n",
      "Epoch [1/10], Batch: 6440, Train Loss: 0.9615\n",
      "Epoch [1/10], Batch: 6450, Train Loss: 0.9721\n",
      "Epoch [1/10], Batch: 6460, Train Loss: 0.9572\n",
      "Epoch [1/10], Batch: 6470, Train Loss: 0.9436\n",
      "Epoch [1/10], Batch: 6480, Train Loss: 0.9421\n",
      "Epoch [1/10], Batch: 6490, Train Loss: 0.9443\n",
      "Epoch [1/10], Batch: 6500, Train Loss: 0.9553\n",
      "Epoch [1/10], Batch: 6510, Train Loss: 0.8667\n",
      "Epoch [1/10], Batch: 6520, Train Loss: 0.9085\n",
      "Epoch [1/10], Batch: 6530, Train Loss: 0.9995\n",
      "Epoch [1/10], Batch: 6540, Train Loss: 0.9861\n",
      "Epoch [1/10], Batch: 6550, Train Loss: 0.9361\n",
      "Epoch [1/10], Batch: 6560, Train Loss: 0.9252\n",
      "Epoch [1/10], Batch: 6570, Train Loss: 0.9235\n",
      "Epoch [1/10], Batch: 6580, Train Loss: 0.9067\n",
      "Epoch [1/10], Batch: 6590, Train Loss: 0.9684\n",
      "Epoch [1/10], Batch: 6600, Train Loss: 1.0106\n",
      "Epoch [1/10], Batch: 6610, Train Loss: 0.9625\n",
      "Epoch [1/10], Batch: 6620, Train Loss: 0.8584\n",
      "Epoch [1/10], Batch: 6630, Train Loss: 0.9602\n",
      "Epoch [1/10], Batch: 6640, Train Loss: 1.0151\n",
      "Epoch [1/10], Batch: 6650, Train Loss: 0.8534\n",
      "Epoch [1/10], Batch: 6660, Train Loss: 0.9667\n",
      "Epoch [1/10], Batch: 6670, Train Loss: 0.9620\n",
      "Epoch [1/10], Batch: 6680, Train Loss: 1.0182\n",
      "Epoch [1/10], Batch: 6690, Train Loss: 0.9609\n",
      "Epoch [1/10], Batch: 6700, Train Loss: 1.0047\n",
      "Epoch [1/10], Batch: 6710, Train Loss: 0.9729\n",
      "Epoch [1/10], Batch: 6720, Train Loss: 0.9408\n",
      "Epoch [1/10], Batch: 6730, Train Loss: 0.9228\n",
      "Epoch [1/10], Batch: 6740, Train Loss: 0.8820\n",
      "Epoch [1/10], Batch: 6750, Train Loss: 0.8900\n",
      "Epoch [1/10], Batch: 6760, Train Loss: 0.9259\n",
      "Epoch [2/10], Batch: 10, Train Loss: 0.9523\n",
      "Epoch [2/10], Batch: 20, Train Loss: 0.8673\n",
      "Epoch [2/10], Batch: 30, Train Loss: 0.9565\n",
      "Epoch [2/10], Batch: 40, Train Loss: 0.9422\n",
      "Epoch [2/10], Batch: 50, Train Loss: 0.9541\n",
      "Epoch [2/10], Batch: 60, Train Loss: 0.9202\n",
      "Epoch [2/10], Batch: 70, Train Loss: 0.9930\n",
      "Epoch [2/10], Batch: 80, Train Loss: 0.9349\n",
      "Epoch [2/10], Batch: 90, Train Loss: 0.8944\n",
      "Epoch [2/10], Batch: 100, Train Loss: 0.9431\n",
      "Epoch [2/10], Batch: 110, Train Loss: 1.0215\n",
      "Epoch [2/10], Batch: 120, Train Loss: 0.9222\n",
      "Epoch [2/10], Batch: 130, Train Loss: 1.0555\n",
      "Epoch [2/10], Batch: 140, Train Loss: 0.8939\n",
      "Epoch [2/10], Batch: 150, Train Loss: 0.9083\n",
      "Epoch [2/10], Batch: 160, Train Loss: 0.9257\n",
      "Epoch [2/10], Batch: 170, Train Loss: 0.9308\n",
      "Epoch [2/10], Batch: 180, Train Loss: 0.9199\n",
      "Epoch [2/10], Batch: 190, Train Loss: 0.8859\n",
      "Epoch [2/10], Batch: 200, Train Loss: 0.8923\n",
      "Epoch [2/10], Batch: 210, Train Loss: 0.9377\n",
      "Epoch [2/10], Batch: 220, Train Loss: 0.9106\n",
      "Epoch [2/10], Batch: 230, Train Loss: 0.9598\n",
      "Epoch [2/10], Batch: 240, Train Loss: 0.9213\n",
      "Epoch [2/10], Batch: 250, Train Loss: 0.9498\n",
      "Epoch [2/10], Batch: 260, Train Loss: 0.9380\n",
      "Epoch [2/10], Batch: 270, Train Loss: 0.9218\n",
      "Epoch [2/10], Batch: 280, Train Loss: 0.9403\n",
      "Epoch [2/10], Batch: 290, Train Loss: 0.9336\n",
      "Epoch [2/10], Batch: 300, Train Loss: 0.9897\n",
      "Epoch [2/10], Batch: 310, Train Loss: 0.8962\n",
      "Epoch [2/10], Batch: 320, Train Loss: 0.8558\n",
      "Epoch [2/10], Batch: 330, Train Loss: 0.8935\n",
      "Epoch [2/10], Batch: 340, Train Loss: 0.9290\n",
      "Epoch [2/10], Batch: 350, Train Loss: 0.9202\n",
      "Epoch [2/10], Batch: 360, Train Loss: 0.8699\n",
      "Epoch [2/10], Batch: 370, Train Loss: 0.9484\n",
      "Epoch [2/10], Batch: 380, Train Loss: 0.9006\n",
      "Epoch [2/10], Batch: 390, Train Loss: 0.9489\n",
      "Epoch [2/10], Batch: 400, Train Loss: 0.9672\n",
      "Epoch [2/10], Batch: 410, Train Loss: 0.9348\n",
      "Epoch [2/10], Batch: 420, Train Loss: 0.8902\n",
      "Epoch [2/10], Batch: 430, Train Loss: 0.8737\n",
      "Epoch [2/10], Batch: 440, Train Loss: 0.9919\n",
      "Epoch [2/10], Batch: 450, Train Loss: 0.9253\n",
      "Epoch [2/10], Batch: 460, Train Loss: 0.9144\n",
      "Epoch [2/10], Batch: 470, Train Loss: 0.9215\n",
      "Epoch [2/10], Batch: 480, Train Loss: 0.9256\n",
      "Epoch [2/10], Batch: 490, Train Loss: 0.9465\n",
      "Epoch [2/10], Batch: 500, Train Loss: 1.0388\n",
      "Epoch [2/10], Batch: 510, Train Loss: 0.9914\n",
      "Epoch [2/10], Batch: 520, Train Loss: 1.0140\n",
      "Epoch [2/10], Batch: 530, Train Loss: 0.9948\n",
      "Epoch [2/10], Batch: 540, Train Loss: 0.9205\n",
      "Epoch [2/10], Batch: 550, Train Loss: 0.9782\n",
      "Epoch [2/10], Batch: 560, Train Loss: 0.8825\n",
      "Epoch [2/10], Batch: 570, Train Loss: 1.0065\n",
      "Epoch [2/10], Batch: 580, Train Loss: 0.8920\n",
      "Epoch [2/10], Batch: 590, Train Loss: 0.9625\n",
      "Epoch [2/10], Batch: 600, Train Loss: 0.9526\n",
      "Epoch [2/10], Batch: 610, Train Loss: 0.9457\n",
      "Epoch [2/10], Batch: 620, Train Loss: 0.9338\n",
      "Epoch [2/10], Batch: 630, Train Loss: 0.9460\n",
      "Epoch [2/10], Batch: 640, Train Loss: 0.9776\n",
      "Epoch [2/10], Batch: 650, Train Loss: 0.9543\n",
      "Epoch [2/10], Batch: 660, Train Loss: 1.0583\n",
      "Epoch [2/10], Batch: 670, Train Loss: 0.9878\n",
      "Epoch [2/10], Batch: 680, Train Loss: 0.9188\n",
      "Epoch [2/10], Batch: 690, Train Loss: 0.9597\n",
      "Epoch [2/10], Batch: 700, Train Loss: 0.9559\n",
      "Epoch [2/10], Batch: 710, Train Loss: 0.9008\n",
      "Epoch [2/10], Batch: 720, Train Loss: 0.9441\n",
      "Epoch [2/10], Batch: 730, Train Loss: 0.9303\n",
      "Epoch [2/10], Batch: 740, Train Loss: 0.9653\n",
      "Epoch [2/10], Batch: 750, Train Loss: 0.9040\n",
      "Epoch [2/10], Batch: 760, Train Loss: 0.9670\n",
      "Epoch [2/10], Batch: 770, Train Loss: 0.9696\n",
      "Epoch [2/10], Batch: 780, Train Loss: 0.8642\n",
      "Epoch [2/10], Batch: 790, Train Loss: 0.9168\n",
      "Epoch [2/10], Batch: 800, Train Loss: 0.8770\n",
      "Epoch [2/10], Batch: 810, Train Loss: 0.9254\n",
      "Epoch [2/10], Batch: 820, Train Loss: 0.9344\n",
      "Epoch [2/10], Batch: 830, Train Loss: 0.9611\n",
      "Epoch [2/10], Batch: 840, Train Loss: 0.9847\n",
      "Epoch [2/10], Batch: 850, Train Loss: 0.9123\n",
      "Epoch [2/10], Batch: 860, Train Loss: 0.8237\n",
      "Epoch [2/10], Batch: 870, Train Loss: 0.9224\n",
      "Epoch [2/10], Batch: 880, Train Loss: 1.0102\n",
      "Epoch [2/10], Batch: 890, Train Loss: 0.9252\n",
      "Epoch [2/10], Batch: 900, Train Loss: 0.9169\n",
      "Epoch [2/10], Batch: 910, Train Loss: 0.9293\n",
      "Epoch [2/10], Batch: 920, Train Loss: 0.9304\n",
      "Epoch [2/10], Batch: 930, Train Loss: 0.9625\n",
      "Epoch [2/10], Batch: 940, Train Loss: 0.8906\n",
      "Epoch [2/10], Batch: 950, Train Loss: 0.9151\n",
      "Epoch [2/10], Batch: 960, Train Loss: 0.8998\n",
      "Epoch [2/10], Batch: 970, Train Loss: 0.8939\n",
      "Epoch [2/10], Batch: 980, Train Loss: 0.9278\n",
      "Epoch [2/10], Batch: 990, Train Loss: 0.9216\n",
      "Epoch [2/10], Batch: 1000, Train Loss: 0.9512\n",
      "Epoch [2/10], Batch: 1010, Train Loss: 0.9021\n",
      "Epoch [2/10], Batch: 1020, Train Loss: 0.8853\n",
      "Epoch [2/10], Batch: 1030, Train Loss: 0.9267\n",
      "Epoch [2/10], Batch: 1040, Train Loss: 0.9640\n",
      "Epoch [2/10], Batch: 1050, Train Loss: 0.8998\n",
      "Epoch [2/10], Batch: 1060, Train Loss: 0.9606\n",
      "Epoch [2/10], Batch: 1070, Train Loss: 0.9767\n",
      "Epoch [2/10], Batch: 1080, Train Loss: 0.8230\n",
      "Epoch [2/10], Batch: 1090, Train Loss: 0.9113\n",
      "Epoch [2/10], Batch: 1100, Train Loss: 0.8924\n",
      "Epoch [2/10], Batch: 1110, Train Loss: 0.9571\n",
      "Epoch [2/10], Batch: 1120, Train Loss: 0.9154\n",
      "Epoch [2/10], Batch: 1130, Train Loss: 0.9407\n",
      "Epoch [2/10], Batch: 1140, Train Loss: 0.9741\n",
      "Epoch [2/10], Batch: 1150, Train Loss: 0.9995\n",
      "Epoch [2/10], Batch: 1160, Train Loss: 0.8416\n",
      "Epoch [2/10], Batch: 1170, Train Loss: 0.9567\n",
      "Epoch [2/10], Batch: 1180, Train Loss: 0.9293\n",
      "Epoch [2/10], Batch: 1190, Train Loss: 0.9343\n",
      "Epoch [2/10], Batch: 1200, Train Loss: 1.0112\n",
      "Epoch [2/10], Batch: 1210, Train Loss: 0.8748\n",
      "Epoch [2/10], Batch: 1220, Train Loss: 0.8965\n",
      "Epoch [2/10], Batch: 1230, Train Loss: 0.9246\n",
      "Epoch [2/10], Batch: 1240, Train Loss: 0.8677\n",
      "Epoch [2/10], Batch: 1250, Train Loss: 0.9168\n",
      "Epoch [2/10], Batch: 1260, Train Loss: 1.0099\n",
      "Epoch [2/10], Batch: 1270, Train Loss: 0.9959\n",
      "Epoch [2/10], Batch: 1280, Train Loss: 0.8751\n",
      "Epoch [2/10], Batch: 1290, Train Loss: 0.9250\n",
      "Epoch [2/10], Batch: 1300, Train Loss: 0.9691\n",
      "Epoch [2/10], Batch: 1310, Train Loss: 0.9078\n",
      "Epoch [2/10], Batch: 1320, Train Loss: 0.9853\n",
      "Epoch [2/10], Batch: 1330, Train Loss: 1.0155\n",
      "Epoch [2/10], Batch: 1340, Train Loss: 1.0089\n",
      "Epoch [2/10], Batch: 1350, Train Loss: 0.7941\n",
      "Epoch [2/10], Batch: 1360, Train Loss: 0.9075\n",
      "Epoch [2/10], Batch: 1370, Train Loss: 0.9713\n",
      "Epoch [2/10], Batch: 1380, Train Loss: 0.8223\n",
      "Epoch [2/10], Batch: 1390, Train Loss: 0.9970\n",
      "Epoch [2/10], Batch: 1400, Train Loss: 0.9111\n",
      "Epoch [2/10], Batch: 1410, Train Loss: 1.0213\n",
      "Epoch [2/10], Batch: 1420, Train Loss: 0.9440\n",
      "Epoch [2/10], Batch: 1430, Train Loss: 0.9962\n",
      "Epoch [2/10], Batch: 1440, Train Loss: 0.8893\n",
      "Epoch [2/10], Batch: 1450, Train Loss: 1.0269\n",
      "Epoch [2/10], Batch: 1460, Train Loss: 0.8710\n",
      "Epoch [2/10], Batch: 1470, Train Loss: 0.9359\n",
      "Epoch [2/10], Batch: 1480, Train Loss: 0.9442\n",
      "Epoch [2/10], Batch: 1490, Train Loss: 0.8991\n",
      "Epoch [2/10], Batch: 1500, Train Loss: 0.9503\n",
      "Epoch [2/10], Batch: 1510, Train Loss: 0.9494\n",
      "Epoch [2/10], Batch: 1520, Train Loss: 0.9017\n",
      "Epoch [2/10], Batch: 1530, Train Loss: 0.8466\n",
      "Epoch [2/10], Batch: 1540, Train Loss: 0.8776\n",
      "Epoch [2/10], Batch: 1550, Train Loss: 0.8899\n",
      "Epoch [2/10], Batch: 1560, Train Loss: 0.9382\n",
      "Epoch [2/10], Batch: 1570, Train Loss: 0.9474\n",
      "Epoch [2/10], Batch: 1580, Train Loss: 1.0299\n",
      "Epoch [2/10], Batch: 1590, Train Loss: 0.8395\n",
      "Epoch [2/10], Batch: 1600, Train Loss: 0.9329\n",
      "Epoch [2/10], Batch: 1610, Train Loss: 0.9471\n",
      "Epoch [2/10], Batch: 1620, Train Loss: 0.8966\n",
      "Epoch [2/10], Batch: 1630, Train Loss: 1.0052\n",
      "Epoch [2/10], Batch: 1640, Train Loss: 0.9078\n",
      "Epoch [2/10], Batch: 1650, Train Loss: 0.9831\n",
      "Epoch [2/10], Batch: 1660, Train Loss: 0.9391\n",
      "Epoch [2/10], Batch: 1670, Train Loss: 0.9559\n",
      "Epoch [2/10], Batch: 1680, Train Loss: 0.9293\n",
      "Epoch [2/10], Batch: 1690, Train Loss: 0.9637\n",
      "Epoch [2/10], Batch: 1700, Train Loss: 0.9206\n",
      "Epoch [2/10], Batch: 1710, Train Loss: 0.9288\n",
      "Epoch [2/10], Batch: 1720, Train Loss: 0.9474\n",
      "Epoch [2/10], Batch: 1730, Train Loss: 0.9298\n",
      "Epoch [2/10], Batch: 1740, Train Loss: 0.8448\n",
      "Epoch [2/10], Batch: 1750, Train Loss: 0.8836\n",
      "Epoch [2/10], Batch: 1760, Train Loss: 0.9593\n",
      "Epoch [2/10], Batch: 1770, Train Loss: 0.9630\n",
      "Epoch [2/10], Batch: 1780, Train Loss: 0.9050\n",
      "Epoch [2/10], Batch: 1790, Train Loss: 0.9284\n",
      "Epoch [2/10], Batch: 1800, Train Loss: 0.9935\n",
      "Epoch [2/10], Batch: 1810, Train Loss: 0.9104\n",
      "Epoch [2/10], Batch: 1820, Train Loss: 0.9398\n",
      "Epoch [2/10], Batch: 1830, Train Loss: 0.9451\n",
      "Epoch [2/10], Batch: 1840, Train Loss: 0.9158\n",
      "Epoch [2/10], Batch: 1850, Train Loss: 0.9015\n",
      "Epoch [2/10], Batch: 1860, Train Loss: 0.9385\n",
      "Epoch [2/10], Batch: 1870, Train Loss: 0.9740\n",
      "Epoch [2/10], Batch: 1880, Train Loss: 0.9272\n",
      "Epoch [2/10], Batch: 1890, Train Loss: 0.9510\n",
      "Epoch [2/10], Batch: 1900, Train Loss: 0.9368\n",
      "Epoch [2/10], Batch: 1910, Train Loss: 0.8543\n",
      "Epoch [2/10], Batch: 1920, Train Loss: 0.9140\n",
      "Epoch [2/10], Batch: 1930, Train Loss: 0.9393\n",
      "Epoch [2/10], Batch: 1940, Train Loss: 0.9330\n",
      "Epoch [2/10], Batch: 1950, Train Loss: 0.9270\n",
      "Epoch [2/10], Batch: 1960, Train Loss: 0.8029\n",
      "Epoch [2/10], Batch: 1970, Train Loss: 0.9887\n",
      "Epoch [2/10], Batch: 1980, Train Loss: 0.8607\n",
      "Epoch [2/10], Batch: 1990, Train Loss: 0.8419\n",
      "Epoch [2/10], Batch: 2000, Train Loss: 0.9037\n",
      "Epoch [2/10], Batch: 2010, Train Loss: 0.9036\n",
      "Epoch [2/10], Batch: 2020, Train Loss: 0.9365\n",
      "Epoch [2/10], Batch: 2030, Train Loss: 0.8597\n",
      "Epoch [2/10], Batch: 2040, Train Loss: 0.9525\n",
      "Epoch [2/10], Batch: 2050, Train Loss: 0.9666\n",
      "Epoch [2/10], Batch: 2060, Train Loss: 0.9775\n",
      "Epoch [2/10], Batch: 2070, Train Loss: 0.8613\n",
      "Epoch [2/10], Batch: 2080, Train Loss: 0.9431\n",
      "Epoch [2/10], Batch: 2090, Train Loss: 0.9164\n",
      "Epoch [2/10], Batch: 2100, Train Loss: 0.9050\n",
      "Epoch [2/10], Batch: 2110, Train Loss: 1.0190\n",
      "Epoch [2/10], Batch: 2120, Train Loss: 0.9442\n",
      "Epoch [2/10], Batch: 2130, Train Loss: 0.9717\n",
      "Epoch [2/10], Batch: 2140, Train Loss: 0.9770\n",
      "Epoch [2/10], Batch: 2150, Train Loss: 0.9360\n",
      "Epoch [2/10], Batch: 2160, Train Loss: 0.9636\n",
      "Epoch [2/10], Batch: 2170, Train Loss: 0.9035\n",
      "Epoch [2/10], Batch: 2180, Train Loss: 0.9791\n",
      "Epoch [2/10], Batch: 2190, Train Loss: 0.8979\n",
      "Epoch [2/10], Batch: 2200, Train Loss: 0.9331\n",
      "Epoch [2/10], Batch: 2210, Train Loss: 0.9668\n",
      "Epoch [2/10], Batch: 2220, Train Loss: 0.9005\n",
      "Epoch [2/10], Batch: 2230, Train Loss: 0.9093\n",
      "Epoch [2/10], Batch: 2240, Train Loss: 0.9250\n",
      "Epoch [2/10], Batch: 2250, Train Loss: 0.9489\n",
      "Epoch [2/10], Batch: 2260, Train Loss: 0.9400\n",
      "Epoch [2/10], Batch: 2270, Train Loss: 0.9416\n",
      "Epoch [2/10], Batch: 2280, Train Loss: 0.8947\n",
      "Epoch [2/10], Batch: 2290, Train Loss: 1.0097\n",
      "Epoch [2/10], Batch: 2300, Train Loss: 0.8875\n",
      "Epoch [2/10], Batch: 2310, Train Loss: 0.8720\n",
      "Epoch [2/10], Batch: 2320, Train Loss: 0.9413\n",
      "Epoch [2/10], Batch: 2330, Train Loss: 0.9647\n",
      "Epoch [2/10], Batch: 2340, Train Loss: 1.0438\n",
      "Epoch [2/10], Batch: 2350, Train Loss: 0.9319\n",
      "Epoch [2/10], Batch: 2360, Train Loss: 1.0037\n",
      "Epoch [2/10], Batch: 2370, Train Loss: 0.9516\n",
      "Epoch [2/10], Batch: 2380, Train Loss: 0.9755\n",
      "Epoch [2/10], Batch: 2390, Train Loss: 0.7606\n",
      "Epoch [2/10], Batch: 2400, Train Loss: 0.9491\n",
      "Epoch [2/10], Batch: 2410, Train Loss: 0.9251\n",
      "Epoch [2/10], Batch: 2420, Train Loss: 0.9276\n",
      "Epoch [2/10], Batch: 2430, Train Loss: 0.9682\n",
      "Epoch [2/10], Batch: 2440, Train Loss: 0.9511\n",
      "Epoch [2/10], Batch: 2450, Train Loss: 0.9028\n",
      "Epoch [2/10], Batch: 2460, Train Loss: 0.9627\n",
      "Epoch [2/10], Batch: 2470, Train Loss: 0.9580\n",
      "Epoch [2/10], Batch: 2480, Train Loss: 0.8551\n",
      "Epoch [2/10], Batch: 2490, Train Loss: 0.9406\n",
      "Epoch [2/10], Batch: 2500, Train Loss: 0.9143\n",
      "Epoch [2/10], Batch: 2510, Train Loss: 0.9489\n",
      "Epoch [2/10], Batch: 2520, Train Loss: 0.9092\n",
      "Epoch [2/10], Batch: 2530, Train Loss: 0.9991\n",
      "Epoch [2/10], Batch: 2540, Train Loss: 0.9845\n",
      "Epoch [2/10], Batch: 2550, Train Loss: 0.8887\n",
      "Epoch [2/10], Batch: 2560, Train Loss: 0.9103\n",
      "Epoch [2/10], Batch: 2570, Train Loss: 0.8698\n",
      "Epoch [2/10], Batch: 2580, Train Loss: 0.8659\n",
      "Epoch [2/10], Batch: 2590, Train Loss: 0.9135\n",
      "Epoch [2/10], Batch: 2600, Train Loss: 0.9056\n",
      "Epoch [2/10], Batch: 2610, Train Loss: 0.8903\n",
      "Epoch [2/10], Batch: 2620, Train Loss: 0.9082\n",
      "Epoch [2/10], Batch: 2630, Train Loss: 0.9249\n",
      "Epoch [2/10], Batch: 2640, Train Loss: 0.8814\n",
      "Epoch [2/10], Batch: 2650, Train Loss: 0.9263\n",
      "Epoch [2/10], Batch: 2660, Train Loss: 0.9077\n",
      "Epoch [2/10], Batch: 2670, Train Loss: 0.8931\n",
      "Epoch [2/10], Batch: 2680, Train Loss: 0.8796\n",
      "Epoch [2/10], Batch: 2690, Train Loss: 0.8837\n",
      "Epoch [2/10], Batch: 2700, Train Loss: 0.9176\n",
      "Epoch [2/10], Batch: 2710, Train Loss: 0.9035\n",
      "Epoch [2/10], Batch: 2720, Train Loss: 0.9947\n",
      "Epoch [2/10], Batch: 2730, Train Loss: 0.8975\n",
      "Epoch [2/10], Batch: 2740, Train Loss: 0.9348\n",
      "Epoch [2/10], Batch: 2750, Train Loss: 0.9103\n",
      "Epoch [2/10], Batch: 2760, Train Loss: 0.8902\n",
      "Epoch [2/10], Batch: 2770, Train Loss: 0.9006\n",
      "Epoch [2/10], Batch: 2780, Train Loss: 0.8441\n",
      "Epoch [2/10], Batch: 2790, Train Loss: 0.8869\n",
      "Epoch [2/10], Batch: 2800, Train Loss: 0.8799\n",
      "Epoch [2/10], Batch: 2810, Train Loss: 0.9686\n",
      "Epoch [2/10], Batch: 2820, Train Loss: 0.9171\n",
      "Epoch [2/10], Batch: 2830, Train Loss: 0.9568\n",
      "Epoch [2/10], Batch: 2840, Train Loss: 0.8161\n",
      "Epoch [2/10], Batch: 2850, Train Loss: 0.9637\n",
      "Epoch [2/10], Batch: 2860, Train Loss: 0.9922\n",
      "Epoch [2/10], Batch: 2870, Train Loss: 0.8265\n",
      "Epoch [2/10], Batch: 2880, Train Loss: 1.0476\n",
      "Epoch [2/10], Batch: 2890, Train Loss: 0.8736\n",
      "Epoch [2/10], Batch: 2900, Train Loss: 0.9619\n",
      "Epoch [2/10], Batch: 2910, Train Loss: 0.8996\n",
      "Epoch [2/10], Batch: 2920, Train Loss: 0.9166\n",
      "Epoch [2/10], Batch: 2930, Train Loss: 0.9186\n",
      "Epoch [2/10], Batch: 2940, Train Loss: 0.9859\n",
      "Epoch [2/10], Batch: 2950, Train Loss: 0.8961\n",
      "Epoch [2/10], Batch: 2960, Train Loss: 1.0270\n",
      "Epoch [2/10], Batch: 2970, Train Loss: 0.9837\n",
      "Epoch [2/10], Batch: 2980, Train Loss: 0.8222\n",
      "Epoch [2/10], Batch: 2990, Train Loss: 0.9270\n",
      "Epoch [2/10], Batch: 3000, Train Loss: 0.9919\n",
      "Epoch [2/10], Batch: 3010, Train Loss: 0.9172\n",
      "Epoch [2/10], Batch: 3020, Train Loss: 0.9539\n",
      "Epoch [2/10], Batch: 3030, Train Loss: 0.8377\n",
      "Epoch [2/10], Batch: 3040, Train Loss: 0.8831\n",
      "Epoch [2/10], Batch: 3050, Train Loss: 0.9708\n",
      "Epoch [2/10], Batch: 3060, Train Loss: 0.8479\n",
      "Epoch [2/10], Batch: 3070, Train Loss: 1.0180\n",
      "Epoch [2/10], Batch: 3080, Train Loss: 1.0137\n",
      "Epoch [2/10], Batch: 3090, Train Loss: 0.8940\n",
      "Epoch [2/10], Batch: 3100, Train Loss: 0.8955\n",
      "Epoch [2/10], Batch: 3110, Train Loss: 0.8131\n",
      "Epoch [2/10], Batch: 3120, Train Loss: 0.9317\n",
      "Epoch [2/10], Batch: 3130, Train Loss: 0.9195\n",
      "Epoch [2/10], Batch: 3140, Train Loss: 0.8899\n",
      "Epoch [2/10], Batch: 3150, Train Loss: 0.9025\n",
      "Epoch [2/10], Batch: 3160, Train Loss: 0.9746\n",
      "Epoch [2/10], Batch: 3170, Train Loss: 0.9049\n",
      "Epoch [2/10], Batch: 3180, Train Loss: 0.9299\n",
      "Epoch [2/10], Batch: 3190, Train Loss: 0.8395\n",
      "Epoch [2/10], Batch: 3200, Train Loss: 1.0382\n",
      "Epoch [2/10], Batch: 3210, Train Loss: 0.9749\n",
      "Epoch [2/10], Batch: 3220, Train Loss: 1.0037\n",
      "Epoch [2/10], Batch: 3230, Train Loss: 0.8382\n",
      "Epoch [2/10], Batch: 3240, Train Loss: 0.8967\n",
      "Epoch [2/10], Batch: 3250, Train Loss: 0.9192\n",
      "Epoch [2/10], Batch: 3260, Train Loss: 0.8643\n",
      "Epoch [2/10], Batch: 3270, Train Loss: 0.9670\n",
      "Epoch [2/10], Batch: 3280, Train Loss: 0.9680\n",
      "Epoch [2/10], Batch: 3290, Train Loss: 0.9078\n",
      "Epoch [2/10], Batch: 3300, Train Loss: 0.9872\n",
      "Epoch [2/10], Batch: 3310, Train Loss: 0.9742\n",
      "Epoch [2/10], Batch: 3320, Train Loss: 0.9657\n",
      "Epoch [2/10], Batch: 3330, Train Loss: 0.7539\n",
      "Epoch [2/10], Batch: 3340, Train Loss: 0.8812\n",
      "Epoch [2/10], Batch: 3350, Train Loss: 0.8891\n",
      "Epoch [2/10], Batch: 3360, Train Loss: 0.8714\n",
      "Epoch [2/10], Batch: 3370, Train Loss: 0.9318\n",
      "Epoch [2/10], Batch: 3380, Train Loss: 0.8860\n",
      "Epoch [2/10], Batch: 3390, Train Loss: 0.8719\n",
      "Epoch [2/10], Batch: 3400, Train Loss: 0.8677\n",
      "Epoch [2/10], Batch: 3410, Train Loss: 0.9323\n",
      "Epoch [2/10], Batch: 3420, Train Loss: 0.8417\n",
      "Epoch [2/10], Batch: 3430, Train Loss: 0.9296\n",
      "Epoch [2/10], Batch: 3440, Train Loss: 0.9768\n",
      "Epoch [2/10], Batch: 3450, Train Loss: 0.8892\n",
      "Epoch [2/10], Batch: 3460, Train Loss: 0.8906\n",
      "Epoch [2/10], Batch: 3470, Train Loss: 0.8939\n",
      "Epoch [2/10], Batch: 3480, Train Loss: 0.8947\n",
      "Epoch [2/10], Batch: 3490, Train Loss: 0.9209\n",
      "Epoch [2/10], Batch: 3500, Train Loss: 0.9711\n",
      "Epoch [2/10], Batch: 3510, Train Loss: 0.9719\n",
      "Epoch [2/10], Batch: 3520, Train Loss: 0.9367\n",
      "Epoch [2/10], Batch: 3530, Train Loss: 0.8790\n",
      "Epoch [2/10], Batch: 3540, Train Loss: 0.8837\n",
      "Epoch [2/10], Batch: 3550, Train Loss: 0.8649\n",
      "Epoch [2/10], Batch: 3560, Train Loss: 0.9373\n",
      "Epoch [2/10], Batch: 3570, Train Loss: 0.8864\n",
      "Epoch [2/10], Batch: 3580, Train Loss: 0.9596\n",
      "Epoch [2/10], Batch: 3590, Train Loss: 0.9840\n",
      "Epoch [2/10], Batch: 3600, Train Loss: 0.8355\n",
      "Epoch [2/10], Batch: 3610, Train Loss: 0.8235\n",
      "Epoch [2/10], Batch: 3620, Train Loss: 0.9841\n",
      "Epoch [2/10], Batch: 3630, Train Loss: 0.9587\n",
      "Epoch [2/10], Batch: 3640, Train Loss: 0.9109\n",
      "Epoch [2/10], Batch: 3650, Train Loss: 0.8763\n",
      "Epoch [2/10], Batch: 3660, Train Loss: 0.9514\n",
      "Epoch [2/10], Batch: 3670, Train Loss: 0.9852\n",
      "Epoch [2/10], Batch: 3680, Train Loss: 0.9016\n",
      "Epoch [2/10], Batch: 3690, Train Loss: 0.9070\n",
      "Epoch [2/10], Batch: 3700, Train Loss: 0.9775\n",
      "Epoch [2/10], Batch: 3710, Train Loss: 1.0211\n",
      "Epoch [2/10], Batch: 3720, Train Loss: 0.9266\n",
      "Epoch [2/10], Batch: 3730, Train Loss: 0.9349\n",
      "Epoch [2/10], Batch: 3740, Train Loss: 0.8759\n",
      "Epoch [2/10], Batch: 3750, Train Loss: 0.8176\n",
      "Epoch [2/10], Batch: 3760, Train Loss: 0.7972\n",
      "Epoch [2/10], Batch: 3770, Train Loss: 0.8681\n",
      "Epoch [2/10], Batch: 3780, Train Loss: 0.9444\n",
      "Epoch [2/10], Batch: 3790, Train Loss: 0.9392\n",
      "Epoch [2/10], Batch: 3800, Train Loss: 0.8640\n",
      "Epoch [2/10], Batch: 3810, Train Loss: 0.8402\n",
      "Epoch [2/10], Batch: 3820, Train Loss: 0.9430\n",
      "Epoch [2/10], Batch: 3830, Train Loss: 0.7786\n",
      "Epoch [2/10], Batch: 3840, Train Loss: 0.9131\n",
      "Epoch [2/10], Batch: 3850, Train Loss: 1.0446\n",
      "Epoch [2/10], Batch: 3860, Train Loss: 0.9527\n",
      "Epoch [2/10], Batch: 3870, Train Loss: 1.0088\n",
      "Epoch [2/10], Batch: 3880, Train Loss: 0.9374\n",
      "Epoch [2/10], Batch: 3890, Train Loss: 0.9130\n",
      "Epoch [2/10], Batch: 3900, Train Loss: 0.8291\n",
      "Epoch [2/10], Batch: 3910, Train Loss: 0.8805\n",
      "Epoch [2/10], Batch: 3920, Train Loss: 0.8859\n",
      "Epoch [2/10], Batch: 3930, Train Loss: 0.8245\n",
      "Epoch [2/10], Batch: 3940, Train Loss: 0.7951\n",
      "Epoch [2/10], Batch: 3950, Train Loss: 0.9686\n",
      "Epoch [2/10], Batch: 3960, Train Loss: 0.9948\n",
      "Epoch [2/10], Batch: 3970, Train Loss: 0.9259\n",
      "Epoch [2/10], Batch: 3980, Train Loss: 0.9128\n",
      "Epoch [2/10], Batch: 3990, Train Loss: 0.9352\n",
      "Epoch [2/10], Batch: 4000, Train Loss: 0.8581\n",
      "Epoch [2/10], Batch: 4010, Train Loss: 0.9424\n",
      "Epoch [2/10], Batch: 4020, Train Loss: 0.8989\n",
      "Epoch [2/10], Batch: 4030, Train Loss: 0.9036\n",
      "Epoch [2/10], Batch: 4040, Train Loss: 0.9277\n",
      "Epoch [2/10], Batch: 4050, Train Loss: 0.7689\n",
      "Epoch [2/10], Batch: 4060, Train Loss: 0.8794\n",
      "Epoch [2/10], Batch: 4070, Train Loss: 0.9432\n",
      "Epoch [2/10], Batch: 4080, Train Loss: 0.9058\n",
      "Epoch [2/10], Batch: 4090, Train Loss: 0.8861\n",
      "Epoch [2/10], Batch: 4100, Train Loss: 0.8807\n",
      "Epoch [2/10], Batch: 4110, Train Loss: 0.9225\n",
      "Epoch [2/10], Batch: 4120, Train Loss: 0.8154\n",
      "Epoch [2/10], Batch: 4130, Train Loss: 0.9978\n",
      "Epoch [2/10], Batch: 4140, Train Loss: 0.9445\n",
      "Epoch [2/10], Batch: 4150, Train Loss: 0.9133\n",
      "Epoch [2/10], Batch: 4160, Train Loss: 0.7962\n",
      "Epoch [2/10], Batch: 4170, Train Loss: 0.8521\n",
      "Epoch [2/10], Batch: 4180, Train Loss: 0.8503\n",
      "Epoch [2/10], Batch: 4190, Train Loss: 0.9345\n",
      "Epoch [2/10], Batch: 4200, Train Loss: 0.8717\n",
      "Epoch [2/10], Batch: 4210, Train Loss: 0.9757\n",
      "Epoch [2/10], Batch: 4220, Train Loss: 0.9175\n",
      "Epoch [2/10], Batch: 4230, Train Loss: 0.9805\n",
      "Epoch [2/10], Batch: 4240, Train Loss: 0.8840\n",
      "Epoch [2/10], Batch: 4250, Train Loss: 0.9122\n",
      "Epoch [2/10], Batch: 4260, Train Loss: 0.8998\n",
      "Epoch [2/10], Batch: 4270, Train Loss: 1.0189\n",
      "Epoch [2/10], Batch: 4280, Train Loss: 0.8995\n",
      "Epoch [2/10], Batch: 4290, Train Loss: 0.9387\n",
      "Epoch [2/10], Batch: 4300, Train Loss: 0.8722\n",
      "Epoch [2/10], Batch: 4310, Train Loss: 0.8740\n",
      "Epoch [2/10], Batch: 4320, Train Loss: 0.9572\n",
      "Epoch [2/10], Batch: 4330, Train Loss: 0.9073\n",
      "Epoch [2/10], Batch: 4340, Train Loss: 0.8777\n",
      "Epoch [2/10], Batch: 4350, Train Loss: 0.8626\n",
      "Epoch [2/10], Batch: 4360, Train Loss: 0.9009\n",
      "Epoch [2/10], Batch: 4370, Train Loss: 0.9464\n",
      "Epoch [2/10], Batch: 4380, Train Loss: 0.9039\n",
      "Epoch [2/10], Batch: 4390, Train Loss: 0.9684\n",
      "Epoch [2/10], Batch: 4400, Train Loss: 0.8435\n",
      "Epoch [2/10], Batch: 4410, Train Loss: 0.8511\n",
      "Epoch [2/10], Batch: 4420, Train Loss: 0.9897\n",
      "Epoch [2/10], Batch: 4430, Train Loss: 0.9145\n",
      "Epoch [2/10], Batch: 4440, Train Loss: 0.9582\n",
      "Epoch [2/10], Batch: 4450, Train Loss: 0.8369\n",
      "Epoch [2/10], Batch: 4460, Train Loss: 0.8896\n",
      "Epoch [2/10], Batch: 4470, Train Loss: 0.9654\n",
      "Epoch [2/10], Batch: 4480, Train Loss: 0.9060\n",
      "Epoch [2/10], Batch: 4490, Train Loss: 0.9563\n",
      "Epoch [2/10], Batch: 4500, Train Loss: 0.9973\n",
      "Epoch [2/10], Batch: 4510, Train Loss: 0.8850\n",
      "Epoch [2/10], Batch: 4520, Train Loss: 0.9212\n",
      "Epoch [2/10], Batch: 4530, Train Loss: 0.8111\n",
      "Epoch [2/10], Batch: 4540, Train Loss: 0.8942\n",
      "Epoch [2/10], Batch: 4550, Train Loss: 0.9230\n",
      "Epoch [2/10], Batch: 4560, Train Loss: 0.8914\n",
      "Epoch [2/10], Batch: 4570, Train Loss: 0.8648\n",
      "Epoch [2/10], Batch: 4580, Train Loss: 0.8792\n",
      "Epoch [2/10], Batch: 4590, Train Loss: 0.8374\n",
      "Epoch [2/10], Batch: 4600, Train Loss: 0.8760\n",
      "Epoch [2/10], Batch: 4610, Train Loss: 0.8312\n",
      "Epoch [2/10], Batch: 4620, Train Loss: 0.9200\n",
      "Epoch [2/10], Batch: 4630, Train Loss: 0.8315\n",
      "Epoch [2/10], Batch: 4640, Train Loss: 0.9510\n",
      "Epoch [2/10], Batch: 4650, Train Loss: 0.9203\n",
      "Epoch [2/10], Batch: 4660, Train Loss: 0.9288\n",
      "Epoch [2/10], Batch: 4670, Train Loss: 0.9289\n",
      "Epoch [2/10], Batch: 4680, Train Loss: 0.8554\n",
      "Epoch [2/10], Batch: 4690, Train Loss: 0.9756\n",
      "Epoch [2/10], Batch: 4700, Train Loss: 1.0375\n",
      "Epoch [2/10], Batch: 4710, Train Loss: 0.9008\n",
      "Epoch [2/10], Batch: 4720, Train Loss: 0.9312\n",
      "Epoch [2/10], Batch: 4730, Train Loss: 0.9468\n",
      "Epoch [2/10], Batch: 4740, Train Loss: 0.8098\n",
      "Epoch [2/10], Batch: 4750, Train Loss: 0.8956\n",
      "Epoch [2/10], Batch: 4760, Train Loss: 0.9151\n",
      "Epoch [2/10], Batch: 4770, Train Loss: 0.8763\n",
      "Epoch [2/10], Batch: 4780, Train Loss: 0.8656\n",
      "Epoch [2/10], Batch: 4790, Train Loss: 0.9896\n",
      "Epoch [2/10], Batch: 4800, Train Loss: 0.9302\n",
      "Epoch [2/10], Batch: 4810, Train Loss: 0.8578\n",
      "Epoch [2/10], Batch: 4820, Train Loss: 0.9665\n",
      "Epoch [2/10], Batch: 4830, Train Loss: 0.8701\n",
      "Epoch [2/10], Batch: 4840, Train Loss: 0.9002\n",
      "Epoch [2/10], Batch: 4850, Train Loss: 0.8681\n",
      "Epoch [2/10], Batch: 4860, Train Loss: 1.0017\n",
      "Epoch [2/10], Batch: 4870, Train Loss: 0.8141\n",
      "Epoch [2/10], Batch: 4880, Train Loss: 0.9324\n",
      "Epoch [2/10], Batch: 4890, Train Loss: 0.9422\n",
      "Epoch [2/10], Batch: 4900, Train Loss: 0.9770\n",
      "Epoch [2/10], Batch: 4910, Train Loss: 0.8629\n",
      "Epoch [2/10], Batch: 4920, Train Loss: 0.8402\n",
      "Epoch [2/10], Batch: 4930, Train Loss: 0.9591\n",
      "Epoch [2/10], Batch: 4940, Train Loss: 0.9101\n",
      "Epoch [2/10], Batch: 4950, Train Loss: 0.9017\n",
      "Epoch [2/10], Batch: 4960, Train Loss: 0.8582\n",
      "Epoch [2/10], Batch: 4970, Train Loss: 0.9192\n",
      "Epoch [2/10], Batch: 4980, Train Loss: 0.9087\n",
      "Epoch [2/10], Batch: 4990, Train Loss: 0.8746\n",
      "Epoch [2/10], Batch: 5000, Train Loss: 0.7653\n",
      "Epoch [2/10], Batch: 5010, Train Loss: 0.9702\n",
      "Epoch [2/10], Batch: 5020, Train Loss: 0.8793\n",
      "Epoch [2/10], Batch: 5030, Train Loss: 0.8848\n",
      "Epoch [2/10], Batch: 5040, Train Loss: 0.9712\n",
      "Epoch [2/10], Batch: 5050, Train Loss: 0.9014\n",
      "Epoch [2/10], Batch: 5060, Train Loss: 0.8658\n",
      "Epoch [2/10], Batch: 5070, Train Loss: 0.8589\n",
      "Epoch [2/10], Batch: 5080, Train Loss: 0.8838\n",
      "Epoch [2/10], Batch: 5090, Train Loss: 0.9698\n",
      "Epoch [2/10], Batch: 5100, Train Loss: 0.8877\n",
      "Epoch [2/10], Batch: 5110, Train Loss: 0.8300\n",
      "Epoch [2/10], Batch: 5120, Train Loss: 0.8185\n",
      "Epoch [2/10], Batch: 5130, Train Loss: 0.9098\n",
      "Epoch [2/10], Batch: 5140, Train Loss: 0.9586\n",
      "Epoch [2/10], Batch: 5150, Train Loss: 0.8669\n",
      "Epoch [2/10], Batch: 5160, Train Loss: 0.9116\n",
      "Epoch [2/10], Batch: 5170, Train Loss: 0.9081\n",
      "Epoch [2/10], Batch: 5180, Train Loss: 0.9225\n",
      "Epoch [2/10], Batch: 5190, Train Loss: 0.8731\n",
      "Epoch [2/10], Batch: 5200, Train Loss: 0.9165\n",
      "Epoch [2/10], Batch: 5210, Train Loss: 0.9481\n",
      "Epoch [2/10], Batch: 5220, Train Loss: 0.9899\n",
      "Epoch [2/10], Batch: 5230, Train Loss: 0.8271\n",
      "Epoch [2/10], Batch: 5240, Train Loss: 0.8876\n",
      "Epoch [2/10], Batch: 5250, Train Loss: 0.9935\n",
      "Epoch [2/10], Batch: 5260, Train Loss: 0.8910\n",
      "Epoch [2/10], Batch: 5270, Train Loss: 0.9161\n",
      "Epoch [2/10], Batch: 5280, Train Loss: 0.9402\n",
      "Epoch [2/10], Batch: 5290, Train Loss: 0.9595\n",
      "Epoch [2/10], Batch: 5300, Train Loss: 0.8776\n",
      "Epoch [2/10], Batch: 5310, Train Loss: 0.9217\n",
      "Epoch [2/10], Batch: 5320, Train Loss: 0.8885\n",
      "Epoch [2/10], Batch: 5330, Train Loss: 0.8558\n",
      "Epoch [2/10], Batch: 5340, Train Loss: 1.0205\n",
      "Epoch [2/10], Batch: 5350, Train Loss: 0.7974\n",
      "Epoch [2/10], Batch: 5360, Train Loss: 0.9293\n",
      "Epoch [2/10], Batch: 5370, Train Loss: 0.8670\n",
      "Epoch [2/10], Batch: 5380, Train Loss: 0.7935\n",
      "Epoch [2/10], Batch: 5390, Train Loss: 0.9772\n",
      "Epoch [2/10], Batch: 5400, Train Loss: 0.9638\n",
      "Epoch [2/10], Batch: 5410, Train Loss: 0.9525\n",
      "Epoch [2/10], Batch: 5420, Train Loss: 0.8619\n",
      "Epoch [2/10], Batch: 5430, Train Loss: 0.8843\n",
      "Epoch [2/10], Batch: 5440, Train Loss: 0.8983\n",
      "Epoch [2/10], Batch: 5450, Train Loss: 0.8641\n",
      "Epoch [2/10], Batch: 5460, Train Loss: 0.8427\n",
      "Epoch [2/10], Batch: 5470, Train Loss: 0.8715\n",
      "Epoch [2/10], Batch: 5480, Train Loss: 0.8465\n",
      "Epoch [2/10], Batch: 5490, Train Loss: 0.8434\n",
      "Epoch [2/10], Batch: 5500, Train Loss: 0.9945\n",
      "Epoch [2/10], Batch: 5510, Train Loss: 0.9278\n",
      "Epoch [2/10], Batch: 5520, Train Loss: 0.9627\n",
      "Epoch [2/10], Batch: 5530, Train Loss: 0.9756\n",
      "Epoch [2/10], Batch: 5540, Train Loss: 0.8688\n",
      "Epoch [2/10], Batch: 5550, Train Loss: 0.9467\n",
      "Epoch [2/10], Batch: 5560, Train Loss: 0.9172\n",
      "Epoch [2/10], Batch: 5570, Train Loss: 0.9004\n",
      "Epoch [2/10], Batch: 5580, Train Loss: 0.8163\n",
      "Epoch [2/10], Batch: 5590, Train Loss: 0.9026\n",
      "Epoch [2/10], Batch: 5600, Train Loss: 0.8222\n",
      "Epoch [2/10], Batch: 5610, Train Loss: 0.8376\n",
      "Epoch [2/10], Batch: 5620, Train Loss: 1.0378\n",
      "Epoch [2/10], Batch: 5630, Train Loss: 0.8803\n",
      "Epoch [2/10], Batch: 5640, Train Loss: 0.9083\n",
      "Epoch [2/10], Batch: 5650, Train Loss: 0.8749\n",
      "Epoch [2/10], Batch: 5660, Train Loss: 0.8751\n",
      "Epoch [2/10], Batch: 5670, Train Loss: 0.8836\n",
      "Epoch [2/10], Batch: 5680, Train Loss: 0.9097\n",
      "Epoch [2/10], Batch: 5690, Train Loss: 0.9449\n",
      "Epoch [2/10], Batch: 5700, Train Loss: 0.8029\n",
      "Epoch [2/10], Batch: 5710, Train Loss: 1.0111\n",
      "Epoch [2/10], Batch: 5720, Train Loss: 0.9517\n",
      "Epoch [2/10], Batch: 5730, Train Loss: 0.9209\n",
      "Epoch [2/10], Batch: 5740, Train Loss: 0.8826\n",
      "Epoch [2/10], Batch: 5750, Train Loss: 0.9150\n",
      "Epoch [2/10], Batch: 5760, Train Loss: 0.9961\n",
      "Epoch [2/10], Batch: 5770, Train Loss: 0.9815\n",
      "Epoch [2/10], Batch: 5780, Train Loss: 0.9617\n",
      "Epoch [2/10], Batch: 5790, Train Loss: 0.9075\n",
      "Epoch [2/10], Batch: 5800, Train Loss: 0.8912\n",
      "Epoch [2/10], Batch: 5810, Train Loss: 0.8625\n",
      "Epoch [2/10], Batch: 5820, Train Loss: 0.9481\n",
      "Epoch [2/10], Batch: 5830, Train Loss: 0.9388\n",
      "Epoch [2/10], Batch: 5840, Train Loss: 0.8955\n",
      "Epoch [2/10], Batch: 5850, Train Loss: 0.9016\n",
      "Epoch [2/10], Batch: 5860, Train Loss: 0.8424\n",
      "Epoch [2/10], Batch: 5870, Train Loss: 0.9159\n",
      "Epoch [2/10], Batch: 5880, Train Loss: 0.9481\n",
      "Epoch [2/10], Batch: 5890, Train Loss: 0.9134\n",
      "Epoch [2/10], Batch: 5900, Train Loss: 0.8643\n",
      "Epoch [2/10], Batch: 5910, Train Loss: 0.8604\n",
      "Epoch [2/10], Batch: 5920, Train Loss: 0.9933\n",
      "Epoch [2/10], Batch: 5930, Train Loss: 1.0096\n",
      "Epoch [2/10], Batch: 5940, Train Loss: 0.8401\n",
      "Epoch [2/10], Batch: 5950, Train Loss: 0.8088\n",
      "Epoch [2/10], Batch: 5960, Train Loss: 0.8728\n",
      "Epoch [2/10], Batch: 5970, Train Loss: 0.9417\n",
      "Epoch [2/10], Batch: 5980, Train Loss: 0.8124\n",
      "Epoch [2/10], Batch: 5990, Train Loss: 0.9860\n",
      "Epoch [2/10], Batch: 6000, Train Loss: 0.7211\n",
      "Epoch [2/10], Batch: 6010, Train Loss: 0.9562\n",
      "Epoch [2/10], Batch: 6020, Train Loss: 0.9136\n",
      "Epoch [2/10], Batch: 6030, Train Loss: 0.8639\n",
      "Epoch [2/10], Batch: 6040, Train Loss: 0.8861\n",
      "Epoch [2/10], Batch: 6050, Train Loss: 0.9127\n",
      "Epoch [2/10], Batch: 6060, Train Loss: 0.9650\n",
      "Epoch [2/10], Batch: 6070, Train Loss: 0.8688\n",
      "Epoch [2/10], Batch: 6080, Train Loss: 0.7659\n",
      "Epoch [2/10], Batch: 6090, Train Loss: 0.8362\n",
      "Epoch [2/10], Batch: 6100, Train Loss: 0.8643\n",
      "Epoch [2/10], Batch: 6110, Train Loss: 0.9031\n",
      "Epoch [2/10], Batch: 6120, Train Loss: 0.7587\n",
      "Epoch [2/10], Batch: 6130, Train Loss: 0.8919\n",
      "Epoch [2/10], Batch: 6140, Train Loss: 0.9115\n",
      "Epoch [2/10], Batch: 6150, Train Loss: 0.9690\n",
      "Epoch [2/10], Batch: 6160, Train Loss: 0.9237\n",
      "Epoch [2/10], Batch: 6170, Train Loss: 0.9390\n",
      "Epoch [2/10], Batch: 6180, Train Loss: 0.9810\n",
      "Epoch [2/10], Batch: 6190, Train Loss: 0.9251\n",
      "Epoch [2/10], Batch: 6200, Train Loss: 0.8759\n",
      "Epoch [2/10], Batch: 6210, Train Loss: 0.8499\n",
      "Epoch [2/10], Batch: 6220, Train Loss: 0.8320\n",
      "Epoch [2/10], Batch: 6230, Train Loss: 0.8640\n",
      "Epoch [2/10], Batch: 6240, Train Loss: 0.8596\n",
      "Epoch [2/10], Batch: 6250, Train Loss: 0.9272\n",
      "Epoch [2/10], Batch: 6260, Train Loss: 1.0430\n",
      "Epoch [2/10], Batch: 6270, Train Loss: 0.9340\n",
      "Epoch [2/10], Batch: 6280, Train Loss: 0.9476\n",
      "Epoch [2/10], Batch: 6290, Train Loss: 0.9067\n",
      "Epoch [2/10], Batch: 6300, Train Loss: 0.8252\n",
      "Epoch [2/10], Batch: 6310, Train Loss: 0.8821\n",
      "Epoch [2/10], Batch: 6320, Train Loss: 0.9467\n",
      "Epoch [2/10], Batch: 6330, Train Loss: 0.8845\n",
      "Epoch [2/10], Batch: 6340, Train Loss: 0.9949\n",
      "Epoch [2/10], Batch: 6350, Train Loss: 0.9362\n",
      "Epoch [2/10], Batch: 6360, Train Loss: 0.9437\n",
      "Epoch [2/10], Batch: 6370, Train Loss: 0.9048\n",
      "Epoch [2/10], Batch: 6380, Train Loss: 0.8710\n",
      "Epoch [2/10], Batch: 6390, Train Loss: 0.8603\n",
      "Epoch [2/10], Batch: 6400, Train Loss: 0.9392\n",
      "Epoch [2/10], Batch: 6410, Train Loss: 0.8409\n",
      "Epoch [2/10], Batch: 6420, Train Loss: 0.8919\n",
      "Epoch [2/10], Batch: 6430, Train Loss: 0.7779\n",
      "Epoch [2/10], Batch: 6440, Train Loss: 0.9012\n",
      "Epoch [2/10], Batch: 6450, Train Loss: 0.8524\n",
      "Epoch [2/10], Batch: 6460, Train Loss: 0.8771\n",
      "Epoch [2/10], Batch: 6470, Train Loss: 0.8640\n",
      "Epoch [2/10], Batch: 6480, Train Loss: 0.8747\n",
      "Epoch [2/10], Batch: 6490, Train Loss: 0.8451\n",
      "Epoch [2/10], Batch: 6500, Train Loss: 0.8513\n",
      "Epoch [2/10], Batch: 6510, Train Loss: 0.7776\n",
      "Epoch [2/10], Batch: 6520, Train Loss: 0.8438\n",
      "Epoch [2/10], Batch: 6530, Train Loss: 0.8697\n",
      "Epoch [2/10], Batch: 6540, Train Loss: 0.9189\n",
      "Epoch [2/10], Batch: 6550, Train Loss: 0.9087\n",
      "Epoch [2/10], Batch: 6560, Train Loss: 0.7987\n",
      "Epoch [2/10], Batch: 6570, Train Loss: 0.8583\n",
      "Epoch [2/10], Batch: 6580, Train Loss: 0.8424\n",
      "Epoch [2/10], Batch: 6590, Train Loss: 0.8485\n",
      "Epoch [2/10], Batch: 6600, Train Loss: 0.9290\n",
      "Epoch [2/10], Batch: 6610, Train Loss: 0.9169\n",
      "Epoch [2/10], Batch: 6620, Train Loss: 0.8011\n",
      "Epoch [2/10], Batch: 6630, Train Loss: 0.8898\n",
      "Epoch [2/10], Batch: 6640, Train Loss: 0.9916\n",
      "Epoch [2/10], Batch: 6650, Train Loss: 0.7908\n",
      "Epoch [2/10], Batch: 6660, Train Loss: 0.9718\n",
      "Epoch [2/10], Batch: 6670, Train Loss: 0.8293\n",
      "Epoch [2/10], Batch: 6680, Train Loss: 0.9300\n",
      "Epoch [2/10], Batch: 6690, Train Loss: 0.9004\n",
      "Epoch [2/10], Batch: 6700, Train Loss: 0.9634\n",
      "Epoch [2/10], Batch: 6710, Train Loss: 0.9691\n",
      "Epoch [2/10], Batch: 6720, Train Loss: 0.8308\n",
      "Epoch [2/10], Batch: 6730, Train Loss: 0.8640\n",
      "Epoch [2/10], Batch: 6740, Train Loss: 0.8424\n",
      "Epoch [2/10], Batch: 6750, Train Loss: 0.6971\n",
      "Epoch [2/10], Batch: 6760, Train Loss: 0.8963\n",
      "Epoch [3/10], Batch: 10, Train Loss: 0.8920\n",
      "Epoch [3/10], Batch: 20, Train Loss: 0.7322\n",
      "Epoch [3/10], Batch: 30, Train Loss: 0.7368\n",
      "Epoch [3/10], Batch: 40, Train Loss: 0.8254\n",
      "Epoch [3/10], Batch: 50, Train Loss: 0.9508\n",
      "Epoch [3/10], Batch: 60, Train Loss: 0.9373\n",
      "Epoch [3/10], Batch: 70, Train Loss: 0.9641\n",
      "Epoch [3/10], Batch: 80, Train Loss: 0.8666\n",
      "Epoch [3/10], Batch: 90, Train Loss: 0.8531\n",
      "Epoch [3/10], Batch: 100, Train Loss: 0.8137\n",
      "Epoch [3/10], Batch: 110, Train Loss: 0.9887\n",
      "Epoch [3/10], Batch: 120, Train Loss: 0.8300\n",
      "Epoch [3/10], Batch: 130, Train Loss: 1.0167\n",
      "Epoch [3/10], Batch: 140, Train Loss: 0.8852\n",
      "Epoch [3/10], Batch: 150, Train Loss: 0.7761\n",
      "Epoch [3/10], Batch: 160, Train Loss: 0.9024\n",
      "Epoch [3/10], Batch: 170, Train Loss: 0.8086\n",
      "Epoch [3/10], Batch: 180, Train Loss: 0.8109\n",
      "Epoch [3/10], Batch: 190, Train Loss: 0.8674\n",
      "Epoch [3/10], Batch: 200, Train Loss: 0.8100\n",
      "Epoch [3/10], Batch: 210, Train Loss: 0.8943\n",
      "Epoch [3/10], Batch: 220, Train Loss: 0.8292\n",
      "Epoch [3/10], Batch: 230, Train Loss: 0.9677\n",
      "Epoch [3/10], Batch: 240, Train Loss: 0.8531\n",
      "Epoch [3/10], Batch: 250, Train Loss: 0.8876\n",
      "Epoch [3/10], Batch: 260, Train Loss: 0.8317\n",
      "Epoch [3/10], Batch: 270, Train Loss: 0.9106\n",
      "Epoch [3/10], Batch: 280, Train Loss: 0.9235\n",
      "Epoch [3/10], Batch: 290, Train Loss: 0.8853\n",
      "Epoch [3/10], Batch: 300, Train Loss: 0.8824\n",
      "Epoch [3/10], Batch: 310, Train Loss: 0.9072\n",
      "Epoch [3/10], Batch: 320, Train Loss: 0.8052\n",
      "Epoch [3/10], Batch: 330, Train Loss: 0.8416\n",
      "Epoch [3/10], Batch: 340, Train Loss: 0.8770\n",
      "Epoch [3/10], Batch: 350, Train Loss: 0.8647\n",
      "Epoch [3/10], Batch: 360, Train Loss: 0.7920\n",
      "Epoch [3/10], Batch: 370, Train Loss: 0.8779\n",
      "Epoch [3/10], Batch: 380, Train Loss: 0.8948\n",
      "Epoch [3/10], Batch: 390, Train Loss: 0.8993\n",
      "Epoch [3/10], Batch: 400, Train Loss: 0.9094\n",
      "Epoch [3/10], Batch: 410, Train Loss: 0.9951\n",
      "Epoch [3/10], Batch: 420, Train Loss: 0.8775\n",
      "Epoch [3/10], Batch: 430, Train Loss: 0.8403\n",
      "Epoch [3/10], Batch: 440, Train Loss: 0.9066\n",
      "Epoch [3/10], Batch: 450, Train Loss: 0.9216\n",
      "Epoch [3/10], Batch: 460, Train Loss: 0.9079\n",
      "Epoch [3/10], Batch: 470, Train Loss: 0.8431\n",
      "Epoch [3/10], Batch: 480, Train Loss: 0.8304\n",
      "Epoch [3/10], Batch: 490, Train Loss: 0.8596\n",
      "Epoch [3/10], Batch: 500, Train Loss: 1.0621\n",
      "Epoch [3/10], Batch: 510, Train Loss: 0.8682\n",
      "Epoch [3/10], Batch: 520, Train Loss: 0.9304\n",
      "Epoch [3/10], Batch: 530, Train Loss: 0.8933\n",
      "Epoch [3/10], Batch: 540, Train Loss: 0.9056\n",
      "Epoch [3/10], Batch: 550, Train Loss: 0.9644\n",
      "Epoch [3/10], Batch: 560, Train Loss: 0.7849\n",
      "Epoch [3/10], Batch: 570, Train Loss: 0.9298\n",
      "Epoch [3/10], Batch: 580, Train Loss: 0.8428\n",
      "Epoch [3/10], Batch: 590, Train Loss: 0.9711\n",
      "Epoch [3/10], Batch: 600, Train Loss: 0.8696\n",
      "Epoch [3/10], Batch: 610, Train Loss: 0.8873\n",
      "Epoch [3/10], Batch: 620, Train Loss: 0.8391\n",
      "Epoch [3/10], Batch: 630, Train Loss: 0.8551\n",
      "Epoch [3/10], Batch: 640, Train Loss: 0.8914\n",
      "Epoch [3/10], Batch: 650, Train Loss: 0.8453\n",
      "Epoch [3/10], Batch: 660, Train Loss: 1.0200\n",
      "Epoch [3/10], Batch: 670, Train Loss: 0.8976\n",
      "Epoch [3/10], Batch: 680, Train Loss: 0.8560\n",
      "Epoch [3/10], Batch: 690, Train Loss: 0.8967\n",
      "Epoch [3/10], Batch: 700, Train Loss: 0.8059\n",
      "Epoch [3/10], Batch: 710, Train Loss: 0.8625\n",
      "Epoch [3/10], Batch: 720, Train Loss: 0.8567\n",
      "Epoch [3/10], Batch: 730, Train Loss: 0.9091\n",
      "Epoch [3/10], Batch: 740, Train Loss: 0.8220\n",
      "Epoch [3/10], Batch: 750, Train Loss: 0.7940\n",
      "Epoch [3/10], Batch: 760, Train Loss: 0.8861\n",
      "Epoch [3/10], Batch: 770, Train Loss: 0.8590\n",
      "Epoch [3/10], Batch: 780, Train Loss: 0.7933\n",
      "Epoch [3/10], Batch: 790, Train Loss: 0.9089\n",
      "Epoch [3/10], Batch: 800, Train Loss: 0.8546\n",
      "Epoch [3/10], Batch: 810, Train Loss: 0.8630\n",
      "Epoch [3/10], Batch: 820, Train Loss: 0.8949\n",
      "Epoch [3/10], Batch: 830, Train Loss: 0.9226\n",
      "Epoch [3/10], Batch: 840, Train Loss: 0.8781\n",
      "Epoch [3/10], Batch: 850, Train Loss: 0.8067\n",
      "Epoch [3/10], Batch: 860, Train Loss: 0.7566\n",
      "Epoch [3/10], Batch: 870, Train Loss: 0.8581\n",
      "Epoch [3/10], Batch: 880, Train Loss: 0.9353\n",
      "Epoch [3/10], Batch: 890, Train Loss: 0.8329\n",
      "Epoch [3/10], Batch: 900, Train Loss: 0.8608\n",
      "Epoch [3/10], Batch: 910, Train Loss: 0.8773\n",
      "Epoch [3/10], Batch: 920, Train Loss: 0.8564\n",
      "Epoch [3/10], Batch: 930, Train Loss: 0.8862\n",
      "Epoch [3/10], Batch: 940, Train Loss: 0.8593\n",
      "Epoch [3/10], Batch: 950, Train Loss: 0.8464\n",
      "Epoch [3/10], Batch: 960, Train Loss: 0.8828\n",
      "Epoch [3/10], Batch: 970, Train Loss: 0.7616\n",
      "Epoch [3/10], Batch: 980, Train Loss: 0.8999\n",
      "Epoch [3/10], Batch: 990, Train Loss: 0.9272\n",
      "Epoch [3/10], Batch: 1000, Train Loss: 0.9561\n",
      "Epoch [3/10], Batch: 1010, Train Loss: 0.8045\n",
      "Epoch [3/10], Batch: 1020, Train Loss: 0.8132\n",
      "Epoch [3/10], Batch: 1030, Train Loss: 0.9007\n",
      "Epoch [3/10], Batch: 1040, Train Loss: 0.8796\n",
      "Epoch [3/10], Batch: 1050, Train Loss: 0.8550\n",
      "Epoch [3/10], Batch: 1060, Train Loss: 0.9355\n",
      "Epoch [3/10], Batch: 1070, Train Loss: 0.8951\n",
      "Epoch [3/10], Batch: 1080, Train Loss: 0.7765\n",
      "Epoch [3/10], Batch: 1090, Train Loss: 0.8068\n",
      "Epoch [3/10], Batch: 1100, Train Loss: 0.7856\n",
      "Epoch [3/10], Batch: 1110, Train Loss: 0.9282\n",
      "Epoch [3/10], Batch: 1120, Train Loss: 0.7809\n",
      "Epoch [3/10], Batch: 1130, Train Loss: 0.8612\n",
      "Epoch [3/10], Batch: 1140, Train Loss: 0.8923\n",
      "Epoch [3/10], Batch: 1150, Train Loss: 0.9295\n",
      "Epoch [3/10], Batch: 1160, Train Loss: 0.7684\n",
      "Epoch [3/10], Batch: 1170, Train Loss: 0.8873\n",
      "Epoch [3/10], Batch: 1180, Train Loss: 0.9576\n",
      "Epoch [3/10], Batch: 1190, Train Loss: 0.8549\n",
      "Epoch [3/10], Batch: 1200, Train Loss: 0.8962\n",
      "Epoch [3/10], Batch: 1210, Train Loss: 0.8217\n",
      "Epoch [3/10], Batch: 1220, Train Loss: 0.8601\n",
      "Epoch [3/10], Batch: 1230, Train Loss: 0.8813\n",
      "Epoch [3/10], Batch: 1240, Train Loss: 0.8334\n",
      "Epoch [3/10], Batch: 1250, Train Loss: 0.8300\n",
      "Epoch [3/10], Batch: 1260, Train Loss: 0.9086\n",
      "Epoch [3/10], Batch: 1270, Train Loss: 0.9520\n",
      "Epoch [3/10], Batch: 1280, Train Loss: 0.8579\n",
      "Epoch [3/10], Batch: 1290, Train Loss: 0.8697\n",
      "Epoch [3/10], Batch: 1300, Train Loss: 0.8356\n",
      "Epoch [3/10], Batch: 1310, Train Loss: 0.8330\n",
      "Epoch [3/10], Batch: 1320, Train Loss: 0.8961\n",
      "Epoch [3/10], Batch: 1330, Train Loss: 0.9930\n",
      "Epoch [3/10], Batch: 1340, Train Loss: 0.9216\n",
      "Epoch [3/10], Batch: 1350, Train Loss: 0.7919\n",
      "Epoch [3/10], Batch: 1360, Train Loss: 0.8540\n",
      "Epoch [3/10], Batch: 1370, Train Loss: 0.9925\n",
      "Epoch [3/10], Batch: 1380, Train Loss: 0.7997\n",
      "Epoch [3/10], Batch: 1390, Train Loss: 0.8968\n",
      "Epoch [3/10], Batch: 1400, Train Loss: 0.7908\n",
      "Epoch [3/10], Batch: 1410, Train Loss: 1.0150\n",
      "Epoch [3/10], Batch: 1420, Train Loss: 0.9209\n",
      "Epoch [3/10], Batch: 1430, Train Loss: 0.9981\n",
      "Epoch [3/10], Batch: 1440, Train Loss: 0.8414\n",
      "Epoch [3/10], Batch: 1450, Train Loss: 0.9218\n",
      "Epoch [3/10], Batch: 1460, Train Loss: 0.8329\n",
      "Epoch [3/10], Batch: 1470, Train Loss: 0.9246\n",
      "Epoch [3/10], Batch: 1480, Train Loss: 0.8985\n",
      "Epoch [3/10], Batch: 1490, Train Loss: 0.7903\n",
      "Epoch [3/10], Batch: 1500, Train Loss: 0.9007\n",
      "Epoch [3/10], Batch: 1510, Train Loss: 0.9168\n",
      "Epoch [3/10], Batch: 1520, Train Loss: 0.8135\n",
      "Epoch [3/10], Batch: 1530, Train Loss: 0.6941\n",
      "Epoch [3/10], Batch: 1540, Train Loss: 0.8531\n",
      "Epoch [3/10], Batch: 1550, Train Loss: 0.8621\n",
      "Epoch [3/10], Batch: 1560, Train Loss: 0.8354\n",
      "Epoch [3/10], Batch: 1570, Train Loss: 0.8549\n",
      "Epoch [3/10], Batch: 1580, Train Loss: 0.9383\n",
      "Epoch [3/10], Batch: 1590, Train Loss: 0.7783\n",
      "Epoch [3/10], Batch: 1600, Train Loss: 0.8915\n",
      "Epoch [3/10], Batch: 1610, Train Loss: 0.8811\n",
      "Epoch [3/10], Batch: 1620, Train Loss: 0.8271\n",
      "Epoch [3/10], Batch: 1630, Train Loss: 0.9845\n",
      "Epoch [3/10], Batch: 1640, Train Loss: 0.7411\n",
      "Epoch [3/10], Batch: 1650, Train Loss: 0.9399\n",
      "Epoch [3/10], Batch: 1660, Train Loss: 0.8263\n",
      "Epoch [3/10], Batch: 1670, Train Loss: 0.9237\n",
      "Epoch [3/10], Batch: 1680, Train Loss: 0.8055\n",
      "Epoch [3/10], Batch: 1690, Train Loss: 0.9742\n",
      "Epoch [3/10], Batch: 1700, Train Loss: 0.8094\n",
      "Epoch [3/10], Batch: 1710, Train Loss: 0.8403\n",
      "Epoch [3/10], Batch: 1720, Train Loss: 0.9060\n",
      "Epoch [3/10], Batch: 1730, Train Loss: 0.7932\n",
      "Epoch [3/10], Batch: 1740, Train Loss: 0.8235\n",
      "Epoch [3/10], Batch: 1750, Train Loss: 0.8491\n",
      "Epoch [3/10], Batch: 1760, Train Loss: 0.8837\n",
      "Epoch [3/10], Batch: 1770, Train Loss: 0.8633\n",
      "Epoch [3/10], Batch: 1780, Train Loss: 0.8218\n",
      "Epoch [3/10], Batch: 1790, Train Loss: 0.8532\n",
      "Epoch [3/10], Batch: 1800, Train Loss: 0.8956\n",
      "Epoch [3/10], Batch: 1810, Train Loss: 0.8081\n",
      "Epoch [3/10], Batch: 1820, Train Loss: 0.9177\n",
      "Epoch [3/10], Batch: 1830, Train Loss: 0.8584\n",
      "Epoch [3/10], Batch: 1840, Train Loss: 0.8935\n",
      "Epoch [3/10], Batch: 1850, Train Loss: 0.8407\n",
      "Epoch [3/10], Batch: 1860, Train Loss: 0.9165\n",
      "Epoch [3/10], Batch: 1870, Train Loss: 0.9460\n",
      "Epoch [3/10], Batch: 1880, Train Loss: 0.8553\n",
      "Epoch [3/10], Batch: 1890, Train Loss: 0.8879\n",
      "Epoch [3/10], Batch: 1900, Train Loss: 0.8778\n",
      "Epoch [3/10], Batch: 1910, Train Loss: 0.8025\n",
      "Epoch [3/10], Batch: 1920, Train Loss: 0.8861\n",
      "Epoch [3/10], Batch: 1930, Train Loss: 0.8863\n",
      "Epoch [3/10], Batch: 1940, Train Loss: 0.8430\n",
      "Epoch [3/10], Batch: 1950, Train Loss: 0.8826\n",
      "Epoch [3/10], Batch: 1960, Train Loss: 0.7463\n",
      "Epoch [3/10], Batch: 1970, Train Loss: 0.9323\n",
      "Epoch [3/10], Batch: 1980, Train Loss: 0.7533\n",
      "Epoch [3/10], Batch: 1990, Train Loss: 0.8058\n",
      "Epoch [3/10], Batch: 2000, Train Loss: 0.8178\n",
      "Epoch [3/10], Batch: 2010, Train Loss: 0.8870\n",
      "Epoch [3/10], Batch: 2020, Train Loss: 0.8620\n",
      "Epoch [3/10], Batch: 2030, Train Loss: 0.8817\n",
      "Epoch [3/10], Batch: 2040, Train Loss: 0.8853\n",
      "Epoch [3/10], Batch: 2050, Train Loss: 0.8688\n",
      "Epoch [3/10], Batch: 2060, Train Loss: 0.8725\n",
      "Epoch [3/10], Batch: 2070, Train Loss: 0.8038\n",
      "Epoch [3/10], Batch: 2080, Train Loss: 0.8180\n",
      "Epoch [3/10], Batch: 2090, Train Loss: 0.8239\n",
      "Epoch [3/10], Batch: 2100, Train Loss: 0.9075\n",
      "Epoch [3/10], Batch: 2110, Train Loss: 0.9647\n",
      "Epoch [3/10], Batch: 2120, Train Loss: 0.8699\n",
      "Epoch [3/10], Batch: 2130, Train Loss: 0.9441\n",
      "Epoch [3/10], Batch: 2140, Train Loss: 0.9183\n",
      "Epoch [3/10], Batch: 2150, Train Loss: 0.8916\n",
      "Epoch [3/10], Batch: 2160, Train Loss: 0.9132\n",
      "Epoch [3/10], Batch: 2170, Train Loss: 0.8000\n",
      "Epoch [3/10], Batch: 2180, Train Loss: 0.8205\n",
      "Epoch [3/10], Batch: 2190, Train Loss: 0.7113\n",
      "Epoch [3/10], Batch: 2200, Train Loss: 0.8867\n",
      "Epoch [3/10], Batch: 2210, Train Loss: 0.8931\n",
      "Epoch [3/10], Batch: 2220, Train Loss: 0.8575\n",
      "Epoch [3/10], Batch: 2230, Train Loss: 0.8778\n",
      "Epoch [3/10], Batch: 2240, Train Loss: 0.9484\n",
      "Epoch [3/10], Batch: 2250, Train Loss: 0.8964\n",
      "Epoch [3/10], Batch: 2260, Train Loss: 0.8966\n",
      "Epoch [3/10], Batch: 2270, Train Loss: 0.8514\n",
      "Epoch [3/10], Batch: 2280, Train Loss: 0.7632\n",
      "Epoch [3/10], Batch: 2290, Train Loss: 0.9999\n",
      "Epoch [3/10], Batch: 2300, Train Loss: 0.7682\n",
      "Epoch [3/10], Batch: 2310, Train Loss: 0.8357\n",
      "Epoch [3/10], Batch: 2320, Train Loss: 0.8774\n",
      "Epoch [3/10], Batch: 2330, Train Loss: 0.9619\n",
      "Epoch [3/10], Batch: 2340, Train Loss: 0.9604\n",
      "Epoch [3/10], Batch: 2350, Train Loss: 0.8426\n",
      "Epoch [3/10], Batch: 2360, Train Loss: 0.9117\n",
      "Epoch [3/10], Batch: 2370, Train Loss: 0.9644\n",
      "Epoch [3/10], Batch: 2380, Train Loss: 0.9341\n",
      "Epoch [3/10], Batch: 2390, Train Loss: 0.6742\n",
      "Epoch [3/10], Batch: 2400, Train Loss: 0.8992\n",
      "Epoch [3/10], Batch: 2410, Train Loss: 0.8748\n",
      "Epoch [3/10], Batch: 2420, Train Loss: 0.8196\n",
      "Epoch [3/10], Batch: 2430, Train Loss: 0.8890\n",
      "Epoch [3/10], Batch: 2440, Train Loss: 0.9049\n",
      "Epoch [3/10], Batch: 2450, Train Loss: 0.8798\n",
      "Epoch [3/10], Batch: 2460, Train Loss: 0.9016\n",
      "Epoch [3/10], Batch: 2470, Train Loss: 0.8785\n",
      "Epoch [3/10], Batch: 2480, Train Loss: 0.7681\n",
      "Epoch [3/10], Batch: 2490, Train Loss: 0.9120\n",
      "Epoch [3/10], Batch: 2500, Train Loss: 0.8490\n",
      "Epoch [3/10], Batch: 2510, Train Loss: 0.8851\n",
      "Epoch [3/10], Batch: 2520, Train Loss: 0.8370\n",
      "Epoch [3/10], Batch: 2530, Train Loss: 0.8901\n",
      "Epoch [3/10], Batch: 2540, Train Loss: 0.9686\n",
      "Epoch [3/10], Batch: 2550, Train Loss: 0.7928\n",
      "Epoch [3/10], Batch: 2560, Train Loss: 0.9094\n",
      "Epoch [3/10], Batch: 2570, Train Loss: 0.7674\n",
      "Epoch [3/10], Batch: 2580, Train Loss: 0.7611\n",
      "Epoch [3/10], Batch: 2590, Train Loss: 0.9001\n",
      "Epoch [3/10], Batch: 2600, Train Loss: 0.9130\n",
      "Epoch [3/10], Batch: 2610, Train Loss: 0.8011\n",
      "Epoch [3/10], Batch: 2620, Train Loss: 0.8642\n",
      "Epoch [3/10], Batch: 2630, Train Loss: 0.9137\n",
      "Epoch [3/10], Batch: 2640, Train Loss: 0.7777\n",
      "Epoch [3/10], Batch: 2650, Train Loss: 0.8992\n",
      "Epoch [3/10], Batch: 2660, Train Loss: 0.8939\n",
      "Epoch [3/10], Batch: 2670, Train Loss: 0.8656\n",
      "Epoch [3/10], Batch: 2680, Train Loss: 0.8780\n",
      "Epoch [3/10], Batch: 2690, Train Loss: 0.7650\n",
      "Epoch [3/10], Batch: 2700, Train Loss: 0.9041\n",
      "Epoch [3/10], Batch: 2710, Train Loss: 0.8115\n",
      "Epoch [3/10], Batch: 2720, Train Loss: 0.8709\n",
      "Epoch [3/10], Batch: 2730, Train Loss: 0.8911\n",
      "Epoch [3/10], Batch: 2740, Train Loss: 0.9558\n",
      "Epoch [3/10], Batch: 2750, Train Loss: 0.8930\n",
      "Epoch [3/10], Batch: 2760, Train Loss: 0.7668\n",
      "Epoch [3/10], Batch: 2770, Train Loss: 0.7804\n",
      "Epoch [3/10], Batch: 2780, Train Loss: 0.8015\n",
      "Epoch [3/10], Batch: 2790, Train Loss: 0.8300\n",
      "Epoch [3/10], Batch: 2800, Train Loss: 0.8014\n",
      "Epoch [3/10], Batch: 2810, Train Loss: 0.9320\n",
      "Epoch [3/10], Batch: 2820, Train Loss: 0.7996\n",
      "Epoch [3/10], Batch: 2830, Train Loss: 0.9425\n",
      "Epoch [3/10], Batch: 2840, Train Loss: 0.7808\n",
      "Epoch [3/10], Batch: 2850, Train Loss: 0.9221\n",
      "Epoch [3/10], Batch: 2860, Train Loss: 0.9058\n",
      "Epoch [3/10], Batch: 2870, Train Loss: 0.7866\n",
      "Epoch [3/10], Batch: 2880, Train Loss: 1.0152\n",
      "Epoch [3/10], Batch: 2890, Train Loss: 0.8487\n",
      "Epoch [3/10], Batch: 2900, Train Loss: 0.8956\n",
      "Epoch [3/10], Batch: 2910, Train Loss: 0.8505\n",
      "Epoch [3/10], Batch: 2920, Train Loss: 0.8814\n",
      "Epoch [3/10], Batch: 2930, Train Loss: 0.8605\n",
      "Epoch [3/10], Batch: 2940, Train Loss: 0.9566\n",
      "Epoch [3/10], Batch: 2950, Train Loss: 0.7708\n",
      "Epoch [3/10], Batch: 2960, Train Loss: 0.9483\n",
      "Epoch [3/10], Batch: 2970, Train Loss: 0.8769\n",
      "Epoch [3/10], Batch: 2980, Train Loss: 0.7583\n",
      "Epoch [3/10], Batch: 2990, Train Loss: 0.7713\n",
      "Epoch [3/10], Batch: 3000, Train Loss: 0.8919\n",
      "Epoch [3/10], Batch: 3010, Train Loss: 0.8439\n",
      "Epoch [3/10], Batch: 3020, Train Loss: 0.9481\n",
      "Epoch [3/10], Batch: 3030, Train Loss: 0.7926\n",
      "Epoch [3/10], Batch: 3040, Train Loss: 0.8420\n",
      "Epoch [3/10], Batch: 3050, Train Loss: 0.9027\n",
      "Epoch [3/10], Batch: 3060, Train Loss: 0.7991\n",
      "Epoch [3/10], Batch: 3070, Train Loss: 0.9445\n",
      "Epoch [3/10], Batch: 3080, Train Loss: 0.9398\n",
      "Epoch [3/10], Batch: 3090, Train Loss: 0.8734\n",
      "Epoch [3/10], Batch: 3100, Train Loss: 0.8238\n",
      "Epoch [3/10], Batch: 3110, Train Loss: 0.7614\n",
      "Epoch [3/10], Batch: 3120, Train Loss: 0.8626\n",
      "Epoch [3/10], Batch: 3130, Train Loss: 0.8622\n",
      "Epoch [3/10], Batch: 3140, Train Loss: 0.8829\n",
      "Epoch [3/10], Batch: 3150, Train Loss: 0.8500\n",
      "Epoch [3/10], Batch: 3160, Train Loss: 0.9259\n",
      "Epoch [3/10], Batch: 3170, Train Loss: 0.8091\n",
      "Epoch [3/10], Batch: 3180, Train Loss: 0.9107\n",
      "Epoch [3/10], Batch: 3190, Train Loss: 0.7006\n",
      "Epoch [3/10], Batch: 3200, Train Loss: 1.0555\n",
      "Epoch [3/10], Batch: 3210, Train Loss: 0.9015\n",
      "Epoch [3/10], Batch: 3220, Train Loss: 0.9530\n",
      "Epoch [3/10], Batch: 3230, Train Loss: 0.8248\n",
      "Epoch [3/10], Batch: 3240, Train Loss: 0.8547\n",
      "Epoch [3/10], Batch: 3250, Train Loss: 0.7986\n",
      "Epoch [3/10], Batch: 3260, Train Loss: 0.8773\n",
      "Epoch [3/10], Batch: 3270, Train Loss: 0.9017\n",
      "Epoch [3/10], Batch: 3280, Train Loss: 0.8842\n",
      "Epoch [3/10], Batch: 3290, Train Loss: 0.8233\n",
      "Epoch [3/10], Batch: 3300, Train Loss: 0.8373\n",
      "Epoch [3/10], Batch: 3310, Train Loss: 0.9290\n",
      "Epoch [3/10], Batch: 3320, Train Loss: 0.8734\n",
      "Epoch [3/10], Batch: 3330, Train Loss: 0.6727\n",
      "Epoch [3/10], Batch: 3340, Train Loss: 0.9198\n",
      "Epoch [3/10], Batch: 3350, Train Loss: 0.8116\n",
      "Epoch [3/10], Batch: 3360, Train Loss: 0.7745\n",
      "Epoch [3/10], Batch: 3370, Train Loss: 0.8449\n",
      "Epoch [3/10], Batch: 3380, Train Loss: 0.8119\n",
      "Epoch [3/10], Batch: 3390, Train Loss: 0.8038\n",
      "Epoch [3/10], Batch: 3400, Train Loss: 0.8188\n",
      "Epoch [3/10], Batch: 3410, Train Loss: 0.8787\n",
      "Epoch [3/10], Batch: 3420, Train Loss: 0.8040\n",
      "Epoch [3/10], Batch: 3430, Train Loss: 0.9537\n",
      "Epoch [3/10], Batch: 3440, Train Loss: 0.9171\n",
      "Epoch [3/10], Batch: 3450, Train Loss: 0.8231\n",
      "Epoch [3/10], Batch: 3460, Train Loss: 0.8801\n",
      "Epoch [3/10], Batch: 3470, Train Loss: 0.8128\n",
      "Epoch [3/10], Batch: 3480, Train Loss: 0.8362\n",
      "Epoch [3/10], Batch: 3490, Train Loss: 0.8309\n",
      "Epoch [3/10], Batch: 3500, Train Loss: 0.8778\n",
      "Epoch [3/10], Batch: 3510, Train Loss: 0.9456\n",
      "Epoch [3/10], Batch: 3520, Train Loss: 0.8677\n",
      "Epoch [3/10], Batch: 3530, Train Loss: 0.8383\n",
      "Epoch [3/10], Batch: 3540, Train Loss: 0.8093\n",
      "Epoch [3/10], Batch: 3550, Train Loss: 0.7777\n",
      "Epoch [3/10], Batch: 3560, Train Loss: 0.9516\n",
      "Epoch [3/10], Batch: 3570, Train Loss: 0.8473\n",
      "Epoch [3/10], Batch: 3580, Train Loss: 0.8498\n",
      "Epoch [3/10], Batch: 3590, Train Loss: 0.9105\n",
      "Epoch [3/10], Batch: 3600, Train Loss: 0.8556\n",
      "Epoch [3/10], Batch: 3610, Train Loss: 0.6812\n",
      "Epoch [3/10], Batch: 3620, Train Loss: 0.9371\n",
      "Epoch [3/10], Batch: 3630, Train Loss: 1.0079\n",
      "Epoch [3/10], Batch: 3640, Train Loss: 0.8339\n",
      "Epoch [3/10], Batch: 3650, Train Loss: 0.7895\n",
      "Epoch [3/10], Batch: 3660, Train Loss: 0.8739\n",
      "Epoch [3/10], Batch: 3670, Train Loss: 0.9144\n",
      "Epoch [3/10], Batch: 3680, Train Loss: 0.9218\n",
      "Epoch [3/10], Batch: 3690, Train Loss: 0.8229\n",
      "Epoch [3/10], Batch: 3700, Train Loss: 0.9589\n",
      "Epoch [3/10], Batch: 3710, Train Loss: 0.9933\n",
      "Epoch [3/10], Batch: 3720, Train Loss: 0.8987\n",
      "Epoch [3/10], Batch: 3730, Train Loss: 0.8762\n",
      "Epoch [3/10], Batch: 3740, Train Loss: 0.8115\n",
      "Epoch [3/10], Batch: 3750, Train Loss: 0.7309\n",
      "Epoch [3/10], Batch: 3760, Train Loss: 0.7261\n",
      "Epoch [3/10], Batch: 3770, Train Loss: 0.8091\n",
      "Epoch [3/10], Batch: 3780, Train Loss: 0.8697\n",
      "Epoch [3/10], Batch: 3790, Train Loss: 0.8478\n",
      "Epoch [3/10], Batch: 3800, Train Loss: 0.7688\n",
      "Epoch [3/10], Batch: 3810, Train Loss: 0.7089\n",
      "Epoch [3/10], Batch: 3820, Train Loss: 0.8655\n",
      "Epoch [3/10], Batch: 3830, Train Loss: 0.7431\n",
      "Epoch [3/10], Batch: 3840, Train Loss: 0.8339\n",
      "Epoch [3/10], Batch: 3850, Train Loss: 0.9237\n",
      "Epoch [3/10], Batch: 3860, Train Loss: 0.9079\n",
      "Epoch [3/10], Batch: 3870, Train Loss: 0.9465\n",
      "Epoch [3/10], Batch: 3880, Train Loss: 0.8770\n",
      "Epoch [3/10], Batch: 3890, Train Loss: 0.8337\n",
      "Epoch [3/10], Batch: 3900, Train Loss: 0.8171\n",
      "Epoch [3/10], Batch: 3910, Train Loss: 0.8924\n",
      "Epoch [3/10], Batch: 3920, Train Loss: 0.8044\n",
      "Epoch [3/10], Batch: 3930, Train Loss: 0.7598\n",
      "Epoch [3/10], Batch: 3940, Train Loss: 0.7710\n",
      "Epoch [3/10], Batch: 3950, Train Loss: 0.8647\n",
      "Epoch [3/10], Batch: 3960, Train Loss: 0.9310\n",
      "Epoch [3/10], Batch: 3970, Train Loss: 0.8385\n",
      "Epoch [3/10], Batch: 3980, Train Loss: 0.8541\n",
      "Epoch [3/10], Batch: 3990, Train Loss: 0.9007\n",
      "Epoch [3/10], Batch: 4000, Train Loss: 0.8470\n",
      "Epoch [3/10], Batch: 4010, Train Loss: 0.8617\n",
      "Epoch [3/10], Batch: 4020, Train Loss: 0.8940\n",
      "Epoch [3/10], Batch: 4030, Train Loss: 0.8905\n",
      "Epoch [3/10], Batch: 4040, Train Loss: 0.8405\n",
      "Epoch [3/10], Batch: 4050, Train Loss: 0.7462\n",
      "Epoch [3/10], Batch: 4060, Train Loss: 0.7945\n",
      "Epoch [3/10], Batch: 4070, Train Loss: 0.8691\n",
      "Epoch [3/10], Batch: 4080, Train Loss: 0.8596\n",
      "Epoch [3/10], Batch: 4090, Train Loss: 0.8613\n",
      "Epoch [3/10], Batch: 4100, Train Loss: 0.8729\n",
      "Epoch [3/10], Batch: 4110, Train Loss: 0.8646\n",
      "Epoch [3/10], Batch: 4120, Train Loss: 0.8408\n",
      "Epoch [3/10], Batch: 4130, Train Loss: 0.9443\n",
      "Epoch [3/10], Batch: 4140, Train Loss: 0.9312\n",
      "Epoch [3/10], Batch: 4150, Train Loss: 0.7720\n",
      "Epoch [3/10], Batch: 4160, Train Loss: 0.7413\n",
      "Epoch [3/10], Batch: 4170, Train Loss: 0.8008\n",
      "Epoch [3/10], Batch: 4180, Train Loss: 0.7174\n",
      "Epoch [3/10], Batch: 4190, Train Loss: 0.9173\n",
      "Epoch [3/10], Batch: 4200, Train Loss: 0.8088\n",
      "Epoch [3/10], Batch: 4210, Train Loss: 0.9036\n",
      "Epoch [3/10], Batch: 4220, Train Loss: 0.8661\n",
      "Epoch [3/10], Batch: 4230, Train Loss: 0.9616\n",
      "Epoch [3/10], Batch: 4240, Train Loss: 0.7980\n",
      "Epoch [3/10], Batch: 4250, Train Loss: 0.8223\n",
      "Epoch [3/10], Batch: 4260, Train Loss: 0.9300\n",
      "Epoch [3/10], Batch: 4270, Train Loss: 1.0165\n",
      "Epoch [3/10], Batch: 4280, Train Loss: 0.8587\n",
      "Epoch [3/10], Batch: 4290, Train Loss: 0.9090\n",
      "Epoch [3/10], Batch: 4300, Train Loss: 0.8464\n",
      "Epoch [3/10], Batch: 4310, Train Loss: 0.8289\n",
      "Epoch [3/10], Batch: 4320, Train Loss: 0.8763\n",
      "Epoch [3/10], Batch: 4330, Train Loss: 0.8637\n",
      "Epoch [3/10], Batch: 4340, Train Loss: 0.8609\n",
      "Epoch [3/10], Batch: 4350, Train Loss: 0.8008\n",
      "Epoch [3/10], Batch: 4360, Train Loss: 0.8011\n",
      "Epoch [3/10], Batch: 4370, Train Loss: 0.9215\n",
      "Epoch [3/10], Batch: 4380, Train Loss: 0.8631\n",
      "Epoch [3/10], Batch: 4390, Train Loss: 0.9153\n",
      "Epoch [3/10], Batch: 4400, Train Loss: 0.7972\n",
      "Epoch [3/10], Batch: 4410, Train Loss: 0.7998\n",
      "Epoch [3/10], Batch: 4420, Train Loss: 0.9419\n",
      "Epoch [3/10], Batch: 4430, Train Loss: 0.9132\n",
      "Epoch [3/10], Batch: 4440, Train Loss: 0.9001\n",
      "Epoch [3/10], Batch: 4450, Train Loss: 0.8137\n",
      "Epoch [3/10], Batch: 4460, Train Loss: 0.8011\n",
      "Epoch [3/10], Batch: 4470, Train Loss: 0.8528\n",
      "Epoch [3/10], Batch: 4480, Train Loss: 0.8859\n",
      "Epoch [3/10], Batch: 4490, Train Loss: 0.9072\n",
      "Epoch [3/10], Batch: 4500, Train Loss: 0.8894\n",
      "Epoch [3/10], Batch: 4510, Train Loss: 0.7846\n",
      "Epoch [3/10], Batch: 4520, Train Loss: 0.8679\n",
      "Epoch [3/10], Batch: 4530, Train Loss: 0.7224\n",
      "Epoch [3/10], Batch: 4540, Train Loss: 0.8522\n",
      "Epoch [3/10], Batch: 4550, Train Loss: 0.7788\n",
      "Epoch [3/10], Batch: 4560, Train Loss: 0.8716\n",
      "Epoch [3/10], Batch: 4570, Train Loss: 0.7813\n",
      "Epoch [3/10], Batch: 4580, Train Loss: 0.8118\n",
      "Epoch [3/10], Batch: 4590, Train Loss: 0.7484\n",
      "Epoch [3/10], Batch: 4600, Train Loss: 0.7971\n",
      "Epoch [3/10], Batch: 4610, Train Loss: 0.8406\n",
      "Epoch [3/10], Batch: 4620, Train Loss: 0.8756\n",
      "Epoch [3/10], Batch: 4630, Train Loss: 0.8095\n",
      "Epoch [3/10], Batch: 4640, Train Loss: 0.8778\n",
      "Epoch [3/10], Batch: 4650, Train Loss: 0.8181\n",
      "Epoch [3/10], Batch: 4660, Train Loss: 0.8415\n",
      "Epoch [3/10], Batch: 4670, Train Loss: 0.9543\n",
      "Epoch [3/10], Batch: 4680, Train Loss: 0.7779\n",
      "Epoch [3/10], Batch: 4690, Train Loss: 0.9106\n",
      "Epoch [3/10], Batch: 4700, Train Loss: 1.0191\n",
      "Epoch [3/10], Batch: 4710, Train Loss: 0.8451\n",
      "Epoch [3/10], Batch: 4720, Train Loss: 0.8519\n",
      "Epoch [3/10], Batch: 4730, Train Loss: 0.9453\n",
      "Epoch [3/10], Batch: 4740, Train Loss: 0.7242\n",
      "Epoch [3/10], Batch: 4750, Train Loss: 0.8176\n",
      "Epoch [3/10], Batch: 4760, Train Loss: 0.8728\n",
      "Epoch [3/10], Batch: 4770, Train Loss: 0.8272\n",
      "Epoch [3/10], Batch: 4780, Train Loss: 0.8361\n",
      "Epoch [3/10], Batch: 4790, Train Loss: 0.9156\n",
      "Epoch [3/10], Batch: 4800, Train Loss: 0.8889\n",
      "Epoch [3/10], Batch: 4810, Train Loss: 0.7744\n",
      "Epoch [3/10], Batch: 4820, Train Loss: 0.9409\n",
      "Epoch [3/10], Batch: 4830, Train Loss: 0.7787\n",
      "Epoch [3/10], Batch: 4840, Train Loss: 0.9233\n",
      "Epoch [3/10], Batch: 4850, Train Loss: 0.8048\n",
      "Epoch [3/10], Batch: 4860, Train Loss: 0.9412\n",
      "Epoch [3/10], Batch: 4870, Train Loss: 0.8059\n",
      "Epoch [3/10], Batch: 4880, Train Loss: 0.8780\n",
      "Epoch [3/10], Batch: 4890, Train Loss: 0.8826\n",
      "Epoch [3/10], Batch: 4900, Train Loss: 0.9804\n",
      "Epoch [3/10], Batch: 4910, Train Loss: 0.7999\n",
      "Epoch [3/10], Batch: 4920, Train Loss: 0.7543\n",
      "Epoch [3/10], Batch: 4930, Train Loss: 0.9686\n",
      "Epoch [3/10], Batch: 4940, Train Loss: 0.8572\n",
      "Epoch [3/10], Batch: 4950, Train Loss: 0.8718\n",
      "Epoch [3/10], Batch: 4960, Train Loss: 0.7531\n",
      "Epoch [3/10], Batch: 4970, Train Loss: 0.8672\n",
      "Epoch [3/10], Batch: 4980, Train Loss: 0.8958\n",
      "Epoch [3/10], Batch: 4990, Train Loss: 0.7967\n",
      "Epoch [3/10], Batch: 5000, Train Loss: 0.6986\n",
      "Epoch [3/10], Batch: 5010, Train Loss: 0.9012\n",
      "Epoch [3/10], Batch: 5020, Train Loss: 0.8431\n",
      "Epoch [3/10], Batch: 5030, Train Loss: 0.8099\n",
      "Epoch [3/10], Batch: 5040, Train Loss: 0.9383\n",
      "Epoch [3/10], Batch: 5050, Train Loss: 0.8401\n",
      "Epoch [3/10], Batch: 5060, Train Loss: 0.8667\n",
      "Epoch [3/10], Batch: 5070, Train Loss: 0.7961\n",
      "Epoch [3/10], Batch: 5080, Train Loss: 0.8533\n",
      "Epoch [3/10], Batch: 5090, Train Loss: 0.8140\n",
      "Epoch [3/10], Batch: 5100, Train Loss: 0.8162\n",
      "Epoch [3/10], Batch: 5110, Train Loss: 0.7962\n",
      "Epoch [3/10], Batch: 5120, Train Loss: 0.7132\n",
      "Epoch [3/10], Batch: 5130, Train Loss: 0.8411\n",
      "Epoch [3/10], Batch: 5140, Train Loss: 0.9632\n",
      "Epoch [3/10], Batch: 5150, Train Loss: 0.7662\n",
      "Epoch [3/10], Batch: 5160, Train Loss: 0.8907\n",
      "Epoch [3/10], Batch: 5170, Train Loss: 0.8181\n",
      "Epoch [3/10], Batch: 5180, Train Loss: 0.8864\n",
      "Epoch [3/10], Batch: 5190, Train Loss: 0.8200\n",
      "Epoch [3/10], Batch: 5200, Train Loss: 0.8305\n",
      "Epoch [3/10], Batch: 5210, Train Loss: 0.8748\n",
      "Epoch [3/10], Batch: 5220, Train Loss: 0.9555\n",
      "Epoch [3/10], Batch: 5230, Train Loss: 0.7392\n",
      "Epoch [3/10], Batch: 5240, Train Loss: 0.8253\n",
      "Epoch [3/10], Batch: 5250, Train Loss: 1.0187\n",
      "Epoch [3/10], Batch: 5260, Train Loss: 0.8906\n",
      "Epoch [3/10], Batch: 5270, Train Loss: 0.8877\n",
      "Epoch [3/10], Batch: 5280, Train Loss: 0.8718\n",
      "Epoch [3/10], Batch: 5290, Train Loss: 0.9386\n",
      "Epoch [3/10], Batch: 5300, Train Loss: 0.8309\n",
      "Epoch [3/10], Batch: 5310, Train Loss: 0.8553\n",
      "Epoch [3/10], Batch: 5320, Train Loss: 0.7933\n",
      "Epoch [3/10], Batch: 5330, Train Loss: 0.7581\n",
      "Epoch [3/10], Batch: 5340, Train Loss: 0.9708\n",
      "Epoch [3/10], Batch: 5350, Train Loss: 0.7860\n",
      "Epoch [3/10], Batch: 5360, Train Loss: 0.9194\n",
      "Epoch [3/10], Batch: 5370, Train Loss: 0.8016\n",
      "Epoch [3/10], Batch: 5380, Train Loss: 0.7635\n",
      "Epoch [3/10], Batch: 5390, Train Loss: 0.9034\n",
      "Epoch [3/10], Batch: 5400, Train Loss: 0.9478\n",
      "Epoch [3/10], Batch: 5410, Train Loss: 0.9732\n",
      "Epoch [3/10], Batch: 5420, Train Loss: 0.8089\n",
      "Epoch [3/10], Batch: 5430, Train Loss: 0.8429\n",
      "Epoch [3/10], Batch: 5440, Train Loss: 0.7989\n",
      "Epoch [3/10], Batch: 5450, Train Loss: 0.8691\n",
      "Epoch [3/10], Batch: 5460, Train Loss: 0.7630\n",
      "Epoch [3/10], Batch: 5470, Train Loss: 0.8055\n",
      "Epoch [3/10], Batch: 5480, Train Loss: 0.7930\n",
      "Epoch [3/10], Batch: 5490, Train Loss: 0.7317\n",
      "Epoch [3/10], Batch: 5500, Train Loss: 0.9919\n",
      "Epoch [3/10], Batch: 5510, Train Loss: 0.8789\n",
      "Epoch [3/10], Batch: 5520, Train Loss: 0.9189\n",
      "Epoch [3/10], Batch: 5530, Train Loss: 0.9337\n",
      "Epoch [3/10], Batch: 5540, Train Loss: 0.8325\n",
      "Epoch [3/10], Batch: 5550, Train Loss: 0.8796\n",
      "Epoch [3/10], Batch: 5560, Train Loss: 0.8456\n",
      "Epoch [3/10], Batch: 5570, Train Loss: 0.8790\n",
      "Epoch [3/10], Batch: 5580, Train Loss: 0.8142\n",
      "Epoch [3/10], Batch: 5590, Train Loss: 0.8967\n",
      "Epoch [3/10], Batch: 5600, Train Loss: 0.7537\n",
      "Epoch [3/10], Batch: 5610, Train Loss: 0.8216\n",
      "Epoch [3/10], Batch: 5620, Train Loss: 0.9267\n",
      "Epoch [3/10], Batch: 5630, Train Loss: 0.8307\n",
      "Epoch [3/10], Batch: 5640, Train Loss: 0.9141\n",
      "Epoch [3/10], Batch: 5650, Train Loss: 0.8801\n",
      "Epoch [3/10], Batch: 5660, Train Loss: 0.8537\n",
      "Epoch [3/10], Batch: 5670, Train Loss: 0.8241\n",
      "Epoch [3/10], Batch: 5680, Train Loss: 0.8684\n",
      "Epoch [3/10], Batch: 5690, Train Loss: 0.9138\n",
      "Epoch [3/10], Batch: 5700, Train Loss: 0.7268\n",
      "Epoch [3/10], Batch: 5710, Train Loss: 1.0028\n",
      "Epoch [3/10], Batch: 5720, Train Loss: 0.9424\n",
      "Epoch [3/10], Batch: 5730, Train Loss: 0.8402\n",
      "Epoch [3/10], Batch: 5740, Train Loss: 0.8488\n",
      "Epoch [3/10], Batch: 5750, Train Loss: 0.8642\n",
      "Epoch [3/10], Batch: 5760, Train Loss: 0.9714\n",
      "Epoch [3/10], Batch: 5770, Train Loss: 0.9456\n",
      "Epoch [3/10], Batch: 5780, Train Loss: 0.9292\n",
      "Epoch [3/10], Batch: 5790, Train Loss: 0.8816\n",
      "Epoch [3/10], Batch: 5800, Train Loss: 0.8970\n",
      "Epoch [3/10], Batch: 5810, Train Loss: 0.8188\n",
      "Epoch [3/10], Batch: 5820, Train Loss: 0.9738\n",
      "Epoch [3/10], Batch: 5830, Train Loss: 0.9230\n",
      "Epoch [3/10], Batch: 5840, Train Loss: 0.8110\n",
      "Epoch [3/10], Batch: 5850, Train Loss: 0.7524\n",
      "Epoch [3/10], Batch: 5860, Train Loss: 0.7917\n",
      "Epoch [3/10], Batch: 5870, Train Loss: 0.8267\n",
      "Epoch [3/10], Batch: 5880, Train Loss: 0.8856\n",
      "Epoch [3/10], Batch: 5890, Train Loss: 0.8701\n",
      "Epoch [3/10], Batch: 5900, Train Loss: 0.7827\n",
      "Epoch [3/10], Batch: 5910, Train Loss: 0.8508\n",
      "Epoch [3/10], Batch: 5920, Train Loss: 0.9254\n",
      "Epoch [3/10], Batch: 5930, Train Loss: 0.9670\n",
      "Epoch [3/10], Batch: 5940, Train Loss: 0.8191\n",
      "Epoch [3/10], Batch: 5950, Train Loss: 0.7685\n",
      "Epoch [3/10], Batch: 5960, Train Loss: 0.8365\n",
      "Epoch [3/10], Batch: 5970, Train Loss: 0.9063\n",
      "Epoch [3/10], Batch: 5980, Train Loss: 0.7978\n",
      "Epoch [3/10], Batch: 5990, Train Loss: 0.9218\n",
      "Epoch [3/10], Batch: 6000, Train Loss: 0.7305\n",
      "Epoch [3/10], Batch: 6010, Train Loss: 0.9464\n",
      "Epoch [3/10], Batch: 6020, Train Loss: 0.8666\n",
      "Epoch [3/10], Batch: 6030, Train Loss: 0.8614\n",
      "Epoch [3/10], Batch: 6040, Train Loss: 0.8289\n",
      "Epoch [3/10], Batch: 6050, Train Loss: 0.8377\n",
      "Epoch [3/10], Batch: 6060, Train Loss: 0.9490\n",
      "Epoch [3/10], Batch: 6070, Train Loss: 0.7741\n",
      "Epoch [3/10], Batch: 6080, Train Loss: 0.7301\n",
      "Epoch [3/10], Batch: 6090, Train Loss: 0.7794\n",
      "Epoch [3/10], Batch: 6100, Train Loss: 0.8272\n",
      "Epoch [3/10], Batch: 6110, Train Loss: 0.8417\n",
      "Epoch [3/10], Batch: 6120, Train Loss: 0.6851\n",
      "Epoch [3/10], Batch: 6130, Train Loss: 0.7978\n",
      "Epoch [3/10], Batch: 6140, Train Loss: 0.8209\n",
      "Epoch [3/10], Batch: 6150, Train Loss: 0.8827\n",
      "Epoch [3/10], Batch: 6160, Train Loss: 0.8961\n",
      "Epoch [3/10], Batch: 6170, Train Loss: 0.8683\n",
      "Epoch [3/10], Batch: 6180, Train Loss: 0.9258\n",
      "Epoch [3/10], Batch: 6190, Train Loss: 0.9095\n",
      "Epoch [3/10], Batch: 6200, Train Loss: 0.8278\n",
      "Epoch [3/10], Batch: 6210, Train Loss: 0.8350\n",
      "Epoch [3/10], Batch: 6220, Train Loss: 0.8115\n",
      "Epoch [3/10], Batch: 6230, Train Loss: 0.8216\n",
      "Epoch [3/10], Batch: 6240, Train Loss: 0.8332\n",
      "Epoch [3/10], Batch: 6250, Train Loss: 0.9131\n",
      "Epoch [3/10], Batch: 6260, Train Loss: 1.0235\n",
      "Epoch [3/10], Batch: 6270, Train Loss: 0.8741\n",
      "Epoch [3/10], Batch: 6280, Train Loss: 0.8771\n",
      "Epoch [3/10], Batch: 6290, Train Loss: 0.8747\n",
      "Epoch [3/10], Batch: 6300, Train Loss: 0.6968\n",
      "Epoch [3/10], Batch: 6310, Train Loss: 0.8804\n",
      "Epoch [3/10], Batch: 6320, Train Loss: 0.9169\n",
      "Epoch [3/10], Batch: 6330, Train Loss: 0.8256\n",
      "Epoch [3/10], Batch: 6340, Train Loss: 0.9739\n",
      "Epoch [3/10], Batch: 6350, Train Loss: 0.9235\n",
      "Epoch [3/10], Batch: 6360, Train Loss: 0.8503\n",
      "Epoch [3/10], Batch: 6370, Train Loss: 0.7990\n",
      "Epoch [3/10], Batch: 6380, Train Loss: 0.8179\n",
      "Epoch [3/10], Batch: 6390, Train Loss: 0.8288\n",
      "Epoch [3/10], Batch: 6400, Train Loss: 0.9194\n",
      "Epoch [3/10], Batch: 6410, Train Loss: 0.7627\n",
      "Epoch [3/10], Batch: 6420, Train Loss: 0.7764\n",
      "Epoch [3/10], Batch: 6430, Train Loss: 0.7602\n",
      "Epoch [3/10], Batch: 6440, Train Loss: 0.8055\n",
      "Epoch [3/10], Batch: 6450, Train Loss: 0.8022\n",
      "Epoch [3/10], Batch: 6460, Train Loss: 0.8502\n",
      "Epoch [3/10], Batch: 6470, Train Loss: 0.8590\n",
      "Epoch [3/10], Batch: 6480, Train Loss: 0.8246\n",
      "Epoch [3/10], Batch: 6490, Train Loss: 0.7534\n",
      "Epoch [3/10], Batch: 6500, Train Loss: 0.8007\n",
      "Epoch [3/10], Batch: 6510, Train Loss: 0.7423\n",
      "Epoch [3/10], Batch: 6520, Train Loss: 0.8086\n",
      "Epoch [3/10], Batch: 6530, Train Loss: 0.8619\n",
      "Epoch [3/10], Batch: 6540, Train Loss: 0.8642\n",
      "Epoch [3/10], Batch: 6550, Train Loss: 0.8823\n",
      "Epoch [3/10], Batch: 6560, Train Loss: 0.7961\n",
      "Epoch [3/10], Batch: 6570, Train Loss: 0.8274\n",
      "Epoch [3/10], Batch: 6580, Train Loss: 0.7926\n",
      "Epoch [3/10], Batch: 6590, Train Loss: 0.8195\n",
      "Epoch [3/10], Batch: 6600, Train Loss: 0.8993\n",
      "Epoch [3/10], Batch: 6610, Train Loss: 0.8298\n",
      "Epoch [3/10], Batch: 6620, Train Loss: 0.7888\n",
      "Epoch [3/10], Batch: 6630, Train Loss: 0.8679\n",
      "Epoch [3/10], Batch: 6640, Train Loss: 0.9467\n",
      "Epoch [3/10], Batch: 6650, Train Loss: 0.8125\n",
      "Epoch [3/10], Batch: 6660, Train Loss: 0.9375\n",
      "Epoch [3/10], Batch: 6670, Train Loss: 0.7444\n",
      "Epoch [3/10], Batch: 6680, Train Loss: 0.8659\n",
      "Epoch [3/10], Batch: 6690, Train Loss: 0.8860\n",
      "Epoch [3/10], Batch: 6700, Train Loss: 0.9547\n",
      "Epoch [3/10], Batch: 6710, Train Loss: 0.9029\n",
      "Epoch [3/10], Batch: 6720, Train Loss: 0.7765\n",
      "Epoch [3/10], Batch: 6730, Train Loss: 0.7887\n",
      "Epoch [3/10], Batch: 6740, Train Loss: 0.7905\n",
      "Epoch [3/10], Batch: 6750, Train Loss: 0.6877\n",
      "Epoch [3/10], Batch: 6760, Train Loss: 0.8748\n",
      "Epoch [4/10], Batch: 10, Train Loss: 0.8488\n",
      "Epoch [4/10], Batch: 20, Train Loss: 0.6668\n",
      "Epoch [4/10], Batch: 30, Train Loss: 0.6826\n",
      "Epoch [4/10], Batch: 40, Train Loss: 0.7731\n",
      "Epoch [4/10], Batch: 50, Train Loss: 0.9584\n",
      "Epoch [4/10], Batch: 60, Train Loss: 0.8198\n",
      "Epoch [4/10], Batch: 70, Train Loss: 0.9328\n",
      "Epoch [4/10], Batch: 80, Train Loss: 0.8403\n",
      "Epoch [4/10], Batch: 90, Train Loss: 0.8085\n",
      "Epoch [4/10], Batch: 100, Train Loss: 0.7903\n",
      "Epoch [4/10], Batch: 110, Train Loss: 0.9746\n",
      "Epoch [4/10], Batch: 120, Train Loss: 0.7808\n",
      "Epoch [4/10], Batch: 130, Train Loss: 0.9650\n",
      "Epoch [4/10], Batch: 140, Train Loss: 0.8651\n",
      "Epoch [4/10], Batch: 150, Train Loss: 0.7766\n",
      "Epoch [4/10], Batch: 160, Train Loss: 0.8461\n",
      "Epoch [4/10], Batch: 170, Train Loss: 0.7804\n",
      "Epoch [4/10], Batch: 180, Train Loss: 0.7015\n",
      "Epoch [4/10], Batch: 190, Train Loss: 0.8088\n",
      "Epoch [4/10], Batch: 200, Train Loss: 0.7601\n",
      "Epoch [4/10], Batch: 210, Train Loss: 0.9017\n",
      "Epoch [4/10], Batch: 220, Train Loss: 0.7725\n",
      "Epoch [4/10], Batch: 230, Train Loss: 0.9317\n",
      "Epoch [4/10], Batch: 240, Train Loss: 0.7690\n",
      "Epoch [4/10], Batch: 250, Train Loss: 0.8589\n",
      "Epoch [4/10], Batch: 260, Train Loss: 0.8111\n",
      "Epoch [4/10], Batch: 270, Train Loss: 0.8315\n",
      "Epoch [4/10], Batch: 280, Train Loss: 0.8112\n",
      "Epoch [4/10], Batch: 290, Train Loss: 0.8627\n",
      "Epoch [4/10], Batch: 300, Train Loss: 0.9037\n",
      "Epoch [4/10], Batch: 310, Train Loss: 0.7933\n",
      "Epoch [4/10], Batch: 320, Train Loss: 0.7618\n",
      "Epoch [4/10], Batch: 330, Train Loss: 0.7920\n",
      "Epoch [4/10], Batch: 340, Train Loss: 0.8729\n",
      "Epoch [4/10], Batch: 350, Train Loss: 0.8522\n",
      "Epoch [4/10], Batch: 360, Train Loss: 0.7811\n",
      "Epoch [4/10], Batch: 370, Train Loss: 0.8088\n",
      "Epoch [4/10], Batch: 380, Train Loss: 0.8647\n",
      "Epoch [4/10], Batch: 390, Train Loss: 0.8636\n",
      "Epoch [4/10], Batch: 400, Train Loss: 0.8742\n",
      "Epoch [4/10], Batch: 410, Train Loss: 0.9162\n",
      "Epoch [4/10], Batch: 420, Train Loss: 0.8642\n",
      "Epoch [4/10], Batch: 430, Train Loss: 0.8253\n",
      "Epoch [4/10], Batch: 440, Train Loss: 0.7734\n",
      "Epoch [4/10], Batch: 450, Train Loss: 0.7999\n",
      "Epoch [4/10], Batch: 460, Train Loss: 0.8828\n",
      "Epoch [4/10], Batch: 470, Train Loss: 0.8108\n",
      "Epoch [4/10], Batch: 480, Train Loss: 0.8168\n",
      "Epoch [4/10], Batch: 490, Train Loss: 0.7859\n",
      "Epoch [4/10], Batch: 500, Train Loss: 0.9885\n",
      "Epoch [4/10], Batch: 510, Train Loss: 0.8082\n",
      "Epoch [4/10], Batch: 520, Train Loss: 0.8991\n",
      "Epoch [4/10], Batch: 530, Train Loss: 0.8621\n",
      "Epoch [4/10], Batch: 540, Train Loss: 0.8455\n",
      "Epoch [4/10], Batch: 550, Train Loss: 0.9454\n",
      "Epoch [4/10], Batch: 560, Train Loss: 0.7729\n",
      "Epoch [4/10], Batch: 570, Train Loss: 0.8844\n",
      "Epoch [4/10], Batch: 580, Train Loss: 0.8013\n",
      "Epoch [4/10], Batch: 590, Train Loss: 0.8967\n",
      "Epoch [4/10], Batch: 600, Train Loss: 0.8119\n",
      "Epoch [4/10], Batch: 610, Train Loss: 0.8196\n",
      "Epoch [4/10], Batch: 620, Train Loss: 0.8098\n",
      "Epoch [4/10], Batch: 630, Train Loss: 0.8305\n",
      "Epoch [4/10], Batch: 640, Train Loss: 0.8752\n",
      "Epoch [4/10], Batch: 650, Train Loss: 0.8151\n",
      "Epoch [4/10], Batch: 660, Train Loss: 1.0063\n",
      "Epoch [4/10], Batch: 670, Train Loss: 0.8597\n",
      "Epoch [4/10], Batch: 680, Train Loss: 0.8326\n",
      "Epoch [4/10], Batch: 690, Train Loss: 0.8479\n",
      "Epoch [4/10], Batch: 700, Train Loss: 0.7399\n",
      "Epoch [4/10], Batch: 710, Train Loss: 0.7660\n",
      "Epoch [4/10], Batch: 720, Train Loss: 0.8011\n",
      "Epoch [4/10], Batch: 730, Train Loss: 0.8506\n",
      "Epoch [4/10], Batch: 740, Train Loss: 0.7823\n",
      "Epoch [4/10], Batch: 750, Train Loss: 0.7225\n",
      "Epoch [4/10], Batch: 760, Train Loss: 0.8814\n",
      "Epoch [4/10], Batch: 770, Train Loss: 0.7537\n",
      "Epoch [4/10], Batch: 780, Train Loss: 0.7172\n",
      "Epoch [4/10], Batch: 790, Train Loss: 0.8798\n",
      "Epoch [4/10], Batch: 800, Train Loss: 0.7984\n",
      "Epoch [4/10], Batch: 810, Train Loss: 0.8159\n",
      "Epoch [4/10], Batch: 820, Train Loss: 0.8953\n",
      "Epoch [4/10], Batch: 830, Train Loss: 0.8917\n",
      "Epoch [4/10], Batch: 840, Train Loss: 0.8667\n",
      "Epoch [4/10], Batch: 850, Train Loss: 0.7671\n",
      "Epoch [4/10], Batch: 860, Train Loss: 0.7561\n",
      "Epoch [4/10], Batch: 870, Train Loss: 0.8317\n",
      "Epoch [4/10], Batch: 880, Train Loss: 0.9226\n",
      "Epoch [4/10], Batch: 890, Train Loss: 0.8041\n",
      "Epoch [4/10], Batch: 900, Train Loss: 0.8074\n",
      "Epoch [4/10], Batch: 910, Train Loss: 0.8167\n",
      "Epoch [4/10], Batch: 920, Train Loss: 0.8031\n",
      "Epoch [4/10], Batch: 930, Train Loss: 0.8339\n",
      "Epoch [4/10], Batch: 940, Train Loss: 0.8897\n",
      "Epoch [4/10], Batch: 950, Train Loss: 0.8381\n",
      "Epoch [4/10], Batch: 960, Train Loss: 0.8996\n",
      "Epoch [4/10], Batch: 970, Train Loss: 0.6643\n",
      "Epoch [4/10], Batch: 980, Train Loss: 0.8170\n",
      "Epoch [4/10], Batch: 990, Train Loss: 0.9001\n",
      "Epoch [4/10], Batch: 1000, Train Loss: 0.8969\n",
      "Epoch [4/10], Batch: 1010, Train Loss: 0.7550\n",
      "Epoch [4/10], Batch: 1020, Train Loss: 0.8027\n",
      "Epoch [4/10], Batch: 1030, Train Loss: 0.8219\n",
      "Epoch [4/10], Batch: 1040, Train Loss: 0.8689\n",
      "Epoch [4/10], Batch: 1050, Train Loss: 0.8657\n",
      "Epoch [4/10], Batch: 1060, Train Loss: 0.9246\n",
      "Epoch [4/10], Batch: 1070, Train Loss: 0.8824\n",
      "Epoch [4/10], Batch: 1080, Train Loss: 0.7372\n",
      "Epoch [4/10], Batch: 1090, Train Loss: 0.7506\n",
      "Epoch [4/10], Batch: 1100, Train Loss: 0.7897\n",
      "Epoch [4/10], Batch: 1110, Train Loss: 0.8721\n",
      "Epoch [4/10], Batch: 1120, Train Loss: 0.6857\n",
      "Epoch [4/10], Batch: 1130, Train Loss: 0.8807\n",
      "Epoch [4/10], Batch: 1140, Train Loss: 0.8885\n",
      "Epoch [4/10], Batch: 1150, Train Loss: 0.8905\n",
      "Epoch [4/10], Batch: 1160, Train Loss: 0.7872\n",
      "Epoch [4/10], Batch: 1170, Train Loss: 0.8728\n",
      "Epoch [4/10], Batch: 1180, Train Loss: 0.9666\n",
      "Epoch [4/10], Batch: 1190, Train Loss: 0.8614\n",
      "Epoch [4/10], Batch: 1200, Train Loss: 0.8312\n",
      "Epoch [4/10], Batch: 1210, Train Loss: 0.7768\n",
      "Epoch [4/10], Batch: 1220, Train Loss: 0.8485\n",
      "Epoch [4/10], Batch: 1230, Train Loss: 0.8653\n",
      "Epoch [4/10], Batch: 1240, Train Loss: 0.8483\n",
      "Epoch [4/10], Batch: 1250, Train Loss: 0.8090\n",
      "Epoch [4/10], Batch: 1260, Train Loss: 0.8353\n",
      "Epoch [4/10], Batch: 1270, Train Loss: 0.8989\n",
      "Epoch [4/10], Batch: 1280, Train Loss: 0.8478\n",
      "Epoch [4/10], Batch: 1290, Train Loss: 0.7874\n",
      "Epoch [4/10], Batch: 1300, Train Loss: 0.7814\n",
      "Epoch [4/10], Batch: 1310, Train Loss: 0.7938\n",
      "Epoch [4/10], Batch: 1320, Train Loss: 0.8013\n",
      "Epoch [4/10], Batch: 1330, Train Loss: 0.9394\n",
      "Epoch [4/10], Batch: 1340, Train Loss: 0.8728\n",
      "Epoch [4/10], Batch: 1350, Train Loss: 0.7750\n",
      "Epoch [4/10], Batch: 1360, Train Loss: 0.7899\n",
      "Epoch [4/10], Batch: 1370, Train Loss: 0.9690\n",
      "Epoch [4/10], Batch: 1380, Train Loss: 0.7804\n",
      "Epoch [4/10], Batch: 1390, Train Loss: 0.8680\n",
      "Epoch [4/10], Batch: 1400, Train Loss: 0.7528\n",
      "Epoch [4/10], Batch: 1410, Train Loss: 1.0146\n",
      "Epoch [4/10], Batch: 1420, Train Loss: 0.8447\n",
      "Epoch [4/10], Batch: 1430, Train Loss: 0.9845\n",
      "Epoch [4/10], Batch: 1440, Train Loss: 0.8422\n",
      "Epoch [4/10], Batch: 1450, Train Loss: 0.8410\n",
      "Epoch [4/10], Batch: 1460, Train Loss: 0.7801\n",
      "Epoch [4/10], Batch: 1470, Train Loss: 0.8808\n",
      "Epoch [4/10], Batch: 1480, Train Loss: 0.8821\n",
      "Epoch [4/10], Batch: 1490, Train Loss: 0.7580\n",
      "Epoch [4/10], Batch: 1500, Train Loss: 0.8692\n",
      "Epoch [4/10], Batch: 1510, Train Loss: 0.8539\n",
      "Epoch [4/10], Batch: 1520, Train Loss: 0.8102\n",
      "Epoch [4/10], Batch: 1530, Train Loss: 0.6600\n",
      "Epoch [4/10], Batch: 1540, Train Loss: 0.7595\n",
      "Epoch [4/10], Batch: 1550, Train Loss: 0.7908\n",
      "Epoch [4/10], Batch: 1560, Train Loss: 0.7479\n",
      "Epoch [4/10], Batch: 1570, Train Loss: 0.8226\n",
      "Epoch [4/10], Batch: 1580, Train Loss: 0.9010\n",
      "Epoch [4/10], Batch: 1590, Train Loss: 0.7271\n",
      "Epoch [4/10], Batch: 1600, Train Loss: 0.8502\n",
      "Epoch [4/10], Batch: 1610, Train Loss: 0.8623\n",
      "Epoch [4/10], Batch: 1620, Train Loss: 0.7825\n",
      "Epoch [4/10], Batch: 1630, Train Loss: 0.9447\n",
      "Epoch [4/10], Batch: 1640, Train Loss: 0.6389\n",
      "Epoch [4/10], Batch: 1650, Train Loss: 0.9336\n",
      "Epoch [4/10], Batch: 1660, Train Loss: 0.7825\n",
      "Epoch [4/10], Batch: 1670, Train Loss: 0.8558\n",
      "Epoch [4/10], Batch: 1680, Train Loss: 0.7807\n",
      "Epoch [4/10], Batch: 1690, Train Loss: 0.9418\n",
      "Epoch [4/10], Batch: 1700, Train Loss: 0.7918\n",
      "Epoch [4/10], Batch: 1710, Train Loss: 0.8036\n",
      "Epoch [4/10], Batch: 1720, Train Loss: 0.8741\n",
      "Epoch [4/10], Batch: 1730, Train Loss: 0.7662\n",
      "Epoch [4/10], Batch: 1740, Train Loss: 0.8079\n",
      "Epoch [4/10], Batch: 1750, Train Loss: 0.8153\n",
      "Epoch [4/10], Batch: 1760, Train Loss: 0.8687\n",
      "Epoch [4/10], Batch: 1770, Train Loss: 0.7694\n",
      "Epoch [4/10], Batch: 1780, Train Loss: 0.7478\n",
      "Epoch [4/10], Batch: 1790, Train Loss: 0.8251\n",
      "Epoch [4/10], Batch: 1800, Train Loss: 0.8341\n",
      "Epoch [4/10], Batch: 1810, Train Loss: 0.7670\n",
      "Epoch [4/10], Batch: 1820, Train Loss: 0.8769\n",
      "Epoch [4/10], Batch: 1830, Train Loss: 0.8697\n",
      "Epoch [4/10], Batch: 1840, Train Loss: 0.8944\n",
      "Epoch [4/10], Batch: 1850, Train Loss: 0.8011\n",
      "Epoch [4/10], Batch: 1860, Train Loss: 0.8369\n",
      "Epoch [4/10], Batch: 1870, Train Loss: 0.8764\n",
      "Epoch [4/10], Batch: 1880, Train Loss: 0.8349\n",
      "Epoch [4/10], Batch: 1890, Train Loss: 0.8342\n",
      "Epoch [4/10], Batch: 1900, Train Loss: 0.8588\n",
      "Epoch [4/10], Batch: 1910, Train Loss: 0.7837\n",
      "Epoch [4/10], Batch: 1920, Train Loss: 0.8729\n",
      "Epoch [4/10], Batch: 1930, Train Loss: 0.8504\n",
      "Epoch [4/10], Batch: 1940, Train Loss: 0.8114\n",
      "Epoch [4/10], Batch: 1950, Train Loss: 0.8922\n",
      "Epoch [4/10], Batch: 1960, Train Loss: 0.7219\n",
      "Epoch [4/10], Batch: 1970, Train Loss: 0.8272\n",
      "Epoch [4/10], Batch: 1980, Train Loss: 0.7508\n",
      "Epoch [4/10], Batch: 1990, Train Loss: 0.7754\n",
      "Epoch [4/10], Batch: 2000, Train Loss: 0.8070\n",
      "Epoch [4/10], Batch: 2010, Train Loss: 0.8455\n",
      "Epoch [4/10], Batch: 2020, Train Loss: 0.8610\n",
      "Epoch [4/10], Batch: 2030, Train Loss: 0.8383\n",
      "Epoch [4/10], Batch: 2040, Train Loss: 0.7787\n",
      "Epoch [4/10], Batch: 2050, Train Loss: 0.8459\n",
      "Epoch [4/10], Batch: 2060, Train Loss: 0.7553\n",
      "Epoch [4/10], Batch: 2070, Train Loss: 0.7784\n",
      "Epoch [4/10], Batch: 2080, Train Loss: 0.7815\n",
      "Epoch [4/10], Batch: 2090, Train Loss: 0.8177\n",
      "Epoch [4/10], Batch: 2100, Train Loss: 0.8219\n",
      "Epoch [4/10], Batch: 2110, Train Loss: 0.9555\n",
      "Epoch [4/10], Batch: 2120, Train Loss: 0.7645\n",
      "Epoch [4/10], Batch: 2130, Train Loss: 0.8806\n",
      "Epoch [4/10], Batch: 2140, Train Loss: 0.9135\n",
      "Epoch [4/10], Batch: 2150, Train Loss: 0.8964\n",
      "Epoch [4/10], Batch: 2160, Train Loss: 0.8603\n",
      "Epoch [4/10], Batch: 2170, Train Loss: 0.7712\n",
      "Epoch [4/10], Batch: 2180, Train Loss: 0.7464\n",
      "Epoch [4/10], Batch: 2190, Train Loss: 0.6524\n",
      "Epoch [4/10], Batch: 2200, Train Loss: 0.8896\n",
      "Epoch [4/10], Batch: 2210, Train Loss: 0.8558\n",
      "Epoch [4/10], Batch: 2220, Train Loss: 0.7733\n",
      "Epoch [4/10], Batch: 2230, Train Loss: 0.8890\n",
      "Epoch [4/10], Batch: 2240, Train Loss: 0.9169\n",
      "Epoch [4/10], Batch: 2250, Train Loss: 0.8581\n",
      "Epoch [4/10], Batch: 2260, Train Loss: 0.8421\n",
      "Epoch [4/10], Batch: 2270, Train Loss: 0.8342\n",
      "Epoch [4/10], Batch: 2280, Train Loss: 0.7608\n",
      "Epoch [4/10], Batch: 2290, Train Loss: 0.8867\n",
      "Epoch [4/10], Batch: 2300, Train Loss: 0.7375\n",
      "Epoch [4/10], Batch: 2310, Train Loss: 0.7902\n",
      "Epoch [4/10], Batch: 2320, Train Loss: 0.9010\n",
      "Epoch [4/10], Batch: 2330, Train Loss: 0.9037\n",
      "Epoch [4/10], Batch: 2340, Train Loss: 0.9051\n",
      "Epoch [4/10], Batch: 2350, Train Loss: 0.7735\n",
      "Epoch [4/10], Batch: 2360, Train Loss: 0.8530\n",
      "Epoch [4/10], Batch: 2370, Train Loss: 0.8792\n",
      "Epoch [4/10], Batch: 2380, Train Loss: 0.9286\n",
      "Epoch [4/10], Batch: 2390, Train Loss: 0.6618\n",
      "Epoch [4/10], Batch: 2400, Train Loss: 0.8798\n",
      "Epoch [4/10], Batch: 2410, Train Loss: 0.8318\n",
      "Epoch [4/10], Batch: 2420, Train Loss: 0.8043\n",
      "Epoch [4/10], Batch: 2430, Train Loss: 0.8121\n",
      "Epoch [4/10], Batch: 2440, Train Loss: 0.8173\n",
      "Epoch [4/10], Batch: 2450, Train Loss: 0.7981\n",
      "Epoch [4/10], Batch: 2460, Train Loss: 0.8731\n",
      "Epoch [4/10], Batch: 2470, Train Loss: 0.8644\n",
      "Epoch [4/10], Batch: 2480, Train Loss: 0.7100\n",
      "Epoch [4/10], Batch: 2490, Train Loss: 0.8698\n",
      "Epoch [4/10], Batch: 2500, Train Loss: 0.8169\n",
      "Epoch [4/10], Batch: 2510, Train Loss: 0.8508\n",
      "Epoch [4/10], Batch: 2520, Train Loss: 0.7907\n",
      "Epoch [4/10], Batch: 2530, Train Loss: 0.8295\n",
      "Epoch [4/10], Batch: 2540, Train Loss: 0.9091\n",
      "Epoch [4/10], Batch: 2550, Train Loss: 0.7762\n",
      "Epoch [4/10], Batch: 2560, Train Loss: 0.8742\n",
      "Epoch [4/10], Batch: 2570, Train Loss: 0.7155\n",
      "Epoch [4/10], Batch: 2580, Train Loss: 0.7485\n",
      "Epoch [4/10], Batch: 2590, Train Loss: 0.8653\n",
      "Epoch [4/10], Batch: 2600, Train Loss: 0.8795\n",
      "Epoch [4/10], Batch: 2610, Train Loss: 0.7972\n",
      "Epoch [4/10], Batch: 2620, Train Loss: 0.7784\n",
      "Epoch [4/10], Batch: 2630, Train Loss: 0.8744\n",
      "Epoch [4/10], Batch: 2640, Train Loss: 0.7386\n",
      "Epoch [4/10], Batch: 2650, Train Loss: 0.8582\n",
      "Epoch [4/10], Batch: 2660, Train Loss: 0.8492\n",
      "Epoch [4/10], Batch: 2670, Train Loss: 0.7946\n",
      "Epoch [4/10], Batch: 2680, Train Loss: 0.8752\n",
      "Epoch [4/10], Batch: 2690, Train Loss: 0.7098\n",
      "Epoch [4/10], Batch: 2700, Train Loss: 0.8642\n",
      "Epoch [4/10], Batch: 2710, Train Loss: 0.8136\n",
      "Epoch [4/10], Batch: 2720, Train Loss: 0.8659\n",
      "Epoch [4/10], Batch: 2730, Train Loss: 0.8557\n",
      "Epoch [4/10], Batch: 2740, Train Loss: 0.9505\n",
      "Epoch [4/10], Batch: 2750, Train Loss: 0.8916\n",
      "Epoch [4/10], Batch: 2760, Train Loss: 0.7534\n",
      "Epoch [4/10], Batch: 2770, Train Loss: 0.7846\n",
      "Epoch [4/10], Batch: 2780, Train Loss: 0.7760\n",
      "Epoch [4/10], Batch: 2790, Train Loss: 0.7208\n",
      "Epoch [4/10], Batch: 2800, Train Loss: 0.7788\n",
      "Epoch [4/10], Batch: 2810, Train Loss: 0.9349\n",
      "Epoch [4/10], Batch: 2820, Train Loss: 0.7437\n",
      "Epoch [4/10], Batch: 2830, Train Loss: 0.9199\n",
      "Epoch [4/10], Batch: 2840, Train Loss: 0.7724\n",
      "Epoch [4/10], Batch: 2850, Train Loss: 0.8895\n",
      "Epoch [4/10], Batch: 2860, Train Loss: 0.8416\n",
      "Epoch [4/10], Batch: 2870, Train Loss: 0.7772\n",
      "Epoch [4/10], Batch: 2880, Train Loss: 1.0210\n",
      "Epoch [4/10], Batch: 2890, Train Loss: 0.8233\n",
      "Epoch [4/10], Batch: 2900, Train Loss: 0.8388\n",
      "Epoch [4/10], Batch: 2910, Train Loss: 0.8801\n",
      "Epoch [4/10], Batch: 2920, Train Loss: 0.8360\n",
      "Epoch [4/10], Batch: 2930, Train Loss: 0.8289\n",
      "Epoch [4/10], Batch: 2940, Train Loss: 0.9524\n",
      "Epoch [4/10], Batch: 2950, Train Loss: 0.7311\n",
      "Epoch [4/10], Batch: 2960, Train Loss: 0.9451\n",
      "Epoch [4/10], Batch: 2970, Train Loss: 0.8315\n",
      "Epoch [4/10], Batch: 2980, Train Loss: 0.7075\n",
      "Epoch [4/10], Batch: 2990, Train Loss: 0.6914\n",
      "Epoch [4/10], Batch: 3000, Train Loss: 0.8325\n",
      "Epoch [4/10], Batch: 3010, Train Loss: 0.8330\n",
      "Epoch [4/10], Batch: 3020, Train Loss: 0.9260\n",
      "Epoch [4/10], Batch: 3030, Train Loss: 0.7427\n",
      "Epoch [4/10], Batch: 3040, Train Loss: 0.7684\n",
      "Epoch [4/10], Batch: 3050, Train Loss: 0.8050\n",
      "Epoch [4/10], Batch: 3060, Train Loss: 0.8034\n",
      "Epoch [4/10], Batch: 3070, Train Loss: 0.9527\n",
      "Epoch [4/10], Batch: 3080, Train Loss: 0.9204\n",
      "Epoch [4/10], Batch: 3090, Train Loss: 0.8667\n",
      "Epoch [4/10], Batch: 3100, Train Loss: 0.8312\n",
      "Epoch [4/10], Batch: 3110, Train Loss: 0.7740\n",
      "Epoch [4/10], Batch: 3120, Train Loss: 0.7896\n",
      "Epoch [4/10], Batch: 3130, Train Loss: 0.8663\n",
      "Epoch [4/10], Batch: 3140, Train Loss: 0.8422\n",
      "Epoch [4/10], Batch: 3150, Train Loss: 0.7731\n",
      "Epoch [4/10], Batch: 3160, Train Loss: 0.9002\n",
      "Epoch [4/10], Batch: 3170, Train Loss: 0.7323\n",
      "Epoch [4/10], Batch: 3180, Train Loss: 0.8794\n",
      "Epoch [4/10], Batch: 3190, Train Loss: 0.6394\n",
      "Epoch [4/10], Batch: 3200, Train Loss: 0.9980\n",
      "Epoch [4/10], Batch: 3210, Train Loss: 0.8774\n",
      "Epoch [4/10], Batch: 3220, Train Loss: 0.9107\n",
      "Epoch [4/10], Batch: 3230, Train Loss: 0.7888\n",
      "Epoch [4/10], Batch: 3240, Train Loss: 0.7754\n",
      "Epoch [4/10], Batch: 3250, Train Loss: 0.7959\n",
      "Epoch [4/10], Batch: 3260, Train Loss: 0.8349\n",
      "Epoch [4/10], Batch: 3270, Train Loss: 0.9089\n",
      "Epoch [4/10], Batch: 3280, Train Loss: 0.8871\n",
      "Epoch [4/10], Batch: 3290, Train Loss: 0.7817\n",
      "Epoch [4/10], Batch: 3300, Train Loss: 0.8023\n",
      "Epoch [4/10], Batch: 3310, Train Loss: 0.8958\n",
      "Epoch [4/10], Batch: 3320, Train Loss: 0.8740\n",
      "Epoch [4/10], Batch: 3330, Train Loss: 0.6567\n",
      "Epoch [4/10], Batch: 3340, Train Loss: 0.8762\n",
      "Epoch [4/10], Batch: 3350, Train Loss: 0.7708\n",
      "Epoch [4/10], Batch: 3360, Train Loss: 0.7381\n",
      "Epoch [4/10], Batch: 3370, Train Loss: 0.7904\n",
      "Epoch [4/10], Batch: 3380, Train Loss: 0.7950\n",
      "Epoch [4/10], Batch: 3390, Train Loss: 0.7627\n",
      "Epoch [4/10], Batch: 3400, Train Loss: 0.8086\n",
      "Epoch [4/10], Batch: 3410, Train Loss: 0.8577\n",
      "Epoch [4/10], Batch: 3420, Train Loss: 0.7790\n",
      "Epoch [4/10], Batch: 3430, Train Loss: 0.9286\n",
      "Epoch [4/10], Batch: 3440, Train Loss: 0.8780\n",
      "Epoch [4/10], Batch: 3450, Train Loss: 0.7677\n",
      "Epoch [4/10], Batch: 3460, Train Loss: 0.8490\n",
      "Epoch [4/10], Batch: 3470, Train Loss: 0.7681\n",
      "Epoch [4/10], Batch: 3480, Train Loss: 0.8047\n",
      "Epoch [4/10], Batch: 3490, Train Loss: 0.8190\n",
      "Epoch [4/10], Batch: 3500, Train Loss: 0.8011\n",
      "Epoch [4/10], Batch: 3510, Train Loss: 0.9032\n",
      "Epoch [4/10], Batch: 3520, Train Loss: 0.8454\n",
      "Epoch [4/10], Batch: 3530, Train Loss: 0.8295\n",
      "Epoch [4/10], Batch: 3540, Train Loss: 0.7570\n",
      "Epoch [4/10], Batch: 3550, Train Loss: 0.7891\n",
      "Epoch [4/10], Batch: 3560, Train Loss: 0.9527\n",
      "Epoch [4/10], Batch: 3570, Train Loss: 0.8131\n",
      "Epoch [4/10], Batch: 3580, Train Loss: 0.7958\n",
      "Epoch [4/10], Batch: 3590, Train Loss: 0.8682\n",
      "Epoch [4/10], Batch: 3600, Train Loss: 0.8943\n",
      "Epoch [4/10], Batch: 3610, Train Loss: 0.6586\n",
      "Epoch [4/10], Batch: 3620, Train Loss: 0.8610\n",
      "Epoch [4/10], Batch: 3630, Train Loss: 0.9673\n",
      "Epoch [4/10], Batch: 3640, Train Loss: 0.7682\n",
      "Epoch [4/10], Batch: 3650, Train Loss: 0.7432\n",
      "Epoch [4/10], Batch: 3660, Train Loss: 0.8570\n",
      "Epoch [4/10], Batch: 3670, Train Loss: 0.8222\n",
      "Epoch [4/10], Batch: 3680, Train Loss: 0.9227\n",
      "Epoch [4/10], Batch: 3690, Train Loss: 0.7868\n",
      "Epoch [4/10], Batch: 3700, Train Loss: 0.8742\n",
      "Epoch [4/10], Batch: 3710, Train Loss: 0.9790\n",
      "Epoch [4/10], Batch: 3720, Train Loss: 0.8512\n",
      "Epoch [4/10], Batch: 3730, Train Loss: 0.7840\n",
      "Epoch [4/10], Batch: 3740, Train Loss: 0.7542\n",
      "Epoch [4/10], Batch: 3750, Train Loss: 0.7219\n",
      "Epoch [4/10], Batch: 3760, Train Loss: 0.7292\n",
      "Epoch [4/10], Batch: 3770, Train Loss: 0.8059\n",
      "Epoch [4/10], Batch: 3780, Train Loss: 0.8995\n",
      "Epoch [4/10], Batch: 3790, Train Loss: 0.8317\n",
      "Epoch [4/10], Batch: 3800, Train Loss: 0.7485\n",
      "Epoch [4/10], Batch: 3810, Train Loss: 0.7063\n",
      "Epoch [4/10], Batch: 3820, Train Loss: 0.8223\n",
      "Epoch [4/10], Batch: 3830, Train Loss: 0.7037\n",
      "Epoch [4/10], Batch: 3840, Train Loss: 0.7977\n",
      "Epoch [4/10], Batch: 3850, Train Loss: 0.8761\n",
      "Epoch [4/10], Batch: 3860, Train Loss: 0.8451\n",
      "Epoch [4/10], Batch: 3870, Train Loss: 0.9075\n",
      "Epoch [4/10], Batch: 3880, Train Loss: 0.8552\n",
      "Epoch [4/10], Batch: 3890, Train Loss: 0.8583\n",
      "Epoch [4/10], Batch: 3900, Train Loss: 0.8011\n",
      "Epoch [4/10], Batch: 3910, Train Loss: 0.8871\n",
      "Epoch [4/10], Batch: 3920, Train Loss: 0.7104\n",
      "Epoch [4/10], Batch: 3930, Train Loss: 0.7177\n",
      "Epoch [4/10], Batch: 3940, Train Loss: 0.7830\n",
      "Epoch [4/10], Batch: 3950, Train Loss: 0.8586\n",
      "Epoch [4/10], Batch: 3960, Train Loss: 0.8807\n",
      "Epoch [4/10], Batch: 3970, Train Loss: 0.7987\n",
      "Epoch [4/10], Batch: 3980, Train Loss: 0.7971\n",
      "Epoch [4/10], Batch: 3990, Train Loss: 0.8402\n",
      "Epoch [4/10], Batch: 4000, Train Loss: 0.8479\n",
      "Epoch [4/10], Batch: 4010, Train Loss: 0.8631\n",
      "Epoch [4/10], Batch: 4020, Train Loss: 0.8446\n",
      "Epoch [4/10], Batch: 4030, Train Loss: 0.8759\n",
      "Epoch [4/10], Batch: 4040, Train Loss: 0.8089\n",
      "Epoch [4/10], Batch: 4050, Train Loss: 0.7198\n",
      "Epoch [4/10], Batch: 4060, Train Loss: 0.7245\n",
      "Epoch [4/10], Batch: 4070, Train Loss: 0.8350\n",
      "Epoch [4/10], Batch: 4080, Train Loss: 0.8413\n",
      "Epoch [4/10], Batch: 4090, Train Loss: 0.8215\n",
      "Epoch [4/10], Batch: 4100, Train Loss: 0.8290\n",
      "Epoch [4/10], Batch: 4110, Train Loss: 0.8503\n",
      "Epoch [4/10], Batch: 4120, Train Loss: 0.7891\n",
      "Epoch [4/10], Batch: 4130, Train Loss: 0.9316\n",
      "Epoch [4/10], Batch: 4140, Train Loss: 0.9129\n",
      "Epoch [4/10], Batch: 4150, Train Loss: 0.7007\n",
      "Epoch [4/10], Batch: 4160, Train Loss: 0.7416\n",
      "Epoch [4/10], Batch: 4170, Train Loss: 0.7582\n",
      "Epoch [4/10], Batch: 4180, Train Loss: 0.6990\n",
      "Epoch [4/10], Batch: 4190, Train Loss: 0.8634\n",
      "Epoch [4/10], Batch: 4200, Train Loss: 0.7771\n",
      "Epoch [4/10], Batch: 4210, Train Loss: 0.8893\n",
      "Epoch [4/10], Batch: 4220, Train Loss: 0.8317\n",
      "Epoch [4/10], Batch: 4230, Train Loss: 0.9392\n",
      "Epoch [4/10], Batch: 4240, Train Loss: 0.7630\n",
      "Epoch [4/10], Batch: 4250, Train Loss: 0.7803\n",
      "Epoch [4/10], Batch: 4260, Train Loss: 0.8902\n",
      "Epoch [4/10], Batch: 4270, Train Loss: 0.9812\n",
      "Epoch [4/10], Batch: 4280, Train Loss: 0.8119\n",
      "Epoch [4/10], Batch: 4290, Train Loss: 0.9238\n",
      "Epoch [4/10], Batch: 4300, Train Loss: 0.8648\n",
      "Epoch [4/10], Batch: 4310, Train Loss: 0.7997\n",
      "Epoch [4/10], Batch: 4320, Train Loss: 0.8067\n",
      "Epoch [4/10], Batch: 4330, Train Loss: 0.7535\n",
      "Epoch [4/10], Batch: 4340, Train Loss: 0.8300\n",
      "Epoch [4/10], Batch: 4350, Train Loss: 0.7783\n",
      "Epoch [4/10], Batch: 4360, Train Loss: 0.7004\n",
      "Epoch [4/10], Batch: 4370, Train Loss: 0.9133\n",
      "Epoch [4/10], Batch: 4380, Train Loss: 0.8042\n",
      "Epoch [4/10], Batch: 4390, Train Loss: 0.8627\n",
      "Epoch [4/10], Batch: 4400, Train Loss: 0.7576\n",
      "Epoch [4/10], Batch: 4410, Train Loss: 0.7503\n",
      "Epoch [4/10], Batch: 4420, Train Loss: 0.9675\n",
      "Epoch [4/10], Batch: 4430, Train Loss: 0.9117\n",
      "Epoch [4/10], Batch: 4440, Train Loss: 0.8807\n",
      "Epoch [4/10], Batch: 4450, Train Loss: 0.7770\n",
      "Epoch [4/10], Batch: 4460, Train Loss: 0.7721\n",
      "Epoch [4/10], Batch: 4470, Train Loss: 0.8119\n",
      "Epoch [4/10], Batch: 4480, Train Loss: 0.8391\n",
      "Epoch [4/10], Batch: 4490, Train Loss: 0.8509\n",
      "Epoch [4/10], Batch: 4500, Train Loss: 0.8615\n",
      "Epoch [4/10], Batch: 4510, Train Loss: 0.7352\n",
      "Epoch [4/10], Batch: 4520, Train Loss: 0.8274\n",
      "Epoch [4/10], Batch: 4530, Train Loss: 0.7038\n",
      "Epoch [4/10], Batch: 4540, Train Loss: 0.7923\n",
      "Epoch [4/10], Batch: 4550, Train Loss: 0.7479\n",
      "Epoch [4/10], Batch: 4560, Train Loss: 0.8436\n",
      "Epoch [4/10], Batch: 4570, Train Loss: 0.7495\n",
      "Epoch [4/10], Batch: 4580, Train Loss: 0.7986\n",
      "Epoch [4/10], Batch: 4590, Train Loss: 0.7288\n",
      "Epoch [4/10], Batch: 4600, Train Loss: 0.7770\n",
      "Epoch [4/10], Batch: 4610, Train Loss: 0.8406\n",
      "Epoch [4/10], Batch: 4620, Train Loss: 0.7718\n",
      "Epoch [4/10], Batch: 4630, Train Loss: 0.7762\n",
      "Epoch [4/10], Batch: 4640, Train Loss: 0.8446\n",
      "Epoch [4/10], Batch: 4650, Train Loss: 0.8058\n",
      "Epoch [4/10], Batch: 4660, Train Loss: 0.8312\n",
      "Epoch [4/10], Batch: 4670, Train Loss: 0.9013\n",
      "Epoch [4/10], Batch: 4680, Train Loss: 0.7692\n",
      "Epoch [4/10], Batch: 4690, Train Loss: 0.8738\n",
      "Epoch [4/10], Batch: 4700, Train Loss: 0.9685\n",
      "Epoch [4/10], Batch: 4710, Train Loss: 0.8181\n",
      "Epoch [4/10], Batch: 4720, Train Loss: 0.8128\n",
      "Epoch [4/10], Batch: 4730, Train Loss: 0.9236\n",
      "Epoch [4/10], Batch: 4740, Train Loss: 0.6693\n",
      "Epoch [4/10], Batch: 4750, Train Loss: 0.7406\n",
      "Epoch [4/10], Batch: 4760, Train Loss: 0.8321\n",
      "Epoch [4/10], Batch: 4770, Train Loss: 0.8093\n",
      "Epoch [4/10], Batch: 4780, Train Loss: 0.7969\n",
      "Epoch [4/10], Batch: 4790, Train Loss: 0.8924\n",
      "Epoch [4/10], Batch: 4800, Train Loss: 0.8468\n",
      "Epoch [4/10], Batch: 4810, Train Loss: 0.7773\n",
      "Epoch [4/10], Batch: 4820, Train Loss: 0.9671\n",
      "Epoch [4/10], Batch: 4830, Train Loss: 0.7431\n",
      "Epoch [4/10], Batch: 4840, Train Loss: 0.9335\n",
      "Epoch [4/10], Batch: 4850, Train Loss: 0.7822\n",
      "Epoch [4/10], Batch: 4860, Train Loss: 0.9140\n",
      "Epoch [4/10], Batch: 4870, Train Loss: 0.7777\n",
      "Epoch [4/10], Batch: 4880, Train Loss: 0.8146\n",
      "Epoch [4/10], Batch: 4890, Train Loss: 0.8548\n",
      "Epoch [4/10], Batch: 4900, Train Loss: 0.9438\n",
      "Epoch [4/10], Batch: 4910, Train Loss: 0.7148\n",
      "Epoch [4/10], Batch: 4920, Train Loss: 0.7288\n",
      "Epoch [4/10], Batch: 4930, Train Loss: 0.9052\n",
      "Epoch [4/10], Batch: 4940, Train Loss: 0.8142\n",
      "Epoch [4/10], Batch: 4950, Train Loss: 0.8451\n",
      "Epoch [4/10], Batch: 4960, Train Loss: 0.7448\n",
      "Epoch [4/10], Batch: 4970, Train Loss: 0.8112\n",
      "Epoch [4/10], Batch: 4980, Train Loss: 0.8887\n",
      "Epoch [4/10], Batch: 4990, Train Loss: 0.7516\n",
      "Epoch [4/10], Batch: 5000, Train Loss: 0.6775\n",
      "Epoch [4/10], Batch: 5010, Train Loss: 0.8781\n",
      "Epoch [4/10], Batch: 5020, Train Loss: 0.8051\n",
      "Epoch [4/10], Batch: 5030, Train Loss: 0.7957\n",
      "Epoch [4/10], Batch: 5040, Train Loss: 0.9173\n",
      "Epoch [4/10], Batch: 5050, Train Loss: 0.8064\n",
      "Epoch [4/10], Batch: 5060, Train Loss: 0.8384\n",
      "Epoch [4/10], Batch: 5070, Train Loss: 0.7373\n",
      "Epoch [4/10], Batch: 5080, Train Loss: 0.8062\n",
      "Epoch [4/10], Batch: 5090, Train Loss: 0.7325\n",
      "Epoch [4/10], Batch: 5100, Train Loss: 0.7758\n",
      "Epoch [4/10], Batch: 5110, Train Loss: 0.8134\n",
      "Epoch [4/10], Batch: 5120, Train Loss: 0.7084\n",
      "Epoch [4/10], Batch: 5130, Train Loss: 0.7645\n",
      "Epoch [4/10], Batch: 5140, Train Loss: 0.9682\n",
      "Epoch [4/10], Batch: 5150, Train Loss: 0.7571\n",
      "Epoch [4/10], Batch: 5160, Train Loss: 0.8819\n",
      "Epoch [4/10], Batch: 5170, Train Loss: 0.8046\n",
      "Epoch [4/10], Batch: 5180, Train Loss: 0.8984\n",
      "Epoch [4/10], Batch: 5190, Train Loss: 0.7258\n",
      "Epoch [4/10], Batch: 5200, Train Loss: 0.7802\n",
      "Epoch [4/10], Batch: 5210, Train Loss: 0.8547\n",
      "Epoch [4/10], Batch: 5220, Train Loss: 0.9248\n",
      "Epoch [4/10], Batch: 5230, Train Loss: 0.7090\n",
      "Epoch [4/10], Batch: 5240, Train Loss: 0.7918\n",
      "Epoch [4/10], Batch: 5250, Train Loss: 1.0397\n",
      "Epoch [4/10], Batch: 5260, Train Loss: 0.9042\n",
      "Epoch [4/10], Batch: 5270, Train Loss: 0.8381\n",
      "Epoch [4/10], Batch: 5280, Train Loss: 0.8155\n",
      "Epoch [4/10], Batch: 5290, Train Loss: 0.9221\n",
      "Epoch [4/10], Batch: 5300, Train Loss: 0.8158\n",
      "Epoch [4/10], Batch: 5310, Train Loss: 0.8004\n",
      "Epoch [4/10], Batch: 5320, Train Loss: 0.7583\n",
      "Epoch [4/10], Batch: 5330, Train Loss: 0.7665\n",
      "Epoch [4/10], Batch: 5340, Train Loss: 0.9837\n",
      "Epoch [4/10], Batch: 5350, Train Loss: 0.7394\n",
      "Epoch [4/10], Batch: 5360, Train Loss: 0.8944\n",
      "Epoch [4/10], Batch: 5370, Train Loss: 0.7557\n",
      "Epoch [4/10], Batch: 5380, Train Loss: 0.7222\n",
      "Epoch [4/10], Batch: 5390, Train Loss: 0.8955\n",
      "Epoch [4/10], Batch: 5400, Train Loss: 0.8582\n",
      "Epoch [4/10], Batch: 5410, Train Loss: 0.9301\n",
      "Epoch [4/10], Batch: 5420, Train Loss: 0.7786\n",
      "Epoch [4/10], Batch: 5430, Train Loss: 0.8007\n",
      "Epoch [4/10], Batch: 5440, Train Loss: 0.7796\n",
      "Epoch [4/10], Batch: 5450, Train Loss: 0.8738\n",
      "Epoch [4/10], Batch: 5460, Train Loss: 0.7534\n",
      "Epoch [4/10], Batch: 5470, Train Loss: 0.7857\n",
      "Epoch [4/10], Batch: 5480, Train Loss: 0.7645\n",
      "Epoch [4/10], Batch: 5490, Train Loss: 0.7494\n",
      "Epoch [4/10], Batch: 5500, Train Loss: 0.9456\n",
      "Epoch [4/10], Batch: 5510, Train Loss: 0.8896\n",
      "Epoch [4/10], Batch: 5520, Train Loss: 0.8496\n",
      "Epoch [4/10], Batch: 5530, Train Loss: 0.9241\n",
      "Epoch [4/10], Batch: 5540, Train Loss: 0.7869\n",
      "Epoch [4/10], Batch: 5550, Train Loss: 0.8537\n",
      "Epoch [4/10], Batch: 5560, Train Loss: 0.7937\n",
      "Epoch [4/10], Batch: 5570, Train Loss: 0.8636\n",
      "Epoch [4/10], Batch: 5580, Train Loss: 0.7746\n",
      "Epoch [4/10], Batch: 5590, Train Loss: 0.8907\n",
      "Epoch [4/10], Batch: 5600, Train Loss: 0.7091\n",
      "Epoch [4/10], Batch: 5610, Train Loss: 0.7911\n",
      "Epoch [4/10], Batch: 5620, Train Loss: 0.9255\n",
      "Epoch [4/10], Batch: 5630, Train Loss: 0.8077\n",
      "Epoch [4/10], Batch: 5640, Train Loss: 0.8870\n",
      "Epoch [4/10], Batch: 5650, Train Loss: 0.8489\n",
      "Epoch [4/10], Batch: 5660, Train Loss: 0.7953\n",
      "Epoch [4/10], Batch: 5670, Train Loss: 0.7910\n",
      "Epoch [4/10], Batch: 5680, Train Loss: 0.8063\n",
      "Epoch [4/10], Batch: 5690, Train Loss: 0.8908\n",
      "Epoch [4/10], Batch: 5700, Train Loss: 0.6934\n",
      "Epoch [4/10], Batch: 5710, Train Loss: 0.9483\n",
      "Epoch [4/10], Batch: 5720, Train Loss: 0.9347\n",
      "Epoch [4/10], Batch: 5730, Train Loss: 0.7819\n",
      "Epoch [4/10], Batch: 5740, Train Loss: 0.8345\n",
      "Epoch [4/10], Batch: 5750, Train Loss: 0.8340\n",
      "Epoch [4/10], Batch: 5760, Train Loss: 0.9241\n",
      "Epoch [4/10], Batch: 5770, Train Loss: 0.8899\n",
      "Epoch [4/10], Batch: 5780, Train Loss: 0.9372\n",
      "Epoch [4/10], Batch: 5790, Train Loss: 0.8802\n",
      "Epoch [4/10], Batch: 5800, Train Loss: 0.8748\n",
      "Epoch [4/10], Batch: 5810, Train Loss: 0.7796\n",
      "Epoch [4/10], Batch: 5820, Train Loss: 0.9104\n",
      "Epoch [4/10], Batch: 5830, Train Loss: 0.8610\n",
      "Epoch [4/10], Batch: 5840, Train Loss: 0.7334\n",
      "Epoch [4/10], Batch: 5850, Train Loss: 0.7782\n",
      "Epoch [4/10], Batch: 5860, Train Loss: 0.7604\n",
      "Epoch [4/10], Batch: 5870, Train Loss: 0.7882\n",
      "Epoch [4/10], Batch: 5880, Train Loss: 0.8426\n",
      "Epoch [4/10], Batch: 5890, Train Loss: 0.8167\n",
      "Epoch [4/10], Batch: 5900, Train Loss: 0.7403\n",
      "Epoch [4/10], Batch: 5910, Train Loss: 0.8493\n",
      "Epoch [4/10], Batch: 5920, Train Loss: 0.8504\n",
      "Epoch [4/10], Batch: 5930, Train Loss: 0.9697\n",
      "Epoch [4/10], Batch: 5940, Train Loss: 0.8213\n",
      "Epoch [4/10], Batch: 5950, Train Loss: 0.7851\n",
      "Epoch [4/10], Batch: 5960, Train Loss: 0.8483\n",
      "Epoch [4/10], Batch: 5970, Train Loss: 0.8560\n",
      "Epoch [4/10], Batch: 5980, Train Loss: 0.7309\n",
      "Epoch [4/10], Batch: 5990, Train Loss: 0.8668\n",
      "Epoch [4/10], Batch: 6000, Train Loss: 0.7303\n",
      "Epoch [4/10], Batch: 6010, Train Loss: 0.9324\n",
      "Epoch [4/10], Batch: 6020, Train Loss: 0.8767\n",
      "Epoch [4/10], Batch: 6030, Train Loss: 0.8868\n",
      "Epoch [4/10], Batch: 6040, Train Loss: 0.7881\n",
      "Epoch [4/10], Batch: 6050, Train Loss: 0.7974\n",
      "Epoch [4/10], Batch: 6060, Train Loss: 0.8966\n",
      "Epoch [4/10], Batch: 6070, Train Loss: 0.7116\n",
      "Epoch [4/10], Batch: 6080, Train Loss: 0.7171\n",
      "Epoch [4/10], Batch: 6090, Train Loss: 0.7399\n",
      "Epoch [4/10], Batch: 6100, Train Loss: 0.8117\n",
      "Epoch [4/10], Batch: 6110, Train Loss: 0.7518\n",
      "Epoch [4/10], Batch: 6120, Train Loss: 0.6633\n",
      "Epoch [4/10], Batch: 6130, Train Loss: 0.7684\n",
      "Epoch [4/10], Batch: 6140, Train Loss: 0.8069\n",
      "Epoch [4/10], Batch: 6150, Train Loss: 0.7610\n",
      "Epoch [4/10], Batch: 6160, Train Loss: 0.8758\n",
      "Epoch [4/10], Batch: 6170, Train Loss: 0.8543\n",
      "Epoch [4/10], Batch: 6180, Train Loss: 0.8933\n",
      "Epoch [4/10], Batch: 6190, Train Loss: 0.8589\n",
      "Epoch [4/10], Batch: 6200, Train Loss: 0.8184\n",
      "Epoch [4/10], Batch: 6210, Train Loss: 0.7693\n",
      "Epoch [4/10], Batch: 6220, Train Loss: 0.8116\n",
      "Epoch [4/10], Batch: 6230, Train Loss: 0.7905\n",
      "Epoch [4/10], Batch: 6240, Train Loss: 0.8294\n",
      "Epoch [4/10], Batch: 6250, Train Loss: 0.9071\n",
      "Epoch [4/10], Batch: 6260, Train Loss: 0.9254\n",
      "Epoch [4/10], Batch: 6270, Train Loss: 0.8940\n",
      "Epoch [4/10], Batch: 6280, Train Loss: 0.9105\n",
      "Epoch [4/10], Batch: 6290, Train Loss: 0.8182\n",
      "Epoch [4/10], Batch: 6300, Train Loss: 0.6763\n",
      "Epoch [4/10], Batch: 6310, Train Loss: 0.8352\n",
      "Epoch [4/10], Batch: 6320, Train Loss: 0.8423\n",
      "Epoch [4/10], Batch: 6330, Train Loss: 0.7847\n",
      "Epoch [4/10], Batch: 6340, Train Loss: 0.8993\n",
      "Epoch [4/10], Batch: 6350, Train Loss: 0.8883\n",
      "Epoch [4/10], Batch: 6360, Train Loss: 0.8253\n",
      "Epoch [4/10], Batch: 6370, Train Loss: 0.7227\n",
      "Epoch [4/10], Batch: 6380, Train Loss: 0.7865\n",
      "Epoch [4/10], Batch: 6390, Train Loss: 0.7819\n",
      "Epoch [4/10], Batch: 6400, Train Loss: 0.8997\n",
      "Epoch [4/10], Batch: 6410, Train Loss: 0.7060\n",
      "Epoch [4/10], Batch: 6420, Train Loss: 0.7672\n",
      "Epoch [4/10], Batch: 6430, Train Loss: 0.7470\n",
      "Epoch [4/10], Batch: 6440, Train Loss: 0.7829\n",
      "Epoch [4/10], Batch: 6450, Train Loss: 0.8220\n",
      "Epoch [4/10], Batch: 6460, Train Loss: 0.7970\n",
      "Epoch [4/10], Batch: 6470, Train Loss: 0.8023\n",
      "Epoch [4/10], Batch: 6480, Train Loss: 0.7937\n",
      "Epoch [4/10], Batch: 6490, Train Loss: 0.6923\n",
      "Epoch [4/10], Batch: 6500, Train Loss: 0.8207\n",
      "Epoch [4/10], Batch: 6510, Train Loss: 0.6976\n",
      "Epoch [4/10], Batch: 6520, Train Loss: 0.7558\n",
      "Epoch [4/10], Batch: 6530, Train Loss: 0.8134\n",
      "Epoch [4/10], Batch: 6540, Train Loss: 0.7941\n",
      "Epoch [4/10], Batch: 6550, Train Loss: 0.8305\n",
      "Epoch [4/10], Batch: 6560, Train Loss: 0.7428\n",
      "Epoch [4/10], Batch: 6570, Train Loss: 0.8081\n",
      "Epoch [4/10], Batch: 6580, Train Loss: 0.7937\n",
      "Epoch [4/10], Batch: 6590, Train Loss: 0.7981\n",
      "Epoch [4/10], Batch: 6600, Train Loss: 0.8853\n",
      "Epoch [4/10], Batch: 6610, Train Loss: 0.8134\n",
      "Epoch [4/10], Batch: 6620, Train Loss: 0.7359\n",
      "Epoch [4/10], Batch: 6630, Train Loss: 0.8120\n",
      "Epoch [4/10], Batch: 6640, Train Loss: 0.8820\n",
      "Epoch [4/10], Batch: 6650, Train Loss: 0.7922\n",
      "Epoch [4/10], Batch: 6660, Train Loss: 0.9255\n",
      "Epoch [4/10], Batch: 6670, Train Loss: 0.7120\n",
      "Epoch [4/10], Batch: 6680, Train Loss: 0.8089\n",
      "Epoch [4/10], Batch: 6690, Train Loss: 0.8419\n",
      "Epoch [4/10], Batch: 6700, Train Loss: 0.9105\n",
      "Epoch [4/10], Batch: 6710, Train Loss: 0.8951\n",
      "Epoch [4/10], Batch: 6720, Train Loss: 0.7765\n",
      "Epoch [4/10], Batch: 6730, Train Loss: 0.7691\n",
      "Epoch [4/10], Batch: 6740, Train Loss: 0.7910\n",
      "Epoch [4/10], Batch: 6750, Train Loss: 0.7145\n",
      "Epoch [4/10], Batch: 6760, Train Loss: 0.8715\n",
      "Epoch [5/10], Batch: 10, Train Loss: 0.7950\n",
      "Epoch [5/10], Batch: 20, Train Loss: 0.6024\n",
      "Epoch [5/10], Batch: 30, Train Loss: 0.6733\n",
      "Epoch [5/10], Batch: 40, Train Loss: 0.7015\n",
      "Epoch [5/10], Batch: 50, Train Loss: 0.9478\n",
      "Epoch [5/10], Batch: 60, Train Loss: 0.7674\n",
      "Epoch [5/10], Batch: 70, Train Loss: 0.8903\n",
      "Epoch [5/10], Batch: 80, Train Loss: 0.8159\n",
      "Epoch [5/10], Batch: 90, Train Loss: 0.7906\n",
      "Epoch [5/10], Batch: 100, Train Loss: 0.7230\n",
      "Epoch [5/10], Batch: 110, Train Loss: 0.9271\n",
      "Epoch [5/10], Batch: 120, Train Loss: 0.7581\n",
      "Epoch [5/10], Batch: 130, Train Loss: 0.9046\n",
      "Epoch [5/10], Batch: 140, Train Loss: 0.8462\n",
      "Epoch [5/10], Batch: 150, Train Loss: 0.7910\n",
      "Epoch [5/10], Batch: 160, Train Loss: 0.7414\n",
      "Epoch [5/10], Batch: 170, Train Loss: 0.7413\n",
      "Epoch [5/10], Batch: 180, Train Loss: 0.6677\n",
      "Epoch [5/10], Batch: 190, Train Loss: 0.7582\n",
      "Epoch [5/10], Batch: 200, Train Loss: 0.6776\n",
      "Epoch [5/10], Batch: 210, Train Loss: 0.8356\n",
      "Epoch [5/10], Batch: 220, Train Loss: 0.7426\n",
      "Epoch [5/10], Batch: 230, Train Loss: 0.9281\n",
      "Epoch [5/10], Batch: 240, Train Loss: 0.7484\n",
      "Epoch [5/10], Batch: 250, Train Loss: 0.8441\n",
      "Epoch [5/10], Batch: 260, Train Loss: 0.7548\n",
      "Epoch [5/10], Batch: 270, Train Loss: 0.7867\n",
      "Epoch [5/10], Batch: 280, Train Loss: 0.7190\n",
      "Epoch [5/10], Batch: 290, Train Loss: 0.8739\n",
      "Epoch [5/10], Batch: 300, Train Loss: 0.8944\n",
      "Epoch [5/10], Batch: 310, Train Loss: 0.7894\n",
      "Epoch [5/10], Batch: 320, Train Loss: 0.7613\n",
      "Epoch [5/10], Batch: 330, Train Loss: 0.7416\n",
      "Epoch [5/10], Batch: 340, Train Loss: 0.8200\n",
      "Epoch [5/10], Batch: 350, Train Loss: 0.7980\n",
      "Epoch [5/10], Batch: 360, Train Loss: 0.7533\n",
      "Epoch [5/10], Batch: 370, Train Loss: 0.7802\n",
      "Epoch [5/10], Batch: 380, Train Loss: 0.8412\n",
      "Epoch [5/10], Batch: 390, Train Loss: 0.8847\n",
      "Epoch [5/10], Batch: 400, Train Loss: 0.8563\n",
      "Epoch [5/10], Batch: 410, Train Loss: 0.9138\n",
      "Epoch [5/10], Batch: 420, Train Loss: 0.8404\n",
      "Epoch [5/10], Batch: 430, Train Loss: 0.8148\n",
      "Epoch [5/10], Batch: 440, Train Loss: 0.6980\n",
      "Epoch [5/10], Batch: 450, Train Loss: 0.7159\n",
      "Epoch [5/10], Batch: 460, Train Loss: 0.8772\n",
      "Epoch [5/10], Batch: 470, Train Loss: 0.7652\n",
      "Epoch [5/10], Batch: 480, Train Loss: 0.8304\n",
      "Epoch [5/10], Batch: 490, Train Loss: 0.6967\n",
      "Epoch [5/10], Batch: 500, Train Loss: 0.9518\n",
      "Epoch [5/10], Batch: 510, Train Loss: 0.7631\n",
      "Epoch [5/10], Batch: 520, Train Loss: 0.8720\n",
      "Epoch [5/10], Batch: 530, Train Loss: 0.8128\n",
      "Epoch [5/10], Batch: 540, Train Loss: 0.8189\n",
      "Epoch [5/10], Batch: 550, Train Loss: 0.8678\n",
      "Epoch [5/10], Batch: 560, Train Loss: 0.7601\n",
      "Epoch [5/10], Batch: 570, Train Loss: 0.8805\n",
      "Epoch [5/10], Batch: 580, Train Loss: 0.7793\n",
      "Epoch [5/10], Batch: 590, Train Loss: 0.8246\n",
      "Epoch [5/10], Batch: 600, Train Loss: 0.7970\n",
      "Epoch [5/10], Batch: 610, Train Loss: 0.7916\n",
      "Epoch [5/10], Batch: 620, Train Loss: 0.7774\n",
      "Epoch [5/10], Batch: 630, Train Loss: 0.8043\n",
      "Epoch [5/10], Batch: 640, Train Loss: 0.8480\n",
      "Epoch [5/10], Batch: 650, Train Loss: 0.7914\n",
      "Epoch [5/10], Batch: 660, Train Loss: 0.9547\n",
      "Epoch [5/10], Batch: 670, Train Loss: 0.8201\n",
      "Epoch [5/10], Batch: 680, Train Loss: 0.7737\n",
      "Epoch [5/10], Batch: 690, Train Loss: 0.8176\n",
      "Epoch [5/10], Batch: 700, Train Loss: 0.7595\n",
      "Epoch [5/10], Batch: 710, Train Loss: 0.7510\n",
      "Epoch [5/10], Batch: 720, Train Loss: 0.7528\n",
      "Epoch [5/10], Batch: 730, Train Loss: 0.7812\n",
      "Epoch [5/10], Batch: 740, Train Loss: 0.7156\n",
      "Epoch [5/10], Batch: 750, Train Loss: 0.6679\n",
      "Epoch [5/10], Batch: 760, Train Loss: 0.8248\n",
      "Epoch [5/10], Batch: 770, Train Loss: 0.7403\n",
      "Epoch [5/10], Batch: 780, Train Loss: 0.6887\n",
      "Epoch [5/10], Batch: 790, Train Loss: 0.8390\n",
      "Epoch [5/10], Batch: 800, Train Loss: 0.7830\n",
      "Epoch [5/10], Batch: 810, Train Loss: 0.7722\n",
      "Epoch [5/10], Batch: 820, Train Loss: 0.8761\n",
      "Epoch [5/10], Batch: 830, Train Loss: 0.8945\n",
      "Epoch [5/10], Batch: 840, Train Loss: 0.8401\n",
      "Epoch [5/10], Batch: 850, Train Loss: 0.7468\n",
      "Epoch [5/10], Batch: 860, Train Loss: 0.7234\n",
      "Epoch [5/10], Batch: 870, Train Loss: 0.8529\n",
      "Epoch [5/10], Batch: 880, Train Loss: 0.8888\n",
      "Epoch [5/10], Batch: 890, Train Loss: 0.7844\n",
      "Epoch [5/10], Batch: 900, Train Loss: 0.7559\n",
      "Epoch [5/10], Batch: 910, Train Loss: 0.8022\n",
      "Epoch [5/10], Batch: 920, Train Loss: 0.8123\n",
      "Epoch [5/10], Batch: 930, Train Loss: 0.8090\n",
      "Epoch [5/10], Batch: 940, Train Loss: 0.8655\n",
      "Epoch [5/10], Batch: 950, Train Loss: 0.8482\n",
      "Epoch [5/10], Batch: 960, Train Loss: 0.8904\n",
      "Epoch [5/10], Batch: 970, Train Loss: 0.6307\n",
      "Epoch [5/10], Batch: 980, Train Loss: 0.8203\n",
      "Epoch [5/10], Batch: 990, Train Loss: 0.8741\n",
      "Epoch [5/10], Batch: 1000, Train Loss: 0.8159\n",
      "Epoch [5/10], Batch: 1010, Train Loss: 0.7379\n",
      "Epoch [5/10], Batch: 1020, Train Loss: 0.7595\n",
      "Epoch [5/10], Batch: 1030, Train Loss: 0.8083\n",
      "Epoch [5/10], Batch: 1040, Train Loss: 0.8618\n",
      "Epoch [5/10], Batch: 1050, Train Loss: 0.8187\n",
      "Epoch [5/10], Batch: 1060, Train Loss: 0.8737\n",
      "Epoch [5/10], Batch: 1070, Train Loss: 0.8441\n",
      "Epoch [5/10], Batch: 1080, Train Loss: 0.7136\n",
      "Epoch [5/10], Batch: 1090, Train Loss: 0.7142\n",
      "Epoch [5/10], Batch: 1100, Train Loss: 0.7447\n",
      "Epoch [5/10], Batch: 1110, Train Loss: 0.8780\n",
      "Epoch [5/10], Batch: 1120, Train Loss: 0.6757\n",
      "Epoch [5/10], Batch: 1130, Train Loss: 0.8807\n",
      "Epoch [5/10], Batch: 1140, Train Loss: 0.8169\n",
      "Epoch [5/10], Batch: 1150, Train Loss: 0.8345\n",
      "Epoch [5/10], Batch: 1160, Train Loss: 0.7334\n",
      "Epoch [5/10], Batch: 1170, Train Loss: 0.8305\n",
      "Epoch [5/10], Batch: 1180, Train Loss: 0.9661\n",
      "Epoch [5/10], Batch: 1190, Train Loss: 0.7905\n",
      "Epoch [5/10], Batch: 1200, Train Loss: 0.8051\n",
      "Epoch [5/10], Batch: 1210, Train Loss: 0.7242\n",
      "Epoch [5/10], Batch: 1220, Train Loss: 0.8451\n",
      "Epoch [5/10], Batch: 1230, Train Loss: 0.8345\n",
      "Epoch [5/10], Batch: 1240, Train Loss: 0.8045\n",
      "Epoch [5/10], Batch: 1250, Train Loss: 0.7939\n",
      "Epoch [5/10], Batch: 1260, Train Loss: 0.8051\n",
      "Epoch [5/10], Batch: 1270, Train Loss: 0.8558\n",
      "Epoch [5/10], Batch: 1280, Train Loss: 0.7734\n",
      "Epoch [5/10], Batch: 1290, Train Loss: 0.7614\n",
      "Epoch [5/10], Batch: 1300, Train Loss: 0.7239\n",
      "Epoch [5/10], Batch: 1310, Train Loss: 0.8052\n",
      "Epoch [5/10], Batch: 1320, Train Loss: 0.7426\n",
      "Epoch [5/10], Batch: 1330, Train Loss: 0.9044\n",
      "Epoch [5/10], Batch: 1340, Train Loss: 0.7707\n",
      "Epoch [5/10], Batch: 1350, Train Loss: 0.7955\n",
      "Epoch [5/10], Batch: 1360, Train Loss: 0.7312\n",
      "Epoch [5/10], Batch: 1370, Train Loss: 0.8936\n",
      "Epoch [5/10], Batch: 1380, Train Loss: 0.7295\n",
      "Epoch [5/10], Batch: 1390, Train Loss: 0.8334\n",
      "Epoch [5/10], Batch: 1400, Train Loss: 0.7644\n",
      "Epoch [5/10], Batch: 1410, Train Loss: 1.0033\n",
      "Epoch [5/10], Batch: 1420, Train Loss: 0.8541\n",
      "Epoch [5/10], Batch: 1430, Train Loss: 0.9786\n",
      "Epoch [5/10], Batch: 1440, Train Loss: 0.8105\n",
      "Epoch [5/10], Batch: 1450, Train Loss: 0.8120\n",
      "Epoch [5/10], Batch: 1460, Train Loss: 0.7578\n",
      "Epoch [5/10], Batch: 1470, Train Loss: 0.8351\n",
      "Epoch [5/10], Batch: 1480, Train Loss: 0.8809\n",
      "Epoch [5/10], Batch: 1490, Train Loss: 0.7459\n",
      "Epoch [5/10], Batch: 1500, Train Loss: 0.8471\n",
      "Epoch [5/10], Batch: 1510, Train Loss: 0.8541\n",
      "Epoch [5/10], Batch: 1520, Train Loss: 0.7177\n",
      "Epoch [5/10], Batch: 1530, Train Loss: 0.6363\n",
      "Epoch [5/10], Batch: 1540, Train Loss: 0.7359\n",
      "Epoch [5/10], Batch: 1550, Train Loss: 0.7802\n",
      "Epoch [5/10], Batch: 1560, Train Loss: 0.7604\n",
      "Epoch [5/10], Batch: 1570, Train Loss: 0.8364\n",
      "Epoch [5/10], Batch: 1580, Train Loss: 0.8487\n",
      "Epoch [5/10], Batch: 1590, Train Loss: 0.7469\n",
      "Epoch [5/10], Batch: 1600, Train Loss: 0.7951\n",
      "Epoch [5/10], Batch: 1610, Train Loss: 0.8762\n",
      "Epoch [5/10], Batch: 1620, Train Loss: 0.8051\n",
      "Epoch [5/10], Batch: 1630, Train Loss: 0.8821\n",
      "Epoch [5/10], Batch: 1640, Train Loss: 0.6648\n",
      "Epoch [5/10], Batch: 1650, Train Loss: 0.8933\n",
      "Epoch [5/10], Batch: 1660, Train Loss: 0.7297\n",
      "Epoch [5/10], Batch: 1670, Train Loss: 0.7942\n",
      "Epoch [5/10], Batch: 1680, Train Loss: 0.7287\n",
      "Epoch [5/10], Batch: 1690, Train Loss: 0.8995\n",
      "Epoch [5/10], Batch: 1700, Train Loss: 0.7690\n",
      "Epoch [5/10], Batch: 1710, Train Loss: 0.7794\n",
      "Epoch [5/10], Batch: 1720, Train Loss: 0.8540\n",
      "Epoch [5/10], Batch: 1730, Train Loss: 0.7869\n",
      "Epoch [5/10], Batch: 1740, Train Loss: 0.7996\n",
      "Epoch [5/10], Batch: 1750, Train Loss: 0.7757\n",
      "Epoch [5/10], Batch: 1760, Train Loss: 0.8621\n",
      "Epoch [5/10], Batch: 1770, Train Loss: 0.7489\n",
      "Epoch [5/10], Batch: 1780, Train Loss: 0.7418\n",
      "Epoch [5/10], Batch: 1790, Train Loss: 0.8416\n",
      "Epoch [5/10], Batch: 1800, Train Loss: 0.8213\n",
      "Epoch [5/10], Batch: 1810, Train Loss: 0.7483\n",
      "Epoch [5/10], Batch: 1820, Train Loss: 0.8053\n",
      "Epoch [5/10], Batch: 1830, Train Loss: 0.8479\n",
      "Epoch [5/10], Batch: 1840, Train Loss: 0.8773\n",
      "Epoch [5/10], Batch: 1850, Train Loss: 0.8407\n",
      "Epoch [5/10], Batch: 1860, Train Loss: 0.8282\n",
      "Epoch [5/10], Batch: 1870, Train Loss: 0.8380\n",
      "Epoch [5/10], Batch: 1880, Train Loss: 0.7976\n",
      "Epoch [5/10], Batch: 1890, Train Loss: 0.8396\n",
      "Epoch [5/10], Batch: 1900, Train Loss: 0.8116\n",
      "Epoch [5/10], Batch: 1910, Train Loss: 0.7046\n",
      "Epoch [5/10], Batch: 1920, Train Loss: 0.8390\n",
      "Epoch [5/10], Batch: 1930, Train Loss: 0.8309\n",
      "Epoch [5/10], Batch: 1940, Train Loss: 0.7698\n",
      "Epoch [5/10], Batch: 1950, Train Loss: 0.8530\n",
      "Epoch [5/10], Batch: 1960, Train Loss: 0.7060\n",
      "Epoch [5/10], Batch: 1970, Train Loss: 0.7715\n",
      "Epoch [5/10], Batch: 1980, Train Loss: 0.7407\n",
      "Epoch [5/10], Batch: 1990, Train Loss: 0.7390\n",
      "Epoch [5/10], Batch: 2000, Train Loss: 0.7895\n",
      "Epoch [5/10], Batch: 2010, Train Loss: 0.7961\n",
      "Epoch [5/10], Batch: 2020, Train Loss: 0.8348\n",
      "Epoch [5/10], Batch: 2030, Train Loss: 0.8156\n",
      "Epoch [5/10], Batch: 2040, Train Loss: 0.7282\n",
      "Epoch [5/10], Batch: 2050, Train Loss: 0.8296\n",
      "Epoch [5/10], Batch: 2060, Train Loss: 0.6694\n",
      "Epoch [5/10], Batch: 2070, Train Loss: 0.7549\n",
      "Epoch [5/10], Batch: 2080, Train Loss: 0.7530\n",
      "Epoch [5/10], Batch: 2090, Train Loss: 0.7756\n",
      "Epoch [5/10], Batch: 2100, Train Loss: 0.7531\n",
      "Epoch [5/10], Batch: 2110, Train Loss: 0.9442\n",
      "Epoch [5/10], Batch: 2120, Train Loss: 0.7430\n",
      "Epoch [5/10], Batch: 2130, Train Loss: 0.8741\n",
      "Epoch [5/10], Batch: 2140, Train Loss: 0.8776\n",
      "Epoch [5/10], Batch: 2150, Train Loss: 0.9832\n",
      "Epoch [5/10], Batch: 2160, Train Loss: 0.8217\n",
      "Epoch [5/10], Batch: 2170, Train Loss: 0.7652\n",
      "Epoch [5/10], Batch: 2180, Train Loss: 0.7117\n",
      "Epoch [5/10], Batch: 2190, Train Loss: 0.6887\n",
      "Epoch [5/10], Batch: 2200, Train Loss: 0.8656\n",
      "Epoch [5/10], Batch: 2210, Train Loss: 0.8119\n",
      "Epoch [5/10], Batch: 2220, Train Loss: 0.7401\n",
      "Epoch [5/10], Batch: 2230, Train Loss: 0.8504\n",
      "Epoch [5/10], Batch: 2240, Train Loss: 0.9541\n",
      "Epoch [5/10], Batch: 2250, Train Loss: 0.7963\n",
      "Epoch [5/10], Batch: 2260, Train Loss: 0.8014\n",
      "Epoch [5/10], Batch: 2270, Train Loss: 0.8151\n",
      "Epoch [5/10], Batch: 2280, Train Loss: 0.7323\n",
      "Epoch [5/10], Batch: 2290, Train Loss: 0.8867\n",
      "Epoch [5/10], Batch: 2300, Train Loss: 0.7603\n",
      "Epoch [5/10], Batch: 2310, Train Loss: 0.7389\n",
      "Epoch [5/10], Batch: 2320, Train Loss: 0.9032\n",
      "Epoch [5/10], Batch: 2330, Train Loss: 0.7932\n",
      "Epoch [5/10], Batch: 2340, Train Loss: 0.8942\n",
      "Epoch [5/10], Batch: 2350, Train Loss: 0.7492\n",
      "Epoch [5/10], Batch: 2360, Train Loss: 0.8010\n",
      "Epoch [5/10], Batch: 2370, Train Loss: 0.8650\n",
      "Epoch [5/10], Batch: 2380, Train Loss: 0.9119\n",
      "Epoch [5/10], Batch: 2390, Train Loss: 0.6643\n",
      "Epoch [5/10], Batch: 2400, Train Loss: 0.7981\n",
      "Epoch [5/10], Batch: 2410, Train Loss: 0.8024\n",
      "Epoch [5/10], Batch: 2420, Train Loss: 0.7742\n",
      "Epoch [5/10], Batch: 2430, Train Loss: 0.7652\n",
      "Epoch [5/10], Batch: 2440, Train Loss: 0.7965\n",
      "Epoch [5/10], Batch: 2450, Train Loss: 0.7673\n",
      "Epoch [5/10], Batch: 2460, Train Loss: 0.8109\n",
      "Epoch [5/10], Batch: 2470, Train Loss: 0.8125\n",
      "Epoch [5/10], Batch: 2480, Train Loss: 0.7173\n",
      "Epoch [5/10], Batch: 2490, Train Loss: 0.8642\n",
      "Epoch [5/10], Batch: 2500, Train Loss: 0.7964\n",
      "Epoch [5/10], Batch: 2510, Train Loss: 0.7665\n",
      "Epoch [5/10], Batch: 2520, Train Loss: 0.7553\n",
      "Epoch [5/10], Batch: 2530, Train Loss: 0.7499\n",
      "Epoch [5/10], Batch: 2540, Train Loss: 0.8369\n",
      "Epoch [5/10], Batch: 2550, Train Loss: 0.7349\n",
      "Epoch [5/10], Batch: 2560, Train Loss: 0.8425\n",
      "Epoch [5/10], Batch: 2570, Train Loss: 0.6550\n",
      "Epoch [5/10], Batch: 2580, Train Loss: 0.7489\n",
      "Epoch [5/10], Batch: 2590, Train Loss: 0.8443\n",
      "Epoch [5/10], Batch: 2600, Train Loss: 0.8049\n",
      "Epoch [5/10], Batch: 2610, Train Loss: 0.8143\n",
      "Epoch [5/10], Batch: 2620, Train Loss: 0.7519\n",
      "Epoch [5/10], Batch: 2630, Train Loss: 0.8048\n",
      "Epoch [5/10], Batch: 2640, Train Loss: 0.7058\n",
      "Epoch [5/10], Batch: 2650, Train Loss: 0.7879\n",
      "Epoch [5/10], Batch: 2660, Train Loss: 0.7945\n",
      "Epoch [5/10], Batch: 2670, Train Loss: 0.7494\n",
      "Epoch [5/10], Batch: 2680, Train Loss: 0.8537\n",
      "Epoch [5/10], Batch: 2690, Train Loss: 0.7203\n",
      "Epoch [5/10], Batch: 2700, Train Loss: 0.8233\n",
      "Epoch [5/10], Batch: 2710, Train Loss: 0.7728\n",
      "Epoch [5/10], Batch: 2720, Train Loss: 0.8292\n",
      "Epoch [5/10], Batch: 2730, Train Loss: 0.8566\n",
      "Epoch [5/10], Batch: 2740, Train Loss: 0.8993\n",
      "Epoch [5/10], Batch: 2750, Train Loss: 0.8639\n",
      "Epoch [5/10], Batch: 2760, Train Loss: 0.7431\n",
      "Epoch [5/10], Batch: 2770, Train Loss: 0.7798\n",
      "Epoch [5/10], Batch: 2780, Train Loss: 0.7289\n",
      "Epoch [5/10], Batch: 2790, Train Loss: 0.6576\n",
      "Epoch [5/10], Batch: 2800, Train Loss: 0.7873\n",
      "Epoch [5/10], Batch: 2810, Train Loss: 0.8703\n",
      "Epoch [5/10], Batch: 2820, Train Loss: 0.7111\n",
      "Epoch [5/10], Batch: 2830, Train Loss: 0.9326\n",
      "Epoch [5/10], Batch: 2840, Train Loss: 0.7176\n",
      "Epoch [5/10], Batch: 2850, Train Loss: 0.8415\n",
      "Epoch [5/10], Batch: 2860, Train Loss: 0.8329\n",
      "Epoch [5/10], Batch: 2870, Train Loss: 0.7190\n",
      "Epoch [5/10], Batch: 2880, Train Loss: 1.0311\n",
      "Epoch [5/10], Batch: 2890, Train Loss: 0.8046\n",
      "Epoch [5/10], Batch: 2900, Train Loss: 0.8034\n",
      "Epoch [5/10], Batch: 2910, Train Loss: 0.8696\n",
      "Epoch [5/10], Batch: 2920, Train Loss: 0.8442\n",
      "Epoch [5/10], Batch: 2930, Train Loss: 0.8167\n",
      "Epoch [5/10], Batch: 2940, Train Loss: 0.8937\n",
      "Epoch [5/10], Batch: 2950, Train Loss: 0.6584\n",
      "Epoch [5/10], Batch: 2960, Train Loss: 0.8914\n",
      "Epoch [5/10], Batch: 2970, Train Loss: 0.8321\n",
      "Epoch [5/10], Batch: 2980, Train Loss: 0.7250\n",
      "Epoch [5/10], Batch: 2990, Train Loss: 0.6592\n",
      "Epoch [5/10], Batch: 3000, Train Loss: 0.7636\n",
      "Epoch [5/10], Batch: 3010, Train Loss: 0.8593\n",
      "Epoch [5/10], Batch: 3020, Train Loss: 0.8913\n",
      "Epoch [5/10], Batch: 3030, Train Loss: 0.6801\n",
      "Epoch [5/10], Batch: 3040, Train Loss: 0.6878\n",
      "Epoch [5/10], Batch: 3050, Train Loss: 0.7521\n",
      "Epoch [5/10], Batch: 3060, Train Loss: 0.7630\n",
      "Epoch [5/10], Batch: 3070, Train Loss: 0.9172\n",
      "Epoch [5/10], Batch: 3080, Train Loss: 0.9259\n",
      "Epoch [5/10], Batch: 3090, Train Loss: 0.8480\n",
      "Epoch [5/10], Batch: 3100, Train Loss: 0.7943\n",
      "Epoch [5/10], Batch: 3110, Train Loss: 0.7475\n",
      "Epoch [5/10], Batch: 3120, Train Loss: 0.7393\n",
      "Epoch [5/10], Batch: 3130, Train Loss: 0.8707\n",
      "Epoch [5/10], Batch: 3140, Train Loss: 0.7943\n",
      "Epoch [5/10], Batch: 3150, Train Loss: 0.7477\n",
      "Epoch [5/10], Batch: 3160, Train Loss: 0.8735\n",
      "Epoch [5/10], Batch: 3170, Train Loss: 0.6778\n",
      "Epoch [5/10], Batch: 3180, Train Loss: 0.9029\n",
      "Epoch [5/10], Batch: 3190, Train Loss: 0.5912\n",
      "Epoch [5/10], Batch: 3200, Train Loss: 1.0408\n",
      "Epoch [5/10], Batch: 3210, Train Loss: 0.8108\n",
      "Epoch [5/10], Batch: 3220, Train Loss: 0.9265\n",
      "Epoch [5/10], Batch: 3230, Train Loss: 0.7904\n",
      "Epoch [5/10], Batch: 3240, Train Loss: 0.7560\n",
      "Epoch [5/10], Batch: 3250, Train Loss: 0.7637\n",
      "Epoch [5/10], Batch: 3260, Train Loss: 0.8179\n",
      "Epoch [5/10], Batch: 3270, Train Loss: 0.9170\n",
      "Epoch [5/10], Batch: 3280, Train Loss: 0.9013\n",
      "Epoch [5/10], Batch: 3290, Train Loss: 0.7732\n",
      "Epoch [5/10], Batch: 3300, Train Loss: 0.7852\n",
      "Epoch [5/10], Batch: 3310, Train Loss: 0.8492\n",
      "Epoch [5/10], Batch: 3320, Train Loss: 0.8691\n",
      "Epoch [5/10], Batch: 3330, Train Loss: 0.6264\n",
      "Epoch [5/10], Batch: 3340, Train Loss: 0.8641\n",
      "Epoch [5/10], Batch: 3350, Train Loss: 0.7440\n",
      "Epoch [5/10], Batch: 3360, Train Loss: 0.6503\n",
      "Epoch [5/10], Batch: 3370, Train Loss: 0.7210\n",
      "Epoch [5/10], Batch: 3380, Train Loss: 0.7666\n",
      "Epoch [5/10], Batch: 3390, Train Loss: 0.7391\n",
      "Epoch [5/10], Batch: 3400, Train Loss: 0.8018\n",
      "Epoch [5/10], Batch: 3410, Train Loss: 0.8404\n",
      "Epoch [5/10], Batch: 3420, Train Loss: 0.7531\n",
      "Epoch [5/10], Batch: 3430, Train Loss: 0.9083\n",
      "Epoch [5/10], Batch: 3440, Train Loss: 0.8512\n",
      "Epoch [5/10], Batch: 3450, Train Loss: 0.7343\n",
      "Epoch [5/10], Batch: 3460, Train Loss: 0.8090\n",
      "Epoch [5/10], Batch: 3470, Train Loss: 0.7304\n",
      "Epoch [5/10], Batch: 3480, Train Loss: 0.7691\n",
      "Epoch [5/10], Batch: 3490, Train Loss: 0.8189\n",
      "Epoch [5/10], Batch: 3500, Train Loss: 0.7829\n",
      "Epoch [5/10], Batch: 3510, Train Loss: 0.8446\n",
      "Epoch [5/10], Batch: 3520, Train Loss: 0.8337\n",
      "Epoch [5/10], Batch: 3530, Train Loss: 0.7946\n",
      "Epoch [5/10], Batch: 3540, Train Loss: 0.7264\n",
      "Epoch [5/10], Batch: 3550, Train Loss: 0.7872\n",
      "Epoch [5/10], Batch: 3560, Train Loss: 0.9343\n",
      "Epoch [5/10], Batch: 3570, Train Loss: 0.7959\n",
      "Epoch [5/10], Batch: 3580, Train Loss: 0.8246\n",
      "Epoch [5/10], Batch: 3590, Train Loss: 0.8573\n",
      "Epoch [5/10], Batch: 3600, Train Loss: 0.8871\n",
      "Epoch [5/10], Batch: 3610, Train Loss: 0.6358\n",
      "Epoch [5/10], Batch: 3620, Train Loss: 0.8053\n",
      "Epoch [5/10], Batch: 3630, Train Loss: 0.8907\n",
      "Epoch [5/10], Batch: 3640, Train Loss: 0.7700\n",
      "Epoch [5/10], Batch: 3650, Train Loss: 0.7138\n",
      "Epoch [5/10], Batch: 3660, Train Loss: 0.8172\n",
      "Epoch [5/10], Batch: 3670, Train Loss: 0.7924\n",
      "Epoch [5/10], Batch: 3680, Train Loss: 0.8982\n",
      "Epoch [5/10], Batch: 3690, Train Loss: 0.7535\n",
      "Epoch [5/10], Batch: 3700, Train Loss: 0.8985\n",
      "Epoch [5/10], Batch: 3710, Train Loss: 0.9471\n",
      "Epoch [5/10], Batch: 3720, Train Loss: 0.7819\n",
      "Epoch [5/10], Batch: 3730, Train Loss: 0.6987\n",
      "Epoch [5/10], Batch: 3740, Train Loss: 0.7381\n",
      "Epoch [5/10], Batch: 3750, Train Loss: 0.6864\n",
      "Epoch [5/10], Batch: 3760, Train Loss: 0.6844\n",
      "Epoch [5/10], Batch: 3770, Train Loss: 0.8127\n",
      "Epoch [5/10], Batch: 3780, Train Loss: 0.8639\n",
      "Epoch [5/10], Batch: 3790, Train Loss: 0.8291\n",
      "Epoch [5/10], Batch: 3800, Train Loss: 0.7524\n",
      "Epoch [5/10], Batch: 3810, Train Loss: 0.6983\n",
      "Epoch [5/10], Batch: 3820, Train Loss: 0.8279\n",
      "Epoch [5/10], Batch: 3830, Train Loss: 0.6921\n",
      "Epoch [5/10], Batch: 3840, Train Loss: 0.7407\n",
      "Epoch [5/10], Batch: 3850, Train Loss: 0.8291\n",
      "Epoch [5/10], Batch: 3860, Train Loss: 0.7920\n",
      "Epoch [5/10], Batch: 3870, Train Loss: 0.8530\n",
      "Epoch [5/10], Batch: 3880, Train Loss: 0.8496\n",
      "Epoch [5/10], Batch: 3890, Train Loss: 0.8481\n",
      "Epoch [5/10], Batch: 3900, Train Loss: 0.7609\n",
      "Epoch [5/10], Batch: 3910, Train Loss: 0.8908\n",
      "Epoch [5/10], Batch: 3920, Train Loss: 0.7459\n",
      "Epoch [5/10], Batch: 3930, Train Loss: 0.7758\n",
      "Epoch [5/10], Batch: 3940, Train Loss: 0.7770\n",
      "Epoch [5/10], Batch: 3950, Train Loss: 0.8224\n",
      "Epoch [5/10], Batch: 3960, Train Loss: 0.8993\n",
      "Epoch [5/10], Batch: 3970, Train Loss: 0.7398\n",
      "Epoch [5/10], Batch: 3980, Train Loss: 0.7793\n",
      "Epoch [5/10], Batch: 3990, Train Loss: 0.7523\n",
      "Epoch [5/10], Batch: 4000, Train Loss: 0.7983\n",
      "Epoch [5/10], Batch: 4010, Train Loss: 0.8474\n",
      "Epoch [5/10], Batch: 4020, Train Loss: 0.8129\n",
      "Epoch [5/10], Batch: 4030, Train Loss: 0.8607\n",
      "Epoch [5/10], Batch: 4040, Train Loss: 0.7493\n",
      "Epoch [5/10], Batch: 4050, Train Loss: 0.7333\n",
      "Epoch [5/10], Batch: 4060, Train Loss: 0.7213\n",
      "Epoch [5/10], Batch: 4070, Train Loss: 0.8193\n",
      "Epoch [5/10], Batch: 4080, Train Loss: 0.8431\n",
      "Epoch [5/10], Batch: 4090, Train Loss: 0.7920\n",
      "Epoch [5/10], Batch: 4100, Train Loss: 0.7785\n",
      "Epoch [5/10], Batch: 4110, Train Loss: 0.8302\n",
      "Epoch [5/10], Batch: 4120, Train Loss: 0.7637\n",
      "Epoch [5/10], Batch: 4130, Train Loss: 0.8528\n",
      "Epoch [5/10], Batch: 4140, Train Loss: 0.8722\n",
      "Epoch [5/10], Batch: 4150, Train Loss: 0.6668\n",
      "Epoch [5/10], Batch: 4160, Train Loss: 0.6910\n",
      "Epoch [5/10], Batch: 4170, Train Loss: 0.7542\n",
      "Epoch [5/10], Batch: 4180, Train Loss: 0.6683\n",
      "Epoch [5/10], Batch: 4190, Train Loss: 0.8421\n",
      "Epoch [5/10], Batch: 4200, Train Loss: 0.7004\n",
      "Epoch [5/10], Batch: 4210, Train Loss: 0.8438\n",
      "Epoch [5/10], Batch: 4220, Train Loss: 0.8229\n",
      "Epoch [5/10], Batch: 4230, Train Loss: 0.9443\n",
      "Epoch [5/10], Batch: 4240, Train Loss: 0.7026\n",
      "Epoch [5/10], Batch: 4250, Train Loss: 0.7329\n",
      "Epoch [5/10], Batch: 4260, Train Loss: 0.8589\n",
      "Epoch [5/10], Batch: 4270, Train Loss: 0.8736\n",
      "Epoch [5/10], Batch: 4280, Train Loss: 0.7863\n",
      "Epoch [5/10], Batch: 4290, Train Loss: 0.8642\n",
      "Epoch [5/10], Batch: 4300, Train Loss: 0.8116\n",
      "Epoch [5/10], Batch: 4310, Train Loss: 0.7678\n",
      "Epoch [5/10], Batch: 4320, Train Loss: 0.7960\n",
      "Epoch [5/10], Batch: 4330, Train Loss: 0.7437\n",
      "Epoch [5/10], Batch: 4340, Train Loss: 0.8244\n",
      "Epoch [5/10], Batch: 4350, Train Loss: 0.6870\n",
      "Epoch [5/10], Batch: 4360, Train Loss: 0.6418\n",
      "Epoch [5/10], Batch: 4370, Train Loss: 0.9184\n",
      "Epoch [5/10], Batch: 4380, Train Loss: 0.7809\n",
      "Epoch [5/10], Batch: 4390, Train Loss: 0.8811\n",
      "Epoch [5/10], Batch: 4400, Train Loss: 0.7493\n",
      "Epoch [5/10], Batch: 4410, Train Loss: 0.7069\n",
      "Epoch [5/10], Batch: 4420, Train Loss: 0.9561\n",
      "Epoch [5/10], Batch: 4430, Train Loss: 0.8706\n",
      "Epoch [5/10], Batch: 4440, Train Loss: 0.8601\n",
      "Epoch [5/10], Batch: 4450, Train Loss: 0.7414\n",
      "Epoch [5/10], Batch: 4460, Train Loss: 0.7500\n",
      "Epoch [5/10], Batch: 4470, Train Loss: 0.7052\n",
      "Epoch [5/10], Batch: 4480, Train Loss: 0.8285\n",
      "Epoch [5/10], Batch: 4490, Train Loss: 0.8251\n",
      "Epoch [5/10], Batch: 4500, Train Loss: 0.8018\n",
      "Epoch [5/10], Batch: 4510, Train Loss: 0.7272\n",
      "Epoch [5/10], Batch: 4520, Train Loss: 0.7443\n",
      "Epoch [5/10], Batch: 4530, Train Loss: 0.6907\n",
      "Epoch [5/10], Batch: 4540, Train Loss: 0.7932\n",
      "Epoch [5/10], Batch: 4550, Train Loss: 0.6988\n",
      "Epoch [5/10], Batch: 4560, Train Loss: 0.8390\n",
      "Epoch [5/10], Batch: 4570, Train Loss: 0.7325\n",
      "Epoch [5/10], Batch: 4580, Train Loss: 0.8099\n",
      "Epoch [5/10], Batch: 4590, Train Loss: 0.6637\n",
      "Epoch [5/10], Batch: 4600, Train Loss: 0.7271\n",
      "Epoch [5/10], Batch: 4610, Train Loss: 0.7722\n",
      "Epoch [5/10], Batch: 4620, Train Loss: 0.6974\n",
      "Epoch [5/10], Batch: 4630, Train Loss: 0.7189\n",
      "Epoch [5/10], Batch: 4640, Train Loss: 0.8555\n",
      "Epoch [5/10], Batch: 4650, Train Loss: 0.8069\n",
      "Epoch [5/10], Batch: 4660, Train Loss: 0.8053\n",
      "Epoch [5/10], Batch: 4670, Train Loss: 0.8931\n",
      "Epoch [5/10], Batch: 4680, Train Loss: 0.7489\n",
      "Epoch [5/10], Batch: 4690, Train Loss: 0.8758\n",
      "Epoch [5/10], Batch: 4700, Train Loss: 0.9284\n",
      "Epoch [5/10], Batch: 4710, Train Loss: 0.7526\n",
      "Epoch [5/10], Batch: 4720, Train Loss: 0.7367\n",
      "Epoch [5/10], Batch: 4730, Train Loss: 0.9101\n",
      "Epoch [5/10], Batch: 4740, Train Loss: 0.6165\n",
      "Epoch [5/10], Batch: 4750, Train Loss: 0.7041\n",
      "Epoch [5/10], Batch: 4760, Train Loss: 0.7437\n",
      "Epoch [5/10], Batch: 4770, Train Loss: 0.7957\n",
      "Epoch [5/10], Batch: 4780, Train Loss: 0.7718\n",
      "Epoch [5/10], Batch: 4790, Train Loss: 0.8708\n",
      "Epoch [5/10], Batch: 4800, Train Loss: 0.7622\n",
      "Epoch [5/10], Batch: 4810, Train Loss: 0.7326\n",
      "Epoch [5/10], Batch: 4820, Train Loss: 0.9650\n",
      "Epoch [5/10], Batch: 4830, Train Loss: 0.7499\n",
      "Epoch [5/10], Batch: 4840, Train Loss: 0.8582\n",
      "Epoch [5/10], Batch: 4850, Train Loss: 0.7313\n",
      "Epoch [5/10], Batch: 4860, Train Loss: 0.8506\n",
      "Epoch [5/10], Batch: 4870, Train Loss: 0.7459\n",
      "Epoch [5/10], Batch: 4880, Train Loss: 0.8141\n",
      "Epoch [5/10], Batch: 4890, Train Loss: 0.8649\n",
      "Epoch [5/10], Batch: 4900, Train Loss: 0.9260\n",
      "Epoch [5/10], Batch: 4910, Train Loss: 0.7049\n",
      "Epoch [5/10], Batch: 4920, Train Loss: 0.7044\n",
      "Epoch [5/10], Batch: 4930, Train Loss: 0.8224\n",
      "Epoch [5/10], Batch: 4940, Train Loss: 0.7618\n",
      "Epoch [5/10], Batch: 4950, Train Loss: 0.8260\n",
      "Epoch [5/10], Batch: 4960, Train Loss: 0.6849\n",
      "Epoch [5/10], Batch: 4970, Train Loss: 0.8016\n",
      "Epoch [5/10], Batch: 4980, Train Loss: 0.8476\n",
      "Epoch [5/10], Batch: 4990, Train Loss: 0.7480\n",
      "Epoch [5/10], Batch: 5000, Train Loss: 0.6300\n",
      "Epoch [5/10], Batch: 5010, Train Loss: 0.8655\n",
      "Epoch [5/10], Batch: 5020, Train Loss: 0.7578\n",
      "Epoch [5/10], Batch: 5030, Train Loss: 0.7737\n",
      "Epoch [5/10], Batch: 5040, Train Loss: 0.9283\n",
      "Epoch [5/10], Batch: 5050, Train Loss: 0.7717\n",
      "Epoch [5/10], Batch: 5060, Train Loss: 0.7856\n",
      "Epoch [5/10], Batch: 5070, Train Loss: 0.7332\n",
      "Epoch [5/10], Batch: 5080, Train Loss: 0.8040\n",
      "Epoch [5/10], Batch: 5090, Train Loss: 0.6757\n",
      "Epoch [5/10], Batch: 5100, Train Loss: 0.7657\n",
      "Epoch [5/10], Batch: 5110, Train Loss: 0.7329\n",
      "Epoch [5/10], Batch: 5120, Train Loss: 0.6665\n",
      "Epoch [5/10], Batch: 5130, Train Loss: 0.7380\n",
      "Epoch [5/10], Batch: 5140, Train Loss: 0.9656\n",
      "Epoch [5/10], Batch: 5150, Train Loss: 0.7183\n",
      "Epoch [5/10], Batch: 5160, Train Loss: 0.8192\n",
      "Epoch [5/10], Batch: 5170, Train Loss: 0.7704\n",
      "Epoch [5/10], Batch: 5180, Train Loss: 0.8796\n",
      "Epoch [5/10], Batch: 5190, Train Loss: 0.6658\n",
      "Epoch [5/10], Batch: 5200, Train Loss: 0.7311\n",
      "Epoch [5/10], Batch: 5210, Train Loss: 0.8243\n",
      "Epoch [5/10], Batch: 5220, Train Loss: 0.9033\n",
      "Epoch [5/10], Batch: 5230, Train Loss: 0.7070\n",
      "Epoch [5/10], Batch: 5240, Train Loss: 0.8124\n",
      "Epoch [5/10], Batch: 5250, Train Loss: 0.9922\n",
      "Epoch [5/10], Batch: 5260, Train Loss: 0.9320\n",
      "Epoch [5/10], Batch: 5270, Train Loss: 0.8146\n",
      "Epoch [5/10], Batch: 5280, Train Loss: 0.7734\n",
      "Epoch [5/10], Batch: 5290, Train Loss: 0.9025\n",
      "Epoch [5/10], Batch: 5300, Train Loss: 0.8697\n",
      "Epoch [5/10], Batch: 5310, Train Loss: 0.7441\n",
      "Epoch [5/10], Batch: 5320, Train Loss: 0.7386\n",
      "Epoch [5/10], Batch: 5330, Train Loss: 0.7536\n",
      "Epoch [5/10], Batch: 5340, Train Loss: 0.9140\n",
      "Epoch [5/10], Batch: 5350, Train Loss: 0.7235\n",
      "Epoch [5/10], Batch: 5360, Train Loss: 0.9031\n",
      "Epoch [5/10], Batch: 5370, Train Loss: 0.7658\n",
      "Epoch [5/10], Batch: 5380, Train Loss: 0.7202\n",
      "Epoch [5/10], Batch: 5390, Train Loss: 0.8853\n",
      "Epoch [5/10], Batch: 5400, Train Loss: 0.8527\n",
      "Epoch [5/10], Batch: 5410, Train Loss: 0.9217\n",
      "Epoch [5/10], Batch: 5420, Train Loss: 0.6988\n",
      "Epoch [5/10], Batch: 5430, Train Loss: 0.7583\n",
      "Epoch [5/10], Batch: 5440, Train Loss: 0.7898\n",
      "Epoch [5/10], Batch: 5450, Train Loss: 0.8161\n",
      "Epoch [5/10], Batch: 5460, Train Loss: 0.7601\n",
      "Epoch [5/10], Batch: 5470, Train Loss: 0.7923\n",
      "Epoch [5/10], Batch: 5480, Train Loss: 0.7223\n",
      "Epoch [5/10], Batch: 5490, Train Loss: 0.7184\n",
      "Epoch [5/10], Batch: 5500, Train Loss: 0.9023\n",
      "Epoch [5/10], Batch: 5510, Train Loss: 0.8872\n",
      "Epoch [5/10], Batch: 5520, Train Loss: 0.8235\n",
      "Epoch [5/10], Batch: 5530, Train Loss: 0.8773\n",
      "Epoch [5/10], Batch: 5540, Train Loss: 0.8076\n",
      "Epoch [5/10], Batch: 5550, Train Loss: 0.8673\n",
      "Epoch [5/10], Batch: 5560, Train Loss: 0.7616\n",
      "Epoch [5/10], Batch: 5570, Train Loss: 0.8146\n",
      "Epoch [5/10], Batch: 5580, Train Loss: 0.7129\n",
      "Epoch [5/10], Batch: 5590, Train Loss: 0.8585\n",
      "Epoch [5/10], Batch: 5600, Train Loss: 0.6549\n",
      "Epoch [5/10], Batch: 5610, Train Loss: 0.7764\n",
      "Epoch [5/10], Batch: 5620, Train Loss: 0.8264\n",
      "Epoch [5/10], Batch: 5630, Train Loss: 0.7893\n",
      "Epoch [5/10], Batch: 5640, Train Loss: 0.8788\n",
      "Epoch [5/10], Batch: 5650, Train Loss: 0.7768\n",
      "Epoch [5/10], Batch: 5660, Train Loss: 0.7398\n",
      "Epoch [5/10], Batch: 5670, Train Loss: 0.7881\n",
      "Epoch [5/10], Batch: 5680, Train Loss: 0.7830\n",
      "Epoch [5/10], Batch: 5690, Train Loss: 0.8456\n",
      "Epoch [5/10], Batch: 5700, Train Loss: 0.6440\n",
      "Epoch [5/10], Batch: 5710, Train Loss: 0.9295\n",
      "Epoch [5/10], Batch: 5720, Train Loss: 0.9064\n",
      "Epoch [5/10], Batch: 5730, Train Loss: 0.7494\n",
      "Epoch [5/10], Batch: 5740, Train Loss: 0.7550\n",
      "Epoch [5/10], Batch: 5750, Train Loss: 0.8077\n",
      "Epoch [5/10], Batch: 5760, Train Loss: 0.9524\n",
      "Epoch [5/10], Batch: 5770, Train Loss: 0.8457\n",
      "Epoch [5/10], Batch: 5780, Train Loss: 0.9578\n",
      "Epoch [5/10], Batch: 5790, Train Loss: 0.8814\n",
      "Epoch [5/10], Batch: 5800, Train Loss: 0.8079\n",
      "Epoch [5/10], Batch: 5810, Train Loss: 0.7560\n",
      "Epoch [5/10], Batch: 5820, Train Loss: 0.9219\n",
      "Epoch [5/10], Batch: 5830, Train Loss: 0.8603\n",
      "Epoch [5/10], Batch: 5840, Train Loss: 0.7089\n",
      "Epoch [5/10], Batch: 5850, Train Loss: 0.7472\n",
      "Epoch [5/10], Batch: 5860, Train Loss: 0.7308\n",
      "Epoch [5/10], Batch: 5870, Train Loss: 0.7666\n",
      "Epoch [5/10], Batch: 5880, Train Loss: 0.8456\n",
      "Epoch [5/10], Batch: 5890, Train Loss: 0.7737\n",
      "Epoch [5/10], Batch: 5900, Train Loss: 0.7342\n",
      "Epoch [5/10], Batch: 5910, Train Loss: 0.8203\n",
      "Epoch [5/10], Batch: 5920, Train Loss: 0.8192\n",
      "Epoch [5/10], Batch: 5930, Train Loss: 0.9969\n",
      "Epoch [5/10], Batch: 5940, Train Loss: 0.8302\n",
      "Epoch [5/10], Batch: 5950, Train Loss: 0.7211\n",
      "Epoch [5/10], Batch: 5960, Train Loss: 0.8360\n",
      "Epoch [5/10], Batch: 5970, Train Loss: 0.8070\n",
      "Epoch [5/10], Batch: 5980, Train Loss: 0.7180\n",
      "Epoch [5/10], Batch: 5990, Train Loss: 0.8450\n",
      "Epoch [5/10], Batch: 6000, Train Loss: 0.7088\n",
      "Epoch [5/10], Batch: 6010, Train Loss: 0.9031\n",
      "Epoch [5/10], Batch: 6020, Train Loss: 0.8284\n",
      "Epoch [5/10], Batch: 6030, Train Loss: 0.8760\n",
      "Epoch [5/10], Batch: 6040, Train Loss: 0.7664\n",
      "Epoch [5/10], Batch: 6050, Train Loss: 0.7948\n",
      "Epoch [5/10], Batch: 6060, Train Loss: 0.8253\n",
      "Epoch [5/10], Batch: 6070, Train Loss: 0.6860\n",
      "Epoch [5/10], Batch: 6080, Train Loss: 0.6993\n",
      "Epoch [5/10], Batch: 6090, Train Loss: 0.6735\n",
      "Epoch [5/10], Batch: 6100, Train Loss: 0.7841\n",
      "Epoch [5/10], Batch: 6110, Train Loss: 0.7160\n",
      "Epoch [5/10], Batch: 6120, Train Loss: 0.6247\n",
      "Epoch [5/10], Batch: 6130, Train Loss: 0.7062\n",
      "Epoch [5/10], Batch: 6140, Train Loss: 0.7760\n",
      "Epoch [5/10], Batch: 6150, Train Loss: 0.7445\n",
      "Epoch [5/10], Batch: 6160, Train Loss: 0.8586\n",
      "Epoch [5/10], Batch: 6170, Train Loss: 0.8667\n",
      "Epoch [5/10], Batch: 6180, Train Loss: 0.8791\n",
      "Epoch [5/10], Batch: 6190, Train Loss: 0.8480\n",
      "Epoch [5/10], Batch: 6200, Train Loss: 0.7617\n",
      "Epoch [5/10], Batch: 6210, Train Loss: 0.7692\n",
      "Epoch [5/10], Batch: 6220, Train Loss: 0.8644\n",
      "Epoch [5/10], Batch: 6230, Train Loss: 0.7831\n",
      "Epoch [5/10], Batch: 6240, Train Loss: 0.8037\n",
      "Epoch [5/10], Batch: 6250, Train Loss: 0.8766\n",
      "Epoch [5/10], Batch: 6260, Train Loss: 0.9044\n",
      "Epoch [5/10], Batch: 6270, Train Loss: 0.8780\n",
      "Epoch [5/10], Batch: 6280, Train Loss: 0.9247\n",
      "Epoch [5/10], Batch: 6290, Train Loss: 0.7548\n",
      "Epoch [5/10], Batch: 6300, Train Loss: 0.6642\n",
      "Epoch [5/10], Batch: 6310, Train Loss: 0.7844\n",
      "Epoch [5/10], Batch: 6320, Train Loss: 0.8185\n",
      "Epoch [5/10], Batch: 6330, Train Loss: 0.7749\n",
      "Epoch [5/10], Batch: 6340, Train Loss: 0.8348\n",
      "Epoch [5/10], Batch: 6350, Train Loss: 0.9229\n",
      "Epoch [5/10], Batch: 6360, Train Loss: 0.8034\n",
      "Epoch [5/10], Batch: 6370, Train Loss: 0.6789\n",
      "Epoch [5/10], Batch: 6380, Train Loss: 0.7814\n",
      "Epoch [5/10], Batch: 6390, Train Loss: 0.7334\n",
      "Epoch [5/10], Batch: 6400, Train Loss: 0.8059\n",
      "Epoch [5/10], Batch: 6410, Train Loss: 0.6901\n",
      "Epoch [5/10], Batch: 6420, Train Loss: 0.7267\n",
      "Epoch [5/10], Batch: 6430, Train Loss: 0.7296\n",
      "Epoch [5/10], Batch: 6440, Train Loss: 0.7632\n",
      "Epoch [5/10], Batch: 6450, Train Loss: 0.8340\n",
      "Epoch [5/10], Batch: 6460, Train Loss: 0.7813\n",
      "Epoch [5/10], Batch: 6470, Train Loss: 0.7620\n",
      "Epoch [5/10], Batch: 6480, Train Loss: 0.7921\n",
      "Epoch [5/10], Batch: 6490, Train Loss: 0.6758\n",
      "Epoch [5/10], Batch: 6500, Train Loss: 0.7842\n",
      "Epoch [5/10], Batch: 6510, Train Loss: 0.6834\n",
      "Epoch [5/10], Batch: 6520, Train Loss: 0.7228\n",
      "Epoch [5/10], Batch: 6530, Train Loss: 0.8001\n",
      "Epoch [5/10], Batch: 6540, Train Loss: 0.7437\n",
      "Epoch [5/10], Batch: 6550, Train Loss: 0.8301\n",
      "Epoch [5/10], Batch: 6560, Train Loss: 0.7223\n",
      "Epoch [5/10], Batch: 6570, Train Loss: 0.7975\n",
      "Epoch [5/10], Batch: 6580, Train Loss: 0.7747\n",
      "Epoch [5/10], Batch: 6590, Train Loss: 0.8057\n",
      "Epoch [5/10], Batch: 6600, Train Loss: 0.8557\n",
      "Epoch [5/10], Batch: 6610, Train Loss: 0.7865\n",
      "Epoch [5/10], Batch: 6620, Train Loss: 0.7419\n",
      "Epoch [5/10], Batch: 6630, Train Loss: 0.7871\n",
      "Epoch [5/10], Batch: 6640, Train Loss: 0.8442\n",
      "Epoch [5/10], Batch: 6650, Train Loss: 0.7542\n",
      "Epoch [5/10], Batch: 6660, Train Loss: 0.9121\n",
      "Epoch [5/10], Batch: 6670, Train Loss: 0.6730\n",
      "Epoch [5/10], Batch: 6680, Train Loss: 0.8006\n",
      "Epoch [5/10], Batch: 6690, Train Loss: 0.7999\n",
      "Epoch [5/10], Batch: 6700, Train Loss: 0.8722\n",
      "Epoch [5/10], Batch: 6710, Train Loss: 0.9002\n",
      "Epoch [5/10], Batch: 6720, Train Loss: 0.7442\n",
      "Epoch [5/10], Batch: 6730, Train Loss: 0.7379\n",
      "Epoch [5/10], Batch: 6740, Train Loss: 0.7744\n",
      "Epoch [5/10], Batch: 6750, Train Loss: 0.6929\n",
      "Epoch [5/10], Batch: 6760, Train Loss: 0.8275\n",
      "Epoch [6/10], Batch: 10, Train Loss: 0.7809\n",
      "Epoch [6/10], Batch: 20, Train Loss: 0.5503\n",
      "Epoch [6/10], Batch: 30, Train Loss: 0.6211\n",
      "Epoch [6/10], Batch: 40, Train Loss: 0.6768\n",
      "Epoch [6/10], Batch: 50, Train Loss: 0.9526\n",
      "Epoch [6/10], Batch: 60, Train Loss: 0.7516\n",
      "Epoch [6/10], Batch: 70, Train Loss: 0.8855\n",
      "Epoch [6/10], Batch: 80, Train Loss: 0.7306\n",
      "Epoch [6/10], Batch: 90, Train Loss: 0.7507\n",
      "Epoch [6/10], Batch: 100, Train Loss: 0.6861\n",
      "Epoch [6/10], Batch: 110, Train Loss: 0.8548\n",
      "Epoch [6/10], Batch: 120, Train Loss: 0.7608\n",
      "Epoch [6/10], Batch: 130, Train Loss: 0.8522\n",
      "Epoch [6/10], Batch: 140, Train Loss: 0.7446\n",
      "Epoch [6/10], Batch: 150, Train Loss: 0.7548\n",
      "Epoch [6/10], Batch: 160, Train Loss: 0.7652\n",
      "Epoch [6/10], Batch: 170, Train Loss: 0.7035\n",
      "Epoch [6/10], Batch: 180, Train Loss: 0.6815\n",
      "Epoch [6/10], Batch: 190, Train Loss: 0.7559\n",
      "Epoch [6/10], Batch: 200, Train Loss: 0.6958\n",
      "Epoch [6/10], Batch: 210, Train Loss: 0.8326\n",
      "Epoch [6/10], Batch: 220, Train Loss: 0.7103\n",
      "Epoch [6/10], Batch: 230, Train Loss: 0.8705\n",
      "Epoch [6/10], Batch: 240, Train Loss: 0.7276\n",
      "Epoch [6/10], Batch: 250, Train Loss: 0.8207\n",
      "Epoch [6/10], Batch: 260, Train Loss: 0.7166\n",
      "Epoch [6/10], Batch: 270, Train Loss: 0.7514\n",
      "Epoch [6/10], Batch: 280, Train Loss: 0.6604\n",
      "Epoch [6/10], Batch: 290, Train Loss: 0.8776\n",
      "Epoch [6/10], Batch: 300, Train Loss: 0.8800\n",
      "Epoch [6/10], Batch: 310, Train Loss: 0.7881\n",
      "Epoch [6/10], Batch: 320, Train Loss: 0.7588\n",
      "Epoch [6/10], Batch: 330, Train Loss: 0.7465\n",
      "Epoch [6/10], Batch: 340, Train Loss: 0.7607\n",
      "Epoch [6/10], Batch: 350, Train Loss: 0.7915\n",
      "Epoch [6/10], Batch: 360, Train Loss: 0.7832\n",
      "Epoch [6/10], Batch: 370, Train Loss: 0.7393\n",
      "Epoch [6/10], Batch: 380, Train Loss: 0.7991\n",
      "Epoch [6/10], Batch: 390, Train Loss: 0.8315\n",
      "Epoch [6/10], Batch: 400, Train Loss: 0.8417\n",
      "Epoch [6/10], Batch: 410, Train Loss: 0.8870\n",
      "Epoch [6/10], Batch: 420, Train Loss: 0.8123\n",
      "Epoch [6/10], Batch: 430, Train Loss: 0.8005\n",
      "Epoch [6/10], Batch: 440, Train Loss: 0.6473\n",
      "Epoch [6/10], Batch: 450, Train Loss: 0.6647\n",
      "Epoch [6/10], Batch: 460, Train Loss: 0.8365\n",
      "Epoch [6/10], Batch: 470, Train Loss: 0.7630\n",
      "Epoch [6/10], Batch: 480, Train Loss: 0.8148\n",
      "Epoch [6/10], Batch: 490, Train Loss: 0.6453\n",
      "Epoch [6/10], Batch: 500, Train Loss: 0.9156\n",
      "Epoch [6/10], Batch: 510, Train Loss: 0.7340\n",
      "Epoch [6/10], Batch: 520, Train Loss: 0.9121\n",
      "Epoch [6/10], Batch: 530, Train Loss: 0.7302\n",
      "Epoch [6/10], Batch: 540, Train Loss: 0.7870\n",
      "Epoch [6/10], Batch: 550, Train Loss: 0.8430\n",
      "Epoch [6/10], Batch: 560, Train Loss: 0.7357\n",
      "Epoch [6/10], Batch: 570, Train Loss: 0.8539\n",
      "Epoch [6/10], Batch: 580, Train Loss: 0.7571\n",
      "Epoch [6/10], Batch: 590, Train Loss: 0.8198\n",
      "Epoch [6/10], Batch: 600, Train Loss: 0.7790\n",
      "Epoch [6/10], Batch: 610, Train Loss: 0.8017\n",
      "Epoch [6/10], Batch: 620, Train Loss: 0.7438\n",
      "Epoch [6/10], Batch: 630, Train Loss: 0.7702\n",
      "Epoch [6/10], Batch: 640, Train Loss: 0.8634\n",
      "Epoch [6/10], Batch: 650, Train Loss: 0.8032\n",
      "Epoch [6/10], Batch: 660, Train Loss: 0.8979\n",
      "Epoch [6/10], Batch: 670, Train Loss: 0.8236\n",
      "Epoch [6/10], Batch: 680, Train Loss: 0.7457\n",
      "Epoch [6/10], Batch: 690, Train Loss: 0.7781\n",
      "Epoch [6/10], Batch: 700, Train Loss: 0.8083\n",
      "Epoch [6/10], Batch: 710, Train Loss: 0.7227\n",
      "Epoch [6/10], Batch: 720, Train Loss: 0.7311\n",
      "Epoch [6/10], Batch: 730, Train Loss: 0.7553\n",
      "Epoch [6/10], Batch: 740, Train Loss: 0.7563\n",
      "Epoch [6/10], Batch: 750, Train Loss: 0.6179\n",
      "Epoch [6/10], Batch: 760, Train Loss: 0.7649\n",
      "Epoch [6/10], Batch: 770, Train Loss: 0.7469\n",
      "Epoch [6/10], Batch: 780, Train Loss: 0.6730\n",
      "Epoch [6/10], Batch: 790, Train Loss: 0.8456\n",
      "Epoch [6/10], Batch: 800, Train Loss: 0.7665\n",
      "Epoch [6/10], Batch: 810, Train Loss: 0.7320\n",
      "Epoch [6/10], Batch: 820, Train Loss: 0.8201\n",
      "Epoch [6/10], Batch: 830, Train Loss: 0.8555\n",
      "Epoch [6/10], Batch: 840, Train Loss: 0.8004\n",
      "Epoch [6/10], Batch: 850, Train Loss: 0.7467\n",
      "Epoch [6/10], Batch: 860, Train Loss: 0.6893\n",
      "Epoch [6/10], Batch: 870, Train Loss: 0.8239\n",
      "Epoch [6/10], Batch: 880, Train Loss: 0.8707\n",
      "Epoch [6/10], Batch: 890, Train Loss: 0.7512\n",
      "Epoch [6/10], Batch: 900, Train Loss: 0.7595\n",
      "Epoch [6/10], Batch: 910, Train Loss: 0.7618\n",
      "Epoch [6/10], Batch: 920, Train Loss: 0.7878\n",
      "Epoch [6/10], Batch: 930, Train Loss: 0.7759\n",
      "Epoch [6/10], Batch: 940, Train Loss: 0.8530\n",
      "Epoch [6/10], Batch: 950, Train Loss: 0.8250\n",
      "Epoch [6/10], Batch: 960, Train Loss: 0.8833\n",
      "Epoch [6/10], Batch: 970, Train Loss: 0.6180\n",
      "Epoch [6/10], Batch: 980, Train Loss: 0.7833\n",
      "Epoch [6/10], Batch: 990, Train Loss: 0.7655\n",
      "Epoch [6/10], Batch: 1000, Train Loss: 0.7668\n",
      "Epoch [6/10], Batch: 1010, Train Loss: 0.7628\n",
      "Epoch [6/10], Batch: 1020, Train Loss: 0.7267\n",
      "Epoch [6/10], Batch: 1030, Train Loss: 0.7896\n",
      "Epoch [6/10], Batch: 1040, Train Loss: 0.8679\n",
      "Epoch [6/10], Batch: 1050, Train Loss: 0.6921\n",
      "Epoch [6/10], Batch: 1060, Train Loss: 0.8382\n",
      "Epoch [6/10], Batch: 1070, Train Loss: 0.8382\n",
      "Epoch [6/10], Batch: 1080, Train Loss: 0.6931\n",
      "Epoch [6/10], Batch: 1090, Train Loss: 0.6991\n",
      "Epoch [6/10], Batch: 1100, Train Loss: 0.7187\n",
      "Epoch [6/10], Batch: 1110, Train Loss: 0.8344\n",
      "Epoch [6/10], Batch: 1120, Train Loss: 0.7005\n",
      "Epoch [6/10], Batch: 1130, Train Loss: 0.8787\n",
      "Epoch [6/10], Batch: 1140, Train Loss: 0.7930\n",
      "Epoch [6/10], Batch: 1150, Train Loss: 0.8287\n",
      "Epoch [6/10], Batch: 1160, Train Loss: 0.7419\n",
      "Epoch [6/10], Batch: 1170, Train Loss: 0.8489\n",
      "Epoch [6/10], Batch: 1180, Train Loss: 0.9666\n",
      "Epoch [6/10], Batch: 1190, Train Loss: 0.7923\n",
      "Epoch [6/10], Batch: 1200, Train Loss: 0.7972\n",
      "Epoch [6/10], Batch: 1210, Train Loss: 0.7066\n",
      "Epoch [6/10], Batch: 1220, Train Loss: 0.8577\n",
      "Epoch [6/10], Batch: 1230, Train Loss: 0.8210\n",
      "Epoch [6/10], Batch: 1240, Train Loss: 0.7735\n",
      "Epoch [6/10], Batch: 1250, Train Loss: 0.7626\n",
      "Epoch [6/10], Batch: 1260, Train Loss: 0.8192\n",
      "Epoch [6/10], Batch: 1270, Train Loss: 0.7973\n",
      "Epoch [6/10], Batch: 1280, Train Loss: 0.7659\n",
      "Epoch [6/10], Batch: 1290, Train Loss: 0.6938\n",
      "Epoch [6/10], Batch: 1300, Train Loss: 0.7103\n",
      "Epoch [6/10], Batch: 1310, Train Loss: 0.7565\n",
      "Epoch [6/10], Batch: 1320, Train Loss: 0.7247\n",
      "Epoch [6/10], Batch: 1330, Train Loss: 0.8837\n",
      "Epoch [6/10], Batch: 1340, Train Loss: 0.7656\n",
      "Epoch [6/10], Batch: 1350, Train Loss: 0.7746\n",
      "Epoch [6/10], Batch: 1360, Train Loss: 0.6621\n",
      "Epoch [6/10], Batch: 1370, Train Loss: 0.8965\n",
      "Epoch [6/10], Batch: 1380, Train Loss: 0.7278\n",
      "Epoch [6/10], Batch: 1390, Train Loss: 0.7958\n",
      "Epoch [6/10], Batch: 1400, Train Loss: 0.7621\n",
      "Epoch [6/10], Batch: 1410, Train Loss: 0.9737\n",
      "Epoch [6/10], Batch: 1420, Train Loss: 0.8370\n",
      "Epoch [6/10], Batch: 1430, Train Loss: 0.9713\n",
      "Epoch [6/10], Batch: 1440, Train Loss: 0.7668\n",
      "Epoch [6/10], Batch: 1450, Train Loss: 0.7713\n",
      "Epoch [6/10], Batch: 1460, Train Loss: 0.7914\n",
      "Epoch [6/10], Batch: 1470, Train Loss: 0.8080\n",
      "Epoch [6/10], Batch: 1480, Train Loss: 0.9182\n",
      "Epoch [6/10], Batch: 1490, Train Loss: 0.7456\n",
      "Epoch [6/10], Batch: 1500, Train Loss: 0.8264\n",
      "Epoch [6/10], Batch: 1510, Train Loss: 0.7582\n",
      "Epoch [6/10], Batch: 1520, Train Loss: 0.7291\n",
      "Epoch [6/10], Batch: 1530, Train Loss: 0.6220\n",
      "Epoch [6/10], Batch: 1540, Train Loss: 0.7147\n",
      "Epoch [6/10], Batch: 1550, Train Loss: 0.7856\n",
      "Epoch [6/10], Batch: 1560, Train Loss: 0.7334\n",
      "Epoch [6/10], Batch: 1570, Train Loss: 0.8235\n",
      "Epoch [6/10], Batch: 1580, Train Loss: 0.8174\n",
      "Epoch [6/10], Batch: 1590, Train Loss: 0.6897\n",
      "Epoch [6/10], Batch: 1600, Train Loss: 0.7611\n",
      "Epoch [6/10], Batch: 1610, Train Loss: 0.8383\n",
      "Epoch [6/10], Batch: 1620, Train Loss: 0.7912\n",
      "Epoch [6/10], Batch: 1630, Train Loss: 0.8543\n",
      "Epoch [6/10], Batch: 1640, Train Loss: 0.6615\n",
      "Epoch [6/10], Batch: 1650, Train Loss: 0.8824\n",
      "Epoch [6/10], Batch: 1660, Train Loss: 0.7005\n",
      "Epoch [6/10], Batch: 1670, Train Loss: 0.7443\n",
      "Epoch [6/10], Batch: 1680, Train Loss: 0.7664\n",
      "Epoch [6/10], Batch: 1690, Train Loss: 0.9139\n",
      "Epoch [6/10], Batch: 1700, Train Loss: 0.7180\n",
      "Epoch [6/10], Batch: 1710, Train Loss: 0.7294\n",
      "Epoch [6/10], Batch: 1720, Train Loss: 0.8489\n",
      "Epoch [6/10], Batch: 1730, Train Loss: 0.8119\n",
      "Epoch [6/10], Batch: 1740, Train Loss: 0.7820\n",
      "Epoch [6/10], Batch: 1750, Train Loss: 0.7959\n",
      "Epoch [6/10], Batch: 1760, Train Loss: 0.8257\n",
      "Epoch [6/10], Batch: 1770, Train Loss: 0.7265\n",
      "Epoch [6/10], Batch: 1780, Train Loss: 0.7304\n",
      "Epoch [6/10], Batch: 1790, Train Loss: 0.8270\n",
      "Epoch [6/10], Batch: 1800, Train Loss: 0.8132\n",
      "Epoch [6/10], Batch: 1810, Train Loss: 0.7480\n",
      "Epoch [6/10], Batch: 1820, Train Loss: 0.7701\n",
      "Epoch [6/10], Batch: 1830, Train Loss: 0.8134\n",
      "Epoch [6/10], Batch: 1840, Train Loss: 0.8576\n",
      "Epoch [6/10], Batch: 1850, Train Loss: 0.8495\n",
      "Epoch [6/10], Batch: 1860, Train Loss: 0.7797\n",
      "Epoch [6/10], Batch: 1870, Train Loss: 0.8460\n",
      "Epoch [6/10], Batch: 1880, Train Loss: 0.8123\n",
      "Epoch [6/10], Batch: 1890, Train Loss: 0.8245\n",
      "Epoch [6/10], Batch: 1900, Train Loss: 0.7589\n",
      "Epoch [6/10], Batch: 1910, Train Loss: 0.6600\n",
      "Epoch [6/10], Batch: 1920, Train Loss: 0.8642\n",
      "Epoch [6/10], Batch: 1930, Train Loss: 0.7941\n",
      "Epoch [6/10], Batch: 1940, Train Loss: 0.7588\n",
      "Epoch [6/10], Batch: 1950, Train Loss: 0.8684\n",
      "Epoch [6/10], Batch: 1960, Train Loss: 0.7207\n",
      "Epoch [6/10], Batch: 1970, Train Loss: 0.7549\n",
      "Epoch [6/10], Batch: 1980, Train Loss: 0.6984\n",
      "Epoch [6/10], Batch: 1990, Train Loss: 0.7267\n",
      "Epoch [6/10], Batch: 2000, Train Loss: 0.7813\n",
      "Epoch [6/10], Batch: 2010, Train Loss: 0.7767\n",
      "Epoch [6/10], Batch: 2020, Train Loss: 0.7855\n",
      "Epoch [6/10], Batch: 2030, Train Loss: 0.7197\n",
      "Epoch [6/10], Batch: 2040, Train Loss: 0.6909\n",
      "Epoch [6/10], Batch: 2050, Train Loss: 0.7839\n",
      "Epoch [6/10], Batch: 2060, Train Loss: 0.6624\n",
      "Epoch [6/10], Batch: 2070, Train Loss: 0.7513\n",
      "Epoch [6/10], Batch: 2080, Train Loss: 0.7349\n",
      "Epoch [6/10], Batch: 2090, Train Loss: 0.7367\n",
      "Epoch [6/10], Batch: 2100, Train Loss: 0.7651\n",
      "Epoch [6/10], Batch: 2110, Train Loss: 0.9053\n",
      "Epoch [6/10], Batch: 2120, Train Loss: 0.6749\n",
      "Epoch [6/10], Batch: 2130, Train Loss: 0.8379\n",
      "Epoch [6/10], Batch: 2140, Train Loss: 0.8724\n",
      "Epoch [6/10], Batch: 2150, Train Loss: 0.9183\n",
      "Epoch [6/10], Batch: 2160, Train Loss: 0.8077\n",
      "Epoch [6/10], Batch: 2170, Train Loss: 0.7514\n",
      "Epoch [6/10], Batch: 2180, Train Loss: 0.7230\n",
      "Epoch [6/10], Batch: 2190, Train Loss: 0.7074\n",
      "Epoch [6/10], Batch: 2200, Train Loss: 0.8080\n",
      "Epoch [6/10], Batch: 2210, Train Loss: 0.7825\n",
      "Epoch [6/10], Batch: 2220, Train Loss: 0.7463\n",
      "Epoch [6/10], Batch: 2230, Train Loss: 0.8314\n",
      "Epoch [6/10], Batch: 2240, Train Loss: 0.9404\n",
      "Epoch [6/10], Batch: 2250, Train Loss: 0.7656\n",
      "Epoch [6/10], Batch: 2260, Train Loss: 0.7832\n",
      "Epoch [6/10], Batch: 2270, Train Loss: 0.7865\n",
      "Epoch [6/10], Batch: 2280, Train Loss: 0.7490\n",
      "Epoch [6/10], Batch: 2290, Train Loss: 0.8319\n",
      "Epoch [6/10], Batch: 2300, Train Loss: 0.7103\n",
      "Epoch [6/10], Batch: 2310, Train Loss: 0.7282\n",
      "Epoch [6/10], Batch: 2320, Train Loss: 0.8829\n",
      "Epoch [6/10], Batch: 2330, Train Loss: 0.7159\n",
      "Epoch [6/10], Batch: 2340, Train Loss: 0.8407\n",
      "Epoch [6/10], Batch: 2350, Train Loss: 0.7467\n",
      "Epoch [6/10], Batch: 2360, Train Loss: 0.7760\n",
      "Epoch [6/10], Batch: 2370, Train Loss: 0.8105\n",
      "Epoch [6/10], Batch: 2380, Train Loss: 0.8881\n",
      "Epoch [6/10], Batch: 2390, Train Loss: 0.6424\n",
      "Epoch [6/10], Batch: 2400, Train Loss: 0.7595\n",
      "Epoch [6/10], Batch: 2410, Train Loss: 0.8077\n",
      "Epoch [6/10], Batch: 2420, Train Loss: 0.7711\n",
      "Epoch [6/10], Batch: 2430, Train Loss: 0.7466\n",
      "Epoch [6/10], Batch: 2440, Train Loss: 0.7616\n",
      "Epoch [6/10], Batch: 2450, Train Loss: 0.7502\n",
      "Epoch [6/10], Batch: 2460, Train Loss: 0.7692\n",
      "Epoch [6/10], Batch: 2470, Train Loss: 0.8162\n",
      "Epoch [6/10], Batch: 2480, Train Loss: 0.7121\n",
      "Epoch [6/10], Batch: 2490, Train Loss: 0.8344\n",
      "Epoch [6/10], Batch: 2500, Train Loss: 0.8105\n",
      "Epoch [6/10], Batch: 2510, Train Loss: 0.7628\n",
      "Epoch [6/10], Batch: 2520, Train Loss: 0.7565\n",
      "Epoch [6/10], Batch: 2530, Train Loss: 0.7028\n",
      "Epoch [6/10], Batch: 2540, Train Loss: 0.8461\n",
      "Epoch [6/10], Batch: 2550, Train Loss: 0.6899\n",
      "Epoch [6/10], Batch: 2560, Train Loss: 0.8194\n",
      "Epoch [6/10], Batch: 2570, Train Loss: 0.6298\n",
      "Epoch [6/10], Batch: 2580, Train Loss: 0.7591\n",
      "Epoch [6/10], Batch: 2590, Train Loss: 0.8339\n",
      "Epoch [6/10], Batch: 2600, Train Loss: 0.7660\n",
      "Epoch [6/10], Batch: 2610, Train Loss: 0.7881\n",
      "Epoch [6/10], Batch: 2620, Train Loss: 0.7291\n",
      "Epoch [6/10], Batch: 2630, Train Loss: 0.7425\n",
      "Epoch [6/10], Batch: 2640, Train Loss: 0.7113\n",
      "Epoch [6/10], Batch: 2650, Train Loss: 0.7272\n",
      "Epoch [6/10], Batch: 2660, Train Loss: 0.7732\n",
      "Epoch [6/10], Batch: 2670, Train Loss: 0.7248\n",
      "Epoch [6/10], Batch: 2680, Train Loss: 0.8689\n",
      "Epoch [6/10], Batch: 2690, Train Loss: 0.7117\n",
      "Epoch [6/10], Batch: 2700, Train Loss: 0.7642\n",
      "Epoch [6/10], Batch: 2710, Train Loss: 0.7330\n",
      "Epoch [6/10], Batch: 2720, Train Loss: 0.7920\n",
      "Epoch [6/10], Batch: 2730, Train Loss: 0.8547\n",
      "Epoch [6/10], Batch: 2740, Train Loss: 0.8820\n",
      "Epoch [6/10], Batch: 2750, Train Loss: 0.8327\n",
      "Epoch [6/10], Batch: 2760, Train Loss: 0.7154\n",
      "Epoch [6/10], Batch: 2770, Train Loss: 0.7374\n",
      "Epoch [6/10], Batch: 2780, Train Loss: 0.7392\n",
      "Epoch [6/10], Batch: 2790, Train Loss: 0.6447\n",
      "Epoch [6/10], Batch: 2800, Train Loss: 0.7890\n",
      "Epoch [6/10], Batch: 2810, Train Loss: 0.8055\n",
      "Epoch [6/10], Batch: 2820, Train Loss: 0.6614\n",
      "Epoch [6/10], Batch: 2830, Train Loss: 0.9096\n",
      "Epoch [6/10], Batch: 2840, Train Loss: 0.7125\n",
      "Epoch [6/10], Batch: 2850, Train Loss: 0.8107\n",
      "Epoch [6/10], Batch: 2860, Train Loss: 0.8397\n",
      "Epoch [6/10], Batch: 2870, Train Loss: 0.7072\n",
      "Epoch [6/10], Batch: 2880, Train Loss: 1.0348\n",
      "Epoch [6/10], Batch: 2890, Train Loss: 0.7991\n",
      "Epoch [6/10], Batch: 2900, Train Loss: 0.8248\n",
      "Epoch [6/10], Batch: 2910, Train Loss: 0.8639\n",
      "Epoch [6/10], Batch: 2920, Train Loss: 0.7995\n",
      "Epoch [6/10], Batch: 2930, Train Loss: 0.7486\n",
      "Epoch [6/10], Batch: 2940, Train Loss: 0.8787\n",
      "Epoch [6/10], Batch: 2950, Train Loss: 0.6804\n",
      "Epoch [6/10], Batch: 2960, Train Loss: 0.9046\n",
      "Epoch [6/10], Batch: 2970, Train Loss: 0.8172\n",
      "Epoch [6/10], Batch: 2980, Train Loss: 0.7174\n",
      "Epoch [6/10], Batch: 2990, Train Loss: 0.6053\n",
      "Epoch [6/10], Batch: 3000, Train Loss: 0.7133\n",
      "Epoch [6/10], Batch: 3010, Train Loss: 0.8585\n",
      "Epoch [6/10], Batch: 3020, Train Loss: 0.8732\n",
      "Epoch [6/10], Batch: 3030, Train Loss: 0.6885\n",
      "Epoch [6/10], Batch: 3040, Train Loss: 0.6809\n",
      "Epoch [6/10], Batch: 3050, Train Loss: 0.7074\n",
      "Epoch [6/10], Batch: 3060, Train Loss: 0.7393\n",
      "Epoch [6/10], Batch: 3070, Train Loss: 0.8827\n",
      "Epoch [6/10], Batch: 3080, Train Loss: 0.9336\n",
      "Epoch [6/10], Batch: 3090, Train Loss: 0.8325\n",
      "Epoch [6/10], Batch: 3100, Train Loss: 0.8216\n",
      "Epoch [6/10], Batch: 3110, Train Loss: 0.7718\n",
      "Epoch [6/10], Batch: 3120, Train Loss: 0.7042\n",
      "Epoch [6/10], Batch: 3130, Train Loss: 0.8578\n",
      "Epoch [6/10], Batch: 3140, Train Loss: 0.7527\n",
      "Epoch [6/10], Batch: 3150, Train Loss: 0.7393\n",
      "Epoch [6/10], Batch: 3160, Train Loss: 0.8576\n",
      "Epoch [6/10], Batch: 3170, Train Loss: 0.6768\n",
      "Epoch [6/10], Batch: 3180, Train Loss: 0.8832\n",
      "Epoch [6/10], Batch: 3190, Train Loss: 0.5592\n",
      "Epoch [6/10], Batch: 3200, Train Loss: 1.0039\n",
      "Epoch [6/10], Batch: 3210, Train Loss: 0.7957\n",
      "Epoch [6/10], Batch: 3220, Train Loss: 0.8860\n",
      "Epoch [6/10], Batch: 3230, Train Loss: 0.7435\n",
      "Epoch [6/10], Batch: 3240, Train Loss: 0.7289\n",
      "Epoch [6/10], Batch: 3250, Train Loss: 0.7298\n",
      "Epoch [6/10], Batch: 3260, Train Loss: 0.7636\n",
      "Epoch [6/10], Batch: 3270, Train Loss: 0.9060\n",
      "Epoch [6/10], Batch: 3280, Train Loss: 0.8731\n",
      "Epoch [6/10], Batch: 3290, Train Loss: 0.7507\n",
      "Epoch [6/10], Batch: 3300, Train Loss: 0.7428\n",
      "Epoch [6/10], Batch: 3310, Train Loss: 0.8540\n",
      "Epoch [6/10], Batch: 3320, Train Loss: 0.8562\n",
      "Epoch [6/10], Batch: 3330, Train Loss: 0.6273\n",
      "Epoch [6/10], Batch: 3340, Train Loss: 0.8318\n",
      "Epoch [6/10], Batch: 3350, Train Loss: 0.7325\n",
      "Epoch [6/10], Batch: 3360, Train Loss: 0.6118\n",
      "Epoch [6/10], Batch: 3370, Train Loss: 0.7041\n",
      "Epoch [6/10], Batch: 3380, Train Loss: 0.7358\n",
      "Epoch [6/10], Batch: 3390, Train Loss: 0.7115\n",
      "Epoch [6/10], Batch: 3400, Train Loss: 0.8022\n",
      "Epoch [6/10], Batch: 3410, Train Loss: 0.7985\n",
      "Epoch [6/10], Batch: 3420, Train Loss: 0.7537\n",
      "Epoch [6/10], Batch: 3430, Train Loss: 0.8893\n",
      "Epoch [6/10], Batch: 3440, Train Loss: 0.8392\n",
      "Epoch [6/10], Batch: 3450, Train Loss: 0.7090\n",
      "Epoch [6/10], Batch: 3460, Train Loss: 0.8066\n",
      "Epoch [6/10], Batch: 3470, Train Loss: 0.7045\n",
      "Epoch [6/10], Batch: 3480, Train Loss: 0.7515\n",
      "Epoch [6/10], Batch: 3490, Train Loss: 0.8155\n",
      "Epoch [6/10], Batch: 3500, Train Loss: 0.7763\n",
      "Epoch [6/10], Batch: 3510, Train Loss: 0.8165\n",
      "Epoch [6/10], Batch: 3520, Train Loss: 0.8449\n",
      "Epoch [6/10], Batch: 3530, Train Loss: 0.7522\n",
      "Epoch [6/10], Batch: 3540, Train Loss: 0.6893\n",
      "Epoch [6/10], Batch: 3550, Train Loss: 0.7903\n",
      "Epoch [6/10], Batch: 3560, Train Loss: 0.8622\n",
      "Epoch [6/10], Batch: 3570, Train Loss: 0.8123\n",
      "Epoch [6/10], Batch: 3580, Train Loss: 0.7865\n",
      "Epoch [6/10], Batch: 3590, Train Loss: 0.8162\n",
      "Epoch [6/10], Batch: 3600, Train Loss: 0.8775\n",
      "Epoch [6/10], Batch: 3610, Train Loss: 0.6610\n",
      "Epoch [6/10], Batch: 3620, Train Loss: 0.7818\n",
      "Epoch [6/10], Batch: 3630, Train Loss: 0.8666\n",
      "Epoch [6/10], Batch: 3640, Train Loss: 0.7038\n",
      "Epoch [6/10], Batch: 3650, Train Loss: 0.7072\n",
      "Epoch [6/10], Batch: 3660, Train Loss: 0.8151\n",
      "Epoch [6/10], Batch: 3670, Train Loss: 0.7468\n",
      "Epoch [6/10], Batch: 3680, Train Loss: 0.9061\n",
      "Epoch [6/10], Batch: 3690, Train Loss: 0.7440\n",
      "Epoch [6/10], Batch: 3700, Train Loss: 0.9305\n",
      "Epoch [6/10], Batch: 3710, Train Loss: 0.9498\n",
      "Epoch [6/10], Batch: 3720, Train Loss: 0.7452\n",
      "Epoch [6/10], Batch: 3730, Train Loss: 0.7005\n",
      "Epoch [6/10], Batch: 3740, Train Loss: 0.7299\n",
      "Epoch [6/10], Batch: 3750, Train Loss: 0.6841\n",
      "Epoch [6/10], Batch: 3760, Train Loss: 0.6849\n",
      "Epoch [6/10], Batch: 3770, Train Loss: 0.8116\n",
      "Epoch [6/10], Batch: 3780, Train Loss: 0.8508\n",
      "Epoch [6/10], Batch: 3790, Train Loss: 0.8120\n",
      "Epoch [6/10], Batch: 3800, Train Loss: 0.7226\n",
      "Epoch [6/10], Batch: 3810, Train Loss: 0.6867\n",
      "Epoch [6/10], Batch: 3820, Train Loss: 0.7852\n",
      "Epoch [6/10], Batch: 3830, Train Loss: 0.6475\n",
      "Epoch [6/10], Batch: 3840, Train Loss: 0.7447\n",
      "Epoch [6/10], Batch: 3850, Train Loss: 0.7578\n",
      "Epoch [6/10], Batch: 3860, Train Loss: 0.7648\n",
      "Epoch [6/10], Batch: 3870, Train Loss: 0.8267\n",
      "Epoch [6/10], Batch: 3880, Train Loss: 0.8185\n",
      "Epoch [6/10], Batch: 3890, Train Loss: 0.8302\n",
      "Epoch [6/10], Batch: 3900, Train Loss: 0.7584\n",
      "Epoch [6/10], Batch: 3910, Train Loss: 0.9191\n",
      "Epoch [6/10], Batch: 3920, Train Loss: 0.7543\n",
      "Epoch [6/10], Batch: 3930, Train Loss: 0.7600\n",
      "Epoch [6/10], Batch: 3940, Train Loss: 0.7871\n",
      "Epoch [6/10], Batch: 3950, Train Loss: 0.8070\n",
      "Epoch [6/10], Batch: 3960, Train Loss: 0.9045\n",
      "Epoch [6/10], Batch: 3970, Train Loss: 0.7208\n",
      "Epoch [6/10], Batch: 3980, Train Loss: 0.7770\n",
      "Epoch [6/10], Batch: 3990, Train Loss: 0.6847\n",
      "Epoch [6/10], Batch: 4000, Train Loss: 0.7966\n",
      "Epoch [6/10], Batch: 4010, Train Loss: 0.7895\n",
      "Epoch [6/10], Batch: 4020, Train Loss: 0.7755\n",
      "Epoch [6/10], Batch: 4030, Train Loss: 0.8586\n",
      "Epoch [6/10], Batch: 4040, Train Loss: 0.7628\n",
      "Epoch [6/10], Batch: 4050, Train Loss: 0.6729\n",
      "Epoch [6/10], Batch: 4060, Train Loss: 0.7045\n",
      "Epoch [6/10], Batch: 4070, Train Loss: 0.7733\n",
      "Epoch [6/10], Batch: 4080, Train Loss: 0.8161\n",
      "Epoch [6/10], Batch: 4090, Train Loss: 0.7616\n",
      "Epoch [6/10], Batch: 4100, Train Loss: 0.7772\n",
      "Epoch [6/10], Batch: 4110, Train Loss: 0.8417\n",
      "Epoch [6/10], Batch: 4120, Train Loss: 0.7204\n",
      "Epoch [6/10], Batch: 4130, Train Loss: 0.8075\n",
      "Epoch [6/10], Batch: 4140, Train Loss: 0.8750\n",
      "Epoch [6/10], Batch: 4150, Train Loss: 0.6659\n",
      "Epoch [6/10], Batch: 4160, Train Loss: 0.6741\n",
      "Epoch [6/10], Batch: 4170, Train Loss: 0.6927\n",
      "Epoch [6/10], Batch: 4180, Train Loss: 0.5923\n",
      "Epoch [6/10], Batch: 4190, Train Loss: 0.8303\n",
      "Epoch [6/10], Batch: 4200, Train Loss: 0.6948\n",
      "Epoch [6/10], Batch: 4210, Train Loss: 0.8009\n",
      "Epoch [6/10], Batch: 4220, Train Loss: 0.7684\n",
      "Epoch [6/10], Batch: 4230, Train Loss: 0.8522\n",
      "Epoch [6/10], Batch: 4240, Train Loss: 0.6828\n",
      "Epoch [6/10], Batch: 4250, Train Loss: 0.7578\n",
      "Epoch [6/10], Batch: 4260, Train Loss: 0.8154\n",
      "Epoch [6/10], Batch: 4270, Train Loss: 0.8310\n",
      "Epoch [6/10], Batch: 4280, Train Loss: 0.7464\n",
      "Epoch [6/10], Batch: 4290, Train Loss: 0.8563\n",
      "Epoch [6/10], Batch: 4300, Train Loss: 0.7617\n",
      "Epoch [6/10], Batch: 4310, Train Loss: 0.7514\n",
      "Epoch [6/10], Batch: 4320, Train Loss: 0.8198\n",
      "Epoch [6/10], Batch: 4330, Train Loss: 0.7421\n",
      "Epoch [6/10], Batch: 4340, Train Loss: 0.8360\n",
      "Epoch [6/10], Batch: 4350, Train Loss: 0.6969\n",
      "Epoch [6/10], Batch: 4360, Train Loss: 0.6192\n",
      "Epoch [6/10], Batch: 4370, Train Loss: 0.9410\n",
      "Epoch [6/10], Batch: 4380, Train Loss: 0.7301\n",
      "Epoch [6/10], Batch: 4390, Train Loss: 0.8349\n",
      "Epoch [6/10], Batch: 4400, Train Loss: 0.7180\n",
      "Epoch [6/10], Batch: 4410, Train Loss: 0.7157\n",
      "Epoch [6/10], Batch: 4420, Train Loss: 0.9508\n",
      "Epoch [6/10], Batch: 4430, Train Loss: 0.8177\n",
      "Epoch [6/10], Batch: 4440, Train Loss: 0.8231\n",
      "Epoch [6/10], Batch: 4450, Train Loss: 0.7090\n",
      "Epoch [6/10], Batch: 4460, Train Loss: 0.7249\n",
      "Epoch [6/10], Batch: 4470, Train Loss: 0.6857\n",
      "Epoch [6/10], Batch: 4480, Train Loss: 0.8274\n",
      "Epoch [6/10], Batch: 4490, Train Loss: 0.7829\n",
      "Epoch [6/10], Batch: 4500, Train Loss: 0.8026\n",
      "Epoch [6/10], Batch: 4510, Train Loss: 0.7395\n",
      "Epoch [6/10], Batch: 4520, Train Loss: 0.7377\n",
      "Epoch [6/10], Batch: 4530, Train Loss: 0.6879\n",
      "Epoch [6/10], Batch: 4540, Train Loss: 0.7870\n",
      "Epoch [6/10], Batch: 4550, Train Loss: 0.6805\n",
      "Epoch [6/10], Batch: 4560, Train Loss: 0.8620\n",
      "Epoch [6/10], Batch: 4570, Train Loss: 0.6813\n",
      "Epoch [6/10], Batch: 4580, Train Loss: 0.8266\n",
      "Epoch [6/10], Batch: 4590, Train Loss: 0.6403\n",
      "Epoch [6/10], Batch: 4600, Train Loss: 0.6870\n",
      "Epoch [6/10], Batch: 4610, Train Loss: 0.7832\n",
      "Epoch [6/10], Batch: 4620, Train Loss: 0.7233\n",
      "Epoch [6/10], Batch: 4630, Train Loss: 0.6633\n",
      "Epoch [6/10], Batch: 4640, Train Loss: 0.8097\n",
      "Epoch [6/10], Batch: 4650, Train Loss: 0.7961\n",
      "Epoch [6/10], Batch: 4660, Train Loss: 0.7667\n",
      "Epoch [6/10], Batch: 4670, Train Loss: 0.8788\n",
      "Epoch [6/10], Batch: 4680, Train Loss: 0.6942\n",
      "Epoch [6/10], Batch: 4690, Train Loss: 0.8658\n",
      "Epoch [6/10], Batch: 4700, Train Loss: 0.8680\n",
      "Epoch [6/10], Batch: 4710, Train Loss: 0.7066\n",
      "Epoch [6/10], Batch: 4720, Train Loss: 0.6990\n",
      "Epoch [6/10], Batch: 4730, Train Loss: 0.8781\n",
      "Epoch [6/10], Batch: 4740, Train Loss: 0.6024\n",
      "Epoch [6/10], Batch: 4750, Train Loss: 0.6605\n",
      "Epoch [6/10], Batch: 4760, Train Loss: 0.7641\n",
      "Epoch [6/10], Batch: 4770, Train Loss: 0.8034\n",
      "Epoch [6/10], Batch: 4780, Train Loss: 0.7554\n",
      "Epoch [6/10], Batch: 4790, Train Loss: 0.8167\n",
      "Epoch [6/10], Batch: 4800, Train Loss: 0.7451\n",
      "Epoch [6/10], Batch: 4810, Train Loss: 0.7247\n",
      "Epoch [6/10], Batch: 4820, Train Loss: 0.9086\n",
      "Epoch [6/10], Batch: 4830, Train Loss: 0.7322\n",
      "Epoch [6/10], Batch: 4840, Train Loss: 0.7714\n",
      "Epoch [6/10], Batch: 4850, Train Loss: 0.6981\n",
      "Epoch [6/10], Batch: 4860, Train Loss: 0.8142\n",
      "Epoch [6/10], Batch: 4870, Train Loss: 0.7282\n",
      "Epoch [6/10], Batch: 4880, Train Loss: 0.7433\n",
      "Epoch [6/10], Batch: 4890, Train Loss: 0.8523\n",
      "Epoch [6/10], Batch: 4900, Train Loss: 0.8990\n",
      "Epoch [6/10], Batch: 4910, Train Loss: 0.7104\n",
      "Epoch [6/10], Batch: 4920, Train Loss: 0.6991\n",
      "Epoch [6/10], Batch: 4930, Train Loss: 0.8152\n",
      "Epoch [6/10], Batch: 4940, Train Loss: 0.7541\n",
      "Epoch [6/10], Batch: 4950, Train Loss: 0.7610\n",
      "Epoch [6/10], Batch: 4960, Train Loss: 0.6686\n",
      "Epoch [6/10], Batch: 4970, Train Loss: 0.7917\n",
      "Epoch [6/10], Batch: 4980, Train Loss: 0.8653\n",
      "Epoch [6/10], Batch: 4990, Train Loss: 0.7428\n",
      "Epoch [6/10], Batch: 5000, Train Loss: 0.6106\n",
      "Epoch [6/10], Batch: 5010, Train Loss: 0.8727\n",
      "Epoch [6/10], Batch: 5020, Train Loss: 0.7714\n",
      "Epoch [6/10], Batch: 5030, Train Loss: 0.7655\n",
      "Epoch [6/10], Batch: 5040, Train Loss: 0.8962\n",
      "Epoch [6/10], Batch: 5050, Train Loss: 0.7638\n",
      "Epoch [6/10], Batch: 5060, Train Loss: 0.7649\n",
      "Epoch [6/10], Batch: 5070, Train Loss: 0.7282\n",
      "Epoch [6/10], Batch: 5080, Train Loss: 0.7424\n",
      "Epoch [6/10], Batch: 5090, Train Loss: 0.6642\n",
      "Epoch [6/10], Batch: 5100, Train Loss: 0.7392\n",
      "Epoch [6/10], Batch: 5110, Train Loss: 0.7708\n",
      "Epoch [6/10], Batch: 5120, Train Loss: 0.6349\n",
      "Epoch [6/10], Batch: 5130, Train Loss: 0.6863\n",
      "Epoch [6/10], Batch: 5140, Train Loss: 0.9383\n",
      "Epoch [6/10], Batch: 5150, Train Loss: 0.7269\n",
      "Epoch [6/10], Batch: 5160, Train Loss: 0.8094\n",
      "Epoch [6/10], Batch: 5170, Train Loss: 0.7827\n",
      "Epoch [6/10], Batch: 5180, Train Loss: 0.8237\n",
      "Epoch [6/10], Batch: 5190, Train Loss: 0.6035\n",
      "Epoch [6/10], Batch: 5200, Train Loss: 0.7165\n",
      "Epoch [6/10], Batch: 5210, Train Loss: 0.7340\n",
      "Epoch [6/10], Batch: 5220, Train Loss: 0.8807\n",
      "Epoch [6/10], Batch: 5230, Train Loss: 0.7094\n",
      "Epoch [6/10], Batch: 5240, Train Loss: 0.7752\n",
      "Epoch [6/10], Batch: 5250, Train Loss: 0.9786\n",
      "Epoch [6/10], Batch: 5260, Train Loss: 0.9302\n",
      "Epoch [6/10], Batch: 5270, Train Loss: 0.8036\n",
      "Epoch [6/10], Batch: 5280, Train Loss: 0.7730\n",
      "Epoch [6/10], Batch: 5290, Train Loss: 0.8710\n",
      "Epoch [6/10], Batch: 5300, Train Loss: 0.8674\n",
      "Epoch [6/10], Batch: 5310, Train Loss: 0.7098\n",
      "Epoch [6/10], Batch: 5320, Train Loss: 0.7360\n",
      "Epoch [6/10], Batch: 5330, Train Loss: 0.7396\n",
      "Epoch [6/10], Batch: 5340, Train Loss: 0.8590\n",
      "Epoch [6/10], Batch: 5350, Train Loss: 0.7278\n",
      "Epoch [6/10], Batch: 5360, Train Loss: 0.8535\n",
      "Epoch [6/10], Batch: 5370, Train Loss: 0.7681\n",
      "Epoch [6/10], Batch: 5380, Train Loss: 0.7289\n",
      "Epoch [6/10], Batch: 5390, Train Loss: 0.8409\n",
      "Epoch [6/10], Batch: 5400, Train Loss: 0.7968\n",
      "Epoch [6/10], Batch: 5410, Train Loss: 0.9149\n",
      "Epoch [6/10], Batch: 5420, Train Loss: 0.6793\n",
      "Epoch [6/10], Batch: 5430, Train Loss: 0.7174\n",
      "Epoch [6/10], Batch: 5440, Train Loss: 0.7680\n",
      "Epoch [6/10], Batch: 5450, Train Loss: 0.7779\n",
      "Epoch [6/10], Batch: 5460, Train Loss: 0.6879\n",
      "Epoch [6/10], Batch: 5470, Train Loss: 0.7596\n",
      "Epoch [6/10], Batch: 5480, Train Loss: 0.6489\n",
      "Epoch [6/10], Batch: 5490, Train Loss: 0.7250\n",
      "Epoch [6/10], Batch: 5500, Train Loss: 0.8747\n",
      "Epoch [6/10], Batch: 5510, Train Loss: 0.9224\n",
      "Epoch [6/10], Batch: 5520, Train Loss: 0.7853\n",
      "Epoch [6/10], Batch: 5530, Train Loss: 0.8444\n",
      "Epoch [6/10], Batch: 5540, Train Loss: 0.7968\n",
      "Epoch [6/10], Batch: 5550, Train Loss: 0.8580\n",
      "Epoch [6/10], Batch: 5560, Train Loss: 0.7087\n",
      "Epoch [6/10], Batch: 5570, Train Loss: 0.8193\n",
      "Epoch [6/10], Batch: 5580, Train Loss: 0.6863\n",
      "Epoch [6/10], Batch: 5590, Train Loss: 0.8471\n",
      "Epoch [6/10], Batch: 5600, Train Loss: 0.6349\n",
      "Epoch [6/10], Batch: 5610, Train Loss: 0.7568\n",
      "Epoch [6/10], Batch: 5620, Train Loss: 0.7838\n",
      "Epoch [6/10], Batch: 5630, Train Loss: 0.7859\n",
      "Epoch [6/10], Batch: 5640, Train Loss: 0.8365\n",
      "Epoch [6/10], Batch: 5650, Train Loss: 0.7647\n",
      "Epoch [6/10], Batch: 5660, Train Loss: 0.6679\n",
      "Epoch [6/10], Batch: 5670, Train Loss: 0.7680\n",
      "Epoch [6/10], Batch: 5680, Train Loss: 0.7608\n",
      "Epoch [6/10], Batch: 5690, Train Loss: 0.8434\n",
      "Epoch [6/10], Batch: 5700, Train Loss: 0.6400\n",
      "Epoch [6/10], Batch: 5710, Train Loss: 0.9298\n",
      "Epoch [6/10], Batch: 5720, Train Loss: 0.8813\n",
      "Epoch [6/10], Batch: 5730, Train Loss: 0.7014\n",
      "Epoch [6/10], Batch: 5740, Train Loss: 0.7204\n",
      "Epoch [6/10], Batch: 5750, Train Loss: 0.7920\n",
      "Epoch [6/10], Batch: 5760, Train Loss: 0.9674\n",
      "Epoch [6/10], Batch: 5770, Train Loss: 0.8334\n",
      "Epoch [6/10], Batch: 5780, Train Loss: 0.9154\n",
      "Epoch [6/10], Batch: 5790, Train Loss: 0.8633\n",
      "Epoch [6/10], Batch: 5800, Train Loss: 0.8021\n",
      "Epoch [6/10], Batch: 5810, Train Loss: 0.7502\n",
      "Epoch [6/10], Batch: 5820, Train Loss: 0.8778\n",
      "Epoch [6/10], Batch: 5830, Train Loss: 0.8288\n",
      "Epoch [6/10], Batch: 5840, Train Loss: 0.7344\n",
      "Epoch [6/10], Batch: 5850, Train Loss: 0.7316\n",
      "Epoch [6/10], Batch: 5860, Train Loss: 0.7358\n",
      "Epoch [6/10], Batch: 5870, Train Loss: 0.6932\n",
      "Epoch [6/10], Batch: 5880, Train Loss: 0.8403\n",
      "Epoch [6/10], Batch: 5890, Train Loss: 0.7445\n",
      "Epoch [6/10], Batch: 5900, Train Loss: 0.7135\n",
      "Epoch [6/10], Batch: 5910, Train Loss: 0.8364\n",
      "Epoch [6/10], Batch: 5920, Train Loss: 0.7778\n",
      "Epoch [6/10], Batch: 5930, Train Loss: 0.9842\n",
      "Epoch [6/10], Batch: 5940, Train Loss: 0.8354\n",
      "Epoch [6/10], Batch: 5950, Train Loss: 0.6991\n",
      "Epoch [6/10], Batch: 5960, Train Loss: 0.8212\n",
      "Epoch [6/10], Batch: 5970, Train Loss: 0.7940\n",
      "Epoch [6/10], Batch: 5980, Train Loss: 0.7094\n",
      "Epoch [6/10], Batch: 5990, Train Loss: 0.8711\n",
      "Epoch [6/10], Batch: 6000, Train Loss: 0.7293\n",
      "Epoch [6/10], Batch: 6010, Train Loss: 0.9107\n",
      "Epoch [6/10], Batch: 6020, Train Loss: 0.8007\n",
      "Epoch [6/10], Batch: 6030, Train Loss: 0.8944\n",
      "Epoch [6/10], Batch: 6040, Train Loss: 0.7447\n",
      "Epoch [6/10], Batch: 6050, Train Loss: 0.7834\n",
      "Epoch [6/10], Batch: 6060, Train Loss: 0.8120\n",
      "Epoch [6/10], Batch: 6070, Train Loss: 0.6669\n",
      "Epoch [6/10], Batch: 6080, Train Loss: 0.6999\n",
      "Epoch [6/10], Batch: 6090, Train Loss: 0.6807\n",
      "Epoch [6/10], Batch: 6100, Train Loss: 0.7368\n",
      "Epoch [6/10], Batch: 6110, Train Loss: 0.6812\n",
      "Epoch [6/10], Batch: 6120, Train Loss: 0.5828\n",
      "Epoch [6/10], Batch: 6130, Train Loss: 0.7186\n",
      "Epoch [6/10], Batch: 6140, Train Loss: 0.7307\n",
      "Epoch [6/10], Batch: 6150, Train Loss: 0.6993\n",
      "Epoch [6/10], Batch: 6160, Train Loss: 0.8276\n",
      "Epoch [6/10], Batch: 6170, Train Loss: 0.8432\n",
      "Epoch [6/10], Batch: 6180, Train Loss: 0.8429\n",
      "Epoch [6/10], Batch: 6190, Train Loss: 0.7925\n",
      "Epoch [6/10], Batch: 6200, Train Loss: 0.7624\n",
      "Epoch [6/10], Batch: 6210, Train Loss: 0.7284\n",
      "Epoch [6/10], Batch: 6220, Train Loss: 0.8086\n",
      "Epoch [6/10], Batch: 6230, Train Loss: 0.7591\n",
      "Epoch [6/10], Batch: 6240, Train Loss: 0.7769\n",
      "Epoch [6/10], Batch: 6250, Train Loss: 0.8661\n",
      "Epoch [6/10], Batch: 6260, Train Loss: 0.8618\n",
      "Epoch [6/10], Batch: 6270, Train Loss: 0.8501\n",
      "Epoch [6/10], Batch: 6280, Train Loss: 0.8880\n",
      "Epoch [6/10], Batch: 6290, Train Loss: 0.7719\n",
      "Epoch [6/10], Batch: 6300, Train Loss: 0.6530\n",
      "Epoch [6/10], Batch: 6310, Train Loss: 0.7612\n",
      "Epoch [6/10], Batch: 6320, Train Loss: 0.8043\n",
      "Epoch [6/10], Batch: 6330, Train Loss: 0.7564\n",
      "Epoch [6/10], Batch: 6340, Train Loss: 0.8300\n",
      "Epoch [6/10], Batch: 6350, Train Loss: 0.9028\n",
      "Epoch [6/10], Batch: 6360, Train Loss: 0.7961\n",
      "Epoch [6/10], Batch: 6370, Train Loss: 0.6663\n",
      "Epoch [6/10], Batch: 6380, Train Loss: 0.7523\n",
      "Epoch [6/10], Batch: 6390, Train Loss: 0.7232\n",
      "Epoch [6/10], Batch: 6400, Train Loss: 0.7945\n",
      "Epoch [6/10], Batch: 6410, Train Loss: 0.6757\n",
      "Epoch [6/10], Batch: 6420, Train Loss: 0.7369\n",
      "Epoch [6/10], Batch: 6430, Train Loss: 0.7185\n",
      "Epoch [6/10], Batch: 6440, Train Loss: 0.7446\n",
      "Epoch [6/10], Batch: 6450, Train Loss: 0.8330\n",
      "Epoch [6/10], Batch: 6460, Train Loss: 0.7622\n",
      "Epoch [6/10], Batch: 6470, Train Loss: 0.7762\n",
      "Epoch [6/10], Batch: 6480, Train Loss: 0.8074\n",
      "Epoch [6/10], Batch: 6490, Train Loss: 0.6999\n",
      "Epoch [6/10], Batch: 6500, Train Loss: 0.7688\n",
      "Epoch [6/10], Batch: 6510, Train Loss: 0.6805\n",
      "Epoch [6/10], Batch: 6520, Train Loss: 0.6968\n",
      "Epoch [6/10], Batch: 6530, Train Loss: 0.7716\n",
      "Epoch [6/10], Batch: 6540, Train Loss: 0.6923\n",
      "Epoch [6/10], Batch: 6550, Train Loss: 0.7952\n",
      "Epoch [6/10], Batch: 6560, Train Loss: 0.7443\n",
      "Epoch [6/10], Batch: 6570, Train Loss: 0.7733\n",
      "Epoch [6/10], Batch: 6580, Train Loss: 0.7273\n",
      "Epoch [6/10], Batch: 6590, Train Loss: 0.7635\n",
      "Epoch [6/10], Batch: 6600, Train Loss: 0.8498\n",
      "Epoch [6/10], Batch: 6610, Train Loss: 0.7017\n",
      "Epoch [6/10], Batch: 6620, Train Loss: 0.7205\n",
      "Epoch [6/10], Batch: 6630, Train Loss: 0.7642\n",
      "Epoch [6/10], Batch: 6640, Train Loss: 0.8270\n",
      "Epoch [6/10], Batch: 6650, Train Loss: 0.7614\n",
      "Epoch [6/10], Batch: 6660, Train Loss: 0.9223\n",
      "Epoch [6/10], Batch: 6670, Train Loss: 0.6675\n",
      "Epoch [6/10], Batch: 6680, Train Loss: 0.7633\n",
      "Epoch [6/10], Batch: 6690, Train Loss: 0.8136\n",
      "Epoch [6/10], Batch: 6700, Train Loss: 0.8314\n",
      "Epoch [6/10], Batch: 6710, Train Loss: 0.8641\n",
      "Epoch [6/10], Batch: 6720, Train Loss: 0.6842\n",
      "Epoch [6/10], Batch: 6730, Train Loss: 0.6980\n",
      "Epoch [6/10], Batch: 6740, Train Loss: 0.7424\n",
      "Epoch [6/10], Batch: 6750, Train Loss: 0.6700\n",
      "Epoch [6/10], Batch: 6760, Train Loss: 0.8075\n",
      "Epoch [7/10], Batch: 10, Train Loss: 0.7674\n",
      "Epoch [7/10], Batch: 20, Train Loss: 0.5482\n",
      "Epoch [7/10], Batch: 30, Train Loss: 0.5655\n",
      "Epoch [7/10], Batch: 40, Train Loss: 0.6550\n",
      "Epoch [7/10], Batch: 50, Train Loss: 0.9231\n",
      "Epoch [7/10], Batch: 60, Train Loss: 0.7335\n",
      "Epoch [7/10], Batch: 70, Train Loss: 0.8039\n",
      "Epoch [7/10], Batch: 80, Train Loss: 0.7270\n",
      "Epoch [7/10], Batch: 90, Train Loss: 0.6921\n",
      "Epoch [7/10], Batch: 100, Train Loss: 0.6897\n",
      "Epoch [7/10], Batch: 110, Train Loss: 0.8549\n",
      "Epoch [7/10], Batch: 120, Train Loss: 0.7482\n",
      "Epoch [7/10], Batch: 130, Train Loss: 0.8124\n",
      "Epoch [7/10], Batch: 140, Train Loss: 0.7904\n",
      "Epoch [7/10], Batch: 150, Train Loss: 0.6992\n",
      "Epoch [7/10], Batch: 160, Train Loss: 0.7139\n",
      "Epoch [7/10], Batch: 170, Train Loss: 0.7357\n",
      "Epoch [7/10], Batch: 180, Train Loss: 0.6323\n",
      "Epoch [7/10], Batch: 190, Train Loss: 0.7103\n",
      "Epoch [7/10], Batch: 200, Train Loss: 0.6491\n",
      "Epoch [7/10], Batch: 210, Train Loss: 0.7882\n",
      "Epoch [7/10], Batch: 220, Train Loss: 0.7005\n",
      "Epoch [7/10], Batch: 230, Train Loss: 0.8424\n",
      "Epoch [7/10], Batch: 240, Train Loss: 0.7128\n",
      "Epoch [7/10], Batch: 250, Train Loss: 0.7965\n",
      "Epoch [7/10], Batch: 260, Train Loss: 0.7467\n",
      "Epoch [7/10], Batch: 270, Train Loss: 0.7434\n",
      "Epoch [7/10], Batch: 280, Train Loss: 0.6184\n",
      "Epoch [7/10], Batch: 290, Train Loss: 0.8474\n",
      "Epoch [7/10], Batch: 300, Train Loss: 0.8651\n",
      "Epoch [7/10], Batch: 310, Train Loss: 0.7704\n",
      "Epoch [7/10], Batch: 320, Train Loss: 0.7403\n",
      "Epoch [7/10], Batch: 330, Train Loss: 0.7224\n",
      "Epoch [7/10], Batch: 340, Train Loss: 0.7243\n",
      "Epoch [7/10], Batch: 350, Train Loss: 0.7855\n",
      "Epoch [7/10], Batch: 360, Train Loss: 0.7458\n",
      "Epoch [7/10], Batch: 370, Train Loss: 0.6986\n",
      "Epoch [7/10], Batch: 380, Train Loss: 0.7924\n",
      "Epoch [7/10], Batch: 390, Train Loss: 0.8048\n",
      "Epoch [7/10], Batch: 400, Train Loss: 0.8177\n",
      "Epoch [7/10], Batch: 410, Train Loss: 0.8758\n",
      "Epoch [7/10], Batch: 420, Train Loss: 0.8116\n",
      "Epoch [7/10], Batch: 430, Train Loss: 0.8079\n",
      "Epoch [7/10], Batch: 440, Train Loss: 0.6150\n",
      "Epoch [7/10], Batch: 450, Train Loss: 0.6809\n",
      "Epoch [7/10], Batch: 460, Train Loss: 0.8183\n",
      "Epoch [7/10], Batch: 470, Train Loss: 0.7932\n",
      "Epoch [7/10], Batch: 480, Train Loss: 0.8046\n",
      "Epoch [7/10], Batch: 490, Train Loss: 0.6592\n",
      "Epoch [7/10], Batch: 500, Train Loss: 0.8893\n",
      "Epoch [7/10], Batch: 510, Train Loss: 0.7203\n",
      "Epoch [7/10], Batch: 520, Train Loss: 0.9286\n",
      "Epoch [7/10], Batch: 530, Train Loss: 0.6917\n",
      "Epoch [7/10], Batch: 540, Train Loss: 0.7750\n",
      "Epoch [7/10], Batch: 550, Train Loss: 0.8165\n",
      "Epoch [7/10], Batch: 560, Train Loss: 0.6983\n",
      "Epoch [7/10], Batch: 570, Train Loss: 0.8396\n",
      "Epoch [7/10], Batch: 580, Train Loss: 0.7150\n",
      "Epoch [7/10], Batch: 590, Train Loss: 0.8226\n",
      "Epoch [7/10], Batch: 600, Train Loss: 0.7105\n",
      "Epoch [7/10], Batch: 610, Train Loss: 0.7536\n",
      "Epoch [7/10], Batch: 620, Train Loss: 0.7675\n",
      "Epoch [7/10], Batch: 630, Train Loss: 0.7316\n",
      "Epoch [7/10], Batch: 640, Train Loss: 0.8382\n",
      "Epoch [7/10], Batch: 650, Train Loss: 0.7969\n",
      "Epoch [7/10], Batch: 660, Train Loss: 0.8862\n",
      "Epoch [7/10], Batch: 670, Train Loss: 0.8042\n",
      "Epoch [7/10], Batch: 680, Train Loss: 0.6853\n",
      "Epoch [7/10], Batch: 690, Train Loss: 0.7019\n",
      "Epoch [7/10], Batch: 700, Train Loss: 0.7439\n",
      "Epoch [7/10], Batch: 710, Train Loss: 0.7043\n",
      "Epoch [7/10], Batch: 720, Train Loss: 0.7463\n",
      "Epoch [7/10], Batch: 730, Train Loss: 0.7330\n",
      "Epoch [7/10], Batch: 740, Train Loss: 0.7221\n",
      "Epoch [7/10], Batch: 750, Train Loss: 0.6009\n",
      "Epoch [7/10], Batch: 760, Train Loss: 0.7806\n",
      "Epoch [7/10], Batch: 770, Train Loss: 0.6753\n",
      "Epoch [7/10], Batch: 780, Train Loss: 0.6570\n",
      "Epoch [7/10], Batch: 790, Train Loss: 0.8613\n",
      "Epoch [7/10], Batch: 800, Train Loss: 0.7821\n",
      "Epoch [7/10], Batch: 810, Train Loss: 0.7017\n",
      "Epoch [7/10], Batch: 820, Train Loss: 0.8064\n",
      "Epoch [7/10], Batch: 830, Train Loss: 0.8389\n",
      "Epoch [7/10], Batch: 840, Train Loss: 0.8050\n",
      "Epoch [7/10], Batch: 850, Train Loss: 0.7613\n",
      "Epoch [7/10], Batch: 860, Train Loss: 0.6804\n",
      "Epoch [7/10], Batch: 870, Train Loss: 0.8350\n",
      "Epoch [7/10], Batch: 880, Train Loss: 0.8272\n",
      "Epoch [7/10], Batch: 890, Train Loss: 0.7604\n",
      "Epoch [7/10], Batch: 900, Train Loss: 0.7463\n",
      "Epoch [7/10], Batch: 910, Train Loss: 0.7293\n",
      "Epoch [7/10], Batch: 920, Train Loss: 0.8050\n",
      "Epoch [7/10], Batch: 930, Train Loss: 0.7606\n",
      "Epoch [7/10], Batch: 940, Train Loss: 0.8198\n",
      "Epoch [7/10], Batch: 950, Train Loss: 0.8070\n",
      "Epoch [7/10], Batch: 960, Train Loss: 0.8759\n",
      "Epoch [7/10], Batch: 970, Train Loss: 0.5931\n",
      "Epoch [7/10], Batch: 980, Train Loss: 0.8121\n",
      "Epoch [7/10], Batch: 990, Train Loss: 0.7288\n",
      "Epoch [7/10], Batch: 1000, Train Loss: 0.7570\n",
      "Epoch [7/10], Batch: 1010, Train Loss: 0.7794\n",
      "Epoch [7/10], Batch: 1020, Train Loss: 0.6983\n",
      "Epoch [7/10], Batch: 1030, Train Loss: 0.7656\n",
      "Epoch [7/10], Batch: 1040, Train Loss: 0.8085\n",
      "Epoch [7/10], Batch: 1050, Train Loss: 0.6692\n",
      "Epoch [7/10], Batch: 1060, Train Loss: 0.8099\n",
      "Epoch [7/10], Batch: 1070, Train Loss: 0.8259\n",
      "Epoch [7/10], Batch: 1080, Train Loss: 0.6651\n",
      "Epoch [7/10], Batch: 1090, Train Loss: 0.6860\n",
      "Epoch [7/10], Batch: 1100, Train Loss: 0.7119\n",
      "Epoch [7/10], Batch: 1110, Train Loss: 0.8194\n",
      "Epoch [7/10], Batch: 1120, Train Loss: 0.6693\n",
      "Epoch [7/10], Batch: 1130, Train Loss: 0.8604\n",
      "Epoch [7/10], Batch: 1140, Train Loss: 0.8229\n",
      "Epoch [7/10], Batch: 1150, Train Loss: 0.7625\n",
      "Epoch [7/10], Batch: 1160, Train Loss: 0.7522\n",
      "Epoch [7/10], Batch: 1170, Train Loss: 0.8175\n",
      "Epoch [7/10], Batch: 1180, Train Loss: 0.8960\n",
      "Epoch [7/10], Batch: 1190, Train Loss: 0.7816\n",
      "Epoch [7/10], Batch: 1200, Train Loss: 0.7520\n",
      "Epoch [7/10], Batch: 1210, Train Loss: 0.7370\n",
      "Epoch [7/10], Batch: 1220, Train Loss: 0.8137\n",
      "Epoch [7/10], Batch: 1230, Train Loss: 0.7922\n",
      "Epoch [7/10], Batch: 1240, Train Loss: 0.8017\n",
      "Epoch [7/10], Batch: 1250, Train Loss: 0.7796\n",
      "Epoch [7/10], Batch: 1260, Train Loss: 0.8036\n",
      "Epoch [7/10], Batch: 1270, Train Loss: 0.7327\n",
      "Epoch [7/10], Batch: 1280, Train Loss: 0.7304\n",
      "Epoch [7/10], Batch: 1290, Train Loss: 0.6657\n",
      "Epoch [7/10], Batch: 1300, Train Loss: 0.7089\n",
      "Epoch [7/10], Batch: 1310, Train Loss: 0.7739\n",
      "Epoch [7/10], Batch: 1320, Train Loss: 0.6965\n",
      "Epoch [7/10], Batch: 1330, Train Loss: 0.8769\n",
      "Epoch [7/10], Batch: 1340, Train Loss: 0.7374\n",
      "Epoch [7/10], Batch: 1350, Train Loss: 0.7646\n",
      "Epoch [7/10], Batch: 1360, Train Loss: 0.6309\n",
      "Epoch [7/10], Batch: 1370, Train Loss: 0.9046\n",
      "Epoch [7/10], Batch: 1380, Train Loss: 0.6755\n",
      "Epoch [7/10], Batch: 1390, Train Loss: 0.7728\n",
      "Epoch [7/10], Batch: 1400, Train Loss: 0.7549\n",
      "Epoch [7/10], Batch: 1410, Train Loss: 0.9671\n",
      "Epoch [7/10], Batch: 1420, Train Loss: 0.7860\n",
      "Epoch [7/10], Batch: 1430, Train Loss: 0.9593\n",
      "Epoch [7/10], Batch: 1440, Train Loss: 0.7686\n",
      "Epoch [7/10], Batch: 1450, Train Loss: 0.7368\n",
      "Epoch [7/10], Batch: 1460, Train Loss: 0.8086\n",
      "Epoch [7/10], Batch: 1470, Train Loss: 0.7455\n",
      "Epoch [7/10], Batch: 1480, Train Loss: 0.8965\n",
      "Epoch [7/10], Batch: 1490, Train Loss: 0.7394\n",
      "Epoch [7/10], Batch: 1500, Train Loss: 0.8350\n",
      "Epoch [7/10], Batch: 1510, Train Loss: 0.7630\n",
      "Epoch [7/10], Batch: 1520, Train Loss: 0.7403\n",
      "Epoch [7/10], Batch: 1530, Train Loss: 0.6272\n",
      "Epoch [7/10], Batch: 1540, Train Loss: 0.6816\n",
      "Epoch [7/10], Batch: 1550, Train Loss: 0.7650\n",
      "Epoch [7/10], Batch: 1560, Train Loss: 0.7051\n",
      "Epoch [7/10], Batch: 1570, Train Loss: 0.7723\n",
      "Epoch [7/10], Batch: 1580, Train Loss: 0.8021\n",
      "Epoch [7/10], Batch: 1590, Train Loss: 0.6807\n",
      "Epoch [7/10], Batch: 1600, Train Loss: 0.7576\n",
      "Epoch [7/10], Batch: 1610, Train Loss: 0.8283\n",
      "Epoch [7/10], Batch: 1620, Train Loss: 0.7955\n",
      "Epoch [7/10], Batch: 1630, Train Loss: 0.8634\n",
      "Epoch [7/10], Batch: 1640, Train Loss: 0.6540\n",
      "Epoch [7/10], Batch: 1650, Train Loss: 0.8599\n",
      "Epoch [7/10], Batch: 1660, Train Loss: 0.6821\n",
      "Epoch [7/10], Batch: 1670, Train Loss: 0.7087\n",
      "Epoch [7/10], Batch: 1680, Train Loss: 0.7345\n",
      "Epoch [7/10], Batch: 1690, Train Loss: 0.8571\n",
      "Epoch [7/10], Batch: 1700, Train Loss: 0.7105\n",
      "Epoch [7/10], Batch: 1710, Train Loss: 0.7209\n",
      "Epoch [7/10], Batch: 1720, Train Loss: 0.8544\n",
      "Epoch [7/10], Batch: 1730, Train Loss: 0.7730\n",
      "Epoch [7/10], Batch: 1740, Train Loss: 0.7627\n",
      "Epoch [7/10], Batch: 1750, Train Loss: 0.7678\n",
      "Epoch [7/10], Batch: 1760, Train Loss: 0.7942\n",
      "Epoch [7/10], Batch: 1770, Train Loss: 0.7165\n",
      "Epoch [7/10], Batch: 1780, Train Loss: 0.7129\n",
      "Epoch [7/10], Batch: 1790, Train Loss: 0.8490\n",
      "Epoch [7/10], Batch: 1800, Train Loss: 0.8172\n",
      "Epoch [7/10], Batch: 1810, Train Loss: 0.6962\n",
      "Epoch [7/10], Batch: 1820, Train Loss: 0.7611\n",
      "Epoch [7/10], Batch: 1830, Train Loss: 0.8064\n",
      "Epoch [7/10], Batch: 1840, Train Loss: 0.8282\n",
      "Epoch [7/10], Batch: 1850, Train Loss: 0.8942\n",
      "Epoch [7/10], Batch: 1860, Train Loss: 0.7601\n",
      "Epoch [7/10], Batch: 1870, Train Loss: 0.8645\n",
      "Epoch [7/10], Batch: 1880, Train Loss: 0.7678\n",
      "Epoch [7/10], Batch: 1890, Train Loss: 0.8328\n",
      "Epoch [7/10], Batch: 1900, Train Loss: 0.7318\n",
      "Epoch [7/10], Batch: 1910, Train Loss: 0.6333\n",
      "Epoch [7/10], Batch: 1920, Train Loss: 0.8287\n",
      "Epoch [7/10], Batch: 1930, Train Loss: 0.8279\n",
      "Epoch [7/10], Batch: 1940, Train Loss: 0.7459\n",
      "Epoch [7/10], Batch: 1950, Train Loss: 0.8509\n",
      "Epoch [7/10], Batch: 1960, Train Loss: 0.7283\n",
      "Epoch [7/10], Batch: 1970, Train Loss: 0.7457\n",
      "Epoch [7/10], Batch: 1980, Train Loss: 0.6834\n",
      "Epoch [7/10], Batch: 1990, Train Loss: 0.7009\n",
      "Epoch [7/10], Batch: 2000, Train Loss: 0.7214\n",
      "Epoch [7/10], Batch: 2010, Train Loss: 0.7122\n",
      "Epoch [7/10], Batch: 2020, Train Loss: 0.8024\n",
      "Epoch [7/10], Batch: 2030, Train Loss: 0.7057\n",
      "Epoch [7/10], Batch: 2040, Train Loss: 0.7142\n",
      "Epoch [7/10], Batch: 2050, Train Loss: 0.7531\n",
      "Epoch [7/10], Batch: 2060, Train Loss: 0.6368\n",
      "Epoch [7/10], Batch: 2070, Train Loss: 0.7513\n",
      "Epoch [7/10], Batch: 2080, Train Loss: 0.7311\n",
      "Epoch [7/10], Batch: 2090, Train Loss: 0.7377\n",
      "Epoch [7/10], Batch: 2100, Train Loss: 0.7852\n",
      "Epoch [7/10], Batch: 2110, Train Loss: 0.9178\n",
      "Epoch [7/10], Batch: 2120, Train Loss: 0.6643\n",
      "Epoch [7/10], Batch: 2130, Train Loss: 0.8166\n",
      "Epoch [7/10], Batch: 2140, Train Loss: 0.8428\n",
      "Epoch [7/10], Batch: 2150, Train Loss: 0.8747\n",
      "Epoch [7/10], Batch: 2160, Train Loss: 0.7959\n",
      "Epoch [7/10], Batch: 2170, Train Loss: 0.7884\n",
      "Epoch [7/10], Batch: 2180, Train Loss: 0.6745\n",
      "Epoch [7/10], Batch: 2190, Train Loss: 0.7162\n",
      "Epoch [7/10], Batch: 2200, Train Loss: 0.7402\n",
      "Epoch [7/10], Batch: 2210, Train Loss: 0.7242\n",
      "Epoch [7/10], Batch: 2220, Train Loss: 0.7165\n",
      "Epoch [7/10], Batch: 2230, Train Loss: 0.8358\n",
      "Epoch [7/10], Batch: 2240, Train Loss: 0.9092\n",
      "Epoch [7/10], Batch: 2250, Train Loss: 0.7472\n",
      "Epoch [7/10], Batch: 2260, Train Loss: 0.7206\n",
      "Epoch [7/10], Batch: 2270, Train Loss: 0.7879\n",
      "Epoch [7/10], Batch: 2280, Train Loss: 0.7293\n",
      "Epoch [7/10], Batch: 2290, Train Loss: 0.8374\n",
      "Epoch [7/10], Batch: 2300, Train Loss: 0.7127\n",
      "Epoch [7/10], Batch: 2310, Train Loss: 0.7218\n",
      "Epoch [7/10], Batch: 2320, Train Loss: 0.8640\n",
      "Epoch [7/10], Batch: 2330, Train Loss: 0.7080\n",
      "Epoch [7/10], Batch: 2340, Train Loss: 0.8357\n",
      "Epoch [7/10], Batch: 2350, Train Loss: 0.7236\n",
      "Epoch [7/10], Batch: 2360, Train Loss: 0.7449\n",
      "Epoch [7/10], Batch: 2370, Train Loss: 0.7697\n",
      "Epoch [7/10], Batch: 2380, Train Loss: 0.8495\n",
      "Epoch [7/10], Batch: 2390, Train Loss: 0.6557\n",
      "Epoch [7/10], Batch: 2400, Train Loss: 0.7335\n",
      "Epoch [7/10], Batch: 2410, Train Loss: 0.7499\n",
      "Epoch [7/10], Batch: 2420, Train Loss: 0.7690\n",
      "Epoch [7/10], Batch: 2430, Train Loss: 0.7456\n",
      "Epoch [7/10], Batch: 2440, Train Loss: 0.7243\n",
      "Epoch [7/10], Batch: 2450, Train Loss: 0.7415\n",
      "Epoch [7/10], Batch: 2460, Train Loss: 0.7405\n",
      "Epoch [7/10], Batch: 2470, Train Loss: 0.8155\n",
      "Epoch [7/10], Batch: 2480, Train Loss: 0.6533\n",
      "Epoch [7/10], Batch: 2490, Train Loss: 0.7886\n",
      "Epoch [7/10], Batch: 2500, Train Loss: 0.7966\n",
      "Epoch [7/10], Batch: 2510, Train Loss: 0.7715\n",
      "Epoch [7/10], Batch: 2520, Train Loss: 0.7282\n",
      "Epoch [7/10], Batch: 2530, Train Loss: 0.6940\n",
      "Epoch [7/10], Batch: 2540, Train Loss: 0.8539\n",
      "Epoch [7/10], Batch: 2550, Train Loss: 0.6835\n",
      "Epoch [7/10], Batch: 2560, Train Loss: 0.8022\n",
      "Epoch [7/10], Batch: 2570, Train Loss: 0.6033\n",
      "Epoch [7/10], Batch: 2580, Train Loss: 0.7205\n",
      "Epoch [7/10], Batch: 2590, Train Loss: 0.7878\n",
      "Epoch [7/10], Batch: 2600, Train Loss: 0.7025\n",
      "Epoch [7/10], Batch: 2610, Train Loss: 0.7338\n",
      "Epoch [7/10], Batch: 2620, Train Loss: 0.6951\n",
      "Epoch [7/10], Batch: 2630, Train Loss: 0.7124\n",
      "Epoch [7/10], Batch: 2640, Train Loss: 0.7064\n",
      "Epoch [7/10], Batch: 2650, Train Loss: 0.7686\n",
      "Epoch [7/10], Batch: 2660, Train Loss: 0.7327\n",
      "Epoch [7/10], Batch: 2670, Train Loss: 0.6990\n",
      "Epoch [7/10], Batch: 2680, Train Loss: 0.8621\n",
      "Epoch [7/10], Batch: 2690, Train Loss: 0.6433\n",
      "Epoch [7/10], Batch: 2700, Train Loss: 0.7453\n",
      "Epoch [7/10], Batch: 2710, Train Loss: 0.7462\n",
      "Epoch [7/10], Batch: 2720, Train Loss: 0.7927\n",
      "Epoch [7/10], Batch: 2730, Train Loss: 0.8298\n",
      "Epoch [7/10], Batch: 2740, Train Loss: 0.8689\n",
      "Epoch [7/10], Batch: 2750, Train Loss: 0.8534\n",
      "Epoch [7/10], Batch: 2760, Train Loss: 0.6846\n",
      "Epoch [7/10], Batch: 2770, Train Loss: 0.7285\n",
      "Epoch [7/10], Batch: 2780, Train Loss: 0.7400\n",
      "Epoch [7/10], Batch: 2790, Train Loss: 0.6134\n",
      "Epoch [7/10], Batch: 2800, Train Loss: 0.7743\n",
      "Epoch [7/10], Batch: 2810, Train Loss: 0.7723\n",
      "Epoch [7/10], Batch: 2820, Train Loss: 0.6760\n",
      "Epoch [7/10], Batch: 2830, Train Loss: 0.9236\n",
      "Epoch [7/10], Batch: 2840, Train Loss: 0.7204\n",
      "Epoch [7/10], Batch: 2850, Train Loss: 0.7505\n",
      "Epoch [7/10], Batch: 2860, Train Loss: 0.7934\n",
      "Epoch [7/10], Batch: 2870, Train Loss: 0.6758\n",
      "Epoch [7/10], Batch: 2880, Train Loss: 1.0396\n",
      "Epoch [7/10], Batch: 2890, Train Loss: 0.8379\n",
      "Epoch [7/10], Batch: 2900, Train Loss: 0.8269\n",
      "Epoch [7/10], Batch: 2910, Train Loss: 0.8336\n",
      "Epoch [7/10], Batch: 2920, Train Loss: 0.7877\n",
      "Epoch [7/10], Batch: 2930, Train Loss: 0.7463\n",
      "Epoch [7/10], Batch: 2940, Train Loss: 0.8761\n",
      "Epoch [7/10], Batch: 2950, Train Loss: 0.6513\n",
      "Epoch [7/10], Batch: 2960, Train Loss: 0.8774\n",
      "Epoch [7/10], Batch: 2970, Train Loss: 0.7753\n",
      "Epoch [7/10], Batch: 2980, Train Loss: 0.6681\n",
      "Epoch [7/10], Batch: 2990, Train Loss: 0.6295\n",
      "Epoch [7/10], Batch: 3000, Train Loss: 0.6634\n",
      "Epoch [7/10], Batch: 3010, Train Loss: 0.8663\n",
      "Epoch [7/10], Batch: 3020, Train Loss: 0.8347\n",
      "Epoch [7/10], Batch: 3030, Train Loss: 0.6324\n",
      "Epoch [7/10], Batch: 3040, Train Loss: 0.6575\n",
      "Epoch [7/10], Batch: 3050, Train Loss: 0.6443\n",
      "Epoch [7/10], Batch: 3060, Train Loss: 0.7260\n",
      "Epoch [7/10], Batch: 3070, Train Loss: 0.8678\n",
      "Epoch [7/10], Batch: 3080, Train Loss: 0.8978\n",
      "Epoch [7/10], Batch: 3090, Train Loss: 0.8437\n",
      "Epoch [7/10], Batch: 3100, Train Loss: 0.7601\n",
      "Epoch [7/10], Batch: 3110, Train Loss: 0.8060\n",
      "Epoch [7/10], Batch: 3120, Train Loss: 0.7224\n",
      "Epoch [7/10], Batch: 3130, Train Loss: 0.8540\n",
      "Epoch [7/10], Batch: 3140, Train Loss: 0.7819\n",
      "Epoch [7/10], Batch: 3150, Train Loss: 0.7043\n",
      "Epoch [7/10], Batch: 3160, Train Loss: 0.8331\n",
      "Epoch [7/10], Batch: 3170, Train Loss: 0.6783\n",
      "Epoch [7/10], Batch: 3180, Train Loss: 0.8566\n",
      "Epoch [7/10], Batch: 3190, Train Loss: 0.5508\n",
      "Epoch [7/10], Batch: 3200, Train Loss: 0.9787\n",
      "Epoch [7/10], Batch: 3210, Train Loss: 0.7830\n",
      "Epoch [7/10], Batch: 3220, Train Loss: 0.8561\n",
      "Epoch [7/10], Batch: 3230, Train Loss: 0.7323\n",
      "Epoch [7/10], Batch: 3240, Train Loss: 0.7149\n",
      "Epoch [7/10], Batch: 3250, Train Loss: 0.7372\n",
      "Epoch [7/10], Batch: 3260, Train Loss: 0.7756\n",
      "Epoch [7/10], Batch: 3270, Train Loss: 0.8843\n",
      "Epoch [7/10], Batch: 3280, Train Loss: 0.8221\n",
      "Epoch [7/10], Batch: 3290, Train Loss: 0.7676\n",
      "Epoch [7/10], Batch: 3300, Train Loss: 0.7111\n",
      "Epoch [7/10], Batch: 3310, Train Loss: 0.8062\n",
      "Epoch [7/10], Batch: 3320, Train Loss: 0.8598\n",
      "Epoch [7/10], Batch: 3330, Train Loss: 0.6238\n",
      "Epoch [7/10], Batch: 3340, Train Loss: 0.8259\n",
      "Epoch [7/10], Batch: 3350, Train Loss: 0.7044\n",
      "Epoch [7/10], Batch: 3360, Train Loss: 0.6095\n",
      "Epoch [7/10], Batch: 3370, Train Loss: 0.6826\n",
      "Epoch [7/10], Batch: 3380, Train Loss: 0.7141\n",
      "Epoch [7/10], Batch: 3390, Train Loss: 0.6805\n",
      "Epoch [7/10], Batch: 3400, Train Loss: 0.8019\n",
      "Epoch [7/10], Batch: 3410, Train Loss: 0.7628\n",
      "Epoch [7/10], Batch: 3420, Train Loss: 0.7439\n",
      "Epoch [7/10], Batch: 3430, Train Loss: 0.8580\n",
      "Epoch [7/10], Batch: 3440, Train Loss: 0.8006\n",
      "Epoch [7/10], Batch: 3450, Train Loss: 0.6921\n",
      "Epoch [7/10], Batch: 3460, Train Loss: 0.7750\n",
      "Epoch [7/10], Batch: 3470, Train Loss: 0.6780\n",
      "Epoch [7/10], Batch: 3480, Train Loss: 0.7389\n",
      "Epoch [7/10], Batch: 3490, Train Loss: 0.8021\n",
      "Epoch [7/10], Batch: 3500, Train Loss: 0.7580\n",
      "Epoch [7/10], Batch: 3510, Train Loss: 0.8206\n",
      "Epoch [7/10], Batch: 3520, Train Loss: 0.8346\n",
      "Epoch [7/10], Batch: 3530, Train Loss: 0.7661\n",
      "Epoch [7/10], Batch: 3540, Train Loss: 0.6750\n",
      "Epoch [7/10], Batch: 3550, Train Loss: 0.7205\n",
      "Epoch [7/10], Batch: 3560, Train Loss: 0.8546\n",
      "Epoch [7/10], Batch: 3570, Train Loss: 0.8210\n",
      "Epoch [7/10], Batch: 3580, Train Loss: 0.7723\n",
      "Epoch [7/10], Batch: 3590, Train Loss: 0.8191\n",
      "Epoch [7/10], Batch: 3600, Train Loss: 0.8231\n",
      "Epoch [7/10], Batch: 3610, Train Loss: 0.6223\n",
      "Epoch [7/10], Batch: 3620, Train Loss: 0.8123\n",
      "Epoch [7/10], Batch: 3630, Train Loss: 0.8331\n",
      "Epoch [7/10], Batch: 3640, Train Loss: 0.6864\n",
      "Epoch [7/10], Batch: 3650, Train Loss: 0.6731\n",
      "Epoch [7/10], Batch: 3660, Train Loss: 0.7725\n",
      "Epoch [7/10], Batch: 3670, Train Loss: 0.7410\n",
      "Epoch [7/10], Batch: 3680, Train Loss: 0.8693\n",
      "Epoch [7/10], Batch: 3690, Train Loss: 0.7306\n",
      "Epoch [7/10], Batch: 3700, Train Loss: 0.8821\n",
      "Epoch [7/10], Batch: 3710, Train Loss: 0.9036\n",
      "Epoch [7/10], Batch: 3720, Train Loss: 0.7505\n",
      "Epoch [7/10], Batch: 3730, Train Loss: 0.6250\n",
      "Epoch [7/10], Batch: 3740, Train Loss: 0.7170\n",
      "Epoch [7/10], Batch: 3750, Train Loss: 0.6653\n",
      "Epoch [7/10], Batch: 3760, Train Loss: 0.7032\n",
      "Epoch [7/10], Batch: 3770, Train Loss: 0.7591\n",
      "Epoch [7/10], Batch: 3780, Train Loss: 0.8579\n",
      "Epoch [7/10], Batch: 3790, Train Loss: 0.7190\n",
      "Epoch [7/10], Batch: 3800, Train Loss: 0.6712\n",
      "Epoch [7/10], Batch: 3810, Train Loss: 0.6836\n",
      "Epoch [7/10], Batch: 3820, Train Loss: 0.7493\n",
      "Epoch [7/10], Batch: 3830, Train Loss: 0.6403\n",
      "Epoch [7/10], Batch: 3840, Train Loss: 0.7556\n",
      "Epoch [7/10], Batch: 3850, Train Loss: 0.7396\n",
      "Epoch [7/10], Batch: 3860, Train Loss: 0.8004\n",
      "Epoch [7/10], Batch: 3870, Train Loss: 0.7850\n",
      "Epoch [7/10], Batch: 3880, Train Loss: 0.8280\n",
      "Epoch [7/10], Batch: 3890, Train Loss: 0.8275\n",
      "Epoch [7/10], Batch: 3900, Train Loss: 0.7635\n",
      "Epoch [7/10], Batch: 3910, Train Loss: 0.9049\n",
      "Epoch [7/10], Batch: 3920, Train Loss: 0.7354\n",
      "Epoch [7/10], Batch: 3930, Train Loss: 0.8175\n",
      "Epoch [7/10], Batch: 3940, Train Loss: 0.7827\n",
      "Epoch [7/10], Batch: 3950, Train Loss: 0.8117\n",
      "Epoch [7/10], Batch: 3960, Train Loss: 0.9073\n",
      "Epoch [7/10], Batch: 3970, Train Loss: 0.6909\n",
      "Epoch [7/10], Batch: 3980, Train Loss: 0.7716\n",
      "Epoch [7/10], Batch: 3990, Train Loss: 0.6131\n",
      "Epoch [7/10], Batch: 4000, Train Loss: 0.7774\n",
      "Epoch [7/10], Batch: 4010, Train Loss: 0.7711\n",
      "Epoch [7/10], Batch: 4020, Train Loss: 0.7463\n",
      "Epoch [7/10], Batch: 4030, Train Loss: 0.8321\n",
      "Epoch [7/10], Batch: 4040, Train Loss: 0.7117\n",
      "Epoch [7/10], Batch: 4050, Train Loss: 0.6645\n",
      "Epoch [7/10], Batch: 4060, Train Loss: 0.7010\n",
      "Epoch [7/10], Batch: 4070, Train Loss: 0.7305\n",
      "Epoch [7/10], Batch: 4080, Train Loss: 0.8213\n",
      "Epoch [7/10], Batch: 4090, Train Loss: 0.7773\n",
      "Epoch [7/10], Batch: 4100, Train Loss: 0.7902\n",
      "Epoch [7/10], Batch: 4110, Train Loss: 0.8518\n",
      "Epoch [7/10], Batch: 4120, Train Loss: 0.7380\n",
      "Epoch [7/10], Batch: 4130, Train Loss: 0.7568\n",
      "Epoch [7/10], Batch: 4140, Train Loss: 0.8403\n",
      "Epoch [7/10], Batch: 4150, Train Loss: 0.6555\n",
      "Epoch [7/10], Batch: 4160, Train Loss: 0.6308\n",
      "Epoch [7/10], Batch: 4170, Train Loss: 0.6756\n",
      "Epoch [7/10], Batch: 4180, Train Loss: 0.5908\n",
      "Epoch [7/10], Batch: 4190, Train Loss: 0.8087\n",
      "Epoch [7/10], Batch: 4200, Train Loss: 0.6755\n",
      "Epoch [7/10], Batch: 4210, Train Loss: 0.7942\n",
      "Epoch [7/10], Batch: 4220, Train Loss: 0.7360\n",
      "Epoch [7/10], Batch: 4230, Train Loss: 0.8209\n",
      "Epoch [7/10], Batch: 4240, Train Loss: 0.6833\n",
      "Epoch [7/10], Batch: 4250, Train Loss: 0.7312\n",
      "Epoch [7/10], Batch: 4260, Train Loss: 0.7889\n",
      "Epoch [7/10], Batch: 4270, Train Loss: 0.8419\n",
      "Epoch [7/10], Batch: 4280, Train Loss: 0.7372\n",
      "Epoch [7/10], Batch: 4290, Train Loss: 0.8526\n",
      "Epoch [7/10], Batch: 4300, Train Loss: 0.7480\n",
      "Epoch [7/10], Batch: 4310, Train Loss: 0.7531\n",
      "Epoch [7/10], Batch: 4320, Train Loss: 0.7836\n",
      "Epoch [7/10], Batch: 4330, Train Loss: 0.7342\n",
      "Epoch [7/10], Batch: 4340, Train Loss: 0.8176\n",
      "Epoch [7/10], Batch: 4350, Train Loss: 0.6504\n",
      "Epoch [7/10], Batch: 4360, Train Loss: 0.6250\n",
      "Epoch [7/10], Batch: 4370, Train Loss: 0.9279\n",
      "Epoch [7/10], Batch: 4380, Train Loss: 0.7418\n",
      "Epoch [7/10], Batch: 4390, Train Loss: 0.8406\n",
      "Epoch [7/10], Batch: 4400, Train Loss: 0.7210\n",
      "Epoch [7/10], Batch: 4410, Train Loss: 0.6663\n",
      "Epoch [7/10], Batch: 4420, Train Loss: 0.9500\n",
      "Epoch [7/10], Batch: 4430, Train Loss: 0.7943\n",
      "Epoch [7/10], Batch: 4440, Train Loss: 0.8620\n",
      "Epoch [7/10], Batch: 4450, Train Loss: 0.7261\n",
      "Epoch [7/10], Batch: 4460, Train Loss: 0.7538\n",
      "Epoch [7/10], Batch: 4470, Train Loss: 0.6731\n",
      "Epoch [7/10], Batch: 4480, Train Loss: 0.8040\n",
      "Epoch [7/10], Batch: 4490, Train Loss: 0.7761\n",
      "Epoch [7/10], Batch: 4500, Train Loss: 0.7999\n",
      "Epoch [7/10], Batch: 4510, Train Loss: 0.7209\n",
      "Epoch [7/10], Batch: 4520, Train Loss: 0.6968\n",
      "Epoch [7/10], Batch: 4530, Train Loss: 0.6520\n",
      "Epoch [7/10], Batch: 4540, Train Loss: 0.7798\n",
      "Epoch [7/10], Batch: 4550, Train Loss: 0.6361\n",
      "Epoch [7/10], Batch: 4560, Train Loss: 0.8369\n",
      "Epoch [7/10], Batch: 4570, Train Loss: 0.6758\n",
      "Epoch [7/10], Batch: 4580, Train Loss: 0.8023\n",
      "Epoch [7/10], Batch: 4590, Train Loss: 0.6518\n",
      "Epoch [7/10], Batch: 4600, Train Loss: 0.6642\n",
      "Epoch [7/10], Batch: 4610, Train Loss: 0.7333\n",
      "Epoch [7/10], Batch: 4620, Train Loss: 0.7187\n",
      "Epoch [7/10], Batch: 4630, Train Loss: 0.6883\n",
      "Epoch [7/10], Batch: 4640, Train Loss: 0.7673\n",
      "Epoch [7/10], Batch: 4650, Train Loss: 0.7716\n",
      "Epoch [7/10], Batch: 4660, Train Loss: 0.7588\n",
      "Epoch [7/10], Batch: 4670, Train Loss: 0.8470\n",
      "Epoch [7/10], Batch: 4680, Train Loss: 0.7191\n",
      "Epoch [7/10], Batch: 4690, Train Loss: 0.8517\n",
      "Epoch [7/10], Batch: 4700, Train Loss: 0.8688\n",
      "Epoch [7/10], Batch: 4710, Train Loss: 0.6664\n",
      "Epoch [7/10], Batch: 4720, Train Loss: 0.6960\n",
      "Epoch [7/10], Batch: 4730, Train Loss: 0.8628\n",
      "Epoch [7/10], Batch: 4740, Train Loss: 0.6111\n",
      "Epoch [7/10], Batch: 4750, Train Loss: 0.6445\n",
      "Epoch [7/10], Batch: 4760, Train Loss: 0.7529\n",
      "Epoch [7/10], Batch: 4770, Train Loss: 0.7581\n",
      "Epoch [7/10], Batch: 4780, Train Loss: 0.7734\n",
      "Epoch [7/10], Batch: 4790, Train Loss: 0.7843\n",
      "Epoch [7/10], Batch: 4800, Train Loss: 0.7642\n",
      "Epoch [7/10], Batch: 4810, Train Loss: 0.7115\n",
      "Epoch [7/10], Batch: 4820, Train Loss: 0.8925\n",
      "Epoch [7/10], Batch: 4830, Train Loss: 0.6768\n",
      "Epoch [7/10], Batch: 4840, Train Loss: 0.7518\n",
      "Epoch [7/10], Batch: 4850, Train Loss: 0.6485\n",
      "Epoch [7/10], Batch: 4860, Train Loss: 0.7899\n",
      "Epoch [7/10], Batch: 4870, Train Loss: 0.7269\n",
      "Epoch [7/10], Batch: 4880, Train Loss: 0.7497\n",
      "Epoch [7/10], Batch: 4890, Train Loss: 0.8150\n",
      "Epoch [7/10], Batch: 4900, Train Loss: 0.9483\n",
      "Epoch [7/10], Batch: 4910, Train Loss: 0.6883\n",
      "Epoch [7/10], Batch: 4920, Train Loss: 0.6880\n",
      "Epoch [7/10], Batch: 4930, Train Loss: 0.8013\n",
      "Epoch [7/10], Batch: 4940, Train Loss: 0.6883\n",
      "Epoch [7/10], Batch: 4950, Train Loss: 0.7656\n",
      "Epoch [7/10], Batch: 4960, Train Loss: 0.6558\n",
      "Epoch [7/10], Batch: 4970, Train Loss: 0.7771\n",
      "Epoch [7/10], Batch: 4980, Train Loss: 0.8550\n",
      "Epoch [7/10], Batch: 4990, Train Loss: 0.7396\n",
      "Epoch [7/10], Batch: 5000, Train Loss: 0.5887\n",
      "Epoch [7/10], Batch: 5010, Train Loss: 0.8445\n",
      "Epoch [7/10], Batch: 5020, Train Loss: 0.7637\n",
      "Epoch [7/10], Batch: 5030, Train Loss: 0.7677\n",
      "Epoch [7/10], Batch: 5040, Train Loss: 0.8922\n",
      "Epoch [7/10], Batch: 5050, Train Loss: 0.7695\n",
      "Epoch [7/10], Batch: 5060, Train Loss: 0.7562\n",
      "Epoch [7/10], Batch: 5070, Train Loss: 0.7199\n",
      "Epoch [7/10], Batch: 5080, Train Loss: 0.7206\n",
      "Epoch [7/10], Batch: 5090, Train Loss: 0.6473\n",
      "Epoch [7/10], Batch: 5100, Train Loss: 0.7431\n",
      "Epoch [7/10], Batch: 5110, Train Loss: 0.7726\n",
      "Epoch [7/10], Batch: 5120, Train Loss: 0.6387\n",
      "Epoch [7/10], Batch: 5130, Train Loss: 0.6490\n",
      "Epoch [7/10], Batch: 5140, Train Loss: 0.9132\n",
      "Epoch [7/10], Batch: 5150, Train Loss: 0.7350\n",
      "Epoch [7/10], Batch: 5160, Train Loss: 0.8305\n",
      "Epoch [7/10], Batch: 5170, Train Loss: 0.7974\n",
      "Epoch [7/10], Batch: 5180, Train Loss: 0.8195\n",
      "Epoch [7/10], Batch: 5190, Train Loss: 0.6232\n",
      "Epoch [7/10], Batch: 5200, Train Loss: 0.7053\n",
      "Epoch [7/10], Batch: 5210, Train Loss: 0.7321\n",
      "Epoch [7/10], Batch: 5220, Train Loss: 0.8536\n",
      "Epoch [7/10], Batch: 5230, Train Loss: 0.7093\n",
      "Epoch [7/10], Batch: 5240, Train Loss: 0.7995\n",
      "Epoch [7/10], Batch: 5250, Train Loss: 0.9068\n",
      "Epoch [7/10], Batch: 5260, Train Loss: 0.9277\n",
      "Epoch [7/10], Batch: 5270, Train Loss: 0.7687\n",
      "Epoch [7/10], Batch: 5280, Train Loss: 0.7184\n",
      "Epoch [7/10], Batch: 5290, Train Loss: 0.8480\n",
      "Epoch [7/10], Batch: 5300, Train Loss: 0.8498\n",
      "Epoch [7/10], Batch: 5310, Train Loss: 0.7300\n",
      "Epoch [7/10], Batch: 5320, Train Loss: 0.6978\n",
      "Epoch [7/10], Batch: 5330, Train Loss: 0.6987\n",
      "Epoch [7/10], Batch: 5340, Train Loss: 0.8616\n",
      "Epoch [7/10], Batch: 5350, Train Loss: 0.6768\n",
      "Epoch [7/10], Batch: 5360, Train Loss: 0.8127\n",
      "Epoch [7/10], Batch: 5370, Train Loss: 0.7456\n",
      "Epoch [7/10], Batch: 5380, Train Loss: 0.7242\n",
      "Epoch [7/10], Batch: 5390, Train Loss: 0.8347\n",
      "Epoch [7/10], Batch: 5400, Train Loss: 0.7413\n",
      "Epoch [7/10], Batch: 5410, Train Loss: 0.8711\n",
      "Epoch [7/10], Batch: 5420, Train Loss: 0.6660\n",
      "Epoch [7/10], Batch: 5430, Train Loss: 0.7013\n",
      "Epoch [7/10], Batch: 5440, Train Loss: 0.7587\n",
      "Epoch [7/10], Batch: 5450, Train Loss: 0.8015\n",
      "Epoch [7/10], Batch: 5460, Train Loss: 0.7277\n",
      "Epoch [7/10], Batch: 5470, Train Loss: 0.7283\n",
      "Epoch [7/10], Batch: 5480, Train Loss: 0.6238\n",
      "Epoch [7/10], Batch: 5490, Train Loss: 0.7158\n",
      "Epoch [7/10], Batch: 5500, Train Loss: 0.8331\n",
      "Epoch [7/10], Batch: 5510, Train Loss: 0.9278\n",
      "Epoch [7/10], Batch: 5520, Train Loss: 0.8030\n",
      "Epoch [7/10], Batch: 5530, Train Loss: 0.8363\n",
      "Epoch [7/10], Batch: 5540, Train Loss: 0.7839\n",
      "Epoch [7/10], Batch: 5550, Train Loss: 0.8528\n",
      "Epoch [7/10], Batch: 5560, Train Loss: 0.7163\n",
      "Epoch [7/10], Batch: 5570, Train Loss: 0.7458\n",
      "Epoch [7/10], Batch: 5580, Train Loss: 0.6818\n",
      "Epoch [7/10], Batch: 5590, Train Loss: 0.8645\n",
      "Epoch [7/10], Batch: 5600, Train Loss: 0.6059\n",
      "Epoch [7/10], Batch: 5610, Train Loss: 0.7530\n",
      "Epoch [7/10], Batch: 5620, Train Loss: 0.8945\n",
      "Epoch [7/10], Batch: 5630, Train Loss: 0.7724\n",
      "Epoch [7/10], Batch: 5640, Train Loss: 0.8095\n",
      "Epoch [7/10], Batch: 5650, Train Loss: 0.7189\n",
      "Epoch [7/10], Batch: 5660, Train Loss: 0.6161\n",
      "Epoch [7/10], Batch: 5670, Train Loss: 0.7729\n",
      "Epoch [7/10], Batch: 5680, Train Loss: 0.7400\n",
      "Epoch [7/10], Batch: 5690, Train Loss: 0.8180\n",
      "Epoch [7/10], Batch: 5700, Train Loss: 0.6279\n",
      "Epoch [7/10], Batch: 5710, Train Loss: 0.8850\n",
      "Epoch [7/10], Batch: 5720, Train Loss: 0.8502\n",
      "Epoch [7/10], Batch: 5730, Train Loss: 0.6822\n",
      "Epoch [7/10], Batch: 5740, Train Loss: 0.7480\n",
      "Epoch [7/10], Batch: 5750, Train Loss: 0.7530\n",
      "Epoch [7/10], Batch: 5760, Train Loss: 0.9745\n",
      "Epoch [7/10], Batch: 5770, Train Loss: 0.8268\n",
      "Epoch [7/10], Batch: 5780, Train Loss: 0.9094\n",
      "Epoch [7/10], Batch: 5790, Train Loss: 0.8817\n",
      "Epoch [7/10], Batch: 5800, Train Loss: 0.8068\n",
      "Epoch [7/10], Batch: 5810, Train Loss: 0.7492\n",
      "Epoch [7/10], Batch: 5820, Train Loss: 0.8973\n",
      "Epoch [7/10], Batch: 5830, Train Loss: 0.7863\n",
      "Epoch [7/10], Batch: 5840, Train Loss: 0.6966\n",
      "Epoch [7/10], Batch: 5850, Train Loss: 0.7742\n",
      "Epoch [7/10], Batch: 5860, Train Loss: 0.7077\n",
      "Epoch [7/10], Batch: 5870, Train Loss: 0.6703\n",
      "Epoch [7/10], Batch: 5880, Train Loss: 0.8341\n",
      "Epoch [7/10], Batch: 5890, Train Loss: 0.7548\n",
      "Epoch [7/10], Batch: 5900, Train Loss: 0.6875\n",
      "Epoch [7/10], Batch: 5910, Train Loss: 0.8127\n",
      "Epoch [7/10], Batch: 5920, Train Loss: 0.7652\n",
      "Epoch [7/10], Batch: 5930, Train Loss: 0.9787\n",
      "Epoch [7/10], Batch: 5940, Train Loss: 0.8656\n",
      "Epoch [7/10], Batch: 5950, Train Loss: 0.7184\n",
      "Epoch [7/10], Batch: 5960, Train Loss: 0.7984\n",
      "Epoch [7/10], Batch: 5970, Train Loss: 0.7607\n",
      "Epoch [7/10], Batch: 5980, Train Loss: 0.6949\n",
      "Epoch [7/10], Batch: 5990, Train Loss: 0.8137\n",
      "Epoch [7/10], Batch: 6000, Train Loss: 0.7244\n",
      "Epoch [7/10], Batch: 6010, Train Loss: 0.9339\n",
      "Epoch [7/10], Batch: 6020, Train Loss: 0.7774\n",
      "Epoch [7/10], Batch: 6030, Train Loss: 0.8895\n",
      "Epoch [7/10], Batch: 6040, Train Loss: 0.7551\n",
      "Epoch [7/10], Batch: 6050, Train Loss: 0.7772\n",
      "Epoch [7/10], Batch: 6060, Train Loss: 0.7851\n",
      "Epoch [7/10], Batch: 6070, Train Loss: 0.6536\n",
      "Epoch [7/10], Batch: 6080, Train Loss: 0.6775\n",
      "Epoch [7/10], Batch: 6090, Train Loss: 0.6749\n",
      "Epoch [7/10], Batch: 6100, Train Loss: 0.7346\n",
      "Epoch [7/10], Batch: 6110, Train Loss: 0.6762\n",
      "Epoch [7/10], Batch: 6120, Train Loss: 0.5938\n",
      "Epoch [7/10], Batch: 6130, Train Loss: 0.7292\n",
      "Epoch [7/10], Batch: 6140, Train Loss: 0.6866\n",
      "Epoch [7/10], Batch: 6150, Train Loss: 0.7294\n",
      "Epoch [7/10], Batch: 6160, Train Loss: 0.8330\n",
      "Epoch [7/10], Batch: 6170, Train Loss: 0.8080\n",
      "Epoch [7/10], Batch: 6180, Train Loss: 0.8448\n",
      "Epoch [7/10], Batch: 6190, Train Loss: 0.8144\n",
      "Epoch [7/10], Batch: 6200, Train Loss: 0.7820\n",
      "Epoch [7/10], Batch: 6210, Train Loss: 0.7187\n",
      "Epoch [7/10], Batch: 6220, Train Loss: 0.7637\n",
      "Epoch [7/10], Batch: 6230, Train Loss: 0.7745\n",
      "Epoch [7/10], Batch: 6240, Train Loss: 0.7909\n",
      "Epoch [7/10], Batch: 6250, Train Loss: 0.8605\n",
      "Epoch [7/10], Batch: 6260, Train Loss: 0.8365\n",
      "Epoch [7/10], Batch: 6270, Train Loss: 0.8082\n",
      "Epoch [7/10], Batch: 6280, Train Loss: 0.8516\n",
      "Epoch [7/10], Batch: 6290, Train Loss: 0.7147\n",
      "Epoch [7/10], Batch: 6300, Train Loss: 0.6264\n",
      "Epoch [7/10], Batch: 6310, Train Loss: 0.7581\n",
      "Epoch [7/10], Batch: 6320, Train Loss: 0.8130\n",
      "Epoch [7/10], Batch: 6330, Train Loss: 0.7010\n",
      "Epoch [7/10], Batch: 6340, Train Loss: 0.8139\n",
      "Epoch [7/10], Batch: 6350, Train Loss: 0.9106\n",
      "Epoch [7/10], Batch: 6360, Train Loss: 0.7917\n",
      "Epoch [7/10], Batch: 6370, Train Loss: 0.6534\n",
      "Epoch [7/10], Batch: 6380, Train Loss: 0.7385\n",
      "Epoch [7/10], Batch: 6390, Train Loss: 0.7017\n",
      "Epoch [7/10], Batch: 6400, Train Loss: 0.8004\n",
      "Epoch [7/10], Batch: 6410, Train Loss: 0.6602\n",
      "Epoch [7/10], Batch: 6420, Train Loss: 0.6859\n",
      "Epoch [7/10], Batch: 6430, Train Loss: 0.6946\n",
      "Epoch [7/10], Batch: 6440, Train Loss: 0.7546\n",
      "Epoch [7/10], Batch: 6450, Train Loss: 0.8429\n",
      "Epoch [7/10], Batch: 6460, Train Loss: 0.7520\n",
      "Epoch [7/10], Batch: 6470, Train Loss: 0.7608\n",
      "Epoch [7/10], Batch: 6480, Train Loss: 0.7714\n",
      "Epoch [7/10], Batch: 6490, Train Loss: 0.6837\n",
      "Epoch [7/10], Batch: 6500, Train Loss: 0.7576\n",
      "Epoch [7/10], Batch: 6510, Train Loss: 0.6820\n",
      "Epoch [7/10], Batch: 6520, Train Loss: 0.6692\n",
      "Epoch [7/10], Batch: 6530, Train Loss: 0.7273\n",
      "Epoch [7/10], Batch: 6540, Train Loss: 0.6641\n",
      "Epoch [7/10], Batch: 6550, Train Loss: 0.8079\n",
      "Epoch [7/10], Batch: 6560, Train Loss: 0.7130\n",
      "Epoch [7/10], Batch: 6570, Train Loss: 0.7370\n",
      "Epoch [7/10], Batch: 6580, Train Loss: 0.7135\n",
      "Epoch [7/10], Batch: 6590, Train Loss: 0.7807\n",
      "Epoch [7/10], Batch: 6600, Train Loss: 0.8175\n",
      "Epoch [7/10], Batch: 6610, Train Loss: 0.6818\n",
      "Epoch [7/10], Batch: 6620, Train Loss: 0.7250\n",
      "Epoch [7/10], Batch: 6630, Train Loss: 0.7853\n",
      "Epoch [7/10], Batch: 6640, Train Loss: 0.7924\n",
      "Epoch [7/10], Batch: 6650, Train Loss: 0.7163\n",
      "Epoch [7/10], Batch: 6660, Train Loss: 0.9245\n",
      "Epoch [7/10], Batch: 6670, Train Loss: 0.6642\n",
      "Epoch [7/10], Batch: 6680, Train Loss: 0.7645\n",
      "Epoch [7/10], Batch: 6690, Train Loss: 0.7879\n",
      "Epoch [7/10], Batch: 6700, Train Loss: 0.8477\n",
      "Epoch [7/10], Batch: 6710, Train Loss: 0.8662\n",
      "Epoch [7/10], Batch: 6720, Train Loss: 0.6747\n",
      "Epoch [7/10], Batch: 6730, Train Loss: 0.6506\n",
      "Epoch [7/10], Batch: 6740, Train Loss: 0.7056\n",
      "Epoch [7/10], Batch: 6750, Train Loss: 0.6675\n",
      "Epoch [7/10], Batch: 6760, Train Loss: 0.7785\n",
      "Epoch [8/10], Batch: 10, Train Loss: 0.7216\n",
      "Epoch [8/10], Batch: 20, Train Loss: 0.5363\n",
      "Epoch [8/10], Batch: 30, Train Loss: 0.5706\n",
      "Epoch [8/10], Batch: 40, Train Loss: 0.5809\n",
      "Epoch [8/10], Batch: 50, Train Loss: 0.8958\n",
      "Epoch [8/10], Batch: 60, Train Loss: 0.7512\n",
      "Epoch [8/10], Batch: 70, Train Loss: 0.7950\n",
      "Epoch [8/10], Batch: 80, Train Loss: 0.6753\n",
      "Epoch [8/10], Batch: 90, Train Loss: 0.7177\n",
      "Epoch [8/10], Batch: 100, Train Loss: 0.6859\n",
      "Epoch [8/10], Batch: 110, Train Loss: 0.8327\n",
      "Epoch [8/10], Batch: 120, Train Loss: 0.7383\n",
      "Epoch [8/10], Batch: 130, Train Loss: 0.6877\n",
      "Epoch [8/10], Batch: 140, Train Loss: 0.7764\n",
      "Epoch [8/10], Batch: 150, Train Loss: 0.6758\n",
      "Epoch [8/10], Batch: 160, Train Loss: 0.7178\n",
      "Epoch [8/10], Batch: 170, Train Loss: 0.7255\n",
      "Epoch [8/10], Batch: 180, Train Loss: 0.6041\n",
      "Epoch [8/10], Batch: 190, Train Loss: 0.6908\n",
      "Epoch [8/10], Batch: 200, Train Loss: 0.6058\n",
      "Epoch [8/10], Batch: 210, Train Loss: 0.7621\n",
      "Epoch [8/10], Batch: 220, Train Loss: 0.6704\n",
      "Epoch [8/10], Batch: 230, Train Loss: 0.7491\n",
      "Epoch [8/10], Batch: 240, Train Loss: 0.7106\n",
      "Epoch [8/10], Batch: 250, Train Loss: 0.7743\n",
      "Epoch [8/10], Batch: 260, Train Loss: 0.7685\n",
      "Epoch [8/10], Batch: 270, Train Loss: 0.7402\n",
      "Epoch [8/10], Batch: 280, Train Loss: 0.6241\n",
      "Epoch [8/10], Batch: 290, Train Loss: 0.8277\n",
      "Epoch [8/10], Batch: 300, Train Loss: 0.8238\n",
      "Epoch [8/10], Batch: 310, Train Loss: 0.7589\n",
      "Epoch [8/10], Batch: 320, Train Loss: 0.7266\n",
      "Epoch [8/10], Batch: 330, Train Loss: 0.7109\n",
      "Epoch [8/10], Batch: 340, Train Loss: 0.6889\n",
      "Epoch [8/10], Batch: 350, Train Loss: 0.7561\n",
      "Epoch [8/10], Batch: 360, Train Loss: 0.7821\n",
      "Epoch [8/10], Batch: 370, Train Loss: 0.7088\n",
      "Epoch [8/10], Batch: 380, Train Loss: 0.7765\n",
      "Epoch [8/10], Batch: 390, Train Loss: 0.7852\n",
      "Epoch [8/10], Batch: 400, Train Loss: 0.8226\n",
      "Epoch [8/10], Batch: 410, Train Loss: 0.8349\n",
      "Epoch [8/10], Batch: 420, Train Loss: 0.8244\n",
      "Epoch [8/10], Batch: 430, Train Loss: 0.7928\n",
      "Epoch [8/10], Batch: 440, Train Loss: 0.5955\n",
      "Epoch [8/10], Batch: 450, Train Loss: 0.6646\n",
      "Epoch [8/10], Batch: 460, Train Loss: 0.7765\n",
      "Epoch [8/10], Batch: 470, Train Loss: 0.7916\n",
      "Epoch [8/10], Batch: 480, Train Loss: 0.7891\n",
      "Epoch [8/10], Batch: 490, Train Loss: 0.6230\n",
      "Epoch [8/10], Batch: 500, Train Loss: 0.8798\n",
      "Epoch [8/10], Batch: 510, Train Loss: 0.7374\n",
      "Epoch [8/10], Batch: 520, Train Loss: 0.8059\n",
      "Epoch [8/10], Batch: 530, Train Loss: 0.7045\n",
      "Epoch [8/10], Batch: 540, Train Loss: 0.7373\n",
      "Epoch [8/10], Batch: 550, Train Loss: 0.8222\n",
      "Epoch [8/10], Batch: 560, Train Loss: 0.7228\n",
      "Epoch [8/10], Batch: 570, Train Loss: 0.8070\n",
      "Epoch [8/10], Batch: 580, Train Loss: 0.6756\n",
      "Epoch [8/10], Batch: 590, Train Loss: 0.7904\n",
      "Epoch [8/10], Batch: 600, Train Loss: 0.7333\n",
      "Epoch [8/10], Batch: 610, Train Loss: 0.7217\n",
      "Epoch [8/10], Batch: 620, Train Loss: 0.7278\n",
      "Epoch [8/10], Batch: 630, Train Loss: 0.7138\n",
      "Epoch [8/10], Batch: 640, Train Loss: 0.7962\n",
      "Epoch [8/10], Batch: 650, Train Loss: 0.7727\n",
      "Epoch [8/10], Batch: 660, Train Loss: 0.8219\n",
      "Epoch [8/10], Batch: 670, Train Loss: 0.8303\n",
      "Epoch [8/10], Batch: 680, Train Loss: 0.7048\n",
      "Epoch [8/10], Batch: 690, Train Loss: 0.7659\n",
      "Epoch [8/10], Batch: 700, Train Loss: 0.7102\n",
      "Epoch [8/10], Batch: 710, Train Loss: 0.6540\n",
      "Epoch [8/10], Batch: 720, Train Loss: 0.7451\n",
      "Epoch [8/10], Batch: 730, Train Loss: 0.6858\n",
      "Epoch [8/10], Batch: 740, Train Loss: 0.7075\n",
      "Epoch [8/10], Batch: 750, Train Loss: 0.5872\n",
      "Epoch [8/10], Batch: 760, Train Loss: 0.7738\n",
      "Epoch [8/10], Batch: 770, Train Loss: 0.6423\n",
      "Epoch [8/10], Batch: 780, Train Loss: 0.6444\n",
      "Epoch [8/10], Batch: 790, Train Loss: 0.8380\n",
      "Epoch [8/10], Batch: 800, Train Loss: 0.7556\n",
      "Epoch [8/10], Batch: 810, Train Loss: 0.6973\n",
      "Epoch [8/10], Batch: 820, Train Loss: 0.7870\n",
      "Epoch [8/10], Batch: 830, Train Loss: 0.8480\n",
      "Epoch [8/10], Batch: 840, Train Loss: 0.7843\n",
      "Epoch [8/10], Batch: 850, Train Loss: 0.7277\n",
      "Epoch [8/10], Batch: 860, Train Loss: 0.6489\n",
      "Epoch [8/10], Batch: 870, Train Loss: 0.7662\n",
      "Epoch [8/10], Batch: 880, Train Loss: 0.8193\n",
      "Epoch [8/10], Batch: 890, Train Loss: 0.7417\n",
      "Epoch [8/10], Batch: 900, Train Loss: 0.7470\n",
      "Epoch [8/10], Batch: 910, Train Loss: 0.7031\n",
      "Epoch [8/10], Batch: 920, Train Loss: 0.7944\n",
      "Epoch [8/10], Batch: 930, Train Loss: 0.7393\n",
      "Epoch [8/10], Batch: 940, Train Loss: 0.8170\n",
      "Epoch [8/10], Batch: 950, Train Loss: 0.7784\n",
      "Epoch [8/10], Batch: 960, Train Loss: 0.8848\n",
      "Epoch [8/10], Batch: 970, Train Loss: 0.5755\n",
      "Epoch [8/10], Batch: 980, Train Loss: 0.8127\n",
      "Epoch [8/10], Batch: 990, Train Loss: 0.6859\n",
      "Epoch [8/10], Batch: 1000, Train Loss: 0.7806\n",
      "Epoch [8/10], Batch: 1010, Train Loss: 0.7250\n",
      "Epoch [8/10], Batch: 1020, Train Loss: 0.6721\n",
      "Epoch [8/10], Batch: 1030, Train Loss: 0.7695\n",
      "Epoch [8/10], Batch: 1040, Train Loss: 0.8134\n",
      "Epoch [8/10], Batch: 1050, Train Loss: 0.6218\n",
      "Epoch [8/10], Batch: 1060, Train Loss: 0.8002\n",
      "Epoch [8/10], Batch: 1070, Train Loss: 0.8197\n",
      "Epoch [8/10], Batch: 1080, Train Loss: 0.6500\n",
      "Epoch [8/10], Batch: 1090, Train Loss: 0.6972\n",
      "Epoch [8/10], Batch: 1100, Train Loss: 0.6916\n",
      "Epoch [8/10], Batch: 1110, Train Loss: 0.8064\n",
      "Epoch [8/10], Batch: 1120, Train Loss: 0.6500\n",
      "Epoch [8/10], Batch: 1130, Train Loss: 0.8264\n",
      "Epoch [8/10], Batch: 1140, Train Loss: 0.7667\n",
      "Epoch [8/10], Batch: 1150, Train Loss: 0.7134\n",
      "Epoch [8/10], Batch: 1160, Train Loss: 0.7225\n",
      "Epoch [8/10], Batch: 1170, Train Loss: 0.7008\n",
      "Epoch [8/10], Batch: 1180, Train Loss: 0.9423\n",
      "Epoch [8/10], Batch: 1190, Train Loss: 0.7004\n",
      "Epoch [8/10], Batch: 1200, Train Loss: 0.7580\n",
      "Epoch [8/10], Batch: 1210, Train Loss: 0.7182\n",
      "Epoch [8/10], Batch: 1220, Train Loss: 0.8461\n",
      "Epoch [8/10], Batch: 1230, Train Loss: 0.8085\n",
      "Epoch [8/10], Batch: 1240, Train Loss: 0.7505\n",
      "Epoch [8/10], Batch: 1250, Train Loss: 0.7575\n",
      "Epoch [8/10], Batch: 1260, Train Loss: 0.8248\n",
      "Epoch [8/10], Batch: 1270, Train Loss: 0.7242\n",
      "Epoch [8/10], Batch: 1280, Train Loss: 0.6372\n",
      "Epoch [8/10], Batch: 1290, Train Loss: 0.6814\n",
      "Epoch [8/10], Batch: 1300, Train Loss: 0.6553\n",
      "Epoch [8/10], Batch: 1310, Train Loss: 0.7718\n",
      "Epoch [8/10], Batch: 1320, Train Loss: 0.6809\n",
      "Epoch [8/10], Batch: 1330, Train Loss: 0.8664\n",
      "Epoch [8/10], Batch: 1340, Train Loss: 0.7140\n",
      "Epoch [8/10], Batch: 1350, Train Loss: 0.7645\n",
      "Epoch [8/10], Batch: 1360, Train Loss: 0.5974\n",
      "Epoch [8/10], Batch: 1370, Train Loss: 0.8570\n",
      "Epoch [8/10], Batch: 1380, Train Loss: 0.6394\n",
      "Epoch [8/10], Batch: 1390, Train Loss: 0.7395\n",
      "Epoch [8/10], Batch: 1400, Train Loss: 0.7371\n",
      "Epoch [8/10], Batch: 1410, Train Loss: 0.9586\n",
      "Epoch [8/10], Batch: 1420, Train Loss: 0.7295\n",
      "Epoch [8/10], Batch: 1430, Train Loss: 0.9197\n",
      "Epoch [8/10], Batch: 1440, Train Loss: 0.7485\n",
      "Epoch [8/10], Batch: 1450, Train Loss: 0.7218\n",
      "Epoch [8/10], Batch: 1460, Train Loss: 0.8364\n",
      "Epoch [8/10], Batch: 1470, Train Loss: 0.7198\n",
      "Epoch [8/10], Batch: 1480, Train Loss: 0.9126\n",
      "Epoch [8/10], Batch: 1490, Train Loss: 0.7403\n",
      "Epoch [8/10], Batch: 1500, Train Loss: 0.8579\n",
      "Epoch [8/10], Batch: 1510, Train Loss: 0.7840\n",
      "Epoch [8/10], Batch: 1520, Train Loss: 0.7474\n",
      "Epoch [8/10], Batch: 1530, Train Loss: 0.6454\n",
      "Epoch [8/10], Batch: 1540, Train Loss: 0.6266\n",
      "Epoch [8/10], Batch: 1550, Train Loss: 0.7522\n",
      "Epoch [8/10], Batch: 1560, Train Loss: 0.7417\n",
      "Epoch [8/10], Batch: 1570, Train Loss: 0.7847\n",
      "Epoch [8/10], Batch: 1580, Train Loss: 0.7937\n",
      "Epoch [8/10], Batch: 1590, Train Loss: 0.6587\n",
      "Epoch [8/10], Batch: 1600, Train Loss: 0.7645\n",
      "Epoch [8/10], Batch: 1610, Train Loss: 0.8303\n",
      "Epoch [8/10], Batch: 1620, Train Loss: 0.7555\n",
      "Epoch [8/10], Batch: 1630, Train Loss: 0.8613\n",
      "Epoch [8/10], Batch: 1640, Train Loss: 0.6281\n",
      "Epoch [8/10], Batch: 1650, Train Loss: 0.8192\n",
      "Epoch [8/10], Batch: 1660, Train Loss: 0.6907\n",
      "Epoch [8/10], Batch: 1670, Train Loss: 0.6917\n",
      "Epoch [8/10], Batch: 1680, Train Loss: 0.6891\n",
      "Epoch [8/10], Batch: 1690, Train Loss: 0.8754\n",
      "Epoch [8/10], Batch: 1700, Train Loss: 0.7032\n",
      "Epoch [8/10], Batch: 1710, Train Loss: 0.7025\n",
      "Epoch [8/10], Batch: 1720, Train Loss: 0.8324\n",
      "Epoch [8/10], Batch: 1730, Train Loss: 0.7880\n",
      "Epoch [8/10], Batch: 1740, Train Loss: 0.7595\n",
      "Epoch [8/10], Batch: 1750, Train Loss: 0.7389\n",
      "Epoch [8/10], Batch: 1760, Train Loss: 0.7833\n",
      "Epoch [8/10], Batch: 1770, Train Loss: 0.7164\n",
      "Epoch [8/10], Batch: 1780, Train Loss: 0.7078\n",
      "Epoch [8/10], Batch: 1790, Train Loss: 0.7761\n",
      "Epoch [8/10], Batch: 1800, Train Loss: 0.8084\n",
      "Epoch [8/10], Batch: 1810, Train Loss: 0.6843\n",
      "Epoch [8/10], Batch: 1820, Train Loss: 0.7286\n",
      "Epoch [8/10], Batch: 1830, Train Loss: 0.8117\n",
      "Epoch [8/10], Batch: 1840, Train Loss: 0.8246\n",
      "Epoch [8/10], Batch: 1850, Train Loss: 0.8457\n",
      "Epoch [8/10], Batch: 1860, Train Loss: 0.7762\n",
      "Epoch [8/10], Batch: 1870, Train Loss: 0.7980\n",
      "Epoch [8/10], Batch: 1880, Train Loss: 0.8445\n",
      "Epoch [8/10], Batch: 1890, Train Loss: 0.8234\n",
      "Epoch [8/10], Batch: 1900, Train Loss: 0.6951\n",
      "Epoch [8/10], Batch: 1910, Train Loss: 0.5852\n",
      "Epoch [8/10], Batch: 1920, Train Loss: 0.7883\n",
      "Epoch [8/10], Batch: 1930, Train Loss: 0.8056\n",
      "Epoch [8/10], Batch: 1940, Train Loss: 0.7112\n",
      "Epoch [8/10], Batch: 1950, Train Loss: 0.8362\n",
      "Epoch [8/10], Batch: 1960, Train Loss: 0.6826\n",
      "Epoch [8/10], Batch: 1970, Train Loss: 0.7545\n",
      "Epoch [8/10], Batch: 1980, Train Loss: 0.6972\n",
      "Epoch [8/10], Batch: 1990, Train Loss: 0.6705\n",
      "Epoch [8/10], Batch: 2000, Train Loss: 0.7175\n",
      "Epoch [8/10], Batch: 2010, Train Loss: 0.7035\n",
      "Epoch [8/10], Batch: 2020, Train Loss: 0.6912\n",
      "Epoch [8/10], Batch: 2030, Train Loss: 0.6781\n",
      "Epoch [8/10], Batch: 2040, Train Loss: 0.6786\n",
      "Epoch [8/10], Batch: 2050, Train Loss: 0.7541\n",
      "Epoch [8/10], Batch: 2060, Train Loss: 0.6055\n",
      "Epoch [8/10], Batch: 2070, Train Loss: 0.7156\n",
      "Epoch [8/10], Batch: 2080, Train Loss: 0.6881\n",
      "Epoch [8/10], Batch: 2090, Train Loss: 0.6716\n",
      "Epoch [8/10], Batch: 2100, Train Loss: 0.7332\n",
      "Epoch [8/10], Batch: 2110, Train Loss: 0.9063\n",
      "Epoch [8/10], Batch: 2120, Train Loss: 0.6627\n",
      "Epoch [8/10], Batch: 2130, Train Loss: 0.8325\n",
      "Epoch [8/10], Batch: 2140, Train Loss: 0.8586\n",
      "Epoch [8/10], Batch: 2150, Train Loss: 0.9084\n",
      "Epoch [8/10], Batch: 2160, Train Loss: 0.7785\n",
      "Epoch [8/10], Batch: 2170, Train Loss: 0.7269\n",
      "Epoch [8/10], Batch: 2180, Train Loss: 0.6903\n",
      "Epoch [8/10], Batch: 2190, Train Loss: 0.7545\n",
      "Epoch [8/10], Batch: 2200, Train Loss: 0.7612\n",
      "Epoch [8/10], Batch: 2210, Train Loss: 0.7958\n",
      "Epoch [8/10], Batch: 2220, Train Loss: 0.7479\n",
      "Epoch [8/10], Batch: 2230, Train Loss: 0.8288\n",
      "Epoch [8/10], Batch: 2240, Train Loss: 0.8721\n",
      "Epoch [8/10], Batch: 2250, Train Loss: 0.7336\n",
      "Epoch [8/10], Batch: 2260, Train Loss: 0.7251\n",
      "Epoch [8/10], Batch: 2270, Train Loss: 0.7843\n",
      "Epoch [8/10], Batch: 2280, Train Loss: 0.7026\n",
      "Epoch [8/10], Batch: 2290, Train Loss: 0.7846\n",
      "Epoch [8/10], Batch: 2300, Train Loss: 0.7042\n",
      "Epoch [8/10], Batch: 2310, Train Loss: 0.7286\n",
      "Epoch [8/10], Batch: 2320, Train Loss: 0.8696\n",
      "Epoch [8/10], Batch: 2330, Train Loss: 0.7068\n",
      "Epoch [8/10], Batch: 2340, Train Loss: 0.8142\n",
      "Epoch [8/10], Batch: 2350, Train Loss: 0.7050\n",
      "Epoch [8/10], Batch: 2360, Train Loss: 0.7363\n",
      "Epoch [8/10], Batch: 2370, Train Loss: 0.7682\n",
      "Epoch [8/10], Batch: 2380, Train Loss: 0.8067\n",
      "Epoch [8/10], Batch: 2390, Train Loss: 0.6173\n",
      "Epoch [8/10], Batch: 2400, Train Loss: 0.7157\n",
      "Epoch [8/10], Batch: 2410, Train Loss: 0.7364\n",
      "Epoch [8/10], Batch: 2420, Train Loss: 0.7003\n",
      "Epoch [8/10], Batch: 2430, Train Loss: 0.7316\n",
      "Epoch [8/10], Batch: 2440, Train Loss: 0.7090\n",
      "Epoch [8/10], Batch: 2450, Train Loss: 0.7045\n",
      "Epoch [8/10], Batch: 2460, Train Loss: 0.7030\n",
      "Epoch [8/10], Batch: 2470, Train Loss: 0.7679\n",
      "Epoch [8/10], Batch: 2480, Train Loss: 0.6454\n",
      "Epoch [8/10], Batch: 2490, Train Loss: 0.8431\n",
      "Epoch [8/10], Batch: 2500, Train Loss: 0.8126\n",
      "Epoch [8/10], Batch: 2510, Train Loss: 0.7484\n",
      "Epoch [8/10], Batch: 2520, Train Loss: 0.7121\n",
      "Epoch [8/10], Batch: 2530, Train Loss: 0.6656\n",
      "Epoch [8/10], Batch: 2540, Train Loss: 0.8499\n",
      "Epoch [8/10], Batch: 2550, Train Loss: 0.6956\n",
      "Epoch [8/10], Batch: 2560, Train Loss: 0.7501\n",
      "Epoch [8/10], Batch: 2570, Train Loss: 0.5945\n",
      "Epoch [8/10], Batch: 2580, Train Loss: 0.7369\n",
      "Epoch [8/10], Batch: 2590, Train Loss: 0.7893\n",
      "Epoch [8/10], Batch: 2600, Train Loss: 0.6713\n",
      "Epoch [8/10], Batch: 2610, Train Loss: 0.7170\n",
      "Epoch [8/10], Batch: 2620, Train Loss: 0.6820\n",
      "Epoch [8/10], Batch: 2630, Train Loss: 0.6737\n",
      "Epoch [8/10], Batch: 2640, Train Loss: 0.7204\n",
      "Epoch [8/10], Batch: 2650, Train Loss: 0.7938\n",
      "Epoch [8/10], Batch: 2660, Train Loss: 0.7283\n",
      "Epoch [8/10], Batch: 2670, Train Loss: 0.6871\n",
      "Epoch [8/10], Batch: 2680, Train Loss: 0.8610\n",
      "Epoch [8/10], Batch: 2690, Train Loss: 0.6462\n",
      "Epoch [8/10], Batch: 2700, Train Loss: 0.7142\n",
      "Epoch [8/10], Batch: 2710, Train Loss: 0.7236\n",
      "Epoch [8/10], Batch: 2720, Train Loss: 0.7272\n",
      "Epoch [8/10], Batch: 2730, Train Loss: 0.8008\n",
      "Epoch [8/10], Batch: 2740, Train Loss: 0.8250\n",
      "Epoch [8/10], Batch: 2750, Train Loss: 0.8234\n",
      "Epoch [8/10], Batch: 2760, Train Loss: 0.7089\n",
      "Epoch [8/10], Batch: 2770, Train Loss: 0.7176\n",
      "Epoch [8/10], Batch: 2780, Train Loss: 0.7591\n",
      "Epoch [8/10], Batch: 2790, Train Loss: 0.5496\n",
      "Epoch [8/10], Batch: 2800, Train Loss: 0.7601\n",
      "Epoch [8/10], Batch: 2810, Train Loss: 0.7396\n",
      "Epoch [8/10], Batch: 2820, Train Loss: 0.7012\n",
      "Epoch [8/10], Batch: 2830, Train Loss: 0.9420\n",
      "Epoch [8/10], Batch: 2840, Train Loss: 0.7330\n",
      "Epoch [8/10], Batch: 2850, Train Loss: 0.7124\n",
      "Epoch [8/10], Batch: 2860, Train Loss: 0.7267\n",
      "Epoch [8/10], Batch: 2870, Train Loss: 0.6781\n",
      "Epoch [8/10], Batch: 2880, Train Loss: 0.9755\n",
      "Epoch [8/10], Batch: 2890, Train Loss: 0.8504\n",
      "Epoch [8/10], Batch: 2900, Train Loss: 0.8368\n",
      "Epoch [8/10], Batch: 2910, Train Loss: 0.8230\n",
      "Epoch [8/10], Batch: 2920, Train Loss: 0.7687\n",
      "Epoch [8/10], Batch: 2930, Train Loss: 0.7591\n",
      "Epoch [8/10], Batch: 2940, Train Loss: 0.8715\n",
      "Epoch [8/10], Batch: 2950, Train Loss: 0.6662\n",
      "Epoch [8/10], Batch: 2960, Train Loss: 0.8003\n",
      "Epoch [8/10], Batch: 2970, Train Loss: 0.7857\n",
      "Epoch [8/10], Batch: 2980, Train Loss: 0.6356\n",
      "Epoch [8/10], Batch: 2990, Train Loss: 0.6153\n",
      "Epoch [8/10], Batch: 3000, Train Loss: 0.6271\n",
      "Epoch [8/10], Batch: 3010, Train Loss: 0.8534\n",
      "Epoch [8/10], Batch: 3020, Train Loss: 0.8042\n",
      "Epoch [8/10], Batch: 3030, Train Loss: 0.6560\n",
      "Epoch [8/10], Batch: 3040, Train Loss: 0.6422\n",
      "Epoch [8/10], Batch: 3050, Train Loss: 0.6496\n",
      "Epoch [8/10], Batch: 3060, Train Loss: 0.7105\n",
      "Epoch [8/10], Batch: 3070, Train Loss: 0.8495\n",
      "Epoch [8/10], Batch: 3080, Train Loss: 0.8671\n",
      "Epoch [8/10], Batch: 3090, Train Loss: 0.8404\n",
      "Epoch [8/10], Batch: 3100, Train Loss: 0.7920\n",
      "Epoch [8/10], Batch: 3110, Train Loss: 0.7759\n",
      "Epoch [8/10], Batch: 3120, Train Loss: 0.7201\n",
      "Epoch [8/10], Batch: 3130, Train Loss: 0.8459\n",
      "Epoch [8/10], Batch: 3140, Train Loss: 0.7662\n",
      "Epoch [8/10], Batch: 3150, Train Loss: 0.6850\n",
      "Epoch [8/10], Batch: 3160, Train Loss: 0.8257\n",
      "Epoch [8/10], Batch: 3170, Train Loss: 0.6668\n",
      "Epoch [8/10], Batch: 3180, Train Loss: 0.8559\n",
      "Epoch [8/10], Batch: 3190, Train Loss: 0.5268\n",
      "Epoch [8/10], Batch: 3200, Train Loss: 0.9260\n",
      "Epoch [8/10], Batch: 3210, Train Loss: 0.7406\n",
      "Epoch [8/10], Batch: 3220, Train Loss: 0.8319\n",
      "Epoch [8/10], Batch: 3230, Train Loss: 0.7227\n",
      "Epoch [8/10], Batch: 3240, Train Loss: 0.7384\n",
      "Epoch [8/10], Batch: 3250, Train Loss: 0.7574\n",
      "Epoch [8/10], Batch: 3260, Train Loss: 0.7186\n",
      "Epoch [8/10], Batch: 3270, Train Loss: 0.8728\n",
      "Epoch [8/10], Batch: 3280, Train Loss: 0.8248\n",
      "Epoch [8/10], Batch: 3290, Train Loss: 0.7908\n",
      "Epoch [8/10], Batch: 3300, Train Loss: 0.6982\n",
      "Epoch [8/10], Batch: 3310, Train Loss: 0.8007\n",
      "Epoch [8/10], Batch: 3320, Train Loss: 0.8130\n",
      "Epoch [8/10], Batch: 3330, Train Loss: 0.6321\n",
      "Epoch [8/10], Batch: 3340, Train Loss: 0.8078\n",
      "Epoch [8/10], Batch: 3350, Train Loss: 0.7279\n",
      "Epoch [8/10], Batch: 3360, Train Loss: 0.6129\n",
      "Epoch [8/10], Batch: 3370, Train Loss: 0.6646\n",
      "Epoch [8/10], Batch: 3380, Train Loss: 0.7850\n",
      "Epoch [8/10], Batch: 3390, Train Loss: 0.6724\n",
      "Epoch [8/10], Batch: 3400, Train Loss: 0.8215\n",
      "Epoch [8/10], Batch: 3410, Train Loss: 0.7733\n",
      "Epoch [8/10], Batch: 3420, Train Loss: 0.7198\n",
      "Epoch [8/10], Batch: 3430, Train Loss: 0.8964\n",
      "Epoch [8/10], Batch: 3440, Train Loss: 0.7724\n",
      "Epoch [8/10], Batch: 3450, Train Loss: 0.6718\n",
      "Epoch [8/10], Batch: 3460, Train Loss: 0.7640\n",
      "Epoch [8/10], Batch: 3470, Train Loss: 0.6840\n",
      "Epoch [8/10], Batch: 3480, Train Loss: 0.6912\n",
      "Epoch [8/10], Batch: 3490, Train Loss: 0.8020\n",
      "Epoch [8/10], Batch: 3500, Train Loss: 0.7343\n",
      "Epoch [8/10], Batch: 3510, Train Loss: 0.7886\n",
      "Epoch [8/10], Batch: 3520, Train Loss: 0.8167\n",
      "Epoch [8/10], Batch: 3530, Train Loss: 0.7290\n",
      "Epoch [8/10], Batch: 3540, Train Loss: 0.6762\n",
      "Epoch [8/10], Batch: 3550, Train Loss: 0.7111\n",
      "Epoch [8/10], Batch: 3560, Train Loss: 0.8568\n",
      "Epoch [8/10], Batch: 3570, Train Loss: 0.8097\n",
      "Epoch [8/10], Batch: 3580, Train Loss: 0.7153\n",
      "Epoch [8/10], Batch: 3590, Train Loss: 0.7850\n",
      "Epoch [8/10], Batch: 3600, Train Loss: 0.8010\n",
      "Epoch [8/10], Batch: 3610, Train Loss: 0.6251\n",
      "Epoch [8/10], Batch: 3620, Train Loss: 0.8296\n",
      "Epoch [8/10], Batch: 3630, Train Loss: 0.8177\n",
      "Epoch [8/10], Batch: 3640, Train Loss: 0.6812\n",
      "Epoch [8/10], Batch: 3650, Train Loss: 0.6691\n",
      "Epoch [8/10], Batch: 3660, Train Loss: 0.7025\n",
      "Epoch [8/10], Batch: 3670, Train Loss: 0.7374\n",
      "Epoch [8/10], Batch: 3680, Train Loss: 0.8608\n",
      "Epoch [8/10], Batch: 3690, Train Loss: 0.7170\n",
      "Epoch [8/10], Batch: 3700, Train Loss: 0.8332\n",
      "Epoch [8/10], Batch: 3710, Train Loss: 0.8548\n",
      "Epoch [8/10], Batch: 3720, Train Loss: 0.6995\n",
      "Epoch [8/10], Batch: 3730, Train Loss: 0.6125\n",
      "Epoch [8/10], Batch: 3740, Train Loss: 0.7109\n",
      "Epoch [8/10], Batch: 3750, Train Loss: 0.6428\n",
      "Epoch [8/10], Batch: 3760, Train Loss: 0.6881\n",
      "Epoch [8/10], Batch: 3770, Train Loss: 0.7630\n",
      "Epoch [8/10], Batch: 3780, Train Loss: 0.7950\n",
      "Epoch [8/10], Batch: 3790, Train Loss: 0.7235\n",
      "Epoch [8/10], Batch: 3800, Train Loss: 0.6533\n",
      "Epoch [8/10], Batch: 3810, Train Loss: 0.6516\n",
      "Epoch [8/10], Batch: 3820, Train Loss: 0.7573\n",
      "Epoch [8/10], Batch: 3830, Train Loss: 0.6463\n",
      "Epoch [8/10], Batch: 3840, Train Loss: 0.7791\n",
      "Epoch [8/10], Batch: 3850, Train Loss: 0.6990\n",
      "Epoch [8/10], Batch: 3860, Train Loss: 0.7688\n",
      "Epoch [8/10], Batch: 3870, Train Loss: 0.7295\n",
      "Epoch [8/10], Batch: 3880, Train Loss: 0.7895\n",
      "Epoch [8/10], Batch: 3890, Train Loss: 0.8545\n",
      "Epoch [8/10], Batch: 3900, Train Loss: 0.7673\n",
      "Epoch [8/10], Batch: 3910, Train Loss: 0.8810\n",
      "Epoch [8/10], Batch: 3920, Train Loss: 0.7242\n",
      "Epoch [8/10], Batch: 3930, Train Loss: 0.8249\n",
      "Epoch [8/10], Batch: 3940, Train Loss: 0.7711\n",
      "Epoch [8/10], Batch: 3950, Train Loss: 0.8159\n",
      "Epoch [8/10], Batch: 3960, Train Loss: 0.9602\n",
      "Epoch [8/10], Batch: 3970, Train Loss: 0.7073\n",
      "Epoch [8/10], Batch: 3980, Train Loss: 0.7367\n",
      "Epoch [8/10], Batch: 3990, Train Loss: 0.6227\n",
      "Epoch [8/10], Batch: 4000, Train Loss: 0.7728\n",
      "Epoch [8/10], Batch: 4010, Train Loss: 0.7594\n",
      "Epoch [8/10], Batch: 4020, Train Loss: 0.7320\n",
      "Epoch [8/10], Batch: 4030, Train Loss: 0.8451\n",
      "Epoch [8/10], Batch: 4040, Train Loss: 0.6823\n",
      "Epoch [8/10], Batch: 4050, Train Loss: 0.6568\n",
      "Epoch [8/10], Batch: 4060, Train Loss: 0.6720\n",
      "Epoch [8/10], Batch: 4070, Train Loss: 0.7366\n",
      "Epoch [8/10], Batch: 4080, Train Loss: 0.8212\n",
      "Epoch [8/10], Batch: 4090, Train Loss: 0.7537\n",
      "Epoch [8/10], Batch: 4100, Train Loss: 0.7718\n",
      "Epoch [8/10], Batch: 4110, Train Loss: 0.8179\n",
      "Epoch [8/10], Batch: 4120, Train Loss: 0.7396\n",
      "Epoch [8/10], Batch: 4130, Train Loss: 0.7612\n",
      "Epoch [8/10], Batch: 4140, Train Loss: 0.8595\n",
      "Epoch [8/10], Batch: 4150, Train Loss: 0.6216\n",
      "Epoch [8/10], Batch: 4160, Train Loss: 0.6713\n",
      "Epoch [8/10], Batch: 4170, Train Loss: 0.6816\n",
      "Epoch [8/10], Batch: 4180, Train Loss: 0.5915\n",
      "Epoch [8/10], Batch: 4190, Train Loss: 0.7981\n",
      "Epoch [8/10], Batch: 4200, Train Loss: 0.6421\n",
      "Epoch [8/10], Batch: 4210, Train Loss: 0.7642\n",
      "Epoch [8/10], Batch: 4220, Train Loss: 0.7119\n",
      "Epoch [8/10], Batch: 4230, Train Loss: 0.7982\n",
      "Epoch [8/10], Batch: 4240, Train Loss: 0.6465\n",
      "Epoch [8/10], Batch: 4250, Train Loss: 0.7300\n",
      "Epoch [8/10], Batch: 4260, Train Loss: 0.7556\n",
      "Epoch [8/10], Batch: 4270, Train Loss: 0.8259\n",
      "Epoch [8/10], Batch: 4280, Train Loss: 0.7515\n",
      "Epoch [8/10], Batch: 4290, Train Loss: 0.8452\n",
      "Epoch [8/10], Batch: 4300, Train Loss: 0.7095\n",
      "Epoch [8/10], Batch: 4310, Train Loss: 0.7662\n",
      "Epoch [8/10], Batch: 4320, Train Loss: 0.7629\n",
      "Epoch [8/10], Batch: 4330, Train Loss: 0.7896\n",
      "Epoch [8/10], Batch: 4340, Train Loss: 0.8134\n",
      "Epoch [8/10], Batch: 4350, Train Loss: 0.6023\n",
      "Epoch [8/10], Batch: 4360, Train Loss: 0.6214\n",
      "Epoch [8/10], Batch: 4370, Train Loss: 0.9607\n",
      "Epoch [8/10], Batch: 4380, Train Loss: 0.7147\n",
      "Epoch [8/10], Batch: 4390, Train Loss: 0.8361\n",
      "Epoch [8/10], Batch: 4400, Train Loss: 0.7013\n",
      "Epoch [8/10], Batch: 4410, Train Loss: 0.6995\n",
      "Epoch [8/10], Batch: 4420, Train Loss: 0.9529\n",
      "Epoch [8/10], Batch: 4430, Train Loss: 0.7885\n",
      "Epoch [8/10], Batch: 4440, Train Loss: 0.8544\n",
      "Epoch [8/10], Batch: 4450, Train Loss: 0.7071\n",
      "Epoch [8/10], Batch: 4460, Train Loss: 0.7600\n",
      "Epoch [8/10], Batch: 4470, Train Loss: 0.6816\n",
      "Epoch [8/10], Batch: 4480, Train Loss: 0.7717\n",
      "Epoch [8/10], Batch: 4490, Train Loss: 0.7522\n",
      "Epoch [8/10], Batch: 4500, Train Loss: 0.7957\n",
      "Epoch [8/10], Batch: 4510, Train Loss: 0.7383\n",
      "Epoch [8/10], Batch: 4520, Train Loss: 0.6726\n",
      "Epoch [8/10], Batch: 4530, Train Loss: 0.6363\n",
      "Epoch [8/10], Batch: 4540, Train Loss: 0.7622\n",
      "Epoch [8/10], Batch: 4550, Train Loss: 0.6634\n",
      "Epoch [8/10], Batch: 4560, Train Loss: 0.8404\n",
      "Epoch [8/10], Batch: 4570, Train Loss: 0.6607\n",
      "Epoch [8/10], Batch: 4580, Train Loss: 0.7869\n",
      "Epoch [8/10], Batch: 4590, Train Loss: 0.6232\n",
      "Epoch [8/10], Batch: 4600, Train Loss: 0.6477\n",
      "Epoch [8/10], Batch: 4610, Train Loss: 0.6930\n",
      "Epoch [8/10], Batch: 4620, Train Loss: 0.7141\n",
      "Epoch [8/10], Batch: 4630, Train Loss: 0.6609\n",
      "Epoch [8/10], Batch: 4640, Train Loss: 0.7635\n",
      "Epoch [8/10], Batch: 4650, Train Loss: 0.7924\n",
      "Epoch [8/10], Batch: 4660, Train Loss: 0.7904\n",
      "Epoch [8/10], Batch: 4670, Train Loss: 0.8337\n",
      "Epoch [8/10], Batch: 4680, Train Loss: 0.6985\n",
      "Epoch [8/10], Batch: 4690, Train Loss: 0.8393\n",
      "Epoch [8/10], Batch: 4700, Train Loss: 0.8223\n",
      "Epoch [8/10], Batch: 4710, Train Loss: 0.6429\n",
      "Epoch [8/10], Batch: 4720, Train Loss: 0.6871\n",
      "Epoch [8/10], Batch: 4730, Train Loss: 0.8396\n",
      "Epoch [8/10], Batch: 4740, Train Loss: 0.6198\n",
      "Epoch [8/10], Batch: 4750, Train Loss: 0.6084\n",
      "Epoch [8/10], Batch: 4760, Train Loss: 0.6784\n",
      "Epoch [8/10], Batch: 4770, Train Loss: 0.7101\n",
      "Epoch [8/10], Batch: 4780, Train Loss: 0.7362\n",
      "Epoch [8/10], Batch: 4790, Train Loss: 0.7979\n",
      "Epoch [8/10], Batch: 4800, Train Loss: 0.7750\n",
      "Epoch [8/10], Batch: 4810, Train Loss: 0.6572\n",
      "Epoch [8/10], Batch: 4820, Train Loss: 0.8780\n",
      "Epoch [8/10], Batch: 4830, Train Loss: 0.6425\n",
      "Epoch [8/10], Batch: 4840, Train Loss: 0.7736\n",
      "Epoch [8/10], Batch: 4850, Train Loss: 0.6668\n",
      "Epoch [8/10], Batch: 4860, Train Loss: 0.7866\n",
      "Epoch [8/10], Batch: 4870, Train Loss: 0.7051\n",
      "Epoch [8/10], Batch: 4880, Train Loss: 0.7400\n",
      "Epoch [8/10], Batch: 4890, Train Loss: 0.7985\n",
      "Epoch [8/10], Batch: 4900, Train Loss: 0.9333\n",
      "Epoch [8/10], Batch: 4910, Train Loss: 0.6595\n",
      "Epoch [8/10], Batch: 4920, Train Loss: 0.6646\n",
      "Epoch [8/10], Batch: 4930, Train Loss: 0.8132\n",
      "Epoch [8/10], Batch: 4940, Train Loss: 0.6707\n",
      "Epoch [8/10], Batch: 4950, Train Loss: 0.7135\n",
      "Epoch [8/10], Batch: 4960, Train Loss: 0.6523\n",
      "Epoch [8/10], Batch: 4970, Train Loss: 0.7663\n",
      "Epoch [8/10], Batch: 4980, Train Loss: 0.8228\n",
      "Epoch [8/10], Batch: 4990, Train Loss: 0.7540\n",
      "Epoch [8/10], Batch: 5000, Train Loss: 0.5899\n",
      "Epoch [8/10], Batch: 5010, Train Loss: 0.8690\n",
      "Epoch [8/10], Batch: 5020, Train Loss: 0.7370\n",
      "Epoch [8/10], Batch: 5030, Train Loss: 0.7428\n",
      "Epoch [8/10], Batch: 5040, Train Loss: 0.9161\n",
      "Epoch [8/10], Batch: 5050, Train Loss: 0.7493\n",
      "Epoch [8/10], Batch: 5060, Train Loss: 0.7409\n",
      "Epoch [8/10], Batch: 5070, Train Loss: 0.7404\n",
      "Epoch [8/10], Batch: 5080, Train Loss: 0.6969\n",
      "Epoch [8/10], Batch: 5090, Train Loss: 0.6387\n",
      "Epoch [8/10], Batch: 5100, Train Loss: 0.7251\n",
      "Epoch [8/10], Batch: 5110, Train Loss: 0.8001\n",
      "Epoch [8/10], Batch: 5120, Train Loss: 0.6190\n",
      "Epoch [8/10], Batch: 5130, Train Loss: 0.6164\n",
      "Epoch [8/10], Batch: 5140, Train Loss: 0.9272\n",
      "Epoch [8/10], Batch: 5150, Train Loss: 0.7464\n",
      "Epoch [8/10], Batch: 5160, Train Loss: 0.8624\n",
      "Epoch [8/10], Batch: 5170, Train Loss: 0.7727\n",
      "Epoch [8/10], Batch: 5180, Train Loss: 0.8516\n",
      "Epoch [8/10], Batch: 5190, Train Loss: 0.6307\n",
      "Epoch [8/10], Batch: 5200, Train Loss: 0.6816\n",
      "Epoch [8/10], Batch: 5210, Train Loss: 0.7181\n",
      "Epoch [8/10], Batch: 5220, Train Loss: 0.8315\n",
      "Epoch [8/10], Batch: 5230, Train Loss: 0.6833\n",
      "Epoch [8/10], Batch: 5240, Train Loss: 0.7764\n",
      "Epoch [8/10], Batch: 5250, Train Loss: 0.8590\n",
      "Epoch [8/10], Batch: 5260, Train Loss: 0.8874\n",
      "Epoch [8/10], Batch: 5270, Train Loss: 0.7809\n",
      "Epoch [8/10], Batch: 5280, Train Loss: 0.6657\n",
      "Epoch [8/10], Batch: 5290, Train Loss: 0.8193\n",
      "Epoch [8/10], Batch: 5300, Train Loss: 0.8247\n",
      "Epoch [8/10], Batch: 5310, Train Loss: 0.7538\n",
      "Epoch [8/10], Batch: 5320, Train Loss: 0.6882\n",
      "Epoch [8/10], Batch: 5330, Train Loss: 0.7118\n",
      "Epoch [8/10], Batch: 5340, Train Loss: 0.8343\n",
      "Epoch [8/10], Batch: 5350, Train Loss: 0.6892\n",
      "Epoch [8/10], Batch: 5360, Train Loss: 0.8000\n",
      "Epoch [8/10], Batch: 5370, Train Loss: 0.7099\n",
      "Epoch [8/10], Batch: 5380, Train Loss: 0.7082\n",
      "Epoch [8/10], Batch: 5390, Train Loss: 0.8089\n",
      "Epoch [8/10], Batch: 5400, Train Loss: 0.8267\n",
      "Epoch [8/10], Batch: 5410, Train Loss: 0.8634\n",
      "Epoch [8/10], Batch: 5420, Train Loss: 0.6315\n",
      "Epoch [8/10], Batch: 5430, Train Loss: 0.6922\n",
      "Epoch [8/10], Batch: 5440, Train Loss: 0.7558\n",
      "Epoch [8/10], Batch: 5450, Train Loss: 0.8046\n",
      "Epoch [8/10], Batch: 5460, Train Loss: 0.7229\n",
      "Epoch [8/10], Batch: 5470, Train Loss: 0.7117\n",
      "Epoch [8/10], Batch: 5480, Train Loss: 0.5911\n",
      "Epoch [8/10], Batch: 5490, Train Loss: 0.7064\n",
      "Epoch [8/10], Batch: 5500, Train Loss: 0.7838\n",
      "Epoch [8/10], Batch: 5510, Train Loss: 0.9143\n",
      "Epoch [8/10], Batch: 5520, Train Loss: 0.7683\n",
      "Epoch [8/10], Batch: 5530, Train Loss: 0.7857\n",
      "Epoch [8/10], Batch: 5540, Train Loss: 0.8089\n",
      "Epoch [8/10], Batch: 5550, Train Loss: 0.8249\n",
      "Epoch [8/10], Batch: 5560, Train Loss: 0.7156\n",
      "Epoch [8/10], Batch: 5570, Train Loss: 0.7230\n",
      "Epoch [8/10], Batch: 5580, Train Loss: 0.6838\n",
      "Epoch [8/10], Batch: 5590, Train Loss: 0.8126\n",
      "Epoch [8/10], Batch: 5600, Train Loss: 0.5981\n",
      "Epoch [8/10], Batch: 5610, Train Loss: 0.7556\n",
      "Epoch [8/10], Batch: 5620, Train Loss: 0.8853\n",
      "Epoch [8/10], Batch: 5630, Train Loss: 0.7603\n",
      "Epoch [8/10], Batch: 5640, Train Loss: 0.7964\n",
      "Epoch [8/10], Batch: 5650, Train Loss: 0.7200\n",
      "Epoch [8/10], Batch: 5660, Train Loss: 0.5895\n",
      "Epoch [8/10], Batch: 5670, Train Loss: 0.7812\n",
      "Epoch [8/10], Batch: 5680, Train Loss: 0.7340\n",
      "Epoch [8/10], Batch: 5690, Train Loss: 0.8078\n",
      "Epoch [8/10], Batch: 5700, Train Loss: 0.6197\n",
      "Epoch [8/10], Batch: 5710, Train Loss: 0.8663\n",
      "Epoch [8/10], Batch: 5720, Train Loss: 0.8480\n",
      "Epoch [8/10], Batch: 5730, Train Loss: 0.6949\n",
      "Epoch [8/10], Batch: 5740, Train Loss: 0.7204\n",
      "Epoch [8/10], Batch: 5750, Train Loss: 0.7697\n",
      "Epoch [8/10], Batch: 5760, Train Loss: 0.9563\n",
      "Epoch [8/10], Batch: 5770, Train Loss: 0.7643\n",
      "Epoch [8/10], Batch: 5780, Train Loss: 0.8890\n",
      "Epoch [8/10], Batch: 5790, Train Loss: 0.8999\n",
      "Epoch [8/10], Batch: 5800, Train Loss: 0.8038\n",
      "Epoch [8/10], Batch: 5810, Train Loss: 0.7125\n",
      "Epoch [8/10], Batch: 5820, Train Loss: 0.8546\n",
      "Epoch [8/10], Batch: 5830, Train Loss: 0.7803\n",
      "Epoch [8/10], Batch: 5840, Train Loss: 0.6429\n",
      "Epoch [8/10], Batch: 5850, Train Loss: 0.6838\n",
      "Epoch [8/10], Batch: 5860, Train Loss: 0.6915\n",
      "Epoch [8/10], Batch: 5870, Train Loss: 0.6673\n",
      "Epoch [8/10], Batch: 5880, Train Loss: 0.8141\n",
      "Epoch [8/10], Batch: 5890, Train Loss: 0.7260\n",
      "Epoch [8/10], Batch: 5900, Train Loss: 0.6884\n",
      "Epoch [8/10], Batch: 5910, Train Loss: 0.7805\n",
      "Epoch [8/10], Batch: 5920, Train Loss: 0.7603\n",
      "Epoch [8/10], Batch: 5930, Train Loss: 0.9736\n",
      "Epoch [8/10], Batch: 5940, Train Loss: 0.8134\n",
      "Epoch [8/10], Batch: 5950, Train Loss: 0.7106\n",
      "Epoch [8/10], Batch: 5960, Train Loss: 0.7494\n",
      "Epoch [8/10], Batch: 5970, Train Loss: 0.7777\n",
      "Epoch [8/10], Batch: 5980, Train Loss: 0.7172\n",
      "Epoch [8/10], Batch: 5990, Train Loss: 0.8199\n",
      "Epoch [8/10], Batch: 6000, Train Loss: 0.7280\n",
      "Epoch [8/10], Batch: 6010, Train Loss: 0.9440\n",
      "Epoch [8/10], Batch: 6020, Train Loss: 0.7702\n",
      "Epoch [8/10], Batch: 6030, Train Loss: 0.8601\n",
      "Epoch [8/10], Batch: 6040, Train Loss: 0.7477\n",
      "Epoch [8/10], Batch: 6050, Train Loss: 0.7377\n",
      "Epoch [8/10], Batch: 6060, Train Loss: 0.8137\n",
      "Epoch [8/10], Batch: 6070, Train Loss: 0.6611\n",
      "Epoch [8/10], Batch: 6080, Train Loss: 0.6795\n",
      "Epoch [8/10], Batch: 6090, Train Loss: 0.6557\n",
      "Epoch [8/10], Batch: 6100, Train Loss: 0.7230\n",
      "Epoch [8/10], Batch: 6110, Train Loss: 0.6663\n",
      "Epoch [8/10], Batch: 6120, Train Loss: 0.6147\n",
      "Epoch [8/10], Batch: 6130, Train Loss: 0.7257\n",
      "Epoch [8/10], Batch: 6140, Train Loss: 0.6715\n",
      "Epoch [8/10], Batch: 6150, Train Loss: 0.6874\n",
      "Epoch [8/10], Batch: 6160, Train Loss: 0.8414\n",
      "Epoch [8/10], Batch: 6170, Train Loss: 0.7814\n",
      "Epoch [8/10], Batch: 6180, Train Loss: 0.8065\n",
      "Epoch [8/10], Batch: 6190, Train Loss: 0.7778\n",
      "Epoch [8/10], Batch: 6200, Train Loss: 0.7816\n",
      "Epoch [8/10], Batch: 6210, Train Loss: 0.7284\n",
      "Epoch [8/10], Batch: 6220, Train Loss: 0.7341\n",
      "Epoch [8/10], Batch: 6230, Train Loss: 0.7611\n",
      "Epoch [8/10], Batch: 6240, Train Loss: 0.8242\n",
      "Epoch [8/10], Batch: 6250, Train Loss: 0.8418\n",
      "Epoch [8/10], Batch: 6260, Train Loss: 0.7742\n",
      "Epoch [8/10], Batch: 6270, Train Loss: 0.7486\n",
      "Epoch [8/10], Batch: 6280, Train Loss: 0.8568\n",
      "Epoch [8/10], Batch: 6290, Train Loss: 0.6855\n",
      "Epoch [8/10], Batch: 6300, Train Loss: 0.6409\n",
      "Epoch [8/10], Batch: 6310, Train Loss: 0.7969\n",
      "Epoch [8/10], Batch: 6320, Train Loss: 0.8692\n",
      "Epoch [8/10], Batch: 6330, Train Loss: 0.6961\n",
      "Epoch [8/10], Batch: 6340, Train Loss: 0.7948\n",
      "Epoch [8/10], Batch: 6350, Train Loss: 0.9148\n",
      "Epoch [8/10], Batch: 6360, Train Loss: 0.7961\n",
      "Epoch [8/10], Batch: 6370, Train Loss: 0.6542\n",
      "Epoch [8/10], Batch: 6380, Train Loss: 0.7091\n",
      "Epoch [8/10], Batch: 6390, Train Loss: 0.6809\n",
      "Epoch [8/10], Batch: 6400, Train Loss: 0.7922\n",
      "Epoch [8/10], Batch: 6410, Train Loss: 0.6949\n",
      "Epoch [8/10], Batch: 6420, Train Loss: 0.6932\n",
      "Epoch [8/10], Batch: 6430, Train Loss: 0.6705\n",
      "Epoch [8/10], Batch: 6440, Train Loss: 0.7343\n",
      "Epoch [8/10], Batch: 6450, Train Loss: 0.8120\n",
      "Epoch [8/10], Batch: 6460, Train Loss: 0.7443\n",
      "Epoch [8/10], Batch: 6470, Train Loss: 0.7254\n",
      "Epoch [8/10], Batch: 6480, Train Loss: 0.7493\n",
      "Epoch [8/10], Batch: 6490, Train Loss: 0.7144\n",
      "Epoch [8/10], Batch: 6500, Train Loss: 0.7237\n",
      "Epoch [8/10], Batch: 6510, Train Loss: 0.6957\n",
      "Epoch [8/10], Batch: 6520, Train Loss: 0.6271\n",
      "Epoch [8/10], Batch: 6530, Train Loss: 0.7409\n",
      "Epoch [8/10], Batch: 6540, Train Loss: 0.6486\n",
      "Epoch [8/10], Batch: 6550, Train Loss: 0.8099\n",
      "Epoch [8/10], Batch: 6560, Train Loss: 0.7073\n",
      "Epoch [8/10], Batch: 6570, Train Loss: 0.7108\n",
      "Epoch [8/10], Batch: 6580, Train Loss: 0.7056\n",
      "Epoch [8/10], Batch: 6590, Train Loss: 0.7671\n",
      "Epoch [8/10], Batch: 6600, Train Loss: 0.8298\n",
      "Epoch [8/10], Batch: 6610, Train Loss: 0.6776\n",
      "Epoch [8/10], Batch: 6620, Train Loss: 0.7075\n",
      "Epoch [8/10], Batch: 6630, Train Loss: 0.7689\n",
      "Epoch [8/10], Batch: 6640, Train Loss: 0.8158\n",
      "Epoch [8/10], Batch: 6650, Train Loss: 0.7662\n",
      "Epoch [8/10], Batch: 6660, Train Loss: 0.9274\n",
      "Epoch [8/10], Batch: 6670, Train Loss: 0.6240\n",
      "Epoch [8/10], Batch: 6680, Train Loss: 0.7638\n",
      "Epoch [8/10], Batch: 6690, Train Loss: 0.7720\n",
      "Epoch [8/10], Batch: 6700, Train Loss: 0.7941\n",
      "Epoch [8/10], Batch: 6710, Train Loss: 0.8422\n",
      "Epoch [8/10], Batch: 6720, Train Loss: 0.7057\n",
      "Epoch [8/10], Batch: 6730, Train Loss: 0.5965\n",
      "Epoch [8/10], Batch: 6740, Train Loss: 0.6979\n",
      "Epoch [8/10], Batch: 6750, Train Loss: 0.6550\n",
      "Epoch [8/10], Batch: 6760, Train Loss: 0.7434\n",
      "Epoch [9/10], Batch: 10, Train Loss: 0.6958\n",
      "Epoch [9/10], Batch: 20, Train Loss: 0.5164\n",
      "Epoch [9/10], Batch: 30, Train Loss: 0.5786\n",
      "Epoch [9/10], Batch: 40, Train Loss: 0.5677\n",
      "Epoch [9/10], Batch: 50, Train Loss: 0.8816\n",
      "Epoch [9/10], Batch: 60, Train Loss: 0.7154\n",
      "Epoch [9/10], Batch: 70, Train Loss: 0.7890\n",
      "Epoch [9/10], Batch: 80, Train Loss: 0.6592\n",
      "Epoch [9/10], Batch: 90, Train Loss: 0.7211\n",
      "Epoch [9/10], Batch: 100, Train Loss: 0.6738\n",
      "Epoch [9/10], Batch: 110, Train Loss: 0.8134\n",
      "Epoch [9/10], Batch: 120, Train Loss: 0.7429\n",
      "Epoch [9/10], Batch: 130, Train Loss: 0.6955\n",
      "Epoch [9/10], Batch: 140, Train Loss: 0.7642\n",
      "Epoch [9/10], Batch: 150, Train Loss: 0.6520\n",
      "Epoch [9/10], Batch: 160, Train Loss: 0.7185\n",
      "Epoch [9/10], Batch: 170, Train Loss: 0.7235\n",
      "Epoch [9/10], Batch: 180, Train Loss: 0.5918\n",
      "Epoch [9/10], Batch: 190, Train Loss: 0.7242\n",
      "Epoch [9/10], Batch: 200, Train Loss: 0.5697\n",
      "Epoch [9/10], Batch: 210, Train Loss: 0.7884\n",
      "Epoch [9/10], Batch: 220, Train Loss: 0.6620\n",
      "Epoch [9/10], Batch: 230, Train Loss: 0.7322\n",
      "Epoch [9/10], Batch: 240, Train Loss: 0.6939\n",
      "Epoch [9/10], Batch: 250, Train Loss: 0.7391\n",
      "Epoch [9/10], Batch: 260, Train Loss: 0.7418\n",
      "Epoch [9/10], Batch: 270, Train Loss: 0.7396\n",
      "Epoch [9/10], Batch: 280, Train Loss: 0.6344\n",
      "Epoch [9/10], Batch: 290, Train Loss: 0.8197\n",
      "Epoch [9/10], Batch: 300, Train Loss: 0.8323\n",
      "Epoch [9/10], Batch: 310, Train Loss: 0.7324\n",
      "Epoch [9/10], Batch: 320, Train Loss: 0.7111\n",
      "Epoch [9/10], Batch: 330, Train Loss: 0.7119\n",
      "Epoch [9/10], Batch: 340, Train Loss: 0.6983\n",
      "Epoch [9/10], Batch: 350, Train Loss: 0.7453\n",
      "Epoch [9/10], Batch: 360, Train Loss: 0.7731\n",
      "Epoch [9/10], Batch: 370, Train Loss: 0.6932\n",
      "Epoch [9/10], Batch: 380, Train Loss: 0.7707\n",
      "Epoch [9/10], Batch: 390, Train Loss: 0.7618\n",
      "Epoch [9/10], Batch: 400, Train Loss: 0.8087\n",
      "Epoch [9/10], Batch: 410, Train Loss: 0.8066\n",
      "Epoch [9/10], Batch: 420, Train Loss: 0.8340\n",
      "Epoch [9/10], Batch: 430, Train Loss: 0.7892\n",
      "Epoch [9/10], Batch: 440, Train Loss: 0.6145\n",
      "Epoch [9/10], Batch: 450, Train Loss: 0.6880\n",
      "Epoch [9/10], Batch: 460, Train Loss: 0.7373\n",
      "Epoch [9/10], Batch: 470, Train Loss: 0.8000\n",
      "Epoch [9/10], Batch: 480, Train Loss: 0.8005\n",
      "Epoch [9/10], Batch: 490, Train Loss: 0.6414\n",
      "Epoch [9/10], Batch: 500, Train Loss: 0.8508\n",
      "Epoch [9/10], Batch: 510, Train Loss: 0.7768\n",
      "Epoch [9/10], Batch: 520, Train Loss: 0.8232\n",
      "Epoch [9/10], Batch: 530, Train Loss: 0.6201\n",
      "Epoch [9/10], Batch: 540, Train Loss: 0.7190\n",
      "Epoch [9/10], Batch: 550, Train Loss: 0.8354\n",
      "Epoch [9/10], Batch: 560, Train Loss: 0.6741\n",
      "Epoch [9/10], Batch: 570, Train Loss: 0.7972\n",
      "Epoch [9/10], Batch: 580, Train Loss: 0.6766\n",
      "Epoch [9/10], Batch: 590, Train Loss: 0.7765\n",
      "Epoch [9/10], Batch: 600, Train Loss: 0.7360\n",
      "Epoch [9/10], Batch: 610, Train Loss: 0.6837\n",
      "Epoch [9/10], Batch: 620, Train Loss: 0.7786\n",
      "Epoch [9/10], Batch: 630, Train Loss: 0.6932\n",
      "Epoch [9/10], Batch: 640, Train Loss: 0.8001\n",
      "Epoch [9/10], Batch: 650, Train Loss: 0.7477\n",
      "Epoch [9/10], Batch: 660, Train Loss: 0.7898\n",
      "Epoch [9/10], Batch: 670, Train Loss: 0.8110\n",
      "Epoch [9/10], Batch: 680, Train Loss: 0.6402\n",
      "Epoch [9/10], Batch: 690, Train Loss: 0.6387\n",
      "Epoch [9/10], Batch: 700, Train Loss: 0.7057\n",
      "Epoch [9/10], Batch: 710, Train Loss: 0.6541\n",
      "Epoch [9/10], Batch: 720, Train Loss: 0.7252\n",
      "Epoch [9/10], Batch: 730, Train Loss: 0.6221\n",
      "Epoch [9/10], Batch: 740, Train Loss: 0.7074\n",
      "Epoch [9/10], Batch: 750, Train Loss: 0.5768\n",
      "Epoch [9/10], Batch: 760, Train Loss: 0.7602\n",
      "Epoch [9/10], Batch: 770, Train Loss: 0.6653\n",
      "Epoch [9/10], Batch: 780, Train Loss: 0.5943\n",
      "Epoch [9/10], Batch: 790, Train Loss: 0.8566\n",
      "Epoch [9/10], Batch: 800, Train Loss: 0.7411\n",
      "Epoch [9/10], Batch: 810, Train Loss: 0.6682\n",
      "Epoch [9/10], Batch: 820, Train Loss: 0.7704\n",
      "Epoch [9/10], Batch: 830, Train Loss: 0.8498\n",
      "Epoch [9/10], Batch: 840, Train Loss: 0.7480\n",
      "Epoch [9/10], Batch: 850, Train Loss: 0.7115\n",
      "Epoch [9/10], Batch: 860, Train Loss: 0.6058\n",
      "Epoch [9/10], Batch: 870, Train Loss: 0.7580\n",
      "Epoch [9/10], Batch: 880, Train Loss: 0.8268\n",
      "Epoch [9/10], Batch: 890, Train Loss: 0.7280\n",
      "Epoch [9/10], Batch: 900, Train Loss: 0.7229\n",
      "Epoch [9/10], Batch: 910, Train Loss: 0.6863\n",
      "Epoch [9/10], Batch: 920, Train Loss: 0.7615\n",
      "Epoch [9/10], Batch: 930, Train Loss: 0.7303\n",
      "Epoch [9/10], Batch: 940, Train Loss: 0.8338\n",
      "Epoch [9/10], Batch: 950, Train Loss: 0.7761\n",
      "Epoch [9/10], Batch: 960, Train Loss: 0.8299\n",
      "Epoch [9/10], Batch: 970, Train Loss: 0.5910\n",
      "Epoch [9/10], Batch: 980, Train Loss: 0.8198\n",
      "Epoch [9/10], Batch: 990, Train Loss: 0.6823\n",
      "Epoch [9/10], Batch: 1000, Train Loss: 0.7588\n",
      "Epoch [9/10], Batch: 1010, Train Loss: 0.7398\n",
      "Epoch [9/10], Batch: 1020, Train Loss: 0.6408\n",
      "Epoch [9/10], Batch: 1030, Train Loss: 0.7401\n",
      "Epoch [9/10], Batch: 1040, Train Loss: 0.7762\n",
      "Epoch [9/10], Batch: 1050, Train Loss: 0.6379\n",
      "Epoch [9/10], Batch: 1060, Train Loss: 0.8098\n",
      "Epoch [9/10], Batch: 1070, Train Loss: 0.8245\n",
      "Epoch [9/10], Batch: 1080, Train Loss: 0.6616\n",
      "Epoch [9/10], Batch: 1090, Train Loss: 0.7213\n",
      "Epoch [9/10], Batch: 1100, Train Loss: 0.6976\n",
      "Epoch [9/10], Batch: 1110, Train Loss: 0.8282\n",
      "Epoch [9/10], Batch: 1120, Train Loss: 0.6857\n",
      "Epoch [9/10], Batch: 1130, Train Loss: 0.7898\n",
      "Epoch [9/10], Batch: 1140, Train Loss: 0.7603\n",
      "Epoch [9/10], Batch: 1150, Train Loss: 0.6757\n",
      "Epoch [9/10], Batch: 1160, Train Loss: 0.6794\n",
      "Epoch [9/10], Batch: 1170, Train Loss: 0.6668\n",
      "Epoch [9/10], Batch: 1180, Train Loss: 0.8738\n",
      "Epoch [9/10], Batch: 1190, Train Loss: 0.7424\n",
      "Epoch [9/10], Batch: 1200, Train Loss: 0.7183\n",
      "Epoch [9/10], Batch: 1210, Train Loss: 0.7250\n",
      "Epoch [9/10], Batch: 1220, Train Loss: 0.8607\n",
      "Epoch [9/10], Batch: 1230, Train Loss: 0.7664\n",
      "Epoch [9/10], Batch: 1240, Train Loss: 0.7242\n",
      "Epoch [9/10], Batch: 1250, Train Loss: 0.7295\n",
      "Epoch [9/10], Batch: 1260, Train Loss: 0.7955\n",
      "Epoch [9/10], Batch: 1270, Train Loss: 0.6961\n",
      "Epoch [9/10], Batch: 1280, Train Loss: 0.6142\n",
      "Epoch [9/10], Batch: 1290, Train Loss: 0.6824\n",
      "Epoch [9/10], Batch: 1300, Train Loss: 0.6434\n",
      "Epoch [9/10], Batch: 1310, Train Loss: 0.7997\n",
      "Epoch [9/10], Batch: 1320, Train Loss: 0.6793\n",
      "Epoch [9/10], Batch: 1330, Train Loss: 0.8620\n",
      "Epoch [9/10], Batch: 1340, Train Loss: 0.7216\n",
      "Epoch [9/10], Batch: 1350, Train Loss: 0.7617\n",
      "Epoch [9/10], Batch: 1360, Train Loss: 0.5966\n",
      "Epoch [9/10], Batch: 1370, Train Loss: 0.8543\n",
      "Epoch [9/10], Batch: 1380, Train Loss: 0.6350\n",
      "Epoch [9/10], Batch: 1390, Train Loss: 0.7398\n",
      "Epoch [9/10], Batch: 1400, Train Loss: 0.7246\n",
      "Epoch [9/10], Batch: 1410, Train Loss: 0.9620\n",
      "Epoch [9/10], Batch: 1420, Train Loss: 0.7201\n",
      "Epoch [9/10], Batch: 1430, Train Loss: 0.9051\n",
      "Epoch [9/10], Batch: 1440, Train Loss: 0.7493\n",
      "Epoch [9/10], Batch: 1450, Train Loss: 0.7190\n",
      "Epoch [9/10], Batch: 1460, Train Loss: 0.8127\n",
      "Epoch [9/10], Batch: 1470, Train Loss: 0.7364\n",
      "Epoch [9/10], Batch: 1480, Train Loss: 0.8903\n",
      "Epoch [9/10], Batch: 1490, Train Loss: 0.7547\n",
      "Epoch [9/10], Batch: 1500, Train Loss: 0.8231\n",
      "Epoch [9/10], Batch: 1510, Train Loss: 0.6802\n",
      "Epoch [9/10], Batch: 1520, Train Loss: 0.6903\n",
      "Epoch [9/10], Batch: 1530, Train Loss: 0.6271\n",
      "Epoch [9/10], Batch: 1540, Train Loss: 0.6186\n",
      "Epoch [9/10], Batch: 1550, Train Loss: 0.7818\n",
      "Epoch [9/10], Batch: 1560, Train Loss: 0.7315\n",
      "Epoch [9/10], Batch: 1570, Train Loss: 0.8129\n",
      "Epoch [9/10], Batch: 1580, Train Loss: 0.7587\n",
      "Epoch [9/10], Batch: 1590, Train Loss: 0.6473\n",
      "Epoch [9/10], Batch: 1600, Train Loss: 0.7813\n",
      "Epoch [9/10], Batch: 1610, Train Loss: 0.8565\n",
      "Epoch [9/10], Batch: 1620, Train Loss: 0.7633\n",
      "Epoch [9/10], Batch: 1630, Train Loss: 0.8061\n",
      "Epoch [9/10], Batch: 1640, Train Loss: 0.6116\n",
      "Epoch [9/10], Batch: 1650, Train Loss: 0.8291\n",
      "Epoch [9/10], Batch: 1660, Train Loss: 0.6655\n",
      "Epoch [9/10], Batch: 1670, Train Loss: 0.6859\n",
      "Epoch [9/10], Batch: 1680, Train Loss: 0.7243\n",
      "Epoch [9/10], Batch: 1690, Train Loss: 0.8696\n",
      "Epoch [9/10], Batch: 1700, Train Loss: 0.6993\n",
      "Epoch [9/10], Batch: 1710, Train Loss: 0.7222\n",
      "Epoch [9/10], Batch: 1720, Train Loss: 0.8162\n",
      "Epoch [9/10], Batch: 1730, Train Loss: 0.7755\n",
      "Epoch [9/10], Batch: 1740, Train Loss: 0.7491\n",
      "Epoch [9/10], Batch: 1750, Train Loss: 0.7620\n",
      "Epoch [9/10], Batch: 1760, Train Loss: 0.7475\n",
      "Epoch [9/10], Batch: 1770, Train Loss: 0.7183\n",
      "Epoch [9/10], Batch: 1780, Train Loss: 0.6924\n",
      "Epoch [9/10], Batch: 1790, Train Loss: 0.8085\n",
      "Epoch [9/10], Batch: 1800, Train Loss: 0.8030\n",
      "Epoch [9/10], Batch: 1810, Train Loss: 0.6682\n",
      "Epoch [9/10], Batch: 1820, Train Loss: 0.7416\n",
      "Epoch [9/10], Batch: 1830, Train Loss: 0.7827\n",
      "Epoch [9/10], Batch: 1840, Train Loss: 0.8130\n",
      "Epoch [9/10], Batch: 1850, Train Loss: 0.8334\n",
      "Epoch [9/10], Batch: 1860, Train Loss: 0.7442\n",
      "Epoch [9/10], Batch: 1870, Train Loss: 0.8248\n",
      "Epoch [9/10], Batch: 1880, Train Loss: 0.7770\n",
      "Epoch [9/10], Batch: 1890, Train Loss: 0.7792\n",
      "Epoch [9/10], Batch: 1900, Train Loss: 0.6891\n",
      "Epoch [9/10], Batch: 1910, Train Loss: 0.5679\n",
      "Epoch [9/10], Batch: 1920, Train Loss: 0.7260\n",
      "Epoch [9/10], Batch: 1930, Train Loss: 0.7769\n",
      "Epoch [9/10], Batch: 1940, Train Loss: 0.6776\n",
      "Epoch [9/10], Batch: 1950, Train Loss: 0.8455\n",
      "Epoch [9/10], Batch: 1960, Train Loss: 0.6901\n",
      "Epoch [9/10], Batch: 1970, Train Loss: 0.7342\n",
      "Epoch [9/10], Batch: 1980, Train Loss: 0.6691\n",
      "Epoch [9/10], Batch: 1990, Train Loss: 0.6372\n",
      "Epoch [9/10], Batch: 2000, Train Loss: 0.6937\n",
      "Epoch [9/10], Batch: 2010, Train Loss: 0.6901\n",
      "Epoch [9/10], Batch: 2020, Train Loss: 0.6651\n",
      "Epoch [9/10], Batch: 2030, Train Loss: 0.6442\n",
      "Epoch [9/10], Batch: 2040, Train Loss: 0.6776\n",
      "Epoch [9/10], Batch: 2050, Train Loss: 0.7273\n",
      "Epoch [9/10], Batch: 2060, Train Loss: 0.6257\n",
      "Epoch [9/10], Batch: 2070, Train Loss: 0.7254\n",
      "Epoch [9/10], Batch: 2080, Train Loss: 0.6743\n",
      "Epoch [9/10], Batch: 2090, Train Loss: 0.6701\n",
      "Epoch [9/10], Batch: 2100, Train Loss: 0.7519\n",
      "Epoch [9/10], Batch: 2110, Train Loss: 0.8786\n",
      "Epoch [9/10], Batch: 2120, Train Loss: 0.6764\n",
      "Epoch [9/10], Batch: 2130, Train Loss: 0.8271\n",
      "Epoch [9/10], Batch: 2140, Train Loss: 0.8395\n",
      "Epoch [9/10], Batch: 2150, Train Loss: 0.8916\n",
      "Epoch [9/10], Batch: 2160, Train Loss: 0.7419\n",
      "Epoch [9/10], Batch: 2170, Train Loss: 0.7319\n",
      "Epoch [9/10], Batch: 2180, Train Loss: 0.6949\n",
      "Epoch [9/10], Batch: 2190, Train Loss: 0.7302\n",
      "Epoch [9/10], Batch: 2200, Train Loss: 0.7136\n",
      "Epoch [9/10], Batch: 2210, Train Loss: 0.7801\n",
      "Epoch [9/10], Batch: 2220, Train Loss: 0.7423\n",
      "Epoch [9/10], Batch: 2230, Train Loss: 0.8424\n",
      "Epoch [9/10], Batch: 2240, Train Loss: 0.8764\n",
      "Epoch [9/10], Batch: 2250, Train Loss: 0.7132\n",
      "Epoch [9/10], Batch: 2260, Train Loss: 0.6988\n",
      "Epoch [9/10], Batch: 2270, Train Loss: 0.7349\n",
      "Epoch [9/10], Batch: 2280, Train Loss: 0.7013\n",
      "Epoch [9/10], Batch: 2290, Train Loss: 0.7845\n",
      "Epoch [9/10], Batch: 2300, Train Loss: 0.6625\n",
      "Epoch [9/10], Batch: 2310, Train Loss: 0.7162\n",
      "Epoch [9/10], Batch: 2320, Train Loss: 0.9001\n",
      "Epoch [9/10], Batch: 2330, Train Loss: 0.6783\n",
      "Epoch [9/10], Batch: 2340, Train Loss: 0.8039\n",
      "Epoch [9/10], Batch: 2350, Train Loss: 0.7280\n",
      "Epoch [9/10], Batch: 2360, Train Loss: 0.7287\n",
      "Epoch [9/10], Batch: 2370, Train Loss: 0.7266\n",
      "Epoch [9/10], Batch: 2380, Train Loss: 0.8121\n",
      "Epoch [9/10], Batch: 2390, Train Loss: 0.6281\n",
      "Epoch [9/10], Batch: 2400, Train Loss: 0.7182\n",
      "Epoch [9/10], Batch: 2410, Train Loss: 0.7234\n",
      "Epoch [9/10], Batch: 2420, Train Loss: 0.7180\n",
      "Epoch [9/10], Batch: 2430, Train Loss: 0.7057\n",
      "Epoch [9/10], Batch: 2440, Train Loss: 0.6559\n",
      "Epoch [9/10], Batch: 2450, Train Loss: 0.7138\n",
      "Epoch [9/10], Batch: 2460, Train Loss: 0.7237\n",
      "Epoch [9/10], Batch: 2470, Train Loss: 0.7441\n",
      "Epoch [9/10], Batch: 2480, Train Loss: 0.6400\n",
      "Epoch [9/10], Batch: 2490, Train Loss: 0.8536\n",
      "Epoch [9/10], Batch: 2500, Train Loss: 0.7791\n",
      "Epoch [9/10], Batch: 2510, Train Loss: 0.6870\n",
      "Epoch [9/10], Batch: 2520, Train Loss: 0.7016\n",
      "Epoch [9/10], Batch: 2530, Train Loss: 0.6489\n",
      "Epoch [9/10], Batch: 2540, Train Loss: 0.8655\n",
      "Epoch [9/10], Batch: 2550, Train Loss: 0.6883\n",
      "Epoch [9/10], Batch: 2560, Train Loss: 0.7441\n",
      "Epoch [9/10], Batch: 2570, Train Loss: 0.5906\n",
      "Epoch [9/10], Batch: 2580, Train Loss: 0.6543\n",
      "Epoch [9/10], Batch: 2590, Train Loss: 0.7847\n",
      "Epoch [9/10], Batch: 2600, Train Loss: 0.6796\n",
      "Epoch [9/10], Batch: 2610, Train Loss: 0.7056\n",
      "Epoch [9/10], Batch: 2620, Train Loss: 0.6543\n",
      "Epoch [9/10], Batch: 2630, Train Loss: 0.6496\n",
      "Epoch [9/10], Batch: 2640, Train Loss: 0.7319\n",
      "Epoch [9/10], Batch: 2650, Train Loss: 0.7413\n",
      "Epoch [9/10], Batch: 2660, Train Loss: 0.7393\n",
      "Epoch [9/10], Batch: 2670, Train Loss: 0.7149\n",
      "Epoch [9/10], Batch: 2680, Train Loss: 0.8435\n",
      "Epoch [9/10], Batch: 2690, Train Loss: 0.6239\n",
      "Epoch [9/10], Batch: 2700, Train Loss: 0.7026\n",
      "Epoch [9/10], Batch: 2710, Train Loss: 0.7426\n",
      "Epoch [9/10], Batch: 2720, Train Loss: 0.7368\n",
      "Epoch [9/10], Batch: 2730, Train Loss: 0.7959\n",
      "Epoch [9/10], Batch: 2740, Train Loss: 0.7731\n",
      "Epoch [9/10], Batch: 2750, Train Loss: 0.7706\n",
      "Epoch [9/10], Batch: 2760, Train Loss: 0.7028\n",
      "Epoch [9/10], Batch: 2770, Train Loss: 0.7583\n",
      "Epoch [9/10], Batch: 2780, Train Loss: 0.7876\n",
      "Epoch [9/10], Batch: 2790, Train Loss: 0.5247\n",
      "Epoch [9/10], Batch: 2800, Train Loss: 0.7369\n",
      "Epoch [9/10], Batch: 2810, Train Loss: 0.7705\n",
      "Epoch [9/10], Batch: 2820, Train Loss: 0.6753\n",
      "Epoch [9/10], Batch: 2830, Train Loss: 0.8742\n",
      "Epoch [9/10], Batch: 2840, Train Loss: 0.7179\n",
      "Epoch [9/10], Batch: 2850, Train Loss: 0.7336\n",
      "Epoch [9/10], Batch: 2860, Train Loss: 0.7509\n",
      "Epoch [9/10], Batch: 2870, Train Loss: 0.6536\n",
      "Epoch [9/10], Batch: 2880, Train Loss: 0.9739\n",
      "Epoch [9/10], Batch: 2890, Train Loss: 0.8527\n",
      "Epoch [9/10], Batch: 2900, Train Loss: 0.8337\n",
      "Epoch [9/10], Batch: 2910, Train Loss: 0.8052\n",
      "Epoch [9/10], Batch: 2920, Train Loss: 0.7692\n",
      "Epoch [9/10], Batch: 2930, Train Loss: 0.7494\n",
      "Epoch [9/10], Batch: 2940, Train Loss: 0.8255\n",
      "Epoch [9/10], Batch: 2950, Train Loss: 0.6758\n",
      "Epoch [9/10], Batch: 2960, Train Loss: 0.7750\n",
      "Epoch [9/10], Batch: 2970, Train Loss: 0.7855\n",
      "Epoch [9/10], Batch: 2980, Train Loss: 0.6432\n",
      "Epoch [9/10], Batch: 2990, Train Loss: 0.6149\n",
      "Epoch [9/10], Batch: 3000, Train Loss: 0.6097\n",
      "Epoch [9/10], Batch: 3010, Train Loss: 0.8611\n",
      "Epoch [9/10], Batch: 3020, Train Loss: 0.8080\n",
      "Epoch [9/10], Batch: 3030, Train Loss: 0.6655\n",
      "Epoch [9/10], Batch: 3040, Train Loss: 0.6653\n",
      "Epoch [9/10], Batch: 3050, Train Loss: 0.6604\n",
      "Epoch [9/10], Batch: 3060, Train Loss: 0.7135\n",
      "Epoch [9/10], Batch: 3070, Train Loss: 0.9071\n",
      "Epoch [9/10], Batch: 3080, Train Loss: 0.8833\n",
      "Epoch [9/10], Batch: 3090, Train Loss: 0.8596\n",
      "Epoch [9/10], Batch: 3100, Train Loss: 0.8163\n",
      "Epoch [9/10], Batch: 3110, Train Loss: 0.7624\n",
      "Epoch [9/10], Batch: 3120, Train Loss: 0.7467\n",
      "Epoch [9/10], Batch: 3130, Train Loss: 0.8311\n",
      "Epoch [9/10], Batch: 3140, Train Loss: 0.7622\n",
      "Epoch [9/10], Batch: 3150, Train Loss: 0.6655\n",
      "Epoch [9/10], Batch: 3160, Train Loss: 0.8400\n",
      "Epoch [9/10], Batch: 3170, Train Loss: 0.6892\n",
      "Epoch [9/10], Batch: 3180, Train Loss: 0.8425\n",
      "Epoch [9/10], Batch: 3190, Train Loss: 0.5099\n",
      "Epoch [9/10], Batch: 3200, Train Loss: 0.9466\n",
      "Epoch [9/10], Batch: 3210, Train Loss: 0.7154\n",
      "Epoch [9/10], Batch: 3220, Train Loss: 0.8031\n",
      "Epoch [9/10], Batch: 3230, Train Loss: 0.7009\n",
      "Epoch [9/10], Batch: 3240, Train Loss: 0.7471\n",
      "Epoch [9/10], Batch: 3250, Train Loss: 0.7564\n",
      "Epoch [9/10], Batch: 3260, Train Loss: 0.7492\n",
      "Epoch [9/10], Batch: 3270, Train Loss: 0.8391\n",
      "Epoch [9/10], Batch: 3280, Train Loss: 0.8119\n",
      "Epoch [9/10], Batch: 3290, Train Loss: 0.7399\n",
      "Epoch [9/10], Batch: 3300, Train Loss: 0.6555\n",
      "Epoch [9/10], Batch: 3310, Train Loss: 0.8137\n",
      "Epoch [9/10], Batch: 3320, Train Loss: 0.8224\n",
      "Epoch [9/10], Batch: 3330, Train Loss: 0.6260\n",
      "Epoch [9/10], Batch: 3340, Train Loss: 0.8132\n",
      "Epoch [9/10], Batch: 3350, Train Loss: 0.6866\n",
      "Epoch [9/10], Batch: 3360, Train Loss: 0.6117\n",
      "Epoch [9/10], Batch: 3370, Train Loss: 0.6620\n",
      "Epoch [9/10], Batch: 3380, Train Loss: 0.7468\n",
      "Epoch [9/10], Batch: 3390, Train Loss: 0.6142\n",
      "Epoch [9/10], Batch: 3400, Train Loss: 0.8002\n",
      "Epoch [9/10], Batch: 3410, Train Loss: 0.7618\n",
      "Epoch [9/10], Batch: 3420, Train Loss: 0.7001\n",
      "Epoch [9/10], Batch: 3430, Train Loss: 0.9377\n",
      "Epoch [9/10], Batch: 3440, Train Loss: 0.7775\n",
      "Epoch [9/10], Batch: 3450, Train Loss: 0.6654\n",
      "Epoch [9/10], Batch: 3460, Train Loss: 0.6887\n",
      "Epoch [9/10], Batch: 3470, Train Loss: 0.6618\n",
      "Epoch [9/10], Batch: 3480, Train Loss: 0.7355\n",
      "Epoch [9/10], Batch: 3490, Train Loss: 0.7799\n",
      "Epoch [9/10], Batch: 3500, Train Loss: 0.8010\n",
      "Epoch [9/10], Batch: 3510, Train Loss: 0.8363\n",
      "Epoch [9/10], Batch: 3520, Train Loss: 0.7598\n",
      "Epoch [9/10], Batch: 3530, Train Loss: 0.7030\n",
      "Epoch [9/10], Batch: 3540, Train Loss: 0.6456\n",
      "Epoch [9/10], Batch: 3550, Train Loss: 0.7498\n",
      "Epoch [9/10], Batch: 3560, Train Loss: 0.8737\n",
      "Epoch [9/10], Batch: 3570, Train Loss: 0.8053\n",
      "Epoch [9/10], Batch: 3580, Train Loss: 0.7335\n",
      "Epoch [9/10], Batch: 3590, Train Loss: 0.7959\n",
      "Epoch [9/10], Batch: 3600, Train Loss: 0.8071\n",
      "Epoch [9/10], Batch: 3610, Train Loss: 0.6672\n",
      "Epoch [9/10], Batch: 3620, Train Loss: 0.7948\n",
      "Epoch [9/10], Batch: 3630, Train Loss: 0.8004\n",
      "Epoch [9/10], Batch: 3640, Train Loss: 0.6682\n",
      "Epoch [9/10], Batch: 3650, Train Loss: 0.6935\n",
      "Epoch [9/10], Batch: 3660, Train Loss: 0.7011\n",
      "Epoch [9/10], Batch: 3670, Train Loss: 0.6932\n",
      "Epoch [9/10], Batch: 3680, Train Loss: 0.8630\n",
      "Epoch [9/10], Batch: 3690, Train Loss: 0.6531\n",
      "Epoch [9/10], Batch: 3700, Train Loss: 0.8138\n",
      "Epoch [9/10], Batch: 3710, Train Loss: 0.8514\n",
      "Epoch [9/10], Batch: 3720, Train Loss: 0.7167\n",
      "Epoch [9/10], Batch: 3730, Train Loss: 0.5939\n",
      "Epoch [9/10], Batch: 3740, Train Loss: 0.6924\n",
      "Epoch [9/10], Batch: 3750, Train Loss: 0.6366\n",
      "Epoch [9/10], Batch: 3760, Train Loss: 0.6982\n",
      "Epoch [9/10], Batch: 3770, Train Loss: 0.7748\n",
      "Epoch [9/10], Batch: 3780, Train Loss: 0.7948\n",
      "Epoch [9/10], Batch: 3790, Train Loss: 0.7119\n",
      "Epoch [9/10], Batch: 3800, Train Loss: 0.6299\n",
      "Epoch [9/10], Batch: 3810, Train Loss: 0.6700\n",
      "Epoch [9/10], Batch: 3820, Train Loss: 0.7401\n",
      "Epoch [9/10], Batch: 3830, Train Loss: 0.6477\n",
      "Epoch [9/10], Batch: 3840, Train Loss: 0.7525\n",
      "Epoch [9/10], Batch: 3850, Train Loss: 0.6865\n",
      "Epoch [9/10], Batch: 3860, Train Loss: 0.7449\n",
      "Epoch [9/10], Batch: 3870, Train Loss: 0.7239\n",
      "Epoch [9/10], Batch: 3880, Train Loss: 0.8209\n",
      "Epoch [9/10], Batch: 3890, Train Loss: 0.8236\n",
      "Epoch [9/10], Batch: 3900, Train Loss: 0.7400\n",
      "Epoch [9/10], Batch: 3910, Train Loss: 0.8594\n",
      "Epoch [9/10], Batch: 3920, Train Loss: 0.7385\n",
      "Epoch [9/10], Batch: 3930, Train Loss: 0.8087\n",
      "Epoch [9/10], Batch: 3940, Train Loss: 0.7575\n",
      "Epoch [9/10], Batch: 3950, Train Loss: 0.7651\n",
      "Epoch [9/10], Batch: 3960, Train Loss: 0.9297\n",
      "Epoch [9/10], Batch: 3970, Train Loss: 0.6814\n",
      "Epoch [9/10], Batch: 3980, Train Loss: 0.7536\n",
      "Epoch [9/10], Batch: 3990, Train Loss: 0.6231\n",
      "Epoch [9/10], Batch: 4000, Train Loss: 0.7124\n",
      "Epoch [9/10], Batch: 4010, Train Loss: 0.7536\n",
      "Epoch [9/10], Batch: 4020, Train Loss: 0.7463\n",
      "Epoch [9/10], Batch: 4030, Train Loss: 0.8395\n",
      "Epoch [9/10], Batch: 4040, Train Loss: 0.6781\n",
      "Epoch [9/10], Batch: 4050, Train Loss: 0.6462\n",
      "Epoch [9/10], Batch: 4060, Train Loss: 0.6720\n",
      "Epoch [9/10], Batch: 4070, Train Loss: 0.6832\n",
      "Epoch [9/10], Batch: 4080, Train Loss: 0.8024\n",
      "Epoch [9/10], Batch: 4090, Train Loss: 0.7484\n",
      "Epoch [9/10], Batch: 4100, Train Loss: 0.7732\n",
      "Epoch [9/10], Batch: 4110, Train Loss: 0.7739\n",
      "Epoch [9/10], Batch: 4120, Train Loss: 0.7320\n",
      "Epoch [9/10], Batch: 4130, Train Loss: 0.7535\n",
      "Epoch [9/10], Batch: 4140, Train Loss: 0.8664\n",
      "Epoch [9/10], Batch: 4150, Train Loss: 0.6198\n",
      "Epoch [9/10], Batch: 4160, Train Loss: 0.6529\n",
      "Epoch [9/10], Batch: 4170, Train Loss: 0.6413\n",
      "Epoch [9/10], Batch: 4180, Train Loss: 0.5908\n",
      "Epoch [9/10], Batch: 4190, Train Loss: 0.7782\n",
      "Epoch [9/10], Batch: 4200, Train Loss: 0.6226\n",
      "Epoch [9/10], Batch: 4210, Train Loss: 0.8059\n",
      "Epoch [9/10], Batch: 4220, Train Loss: 0.7112\n",
      "Epoch [9/10], Batch: 4230, Train Loss: 0.7717\n",
      "Epoch [9/10], Batch: 4240, Train Loss: 0.6293\n",
      "Epoch [9/10], Batch: 4250, Train Loss: 0.7477\n",
      "Epoch [9/10], Batch: 4260, Train Loss: 0.7342\n",
      "Epoch [9/10], Batch: 4270, Train Loss: 0.8290\n",
      "Epoch [9/10], Batch: 4280, Train Loss: 0.7542\n",
      "Epoch [9/10], Batch: 4290, Train Loss: 0.8124\n",
      "Epoch [9/10], Batch: 4300, Train Loss: 0.6602\n",
      "Epoch [9/10], Batch: 4310, Train Loss: 0.7469\n",
      "Epoch [9/10], Batch: 4320, Train Loss: 0.7304\n",
      "Epoch [9/10], Batch: 4330, Train Loss: 0.7403\n",
      "Epoch [9/10], Batch: 4340, Train Loss: 0.8086\n",
      "Epoch [9/10], Batch: 4350, Train Loss: 0.5788\n",
      "Epoch [9/10], Batch: 4360, Train Loss: 0.5900\n",
      "Epoch [9/10], Batch: 4370, Train Loss: 0.9383\n",
      "Epoch [9/10], Batch: 4380, Train Loss: 0.7121\n",
      "Epoch [9/10], Batch: 4390, Train Loss: 0.7827\n",
      "Epoch [9/10], Batch: 4400, Train Loss: 0.7316\n",
      "Epoch [9/10], Batch: 4410, Train Loss: 0.6831\n",
      "Epoch [9/10], Batch: 4420, Train Loss: 0.9684\n",
      "Epoch [9/10], Batch: 4430, Train Loss: 0.7986\n",
      "Epoch [9/10], Batch: 4440, Train Loss: 0.8153\n",
      "Epoch [9/10], Batch: 4450, Train Loss: 0.6818\n",
      "Epoch [9/10], Batch: 4460, Train Loss: 0.7352\n",
      "Epoch [9/10], Batch: 4470, Train Loss: 0.6145\n",
      "Epoch [9/10], Batch: 4480, Train Loss: 0.7562\n",
      "Epoch [9/10], Batch: 4490, Train Loss: 0.7519\n",
      "Epoch [9/10], Batch: 4500, Train Loss: 0.7751\n",
      "Epoch [9/10], Batch: 4510, Train Loss: 0.7174\n",
      "Epoch [9/10], Batch: 4520, Train Loss: 0.6632\n",
      "Epoch [9/10], Batch: 4530, Train Loss: 0.6139\n",
      "Epoch [9/10], Batch: 4540, Train Loss: 0.7445\n",
      "Epoch [9/10], Batch: 4550, Train Loss: 0.6736\n",
      "Epoch [9/10], Batch: 4560, Train Loss: 0.8280\n",
      "Epoch [9/10], Batch: 4570, Train Loss: 0.6451\n",
      "Epoch [9/10], Batch: 4580, Train Loss: 0.7920\n",
      "Epoch [9/10], Batch: 4590, Train Loss: 0.6150\n",
      "Epoch [9/10], Batch: 4600, Train Loss: 0.6458\n",
      "Epoch [9/10], Batch: 4610, Train Loss: 0.6868\n",
      "Epoch [9/10], Batch: 4620, Train Loss: 0.6927\n",
      "Epoch [9/10], Batch: 4630, Train Loss: 0.6250\n",
      "Epoch [9/10], Batch: 4640, Train Loss: 0.7381\n",
      "Epoch [9/10], Batch: 4650, Train Loss: 0.7785\n",
      "Epoch [9/10], Batch: 4660, Train Loss: 0.6824\n",
      "Epoch [9/10], Batch: 4670, Train Loss: 0.8556\n",
      "Epoch [9/10], Batch: 4680, Train Loss: 0.7173\n",
      "Epoch [9/10], Batch: 4690, Train Loss: 0.8130\n",
      "Epoch [9/10], Batch: 4700, Train Loss: 0.8350\n",
      "Epoch [9/10], Batch: 4710, Train Loss: 0.6529\n",
      "Epoch [9/10], Batch: 4720, Train Loss: 0.6775\n",
      "Epoch [9/10], Batch: 4730, Train Loss: 0.8629\n",
      "Epoch [9/10], Batch: 4740, Train Loss: 0.6054\n",
      "Epoch [9/10], Batch: 4750, Train Loss: 0.6560\n",
      "Epoch [9/10], Batch: 4760, Train Loss: 0.7094\n",
      "Epoch [9/10], Batch: 4770, Train Loss: 0.7124\n",
      "Epoch [9/10], Batch: 4780, Train Loss: 0.6970\n",
      "Epoch [9/10], Batch: 4790, Train Loss: 0.7650\n",
      "Epoch [9/10], Batch: 4800, Train Loss: 0.7835\n",
      "Epoch [9/10], Batch: 4810, Train Loss: 0.6521\n",
      "Epoch [9/10], Batch: 4820, Train Loss: 0.8079\n",
      "Epoch [9/10], Batch: 4830, Train Loss: 0.6329\n",
      "Epoch [9/10], Batch: 4840, Train Loss: 0.7537\n",
      "Epoch [9/10], Batch: 4850, Train Loss: 0.6652\n",
      "Epoch [9/10], Batch: 4860, Train Loss: 0.7610\n",
      "Epoch [9/10], Batch: 4870, Train Loss: 0.7172\n",
      "Epoch [9/10], Batch: 4880, Train Loss: 0.7216\n",
      "Epoch [9/10], Batch: 4890, Train Loss: 0.8090\n",
      "Epoch [9/10], Batch: 4900, Train Loss: 0.9099\n",
      "Epoch [9/10], Batch: 4910, Train Loss: 0.6358\n",
      "Epoch [9/10], Batch: 4920, Train Loss: 0.6195\n",
      "Epoch [9/10], Batch: 4930, Train Loss: 0.7590\n",
      "Epoch [9/10], Batch: 4940, Train Loss: 0.6742\n",
      "Epoch [9/10], Batch: 4950, Train Loss: 0.7211\n",
      "Epoch [9/10], Batch: 4960, Train Loss: 0.6703\n",
      "Epoch [9/10], Batch: 4970, Train Loss: 0.7896\n",
      "Epoch [9/10], Batch: 4980, Train Loss: 0.7906\n",
      "Epoch [9/10], Batch: 4990, Train Loss: 0.7457\n",
      "Epoch [9/10], Batch: 5000, Train Loss: 0.5822\n",
      "Epoch [9/10], Batch: 5010, Train Loss: 0.8687\n",
      "Epoch [9/10], Batch: 5020, Train Loss: 0.7246\n",
      "Epoch [9/10], Batch: 5030, Train Loss: 0.7397\n",
      "Epoch [9/10], Batch: 5040, Train Loss: 0.8692\n",
      "Epoch [9/10], Batch: 5050, Train Loss: 0.7504\n",
      "Epoch [9/10], Batch: 5060, Train Loss: 0.7345\n",
      "Epoch [9/10], Batch: 5070, Train Loss: 0.7221\n",
      "Epoch [9/10], Batch: 5080, Train Loss: 0.6775\n",
      "Epoch [9/10], Batch: 5090, Train Loss: 0.6291\n",
      "Epoch [9/10], Batch: 5100, Train Loss: 0.7105\n",
      "Epoch [9/10], Batch: 5110, Train Loss: 0.7944\n",
      "Epoch [9/10], Batch: 5120, Train Loss: 0.6154\n",
      "Epoch [9/10], Batch: 5130, Train Loss: 0.6464\n",
      "Epoch [9/10], Batch: 5140, Train Loss: 0.9386\n",
      "Epoch [9/10], Batch: 5150, Train Loss: 0.7608\n",
      "Epoch [9/10], Batch: 5160, Train Loss: 0.8814\n",
      "Epoch [9/10], Batch: 5170, Train Loss: 0.7614\n",
      "Epoch [9/10], Batch: 5180, Train Loss: 0.7834\n",
      "Epoch [9/10], Batch: 5190, Train Loss: 0.6764\n",
      "Epoch [9/10], Batch: 5200, Train Loss: 0.7133\n",
      "Epoch [9/10], Batch: 5210, Train Loss: 0.7037\n",
      "Epoch [9/10], Batch: 5220, Train Loss: 0.8262\n",
      "Epoch [9/10], Batch: 5230, Train Loss: 0.6873\n",
      "Epoch [9/10], Batch: 5240, Train Loss: 0.7623\n",
      "Epoch [9/10], Batch: 5250, Train Loss: 0.8492\n",
      "Epoch [9/10], Batch: 5260, Train Loss: 0.8636\n",
      "Epoch [9/10], Batch: 5270, Train Loss: 0.7563\n",
      "Epoch [9/10], Batch: 5280, Train Loss: 0.6288\n",
      "Epoch [9/10], Batch: 5290, Train Loss: 0.7981\n",
      "Epoch [9/10], Batch: 5300, Train Loss: 0.7900\n",
      "Epoch [9/10], Batch: 5310, Train Loss: 0.7392\n",
      "Epoch [9/10], Batch: 5320, Train Loss: 0.6833\n",
      "Epoch [9/10], Batch: 5330, Train Loss: 0.6569\n",
      "Epoch [9/10], Batch: 5340, Train Loss: 0.8138\n",
      "Epoch [9/10], Batch: 5350, Train Loss: 0.6858\n",
      "Epoch [9/10], Batch: 5360, Train Loss: 0.7563\n",
      "Epoch [9/10], Batch: 5370, Train Loss: 0.6994\n",
      "Epoch [9/10], Batch: 5380, Train Loss: 0.6942\n",
      "Epoch [9/10], Batch: 5390, Train Loss: 0.7795\n",
      "Epoch [9/10], Batch: 5400, Train Loss: 0.7099\n",
      "Epoch [9/10], Batch: 5410, Train Loss: 0.8067\n",
      "Epoch [9/10], Batch: 5420, Train Loss: 0.6137\n",
      "Epoch [9/10], Batch: 5430, Train Loss: 0.6847\n",
      "Epoch [9/10], Batch: 5440, Train Loss: 0.7565\n",
      "Epoch [9/10], Batch: 5450, Train Loss: 0.7678\n",
      "Epoch [9/10], Batch: 5460, Train Loss: 0.7308\n",
      "Epoch [9/10], Batch: 5470, Train Loss: 0.6939\n",
      "Epoch [9/10], Batch: 5480, Train Loss: 0.5584\n",
      "Epoch [9/10], Batch: 5490, Train Loss: 0.6861\n",
      "Epoch [9/10], Batch: 5500, Train Loss: 0.7608\n",
      "Epoch [9/10], Batch: 5510, Train Loss: 0.8781\n",
      "Epoch [9/10], Batch: 5520, Train Loss: 0.7821\n",
      "Epoch [9/10], Batch: 5530, Train Loss: 0.7866\n",
      "Epoch [9/10], Batch: 5540, Train Loss: 0.8207\n",
      "Epoch [9/10], Batch: 5550, Train Loss: 0.7956\n",
      "Epoch [9/10], Batch: 5560, Train Loss: 0.6950\n",
      "Epoch [9/10], Batch: 5570, Train Loss: 0.7377\n",
      "Epoch [9/10], Batch: 5580, Train Loss: 0.6324\n",
      "Epoch [9/10], Batch: 5590, Train Loss: 0.8052\n",
      "Epoch [9/10], Batch: 5600, Train Loss: 0.5703\n",
      "Epoch [9/10], Batch: 5610, Train Loss: 0.7643\n",
      "Epoch [9/10], Batch: 5620, Train Loss: 0.8484\n",
      "Epoch [9/10], Batch: 5630, Train Loss: 0.7746\n",
      "Epoch [9/10], Batch: 5640, Train Loss: 0.8067\n",
      "Epoch [9/10], Batch: 5650, Train Loss: 0.7041\n",
      "Epoch [9/10], Batch: 5660, Train Loss: 0.6019\n",
      "Epoch [9/10], Batch: 5670, Train Loss: 0.7792\n",
      "Epoch [9/10], Batch: 5680, Train Loss: 0.7431\n",
      "Epoch [9/10], Batch: 5690, Train Loss: 0.7784\n",
      "Epoch [9/10], Batch: 5700, Train Loss: 0.5871\n",
      "Epoch [9/10], Batch: 5710, Train Loss: 0.8607\n",
      "Epoch [9/10], Batch: 5720, Train Loss: 0.8561\n",
      "Epoch [9/10], Batch: 5730, Train Loss: 0.6735\n",
      "Epoch [9/10], Batch: 5740, Train Loss: 0.7174\n",
      "Epoch [9/10], Batch: 5750, Train Loss: 0.7759\n",
      "Epoch [9/10], Batch: 5760, Train Loss: 0.9668\n",
      "Epoch [9/10], Batch: 5770, Train Loss: 0.7682\n",
      "Epoch [9/10], Batch: 5780, Train Loss: 0.8874\n",
      "Epoch [9/10], Batch: 5790, Train Loss: 0.8723\n",
      "Epoch [9/10], Batch: 5800, Train Loss: 0.7465\n",
      "Epoch [9/10], Batch: 5810, Train Loss: 0.7024\n",
      "Epoch [9/10], Batch: 5820, Train Loss: 0.8169\n",
      "Epoch [9/10], Batch: 5830, Train Loss: 0.7928\n",
      "Epoch [9/10], Batch: 5840, Train Loss: 0.6376\n",
      "Epoch [9/10], Batch: 5850, Train Loss: 0.6439\n",
      "Epoch [9/10], Batch: 5860, Train Loss: 0.7079\n",
      "Epoch [9/10], Batch: 5870, Train Loss: 0.6562\n",
      "Epoch [9/10], Batch: 5880, Train Loss: 0.8408\n",
      "Epoch [9/10], Batch: 5890, Train Loss: 0.7544\n",
      "Epoch [9/10], Batch: 5900, Train Loss: 0.7054\n",
      "Epoch [9/10], Batch: 5910, Train Loss: 0.7763\n",
      "Epoch [9/10], Batch: 5920, Train Loss: 0.7346\n",
      "Epoch [9/10], Batch: 5930, Train Loss: 0.9253\n",
      "Epoch [9/10], Batch: 5940, Train Loss: 0.7903\n",
      "Epoch [9/10], Batch: 5950, Train Loss: 0.6848\n",
      "Epoch [9/10], Batch: 5960, Train Loss: 0.8064\n",
      "Epoch [9/10], Batch: 5970, Train Loss: 0.7598\n",
      "Epoch [9/10], Batch: 5980, Train Loss: 0.7024\n",
      "Epoch [9/10], Batch: 5990, Train Loss: 0.8387\n",
      "Epoch [9/10], Batch: 6000, Train Loss: 0.6832\n",
      "Epoch [9/10], Batch: 6010, Train Loss: 0.8792\n",
      "Epoch [9/10], Batch: 6020, Train Loss: 0.7370\n",
      "Epoch [9/10], Batch: 6030, Train Loss: 0.8587\n",
      "Epoch [9/10], Batch: 6040, Train Loss: 0.7491\n",
      "Epoch [9/10], Batch: 6050, Train Loss: 0.7256\n",
      "Epoch [9/10], Batch: 6060, Train Loss: 0.7568\n",
      "Epoch [9/10], Batch: 6070, Train Loss: 0.6398\n",
      "Epoch [9/10], Batch: 6080, Train Loss: 0.6666\n",
      "Epoch [9/10], Batch: 6090, Train Loss: 0.6188\n",
      "Epoch [9/10], Batch: 6100, Train Loss: 0.7076\n",
      "Epoch [9/10], Batch: 6110, Train Loss: 0.7114\n",
      "Epoch [9/10], Batch: 6120, Train Loss: 0.6069\n",
      "Epoch [9/10], Batch: 6130, Train Loss: 0.7461\n",
      "Epoch [9/10], Batch: 6140, Train Loss: 0.6849\n",
      "Epoch [9/10], Batch: 6150, Train Loss: 0.7016\n",
      "Epoch [9/10], Batch: 6160, Train Loss: 0.8543\n",
      "Epoch [9/10], Batch: 6170, Train Loss: 0.7902\n",
      "Epoch [9/10], Batch: 6180, Train Loss: 0.7750\n",
      "Epoch [9/10], Batch: 6190, Train Loss: 0.7831\n",
      "Epoch [9/10], Batch: 6200, Train Loss: 0.7263\n",
      "Epoch [9/10], Batch: 6210, Train Loss: 0.7081\n",
      "Epoch [9/10], Batch: 6220, Train Loss: 0.7467\n",
      "Epoch [9/10], Batch: 6230, Train Loss: 0.7206\n",
      "Epoch [9/10], Batch: 6240, Train Loss: 0.8151\n",
      "Epoch [9/10], Batch: 6250, Train Loss: 0.8431\n",
      "Epoch [9/10], Batch: 6260, Train Loss: 0.7858\n",
      "Epoch [9/10], Batch: 6270, Train Loss: 0.7519\n",
      "Epoch [9/10], Batch: 6280, Train Loss: 0.8269\n",
      "Epoch [9/10], Batch: 6290, Train Loss: 0.6859\n",
      "Epoch [9/10], Batch: 6300, Train Loss: 0.6191\n",
      "Epoch [9/10], Batch: 6310, Train Loss: 0.7302\n",
      "Epoch [9/10], Batch: 6320, Train Loss: 0.8843\n",
      "Epoch [9/10], Batch: 6330, Train Loss: 0.6826\n",
      "Epoch [9/10], Batch: 6340, Train Loss: 0.8047\n",
      "Epoch [9/10], Batch: 6350, Train Loss: 0.8909\n",
      "Epoch [9/10], Batch: 6360, Train Loss: 0.7752\n",
      "Epoch [9/10], Batch: 6370, Train Loss: 0.6667\n",
      "Epoch [9/10], Batch: 6380, Train Loss: 0.7038\n",
      "Epoch [9/10], Batch: 6390, Train Loss: 0.6755\n",
      "Epoch [9/10], Batch: 6400, Train Loss: 0.7956\n",
      "Epoch [9/10], Batch: 6410, Train Loss: 0.6650\n",
      "Epoch [9/10], Batch: 6420, Train Loss: 0.7015\n",
      "Epoch [9/10], Batch: 6430, Train Loss: 0.6513\n",
      "Epoch [9/10], Batch: 6440, Train Loss: 0.7394\n",
      "Epoch [9/10], Batch: 6450, Train Loss: 0.8011\n",
      "Epoch [9/10], Batch: 6460, Train Loss: 0.7309\n",
      "Epoch [9/10], Batch: 6470, Train Loss: 0.7132\n",
      "Epoch [9/10], Batch: 6480, Train Loss: 0.7649\n",
      "Epoch [9/10], Batch: 6490, Train Loss: 0.6905\n",
      "Epoch [9/10], Batch: 6500, Train Loss: 0.7296\n",
      "Epoch [9/10], Batch: 6510, Train Loss: 0.6743\n",
      "Epoch [9/10], Batch: 6520, Train Loss: 0.5943\n",
      "Epoch [9/10], Batch: 6530, Train Loss: 0.6817\n",
      "Epoch [9/10], Batch: 6540, Train Loss: 0.6265\n",
      "Epoch [9/10], Batch: 6550, Train Loss: 0.7994\n",
      "Epoch [9/10], Batch: 6560, Train Loss: 0.6988\n",
      "Epoch [9/10], Batch: 6570, Train Loss: 0.7195\n",
      "Epoch [9/10], Batch: 6580, Train Loss: 0.6718\n",
      "Epoch [9/10], Batch: 6590, Train Loss: 0.7746\n",
      "Epoch [9/10], Batch: 6600, Train Loss: 0.8258\n",
      "Epoch [9/10], Batch: 6610, Train Loss: 0.6926\n",
      "Epoch [9/10], Batch: 6620, Train Loss: 0.6891\n",
      "Epoch [9/10], Batch: 6630, Train Loss: 0.7705\n",
      "Epoch [9/10], Batch: 6640, Train Loss: 0.7816\n",
      "Epoch [9/10], Batch: 6650, Train Loss: 0.7207\n",
      "Epoch [9/10], Batch: 6660, Train Loss: 0.9031\n",
      "Epoch [9/10], Batch: 6670, Train Loss: 0.6542\n",
      "Epoch [9/10], Batch: 6680, Train Loss: 0.7722\n",
      "Epoch [9/10], Batch: 6690, Train Loss: 0.7409\n",
      "Epoch [9/10], Batch: 6700, Train Loss: 0.7878\n",
      "Epoch [9/10], Batch: 6710, Train Loss: 0.8388\n",
      "Epoch [9/10], Batch: 6720, Train Loss: 0.6856\n",
      "Epoch [9/10], Batch: 6730, Train Loss: 0.5930\n",
      "Epoch [9/10], Batch: 6740, Train Loss: 0.6930\n",
      "Epoch [9/10], Batch: 6750, Train Loss: 0.6056\n",
      "Epoch [9/10], Batch: 6760, Train Loss: 0.7422\n",
      "Epoch [10/10], Batch: 10, Train Loss: 0.6870\n",
      "Epoch [10/10], Batch: 20, Train Loss: 0.4864\n",
      "Epoch [10/10], Batch: 30, Train Loss: 0.5877\n",
      "Epoch [10/10], Batch: 40, Train Loss: 0.5661\n",
      "Epoch [10/10], Batch: 50, Train Loss: 0.8597\n",
      "Epoch [10/10], Batch: 60, Train Loss: 0.6994\n",
      "Epoch [10/10], Batch: 70, Train Loss: 0.7975\n",
      "Epoch [10/10], Batch: 80, Train Loss: 0.6817\n",
      "Epoch [10/10], Batch: 90, Train Loss: 0.7027\n",
      "Epoch [10/10], Batch: 100, Train Loss: 0.6915\n",
      "Epoch [10/10], Batch: 110, Train Loss: 0.8081\n",
      "Epoch [10/10], Batch: 120, Train Loss: 0.6828\n",
      "Epoch [10/10], Batch: 130, Train Loss: 0.7014\n",
      "Epoch [10/10], Batch: 140, Train Loss: 0.7148\n",
      "Epoch [10/10], Batch: 150, Train Loss: 0.6285\n",
      "Epoch [10/10], Batch: 160, Train Loss: 0.6802\n",
      "Epoch [10/10], Batch: 170, Train Loss: 0.7472\n",
      "Epoch [10/10], Batch: 180, Train Loss: 0.5637\n",
      "Epoch [10/10], Batch: 190, Train Loss: 0.6083\n",
      "Epoch [10/10], Batch: 200, Train Loss: 0.5337\n",
      "Epoch [10/10], Batch: 210, Train Loss: 0.7292\n",
      "Epoch [10/10], Batch: 220, Train Loss: 0.6911\n",
      "Epoch [10/10], Batch: 230, Train Loss: 0.6929\n",
      "Epoch [10/10], Batch: 240, Train Loss: 0.7173\n",
      "Epoch [10/10], Batch: 250, Train Loss: 0.6829\n",
      "Epoch [10/10], Batch: 260, Train Loss: 0.7526\n",
      "Epoch [10/10], Batch: 270, Train Loss: 0.7375\n",
      "Epoch [10/10], Batch: 280, Train Loss: 0.6295\n",
      "Epoch [10/10], Batch: 290, Train Loss: 0.7977\n",
      "Epoch [10/10], Batch: 300, Train Loss: 0.7423\n",
      "Epoch [10/10], Batch: 310, Train Loss: 0.7148\n",
      "Epoch [10/10], Batch: 320, Train Loss: 0.6986\n",
      "Epoch [10/10], Batch: 330, Train Loss: 0.6891\n",
      "Epoch [10/10], Batch: 340, Train Loss: 0.7074\n",
      "Epoch [10/10], Batch: 350, Train Loss: 0.7158\n",
      "Epoch [10/10], Batch: 360, Train Loss: 0.7644\n",
      "Epoch [10/10], Batch: 370, Train Loss: 0.6748\n",
      "Epoch [10/10], Batch: 380, Train Loss: 0.7532\n",
      "Epoch [10/10], Batch: 390, Train Loss: 0.7471\n",
      "Epoch [10/10], Batch: 400, Train Loss: 0.7722\n",
      "Epoch [10/10], Batch: 410, Train Loss: 0.7948\n",
      "Epoch [10/10], Batch: 420, Train Loss: 0.8337\n",
      "Epoch [10/10], Batch: 430, Train Loss: 0.7534\n",
      "Epoch [10/10], Batch: 440, Train Loss: 0.6294\n",
      "Epoch [10/10], Batch: 450, Train Loss: 0.6885\n",
      "Epoch [10/10], Batch: 460, Train Loss: 0.7215\n",
      "Epoch [10/10], Batch: 470, Train Loss: 0.7864\n",
      "Epoch [10/10], Batch: 480, Train Loss: 0.7704\n",
      "Epoch [10/10], Batch: 490, Train Loss: 0.6117\n",
      "Epoch [10/10], Batch: 500, Train Loss: 0.8341\n",
      "Epoch [10/10], Batch: 510, Train Loss: 0.7213\n",
      "Epoch [10/10], Batch: 520, Train Loss: 0.8312\n",
      "Epoch [10/10], Batch: 530, Train Loss: 0.6452\n",
      "Epoch [10/10], Batch: 540, Train Loss: 0.6999\n",
      "Epoch [10/10], Batch: 550, Train Loss: 0.7973\n",
      "Epoch [10/10], Batch: 560, Train Loss: 0.6473\n",
      "Epoch [10/10], Batch: 570, Train Loss: 0.7990\n",
      "Epoch [10/10], Batch: 580, Train Loss: 0.6471\n",
      "Epoch [10/10], Batch: 590, Train Loss: 0.7595\n",
      "Epoch [10/10], Batch: 600, Train Loss: 0.7130\n",
      "Epoch [10/10], Batch: 610, Train Loss: 0.6713\n",
      "Epoch [10/10], Batch: 620, Train Loss: 0.7703\n",
      "Epoch [10/10], Batch: 630, Train Loss: 0.6671\n",
      "Epoch [10/10], Batch: 640, Train Loss: 0.7933\n",
      "Epoch [10/10], Batch: 650, Train Loss: 0.7206\n",
      "Epoch [10/10], Batch: 660, Train Loss: 0.8065\n",
      "Epoch [10/10], Batch: 670, Train Loss: 0.7840\n",
      "Epoch [10/10], Batch: 680, Train Loss: 0.6304\n",
      "Epoch [10/10], Batch: 690, Train Loss: 0.6071\n",
      "Epoch [10/10], Batch: 700, Train Loss: 0.7230\n",
      "Epoch [10/10], Batch: 710, Train Loss: 0.6683\n",
      "Epoch [10/10], Batch: 720, Train Loss: 0.7147\n",
      "Epoch [10/10], Batch: 730, Train Loss: 0.6135\n",
      "Epoch [10/10], Batch: 740, Train Loss: 0.7180\n",
      "Epoch [10/10], Batch: 750, Train Loss: 0.5655\n",
      "Epoch [10/10], Batch: 760, Train Loss: 0.7512\n",
      "Epoch [10/10], Batch: 770, Train Loss: 0.6374\n",
      "Epoch [10/10], Batch: 780, Train Loss: 0.6243\n",
      "Epoch [10/10], Batch: 790, Train Loss: 0.8052\n",
      "Epoch [10/10], Batch: 800, Train Loss: 0.7500\n",
      "Epoch [10/10], Batch: 810, Train Loss: 0.6644\n",
      "Epoch [10/10], Batch: 820, Train Loss: 0.7449\n",
      "Epoch [10/10], Batch: 830, Train Loss: 0.8103\n",
      "Epoch [10/10], Batch: 840, Train Loss: 0.6612\n",
      "Epoch [10/10], Batch: 850, Train Loss: 0.7108\n",
      "Epoch [10/10], Batch: 860, Train Loss: 0.5900\n",
      "Epoch [10/10], Batch: 870, Train Loss: 0.7324\n",
      "Epoch [10/10], Batch: 880, Train Loss: 0.8121\n",
      "Epoch [10/10], Batch: 890, Train Loss: 0.6934\n",
      "Epoch [10/10], Batch: 900, Train Loss: 0.7058\n",
      "Epoch [10/10], Batch: 910, Train Loss: 0.6732\n",
      "Epoch [10/10], Batch: 920, Train Loss: 0.7811\n",
      "Epoch [10/10], Batch: 930, Train Loss: 0.7431\n",
      "Epoch [10/10], Batch: 940, Train Loss: 0.8269\n",
      "Epoch [10/10], Batch: 950, Train Loss: 0.7933\n",
      "Epoch [10/10], Batch: 960, Train Loss: 0.7826\n",
      "Epoch [10/10], Batch: 970, Train Loss: 0.5927\n",
      "Epoch [10/10], Batch: 980, Train Loss: 0.8257\n",
      "Epoch [10/10], Batch: 990, Train Loss: 0.6400\n",
      "Epoch [10/10], Batch: 1000, Train Loss: 0.7546\n",
      "Epoch [10/10], Batch: 1010, Train Loss: 0.7512\n",
      "Epoch [10/10], Batch: 1020, Train Loss: 0.6734\n",
      "Epoch [10/10], Batch: 1030, Train Loss: 0.7224\n",
      "Epoch [10/10], Batch: 1040, Train Loss: 0.7619\n",
      "Epoch [10/10], Batch: 1050, Train Loss: 0.6058\n",
      "Epoch [10/10], Batch: 1060, Train Loss: 0.8089\n",
      "Epoch [10/10], Batch: 1070, Train Loss: 0.8563\n",
      "Epoch [10/10], Batch: 1080, Train Loss: 0.6366\n",
      "Epoch [10/10], Batch: 1090, Train Loss: 0.6831\n",
      "Epoch [10/10], Batch: 1100, Train Loss: 0.6814\n",
      "Epoch [10/10], Batch: 1110, Train Loss: 0.7790\n",
      "Epoch [10/10], Batch: 1120, Train Loss: 0.6869\n",
      "Epoch [10/10], Batch: 1130, Train Loss: 0.7765\n",
      "Epoch [10/10], Batch: 1140, Train Loss: 0.7274\n",
      "Epoch [10/10], Batch: 1150, Train Loss: 0.6938\n",
      "Epoch [10/10], Batch: 1160, Train Loss: 0.6497\n",
      "Epoch [10/10], Batch: 1170, Train Loss: 0.6361\n",
      "Epoch [10/10], Batch: 1180, Train Loss: 0.8684\n",
      "Epoch [10/10], Batch: 1190, Train Loss: 0.7759\n",
      "Epoch [10/10], Batch: 1200, Train Loss: 0.7207\n",
      "Epoch [10/10], Batch: 1210, Train Loss: 0.6916\n",
      "Epoch [10/10], Batch: 1220, Train Loss: 0.8419\n",
      "Epoch [10/10], Batch: 1230, Train Loss: 0.7536\n",
      "Epoch [10/10], Batch: 1240, Train Loss: 0.7373\n",
      "Epoch [10/10], Batch: 1250, Train Loss: 0.7571\n",
      "Epoch [10/10], Batch: 1260, Train Loss: 0.7713\n",
      "Epoch [10/10], Batch: 1270, Train Loss: 0.6986\n",
      "Epoch [10/10], Batch: 1280, Train Loss: 0.6271\n",
      "Epoch [10/10], Batch: 1290, Train Loss: 0.6581\n",
      "Epoch [10/10], Batch: 1300, Train Loss: 0.6245\n",
      "Epoch [10/10], Batch: 1310, Train Loss: 0.8037\n",
      "Epoch [10/10], Batch: 1320, Train Loss: 0.6585\n",
      "Epoch [10/10], Batch: 1330, Train Loss: 0.8553\n",
      "Epoch [10/10], Batch: 1340, Train Loss: 0.7275\n",
      "Epoch [10/10], Batch: 1350, Train Loss: 0.7580\n",
      "Epoch [10/10], Batch: 1360, Train Loss: 0.5900\n",
      "Epoch [10/10], Batch: 1370, Train Loss: 0.8590\n",
      "Epoch [10/10], Batch: 1380, Train Loss: 0.6142\n",
      "Epoch [10/10], Batch: 1390, Train Loss: 0.6966\n",
      "Epoch [10/10], Batch: 1400, Train Loss: 0.7163\n",
      "Epoch [10/10], Batch: 1410, Train Loss: 0.9831\n",
      "Epoch [10/10], Batch: 1420, Train Loss: 0.6720\n",
      "Epoch [10/10], Batch: 1430, Train Loss: 0.9138\n",
      "Epoch [10/10], Batch: 1440, Train Loss: 0.7145\n",
      "Epoch [10/10], Batch: 1450, Train Loss: 0.7090\n",
      "Epoch [10/10], Batch: 1460, Train Loss: 0.8024\n",
      "Epoch [10/10], Batch: 1470, Train Loss: 0.7519\n",
      "Epoch [10/10], Batch: 1480, Train Loss: 0.8742\n",
      "Epoch [10/10], Batch: 1490, Train Loss: 0.7617\n",
      "Epoch [10/10], Batch: 1500, Train Loss: 0.7702\n",
      "Epoch [10/10], Batch: 1510, Train Loss: 0.6839\n",
      "Epoch [10/10], Batch: 1520, Train Loss: 0.6964\n",
      "Epoch [10/10], Batch: 1530, Train Loss: 0.6287\n",
      "Epoch [10/10], Batch: 1540, Train Loss: 0.5974\n",
      "Epoch [10/10], Batch: 1550, Train Loss: 0.7486\n",
      "Epoch [10/10], Batch: 1560, Train Loss: 0.7272\n",
      "Epoch [10/10], Batch: 1570, Train Loss: 0.7879\n",
      "Epoch [10/10], Batch: 1580, Train Loss: 0.7260\n",
      "Epoch [10/10], Batch: 1590, Train Loss: 0.6302\n",
      "Epoch [10/10], Batch: 1600, Train Loss: 0.7803\n",
      "Epoch [10/10], Batch: 1610, Train Loss: 0.8457\n",
      "Epoch [10/10], Batch: 1620, Train Loss: 0.7418\n",
      "Epoch [10/10], Batch: 1630, Train Loss: 0.8038\n",
      "Epoch [10/10], Batch: 1640, Train Loss: 0.6250\n",
      "Epoch [10/10], Batch: 1650, Train Loss: 0.8006\n",
      "Epoch [10/10], Batch: 1660, Train Loss: 0.6350\n",
      "Epoch [10/10], Batch: 1670, Train Loss: 0.7006\n",
      "Epoch [10/10], Batch: 1680, Train Loss: 0.7611\n",
      "Epoch [10/10], Batch: 1690, Train Loss: 0.8525\n",
      "Epoch [10/10], Batch: 1700, Train Loss: 0.6845\n",
      "Epoch [10/10], Batch: 1710, Train Loss: 0.6750\n",
      "Epoch [10/10], Batch: 1720, Train Loss: 0.7833\n",
      "Epoch [10/10], Batch: 1730, Train Loss: 0.7633\n",
      "Epoch [10/10], Batch: 1740, Train Loss: 0.7555\n",
      "Epoch [10/10], Batch: 1750, Train Loss: 0.7753\n",
      "Epoch [10/10], Batch: 1760, Train Loss: 0.7438\n",
      "Epoch [10/10], Batch: 1770, Train Loss: 0.6842\n",
      "Epoch [10/10], Batch: 1780, Train Loss: 0.7061\n",
      "Epoch [10/10], Batch: 1790, Train Loss: 0.7936\n",
      "Epoch [10/10], Batch: 1800, Train Loss: 0.7981\n",
      "Epoch [10/10], Batch: 1810, Train Loss: 0.6633\n",
      "Epoch [10/10], Batch: 1820, Train Loss: 0.7368\n",
      "Epoch [10/10], Batch: 1830, Train Loss: 0.7732\n",
      "Epoch [10/10], Batch: 1840, Train Loss: 0.8136\n",
      "Epoch [10/10], Batch: 1850, Train Loss: 0.8208\n",
      "Epoch [10/10], Batch: 1860, Train Loss: 0.7008\n",
      "Epoch [10/10], Batch: 1870, Train Loss: 0.7820\n",
      "Epoch [10/10], Batch: 1880, Train Loss: 0.7208\n",
      "Epoch [10/10], Batch: 1890, Train Loss: 0.7931\n",
      "Epoch [10/10], Batch: 1900, Train Loss: 0.6828\n",
      "Epoch [10/10], Batch: 1910, Train Loss: 0.6097\n",
      "Epoch [10/10], Batch: 1920, Train Loss: 0.7446\n",
      "Epoch [10/10], Batch: 1930, Train Loss: 0.7950\n",
      "Epoch [10/10], Batch: 1940, Train Loss: 0.6534\n",
      "Epoch [10/10], Batch: 1950, Train Loss: 0.8813\n",
      "Epoch [10/10], Batch: 1960, Train Loss: 0.6922\n",
      "Epoch [10/10], Batch: 1970, Train Loss: 0.7383\n",
      "Epoch [10/10], Batch: 1980, Train Loss: 0.6365\n",
      "Epoch [10/10], Batch: 1990, Train Loss: 0.6701\n",
      "Epoch [10/10], Batch: 2000, Train Loss: 0.6841\n",
      "Epoch [10/10], Batch: 2010, Train Loss: 0.6825\n",
      "Epoch [10/10], Batch: 2020, Train Loss: 0.6707\n",
      "Epoch [10/10], Batch: 2030, Train Loss: 0.6208\n",
      "Epoch [10/10], Batch: 2040, Train Loss: 0.6928\n",
      "Epoch [10/10], Batch: 2050, Train Loss: 0.7418\n",
      "Epoch [10/10], Batch: 2060, Train Loss: 0.6337\n",
      "Epoch [10/10], Batch: 2070, Train Loss: 0.7147\n",
      "Epoch [10/10], Batch: 2080, Train Loss: 0.6460\n",
      "Epoch [10/10], Batch: 2090, Train Loss: 0.6709\n",
      "Epoch [10/10], Batch: 2100, Train Loss: 0.7766\n",
      "Epoch [10/10], Batch: 2110, Train Loss: 0.8302\n",
      "Epoch [10/10], Batch: 2120, Train Loss: 0.6463\n",
      "Epoch [10/10], Batch: 2130, Train Loss: 0.8214\n",
      "Epoch [10/10], Batch: 2140, Train Loss: 0.8270\n",
      "Epoch [10/10], Batch: 2150, Train Loss: 0.8602\n",
      "Epoch [10/10], Batch: 2160, Train Loss: 0.7228\n",
      "Epoch [10/10], Batch: 2170, Train Loss: 0.7431\n",
      "Epoch [10/10], Batch: 2180, Train Loss: 0.7019\n",
      "Epoch [10/10], Batch: 2190, Train Loss: 0.7179\n",
      "Epoch [10/10], Batch: 2200, Train Loss: 0.7187\n",
      "Epoch [10/10], Batch: 2210, Train Loss: 0.7220\n",
      "Epoch [10/10], Batch: 2220, Train Loss: 0.7393\n",
      "Epoch [10/10], Batch: 2230, Train Loss: 0.8433\n",
      "Epoch [10/10], Batch: 2240, Train Loss: 0.8604\n",
      "Epoch [10/10], Batch: 2250, Train Loss: 0.7111\n",
      "Epoch [10/10], Batch: 2260, Train Loss: 0.7169\n",
      "Epoch [10/10], Batch: 2270, Train Loss: 0.7140\n",
      "Epoch [10/10], Batch: 2280, Train Loss: 0.7181\n",
      "Epoch [10/10], Batch: 2290, Train Loss: 0.8003\n",
      "Epoch [10/10], Batch: 2300, Train Loss: 0.6216\n",
      "Epoch [10/10], Batch: 2310, Train Loss: 0.6926\n",
      "Epoch [10/10], Batch: 2320, Train Loss: 0.8655\n",
      "Epoch [10/10], Batch: 2330, Train Loss: 0.6917\n",
      "Epoch [10/10], Batch: 2340, Train Loss: 0.7708\n",
      "Epoch [10/10], Batch: 2350, Train Loss: 0.7251\n",
      "Epoch [10/10], Batch: 2360, Train Loss: 0.7536\n",
      "Epoch [10/10], Batch: 2370, Train Loss: 0.7567\n",
      "Epoch [10/10], Batch: 2380, Train Loss: 0.7688\n",
      "Epoch [10/10], Batch: 2390, Train Loss: 0.6148\n",
      "Epoch [10/10], Batch: 2400, Train Loss: 0.7092\n",
      "Epoch [10/10], Batch: 2410, Train Loss: 0.7146\n",
      "Epoch [10/10], Batch: 2420, Train Loss: 0.6915\n",
      "Epoch [10/10], Batch: 2430, Train Loss: 0.7041\n",
      "Epoch [10/10], Batch: 2440, Train Loss: 0.6438\n",
      "Epoch [10/10], Batch: 2450, Train Loss: 0.6820\n",
      "Epoch [10/10], Batch: 2460, Train Loss: 0.6774\n",
      "Epoch [10/10], Batch: 2470, Train Loss: 0.7137\n",
      "Epoch [10/10], Batch: 2480, Train Loss: 0.6080\n",
      "Epoch [10/10], Batch: 2490, Train Loss: 0.8377\n",
      "Epoch [10/10], Batch: 2500, Train Loss: 0.7572\n",
      "Epoch [10/10], Batch: 2510, Train Loss: 0.6915\n",
      "Epoch [10/10], Batch: 2520, Train Loss: 0.6712\n",
      "Epoch [10/10], Batch: 2530, Train Loss: 0.6477\n",
      "Epoch [10/10], Batch: 2540, Train Loss: 0.8312\n",
      "Epoch [10/10], Batch: 2550, Train Loss: 0.6681\n",
      "Epoch [10/10], Batch: 2560, Train Loss: 0.7248\n",
      "Epoch [10/10], Batch: 2570, Train Loss: 0.6069\n",
      "Epoch [10/10], Batch: 2580, Train Loss: 0.6764\n",
      "Epoch [10/10], Batch: 2590, Train Loss: 0.7669\n",
      "Epoch [10/10], Batch: 2600, Train Loss: 0.6491\n",
      "Epoch [10/10], Batch: 2610, Train Loss: 0.7200\n",
      "Epoch [10/10], Batch: 2620, Train Loss: 0.6292\n",
      "Epoch [10/10], Batch: 2630, Train Loss: 0.6512\n",
      "Epoch [10/10], Batch: 2640, Train Loss: 0.7584\n",
      "Epoch [10/10], Batch: 2650, Train Loss: 0.6918\n",
      "Epoch [10/10], Batch: 2660, Train Loss: 0.7108\n",
      "Epoch [10/10], Batch: 2670, Train Loss: 0.6598\n",
      "Epoch [10/10], Batch: 2680, Train Loss: 0.8342\n",
      "Epoch [10/10], Batch: 2690, Train Loss: 0.6368\n",
      "Epoch [10/10], Batch: 2700, Train Loss: 0.6916\n",
      "Epoch [10/10], Batch: 2710, Train Loss: 0.7052\n",
      "Epoch [10/10], Batch: 2720, Train Loss: 0.7271\n",
      "Epoch [10/10], Batch: 2730, Train Loss: 0.7892\n",
      "Epoch [10/10], Batch: 2740, Train Loss: 0.7927\n",
      "Epoch [10/10], Batch: 2750, Train Loss: 0.7739\n",
      "Epoch [10/10], Batch: 2760, Train Loss: 0.6838\n",
      "Epoch [10/10], Batch: 2770, Train Loss: 0.7106\n",
      "Epoch [10/10], Batch: 2780, Train Loss: 0.7601\n",
      "Epoch [10/10], Batch: 2790, Train Loss: 0.5161\n",
      "Epoch [10/10], Batch: 2800, Train Loss: 0.7202\n",
      "Epoch [10/10], Batch: 2810, Train Loss: 0.7561\n",
      "Epoch [10/10], Batch: 2820, Train Loss: 0.6260\n",
      "Epoch [10/10], Batch: 2830, Train Loss: 0.8780\n",
      "Epoch [10/10], Batch: 2840, Train Loss: 0.7453\n",
      "Epoch [10/10], Batch: 2850, Train Loss: 0.7230\n",
      "Epoch [10/10], Batch: 2860, Train Loss: 0.7297\n",
      "Epoch [10/10], Batch: 2870, Train Loss: 0.6352\n",
      "Epoch [10/10], Batch: 2880, Train Loss: 0.9775\n",
      "Epoch [10/10], Batch: 2890, Train Loss: 0.8161\n",
      "Epoch [10/10], Batch: 2900, Train Loss: 0.8191\n",
      "Epoch [10/10], Batch: 2910, Train Loss: 0.8305\n",
      "Epoch [10/10], Batch: 2920, Train Loss: 0.7456\n",
      "Epoch [10/10], Batch: 2930, Train Loss: 0.7110\n",
      "Epoch [10/10], Batch: 2940, Train Loss: 0.8382\n",
      "Epoch [10/10], Batch: 2950, Train Loss: 0.6553\n",
      "Epoch [10/10], Batch: 2960, Train Loss: 0.7400\n",
      "Epoch [10/10], Batch: 2970, Train Loss: 0.7605\n",
      "Epoch [10/10], Batch: 2980, Train Loss: 0.6151\n",
      "Epoch [10/10], Batch: 2990, Train Loss: 0.5996\n",
      "Epoch [10/10], Batch: 3000, Train Loss: 0.6378\n",
      "Epoch [10/10], Batch: 3010, Train Loss: 0.8834\n",
      "Epoch [10/10], Batch: 3020, Train Loss: 0.7818\n",
      "Epoch [10/10], Batch: 3030, Train Loss: 0.6189\n",
      "Epoch [10/10], Batch: 3040, Train Loss: 0.6861\n",
      "Epoch [10/10], Batch: 3050, Train Loss: 0.6509\n",
      "Epoch [10/10], Batch: 3060, Train Loss: 0.7269\n",
      "Epoch [10/10], Batch: 3070, Train Loss: 0.8431\n",
      "Epoch [10/10], Batch: 3080, Train Loss: 0.8924\n",
      "Epoch [10/10], Batch: 3090, Train Loss: 0.8469\n",
      "Epoch [10/10], Batch: 3100, Train Loss: 0.7759\n",
      "Epoch [10/10], Batch: 3110, Train Loss: 0.7401\n",
      "Epoch [10/10], Batch: 3120, Train Loss: 0.7347\n",
      "Epoch [10/10], Batch: 3130, Train Loss: 0.8186\n",
      "Epoch [10/10], Batch: 3140, Train Loss: 0.7408\n",
      "Epoch [10/10], Batch: 3150, Train Loss: 0.6569\n",
      "Epoch [10/10], Batch: 3160, Train Loss: 0.8238\n",
      "Epoch [10/10], Batch: 3170, Train Loss: 0.6726\n",
      "Epoch [10/10], Batch: 3180, Train Loss: 0.8371\n",
      "Epoch [10/10], Batch: 3190, Train Loss: 0.5016\n",
      "Epoch [10/10], Batch: 3200, Train Loss: 0.9207\n",
      "Epoch [10/10], Batch: 3210, Train Loss: 0.6993\n",
      "Epoch [10/10], Batch: 3220, Train Loss: 0.7976\n",
      "Epoch [10/10], Batch: 3230, Train Loss: 0.6867\n",
      "Epoch [10/10], Batch: 3240, Train Loss: 0.7171\n",
      "Epoch [10/10], Batch: 3250, Train Loss: 0.7339\n",
      "Epoch [10/10], Batch: 3260, Train Loss: 0.7493\n",
      "Epoch [10/10], Batch: 3270, Train Loss: 0.8055\n",
      "Epoch [10/10], Batch: 3280, Train Loss: 0.8128\n",
      "Epoch [10/10], Batch: 3290, Train Loss: 0.7625\n",
      "Epoch [10/10], Batch: 3300, Train Loss: 0.6431\n",
      "Epoch [10/10], Batch: 3310, Train Loss: 0.7918\n",
      "Epoch [10/10], Batch: 3320, Train Loss: 0.8040\n",
      "Epoch [10/10], Batch: 3330, Train Loss: 0.6059\n",
      "Epoch [10/10], Batch: 3340, Train Loss: 0.7660\n",
      "Epoch [10/10], Batch: 3350, Train Loss: 0.6453\n",
      "Epoch [10/10], Batch: 3360, Train Loss: 0.5753\n",
      "Epoch [10/10], Batch: 3370, Train Loss: 0.6593\n",
      "Epoch [10/10], Batch: 3380, Train Loss: 0.6607\n",
      "Epoch [10/10], Batch: 3390, Train Loss: 0.6014\n",
      "Epoch [10/10], Batch: 3400, Train Loss: 0.7806\n",
      "Epoch [10/10], Batch: 3410, Train Loss: 0.7372\n",
      "Epoch [10/10], Batch: 3420, Train Loss: 0.6477\n",
      "Epoch [10/10], Batch: 3430, Train Loss: 0.8783\n",
      "Epoch [10/10], Batch: 3440, Train Loss: 0.7682\n",
      "Epoch [10/10], Batch: 3450, Train Loss: 0.6604\n",
      "Epoch [10/10], Batch: 3460, Train Loss: 0.7035\n",
      "Epoch [10/10], Batch: 3470, Train Loss: 0.6306\n",
      "Epoch [10/10], Batch: 3480, Train Loss: 0.7455\n",
      "Epoch [10/10], Batch: 3490, Train Loss: 0.7267\n",
      "Epoch [10/10], Batch: 3500, Train Loss: 0.8155\n",
      "Epoch [10/10], Batch: 3510, Train Loss: 0.8366\n",
      "Epoch [10/10], Batch: 3520, Train Loss: 0.7579\n",
      "Epoch [10/10], Batch: 3530, Train Loss: 0.6983\n",
      "Epoch [10/10], Batch: 3540, Train Loss: 0.6099\n",
      "Epoch [10/10], Batch: 3550, Train Loss: 0.7144\n",
      "Epoch [10/10], Batch: 3560, Train Loss: 0.8513\n",
      "Epoch [10/10], Batch: 3570, Train Loss: 0.8728\n",
      "Epoch [10/10], Batch: 3580, Train Loss: 0.6982\n",
      "Epoch [10/10], Batch: 3590, Train Loss: 0.7439\n",
      "Epoch [10/10], Batch: 3600, Train Loss: 0.8567\n",
      "Epoch [10/10], Batch: 3610, Train Loss: 0.6543\n",
      "Epoch [10/10], Batch: 3620, Train Loss: 0.7467\n",
      "Epoch [10/10], Batch: 3630, Train Loss: 0.8109\n",
      "Epoch [10/10], Batch: 3640, Train Loss: 0.6621\n",
      "Epoch [10/10], Batch: 3650, Train Loss: 0.6862\n",
      "Epoch [10/10], Batch: 3660, Train Loss: 0.7051\n",
      "Epoch [10/10], Batch: 3670, Train Loss: 0.6746\n",
      "Epoch [10/10], Batch: 3680, Train Loss: 0.8372\n",
      "Epoch [10/10], Batch: 3690, Train Loss: 0.7050\n",
      "Epoch [10/10], Batch: 3700, Train Loss: 0.8316\n",
      "Epoch [10/10], Batch: 3710, Train Loss: 0.7794\n",
      "Epoch [10/10], Batch: 3720, Train Loss: 0.7349\n",
      "Epoch [10/10], Batch: 3730, Train Loss: 0.5693\n",
      "Epoch [10/10], Batch: 3740, Train Loss: 0.6941\n",
      "Epoch [10/10], Batch: 3750, Train Loss: 0.6461\n",
      "Epoch [10/10], Batch: 3760, Train Loss: 0.6917\n",
      "Epoch [10/10], Batch: 3770, Train Loss: 0.7336\n",
      "Epoch [10/10], Batch: 3780, Train Loss: 0.7812\n",
      "Epoch [10/10], Batch: 3790, Train Loss: 0.7181\n",
      "Epoch [10/10], Batch: 3800, Train Loss: 0.6114\n",
      "Epoch [10/10], Batch: 3810, Train Loss: 0.6788\n",
      "Epoch [10/10], Batch: 3820, Train Loss: 0.7526\n",
      "Epoch [10/10], Batch: 3830, Train Loss: 0.6213\n",
      "Epoch [10/10], Batch: 3840, Train Loss: 0.7292\n",
      "Epoch [10/10], Batch: 3850, Train Loss: 0.6934\n",
      "Epoch [10/10], Batch: 3860, Train Loss: 0.7210\n",
      "Epoch [10/10], Batch: 3870, Train Loss: 0.7261\n",
      "Epoch [10/10], Batch: 3880, Train Loss: 0.7804\n",
      "Epoch [10/10], Batch: 3890, Train Loss: 0.8249\n",
      "Epoch [10/10], Batch: 3900, Train Loss: 0.7293\n",
      "Epoch [10/10], Batch: 3910, Train Loss: 0.8050\n",
      "Epoch [10/10], Batch: 3920, Train Loss: 0.7253\n",
      "Epoch [10/10], Batch: 3930, Train Loss: 0.8297\n",
      "Epoch [10/10], Batch: 3940, Train Loss: 0.7351\n",
      "Epoch [10/10], Batch: 3950, Train Loss: 0.7568\n",
      "Epoch [10/10], Batch: 3960, Train Loss: 0.8948\n",
      "Epoch [10/10], Batch: 3970, Train Loss: 0.6321\n",
      "Epoch [10/10], Batch: 3980, Train Loss: 0.7492\n",
      "Epoch [10/10], Batch: 3990, Train Loss: 0.5908\n",
      "Epoch [10/10], Batch: 4000, Train Loss: 0.7025\n",
      "Epoch [10/10], Batch: 4010, Train Loss: 0.8032\n",
      "Epoch [10/10], Batch: 4020, Train Loss: 0.6930\n",
      "Epoch [10/10], Batch: 4030, Train Loss: 0.8189\n",
      "Epoch [10/10], Batch: 4040, Train Loss: 0.6574\n",
      "Epoch [10/10], Batch: 4050, Train Loss: 0.6194\n",
      "Epoch [10/10], Batch: 4060, Train Loss: 0.6448\n",
      "Epoch [10/10], Batch: 4070, Train Loss: 0.6712\n",
      "Epoch [10/10], Batch: 4080, Train Loss: 0.7838\n",
      "Epoch [10/10], Batch: 4090, Train Loss: 0.7124\n",
      "Epoch [10/10], Batch: 4100, Train Loss: 0.7697\n",
      "Epoch [10/10], Batch: 4110, Train Loss: 0.7558\n",
      "Epoch [10/10], Batch: 4120, Train Loss: 0.7435\n",
      "Epoch [10/10], Batch: 4130, Train Loss: 0.7650\n",
      "Epoch [10/10], Batch: 4140, Train Loss: 0.8340\n",
      "Epoch [10/10], Batch: 4150, Train Loss: 0.5773\n",
      "Epoch [10/10], Batch: 4160, Train Loss: 0.6416\n",
      "Epoch [10/10], Batch: 4170, Train Loss: 0.6570\n",
      "Epoch [10/10], Batch: 4180, Train Loss: 0.5985\n",
      "Epoch [10/10], Batch: 4190, Train Loss: 0.7464\n",
      "Epoch [10/10], Batch: 4200, Train Loss: 0.5992\n",
      "Epoch [10/10], Batch: 4210, Train Loss: 0.8078\n",
      "Epoch [10/10], Batch: 4220, Train Loss: 0.6971\n",
      "Epoch [10/10], Batch: 4230, Train Loss: 0.7879\n",
      "Epoch [10/10], Batch: 4240, Train Loss: 0.6371\n",
      "Epoch [10/10], Batch: 4250, Train Loss: 0.7233\n",
      "Epoch [10/10], Batch: 4260, Train Loss: 0.6745\n",
      "Epoch [10/10], Batch: 4270, Train Loss: 0.8556\n",
      "Epoch [10/10], Batch: 4280, Train Loss: 0.7341\n",
      "Epoch [10/10], Batch: 4290, Train Loss: 0.8026\n",
      "Epoch [10/10], Batch: 4300, Train Loss: 0.6228\n",
      "Epoch [10/10], Batch: 4310, Train Loss: 0.7294\n",
      "Epoch [10/10], Batch: 4320, Train Loss: 0.7040\n",
      "Epoch [10/10], Batch: 4330, Train Loss: 0.7536\n",
      "Epoch [10/10], Batch: 4340, Train Loss: 0.8221\n",
      "Epoch [10/10], Batch: 4350, Train Loss: 0.5589\n",
      "Epoch [10/10], Batch: 4360, Train Loss: 0.6035\n",
      "Epoch [10/10], Batch: 4370, Train Loss: 0.9358\n",
      "Epoch [10/10], Batch: 4380, Train Loss: 0.7115\n",
      "Epoch [10/10], Batch: 4390, Train Loss: 0.7722\n",
      "Epoch [10/10], Batch: 4400, Train Loss: 0.7290\n",
      "Epoch [10/10], Batch: 4410, Train Loss: 0.6535\n",
      "Epoch [10/10], Batch: 4420, Train Loss: 0.9499\n",
      "Epoch [10/10], Batch: 4430, Train Loss: 0.7659\n",
      "Epoch [10/10], Batch: 4440, Train Loss: 0.8031\n",
      "Epoch [10/10], Batch: 4450, Train Loss: 0.6633\n",
      "Epoch [10/10], Batch: 4460, Train Loss: 0.7307\n",
      "Epoch [10/10], Batch: 4470, Train Loss: 0.5743\n",
      "Epoch [10/10], Batch: 4480, Train Loss: 0.7337\n",
      "Epoch [10/10], Batch: 4490, Train Loss: 0.7426\n",
      "Epoch [10/10], Batch: 4500, Train Loss: 0.7658\n",
      "Epoch [10/10], Batch: 4510, Train Loss: 0.6490\n",
      "Epoch [10/10], Batch: 4520, Train Loss: 0.6526\n",
      "Epoch [10/10], Batch: 4530, Train Loss: 0.6032\n",
      "Epoch [10/10], Batch: 4540, Train Loss: 0.7344\n",
      "Epoch [10/10], Batch: 4550, Train Loss: 0.6779\n",
      "Epoch [10/10], Batch: 4560, Train Loss: 0.7921\n",
      "Epoch [10/10], Batch: 4570, Train Loss: 0.6414\n",
      "Epoch [10/10], Batch: 4580, Train Loss: 0.7760\n",
      "Epoch [10/10], Batch: 4590, Train Loss: 0.6146\n",
      "Epoch [10/10], Batch: 4600, Train Loss: 0.6476\n",
      "Epoch [10/10], Batch: 4610, Train Loss: 0.6658\n",
      "Epoch [10/10], Batch: 4620, Train Loss: 0.7074\n",
      "Epoch [10/10], Batch: 4630, Train Loss: 0.5592\n",
      "Epoch [10/10], Batch: 4640, Train Loss: 0.7512\n",
      "Epoch [10/10], Batch: 4650, Train Loss: 0.7992\n",
      "Epoch [10/10], Batch: 4660, Train Loss: 0.7000\n",
      "Epoch [10/10], Batch: 4670, Train Loss: 0.8180\n",
      "Epoch [10/10], Batch: 4680, Train Loss: 0.6967\n",
      "Epoch [10/10], Batch: 4690, Train Loss: 0.7677\n",
      "Epoch [10/10], Batch: 4700, Train Loss: 0.8577\n",
      "Epoch [10/10], Batch: 4710, Train Loss: 0.6350\n",
      "Epoch [10/10], Batch: 4720, Train Loss: 0.6491\n",
      "Epoch [10/10], Batch: 4730, Train Loss: 0.8712\n",
      "Epoch [10/10], Batch: 4740, Train Loss: 0.6034\n",
      "Epoch [10/10], Batch: 4750, Train Loss: 0.6258\n",
      "Epoch [10/10], Batch: 4760, Train Loss: 0.6801\n",
      "Epoch [10/10], Batch: 4770, Train Loss: 0.6430\n",
      "Epoch [10/10], Batch: 4780, Train Loss: 0.6907\n",
      "Epoch [10/10], Batch: 4790, Train Loss: 0.7284\n",
      "Epoch [10/10], Batch: 4800, Train Loss: 0.7380\n",
      "Epoch [10/10], Batch: 4810, Train Loss: 0.6456\n",
      "Epoch [10/10], Batch: 4820, Train Loss: 0.7684\n",
      "Epoch [10/10], Batch: 4830, Train Loss: 0.6148\n",
      "Epoch [10/10], Batch: 4840, Train Loss: 0.7558\n",
      "Epoch [10/10], Batch: 4850, Train Loss: 0.6525\n",
      "Epoch [10/10], Batch: 4860, Train Loss: 0.7433\n",
      "Epoch [10/10], Batch: 4870, Train Loss: 0.6989\n",
      "Epoch [10/10], Batch: 4880, Train Loss: 0.6775\n",
      "Epoch [10/10], Batch: 4890, Train Loss: 0.8031\n",
      "Epoch [10/10], Batch: 4900, Train Loss: 0.9120\n",
      "Epoch [10/10], Batch: 4910, Train Loss: 0.6814\n",
      "Epoch [10/10], Batch: 4920, Train Loss: 0.5935\n",
      "Epoch [10/10], Batch: 4930, Train Loss: 0.7844\n",
      "Epoch [10/10], Batch: 4940, Train Loss: 0.6713\n",
      "Epoch [10/10], Batch: 4950, Train Loss: 0.6864\n",
      "Epoch [10/10], Batch: 4960, Train Loss: 0.6497\n",
      "Epoch [10/10], Batch: 4970, Train Loss: 0.7619\n",
      "Epoch [10/10], Batch: 4980, Train Loss: 0.7652\n",
      "Epoch [10/10], Batch: 4990, Train Loss: 0.7395\n",
      "Epoch [10/10], Batch: 5000, Train Loss: 0.5477\n",
      "Epoch [10/10], Batch: 5010, Train Loss: 0.8618\n",
      "Epoch [10/10], Batch: 5020, Train Loss: 0.7682\n",
      "Epoch [10/10], Batch: 5030, Train Loss: 0.7359\n",
      "Epoch [10/10], Batch: 5040, Train Loss: 0.8569\n",
      "Epoch [10/10], Batch: 5050, Train Loss: 0.7155\n",
      "Epoch [10/10], Batch: 5060, Train Loss: 0.7172\n",
      "Epoch [10/10], Batch: 5070, Train Loss: 0.7246\n",
      "Epoch [10/10], Batch: 5080, Train Loss: 0.6523\n",
      "Epoch [10/10], Batch: 5090, Train Loss: 0.6090\n",
      "Epoch [10/10], Batch: 5100, Train Loss: 0.6711\n",
      "Epoch [10/10], Batch: 5110, Train Loss: 0.7871\n",
      "Epoch [10/10], Batch: 5120, Train Loss: 0.5854\n",
      "Epoch [10/10], Batch: 5130, Train Loss: 0.6380\n",
      "Epoch [10/10], Batch: 5140, Train Loss: 0.9346\n",
      "Epoch [10/10], Batch: 5150, Train Loss: 0.7495\n",
      "Epoch [10/10], Batch: 5160, Train Loss: 0.8737\n",
      "Epoch [10/10], Batch: 5170, Train Loss: 0.7707\n",
      "Epoch [10/10], Batch: 5180, Train Loss: 0.7485\n",
      "Epoch [10/10], Batch: 5190, Train Loss: 0.6597\n",
      "Epoch [10/10], Batch: 5200, Train Loss: 0.6832\n",
      "Epoch [10/10], Batch: 5210, Train Loss: 0.6984\n",
      "Epoch [10/10], Batch: 5220, Train Loss: 0.8593\n",
      "Epoch [10/10], Batch: 5230, Train Loss: 0.6435\n",
      "Epoch [10/10], Batch: 5240, Train Loss: 0.7686\n",
      "Epoch [10/10], Batch: 5250, Train Loss: 0.8487\n",
      "Epoch [10/10], Batch: 5260, Train Loss: 0.8221\n",
      "Epoch [10/10], Batch: 5270, Train Loss: 0.7201\n",
      "Epoch [10/10], Batch: 5280, Train Loss: 0.6334\n",
      "Epoch [10/10], Batch: 5290, Train Loss: 0.8096\n",
      "Epoch [10/10], Batch: 5300, Train Loss: 0.8132\n",
      "Epoch [10/10], Batch: 5310, Train Loss: 0.6891\n",
      "Epoch [10/10], Batch: 5320, Train Loss: 0.6325\n",
      "Epoch [10/10], Batch: 5330, Train Loss: 0.6274\n",
      "Epoch [10/10], Batch: 5340, Train Loss: 0.7882\n",
      "Epoch [10/10], Batch: 5350, Train Loss: 0.6816\n",
      "Epoch [10/10], Batch: 5360, Train Loss: 0.7973\n",
      "Epoch [10/10], Batch: 5370, Train Loss: 0.6810\n",
      "Epoch [10/10], Batch: 5380, Train Loss: 0.7314\n",
      "Epoch [10/10], Batch: 5390, Train Loss: 0.7885\n",
      "Epoch [10/10], Batch: 5400, Train Loss: 0.7211\n",
      "Epoch [10/10], Batch: 5410, Train Loss: 0.8574\n",
      "Epoch [10/10], Batch: 5420, Train Loss: 0.6351\n",
      "Epoch [10/10], Batch: 5430, Train Loss: 0.6731\n",
      "Epoch [10/10], Batch: 5440, Train Loss: 0.7464\n",
      "Epoch [10/10], Batch: 5450, Train Loss: 0.7351\n",
      "Epoch [10/10], Batch: 5460, Train Loss: 0.7150\n",
      "Epoch [10/10], Batch: 5470, Train Loss: 0.6612\n",
      "Epoch [10/10], Batch: 5480, Train Loss: 0.5459\n",
      "Epoch [10/10], Batch: 5490, Train Loss: 0.6945\n",
      "Epoch [10/10], Batch: 5500, Train Loss: 0.7616\n",
      "Epoch [10/10], Batch: 5510, Train Loss: 0.8339\n",
      "Epoch [10/10], Batch: 5520, Train Loss: 0.7811\n",
      "Epoch [10/10], Batch: 5530, Train Loss: 0.7899\n",
      "Epoch [10/10], Batch: 5540, Train Loss: 0.7633\n",
      "Epoch [10/10], Batch: 5550, Train Loss: 0.7922\n",
      "Epoch [10/10], Batch: 5560, Train Loss: 0.6774\n",
      "Epoch [10/10], Batch: 5570, Train Loss: 0.7473\n",
      "Epoch [10/10], Batch: 5580, Train Loss: 0.6392\n",
      "Epoch [10/10], Batch: 5590, Train Loss: 0.7929\n",
      "Epoch [10/10], Batch: 5600, Train Loss: 0.6069\n",
      "Epoch [10/10], Batch: 5610, Train Loss: 0.7528\n",
      "Epoch [10/10], Batch: 5620, Train Loss: 0.8945\n",
      "Epoch [10/10], Batch: 5630, Train Loss: 0.7577\n",
      "Epoch [10/10], Batch: 5640, Train Loss: 0.7957\n",
      "Epoch [10/10], Batch: 5650, Train Loss: 0.7034\n",
      "Epoch [10/10], Batch: 5660, Train Loss: 0.6051\n",
      "Epoch [10/10], Batch: 5670, Train Loss: 0.7793\n",
      "Epoch [10/10], Batch: 5680, Train Loss: 0.7680\n",
      "Epoch [10/10], Batch: 5690, Train Loss: 0.7389\n",
      "Epoch [10/10], Batch: 5700, Train Loss: 0.5725\n",
      "Epoch [10/10], Batch: 5710, Train Loss: 0.8259\n",
      "Epoch [10/10], Batch: 5720, Train Loss: 0.8682\n",
      "Epoch [10/10], Batch: 5730, Train Loss: 0.6773\n",
      "Epoch [10/10], Batch: 5740, Train Loss: 0.7075\n",
      "Epoch [10/10], Batch: 5750, Train Loss: 0.7536\n",
      "Epoch [10/10], Batch: 5760, Train Loss: 0.9460\n",
      "Epoch [10/10], Batch: 5770, Train Loss: 0.7349\n",
      "Epoch [10/10], Batch: 5780, Train Loss: 0.8595\n",
      "Epoch [10/10], Batch: 5790, Train Loss: 0.8091\n",
      "Epoch [10/10], Batch: 5800, Train Loss: 0.7278\n",
      "Epoch [10/10], Batch: 5810, Train Loss: 0.7267\n",
      "Epoch [10/10], Batch: 5820, Train Loss: 0.8061\n",
      "Epoch [10/10], Batch: 5830, Train Loss: 0.7450\n",
      "Epoch [10/10], Batch: 5840, Train Loss: 0.6236\n",
      "Epoch [10/10], Batch: 5850, Train Loss: 0.6650\n",
      "Epoch [10/10], Batch: 5860, Train Loss: 0.6870\n",
      "Epoch [10/10], Batch: 5870, Train Loss: 0.6274\n",
      "Epoch [10/10], Batch: 5880, Train Loss: 0.8019\n",
      "Epoch [10/10], Batch: 5890, Train Loss: 0.7248\n",
      "Epoch [10/10], Batch: 5900, Train Loss: 0.7227\n",
      "Epoch [10/10], Batch: 5910, Train Loss: 0.7968\n",
      "Epoch [10/10], Batch: 5920, Train Loss: 0.7296\n",
      "Epoch [10/10], Batch: 5930, Train Loss: 0.9138\n",
      "Epoch [10/10], Batch: 5940, Train Loss: 0.7831\n",
      "Epoch [10/10], Batch: 5950, Train Loss: 0.6874\n",
      "Epoch [10/10], Batch: 5960, Train Loss: 0.7801\n",
      "Epoch [10/10], Batch: 5970, Train Loss: 0.7630\n",
      "Epoch [10/10], Batch: 5980, Train Loss: 0.7116\n",
      "Epoch [10/10], Batch: 5990, Train Loss: 0.8216\n",
      "Epoch [10/10], Batch: 6000, Train Loss: 0.6868\n",
      "Epoch [10/10], Batch: 6010, Train Loss: 0.8503\n",
      "Epoch [10/10], Batch: 6020, Train Loss: 0.7085\n",
      "Epoch [10/10], Batch: 6030, Train Loss: 0.8899\n",
      "Epoch [10/10], Batch: 6040, Train Loss: 0.7729\n",
      "Epoch [10/10], Batch: 6050, Train Loss: 0.7537\n",
      "Epoch [10/10], Batch: 6060, Train Loss: 0.7749\n",
      "Epoch [10/10], Batch: 6070, Train Loss: 0.6089\n",
      "Epoch [10/10], Batch: 6080, Train Loss: 0.6719\n",
      "Epoch [10/10], Batch: 6090, Train Loss: 0.6052\n",
      "Epoch [10/10], Batch: 6100, Train Loss: 0.6804\n",
      "Epoch [10/10], Batch: 6110, Train Loss: 0.7160\n",
      "Epoch [10/10], Batch: 6120, Train Loss: 0.6200\n",
      "Epoch [10/10], Batch: 6130, Train Loss: 0.7366\n",
      "Epoch [10/10], Batch: 6140, Train Loss: 0.7147\n",
      "Epoch [10/10], Batch: 6150, Train Loss: 0.7018\n",
      "Epoch [10/10], Batch: 6160, Train Loss: 0.8863\n",
      "Epoch [10/10], Batch: 6170, Train Loss: 0.8082\n",
      "Epoch [10/10], Batch: 6180, Train Loss: 0.7263\n",
      "Epoch [10/10], Batch: 6190, Train Loss: 0.7729\n",
      "Epoch [10/10], Batch: 6200, Train Loss: 0.7301\n",
      "Epoch [10/10], Batch: 6210, Train Loss: 0.7132\n",
      "Epoch [10/10], Batch: 6220, Train Loss: 0.7416\n",
      "Epoch [10/10], Batch: 6230, Train Loss: 0.7345\n",
      "Epoch [10/10], Batch: 6240, Train Loss: 0.8080\n",
      "Epoch [10/10], Batch: 6250, Train Loss: 0.8205\n",
      "Epoch [10/10], Batch: 6260, Train Loss: 0.7742\n",
      "Epoch [10/10], Batch: 6270, Train Loss: 0.7466\n",
      "Epoch [10/10], Batch: 6280, Train Loss: 0.8087\n",
      "Epoch [10/10], Batch: 6290, Train Loss: 0.6694\n",
      "Epoch [10/10], Batch: 6300, Train Loss: 0.6202\n",
      "Epoch [10/10], Batch: 6310, Train Loss: 0.7207\n",
      "Epoch [10/10], Batch: 6320, Train Loss: 0.8699\n",
      "Epoch [10/10], Batch: 6330, Train Loss: 0.7290\n",
      "Epoch [10/10], Batch: 6340, Train Loss: 0.8053\n",
      "Epoch [10/10], Batch: 6350, Train Loss: 0.8868\n",
      "Epoch [10/10], Batch: 6360, Train Loss: 0.7698\n",
      "Epoch [10/10], Batch: 6370, Train Loss: 0.6624\n",
      "Epoch [10/10], Batch: 6380, Train Loss: 0.7201\n",
      "Epoch [10/10], Batch: 6390, Train Loss: 0.6708\n",
      "Epoch [10/10], Batch: 6400, Train Loss: 0.7779\n",
      "Epoch [10/10], Batch: 6410, Train Loss: 0.6774\n",
      "Epoch [10/10], Batch: 6420, Train Loss: 0.7129\n",
      "Epoch [10/10], Batch: 6430, Train Loss: 0.6710\n",
      "Epoch [10/10], Batch: 6440, Train Loss: 0.7382\n",
      "Epoch [10/10], Batch: 6450, Train Loss: 0.7752\n",
      "Epoch [10/10], Batch: 6460, Train Loss: 0.7201\n",
      "Epoch [10/10], Batch: 6470, Train Loss: 0.7103\n",
      "Epoch [10/10], Batch: 6480, Train Loss: 0.7433\n",
      "Epoch [10/10], Batch: 6490, Train Loss: 0.6469\n",
      "Epoch [10/10], Batch: 6500, Train Loss: 0.7321\n",
      "Epoch [10/10], Batch: 6510, Train Loss: 0.6345\n",
      "Epoch [10/10], Batch: 6520, Train Loss: 0.6287\n",
      "Epoch [10/10], Batch: 6530, Train Loss: 0.6498\n",
      "Epoch [10/10], Batch: 6540, Train Loss: 0.6320\n",
      "Epoch [10/10], Batch: 6550, Train Loss: 0.8086\n",
      "Epoch [10/10], Batch: 6560, Train Loss: 0.7016\n",
      "Epoch [10/10], Batch: 6570, Train Loss: 0.6994\n",
      "Epoch [10/10], Batch: 6580, Train Loss: 0.6851\n",
      "Epoch [10/10], Batch: 6590, Train Loss: 0.7832\n",
      "Epoch [10/10], Batch: 6600, Train Loss: 0.7958\n",
      "Epoch [10/10], Batch: 6610, Train Loss: 0.6982\n",
      "Epoch [10/10], Batch: 6620, Train Loss: 0.6481\n",
      "Epoch [10/10], Batch: 6630, Train Loss: 0.7735\n",
      "Epoch [10/10], Batch: 6640, Train Loss: 0.7904\n",
      "Epoch [10/10], Batch: 6650, Train Loss: 0.7145\n",
      "Epoch [10/10], Batch: 6660, Train Loss: 0.8673\n",
      "Epoch [10/10], Batch: 6670, Train Loss: 0.6564\n",
      "Epoch [10/10], Batch: 6680, Train Loss: 0.7818\n",
      "Epoch [10/10], Batch: 6690, Train Loss: 0.7155\n",
      "Epoch [10/10], Batch: 6700, Train Loss: 0.7776\n",
      "Epoch [10/10], Batch: 6710, Train Loss: 0.8261\n",
      "Epoch [10/10], Batch: 6720, Train Loss: 0.6494\n",
      "Epoch [10/10], Batch: 6730, Train Loss: 0.5873\n",
      "Epoch [10/10], Batch: 6740, Train Loss: 0.7002\n",
      "Epoch [10/10], Batch: 6750, Train Loss: 0.5963\n",
      "Epoch [10/10], Batch: 6760, Train Loss: 0.7139\n",
      "Epoch [10/10], Train Loss: 6.1866, Test Loss: 0.7265\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    Towers.train() \n",
    "    train_loss = 0.0\n",
    "\n",
    "    i = 0\n",
    "    for batch in TrainingDataloader:\n",
    "        i +=1\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the model to get embeddings\n",
    "        query_embeddings, relevant_doc_embeddings, irrelevant_doc_embeddings = Towers(\n",
    "            batch['query'], \n",
    "            batch['relevant'], \n",
    "            batch['irrelevant']\n",
    "        )\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = triplet_loss_function_cosine(query_embeddings, relevant_doc_embeddings, irrelevant_doc_embeddings, margin)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        if (i) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch: {i}, Train Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # break\n",
    "    \n",
    "# Testing phase\n",
    "Towers.eval()  # Set model to evaluation mode\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():  # No need to track gradients for testing\n",
    "    for batch in TestingDataloader:\n",
    "        query_embeddings, relevant_doc_embeddings, irrelevant_doc_embeddings = Towers(\n",
    "            batch['query'], \n",
    "            batch['relevant'], \n",
    "            batch['irrelevant']\n",
    "        )\n",
    "        \n",
    "        loss = triplet_loss_function_cosine(query_embeddings, relevant_doc_embeddings, irrelevant_doc_embeddings, margin)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "avg_train_loss = train_loss / len(TestingDataloader)\n",
    "avg_test_loss = test_loss / len(TestingDataloader)\n",
    "    \n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'AlexTwoTowersDictLocal.pth'\n",
    "torch.save(Towers.state_dict(), 'AlexTwoTowersDictLocal.pth')\n",
    "torch.save(Towers, 'AlexTwoTowersLocal.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lib Collection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LibDocsCollection(databases):\n",
    "    documents = []\n",
    "    for database in databases:\n",
    "        for index, row in database.iterrows():\n",
    "            for doc in row['passages']['passage_text']:\n",
    "               documents.append(doc)\n",
    "    documents = pd.DataFrame(documents, columns=['document'])\n",
    "    unique_documents = documents.drop_duplicates(subset=['document']).reset_index(drop=True)\n",
    "    print(documents.shape)\n",
    "    print(unique_documents.shape)\n",
    "    return unique_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Libriary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(837729, 1)\n",
      "(767675, 1)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet('train.parquet')\n",
    "test = pd.read_parquet('test.parquet')\n",
    "validate = pd.read_parquet('validate.parquet')\n",
    "\n",
    "libriary = LibDocsCollection([train, test, validate])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoloDataset(Dataset):\n",
    "    def __init__(self, sp, texts, device):\n",
    "        self.texts = texts\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def to_w2v_embedding(self, sp, text):\n",
    "        tokens = sp.encode_as_pieces(text.lower())\n",
    "\n",
    "        embeddings = []\n",
    "        for token in tokens:\n",
    "            if (token in w2v_model.wv): \n",
    "                embeddings.append(w2v_model.wv[token])\n",
    "\n",
    "        return np.stack(embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.to_w2v_embedding(sp, self.texts.iloc[idx]['document']), dtype=torch.float, device=self.device)\n",
    "    \n",
    "def solo_collate_fn(batch):\n",
    "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=0)\n",
    "    return padded_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docs Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocsDataset = SoloDataset(sp, libriary, device)\n",
    "\n",
    "batch_size = 100\n",
    "docsEmbeddingsDataloader = DataLoader(DocsDataset, batch_size, shuffle=False, collate_fn=solo_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Towers = torch.load('AlexTwoTowersLocal.pth', map_location=device)\n",
    "# OR Load the model's state dictionary (Testing the same)\n",
    "Towers.load_state_dict(torch.load('AlexTwoTowersDictLocal.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode All Documents in Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "Batch: 74\n",
      "Batch: 75\n",
      "Batch: 76\n",
      "Batch: 77\n",
      "Batch: 78\n",
      "Batch: 79\n",
      "Batch: 80\n",
      "Batch: 81\n",
      "Batch: 82\n",
      "Batch: 83\n",
      "Batch: 84\n",
      "Batch: 85\n",
      "Batch: 86\n",
      "Batch: 87\n",
      "Batch: 88\n",
      "Batch: 89\n",
      "Batch: 90\n",
      "Batch: 91\n",
      "Batch: 92\n",
      "Batch: 93\n",
      "Batch: 94\n",
      "Batch: 95\n",
      "Batch: 96\n",
      "Batch: 97\n",
      "Batch: 98\n",
      "Batch: 99\n",
      "Batch: 100\n",
      "Batch: 101\n",
      "Batch: 102\n",
      "Batch: 103\n",
      "Batch: 104\n",
      "Batch: 105\n",
      "Batch: 106\n",
      "Batch: 107\n",
      "Batch: 108\n",
      "Batch: 109\n",
      "Batch: 110\n",
      "Batch: 111\n",
      "Batch: 112\n",
      "Batch: 113\n",
      "Batch: 114\n",
      "Batch: 115\n",
      "Batch: 116\n",
      "Batch: 117\n",
      "Batch: 118\n",
      "Batch: 119\n",
      "Batch: 120\n",
      "Batch: 121\n",
      "Batch: 122\n",
      "Batch: 123\n",
      "Batch: 124\n",
      "Batch: 125\n",
      "Batch: 126\n",
      "Batch: 127\n",
      "Batch: 128\n",
      "Batch: 129\n",
      "Batch: 130\n",
      "Batch: 131\n",
      "Batch: 132\n",
      "Batch: 133\n",
      "Batch: 134\n",
      "Batch: 135\n",
      "Batch: 136\n",
      "Batch: 137\n",
      "Batch: 138\n",
      "Batch: 139\n",
      "Batch: 140\n",
      "Batch: 141\n",
      "Batch: 142\n",
      "Batch: 143\n",
      "Batch: 144\n",
      "Batch: 145\n",
      "Batch: 146\n",
      "Batch: 147\n",
      "Batch: 148\n",
      "Batch: 149\n",
      "Batch: 150\n",
      "Batch: 151\n",
      "Batch: 152\n",
      "Batch: 153\n",
      "Batch: 154\n",
      "Batch: 155\n",
      "Batch: 156\n",
      "Batch: 157\n",
      "Batch: 158\n",
      "Batch: 159\n",
      "Batch: 160\n",
      "Batch: 161\n",
      "Batch: 162\n",
      "Batch: 163\n",
      "Batch: 164\n",
      "Batch: 165\n",
      "Batch: 166\n",
      "Batch: 167\n",
      "Batch: 168\n",
      "Batch: 169\n",
      "Batch: 170\n",
      "Batch: 171\n",
      "Batch: 172\n",
      "Batch: 173\n",
      "Batch: 174\n",
      "Batch: 175\n",
      "Batch: 176\n",
      "Batch: 177\n",
      "Batch: 178\n",
      "Batch: 179\n",
      "Batch: 180\n",
      "Batch: 181\n",
      "Batch: 182\n",
      "Batch: 183\n",
      "Batch: 184\n",
      "Batch: 185\n",
      "Batch: 186\n",
      "Batch: 187\n",
      "Batch: 188\n",
      "Batch: 189\n",
      "Batch: 190\n",
      "Batch: 191\n",
      "Batch: 192\n",
      "Batch: 193\n",
      "Batch: 194\n",
      "Batch: 195\n",
      "Batch: 196\n",
      "Batch: 197\n",
      "Batch: 198\n",
      "Batch: 199\n",
      "Batch: 200\n",
      "Batch: 201\n",
      "Batch: 202\n",
      "Batch: 203\n",
      "Batch: 204\n",
      "Batch: 205\n",
      "Batch: 206\n",
      "Batch: 207\n",
      "Batch: 208\n",
      "Batch: 209\n",
      "Batch: 210\n",
      "Batch: 211\n",
      "Batch: 212\n",
      "Batch: 213\n",
      "Batch: 214\n",
      "Batch: 215\n",
      "Batch: 216\n",
      "Batch: 217\n",
      "Batch: 218\n",
      "Batch: 219\n",
      "Batch: 220\n",
      "Batch: 221\n",
      "Batch: 222\n",
      "Batch: 223\n",
      "Batch: 224\n",
      "Batch: 225\n",
      "Batch: 226\n",
      "Batch: 227\n",
      "Batch: 228\n",
      "Batch: 229\n",
      "Batch: 230\n",
      "Batch: 231\n",
      "Batch: 232\n",
      "Batch: 233\n",
      "Batch: 234\n",
      "Batch: 235\n",
      "Batch: 236\n",
      "Batch: 237\n",
      "Batch: 238\n",
      "Batch: 239\n",
      "Batch: 240\n",
      "Batch: 241\n",
      "Batch: 242\n",
      "Batch: 243\n",
      "Batch: 244\n",
      "Batch: 245\n",
      "Batch: 246\n",
      "Batch: 247\n",
      "Batch: 248\n",
      "Batch: 249\n",
      "Batch: 250\n",
      "Batch: 251\n",
      "Batch: 252\n",
      "Batch: 253\n",
      "Batch: 254\n",
      "Batch: 255\n",
      "Batch: 256\n",
      "Batch: 257\n",
      "Batch: 258\n",
      "Batch: 259\n",
      "Batch: 260\n",
      "Batch: 261\n",
      "Batch: 262\n",
      "Batch: 263\n",
      "Batch: 264\n",
      "Batch: 265\n",
      "Batch: 266\n",
      "Batch: 267\n",
      "Batch: 268\n",
      "Batch: 269\n",
      "Batch: 270\n",
      "Batch: 271\n",
      "Batch: 272\n",
      "Batch: 273\n",
      "Batch: 274\n",
      "Batch: 275\n",
      "Batch: 276\n",
      "Batch: 277\n",
      "Batch: 278\n",
      "Batch: 279\n",
      "Batch: 280\n",
      "Batch: 281\n",
      "Batch: 282\n",
      "Batch: 283\n",
      "Batch: 284\n",
      "Batch: 285\n",
      "Batch: 286\n",
      "Batch: 287\n",
      "Batch: 288\n",
      "Batch: 289\n",
      "Batch: 290\n",
      "Batch: 291\n",
      "Batch: 292\n",
      "Batch: 293\n",
      "Batch: 294\n",
      "Batch: 295\n",
      "Batch: 296\n",
      "Batch: 297\n",
      "Batch: 298\n",
      "Batch: 299\n",
      "Batch: 300\n",
      "Batch: 301\n",
      "Batch: 302\n",
      "Batch: 303\n",
      "Batch: 304\n",
      "Batch: 305\n",
      "Batch: 306\n",
      "Batch: 307\n",
      "Batch: 308\n",
      "Batch: 309\n",
      "Batch: 310\n",
      "Batch: 311\n",
      "Batch: 312\n",
      "Batch: 313\n",
      "Batch: 314\n",
      "Batch: 315\n",
      "Batch: 316\n",
      "Batch: 317\n",
      "Batch: 318\n",
      "Batch: 319\n",
      "Batch: 320\n",
      "Batch: 321\n",
      "Batch: 322\n",
      "Batch: 323\n",
      "Batch: 324\n",
      "Batch: 325\n",
      "Batch: 326\n",
      "Batch: 327\n",
      "Batch: 328\n",
      "Batch: 329\n",
      "Batch: 330\n",
      "Batch: 331\n",
      "Batch: 332\n",
      "Batch: 333\n",
      "Batch: 334\n",
      "Batch: 335\n",
      "Batch: 336\n",
      "Batch: 337\n",
      "Batch: 338\n",
      "Batch: 339\n",
      "Batch: 340\n",
      "Batch: 341\n",
      "Batch: 342\n",
      "Batch: 343\n",
      "Batch: 344\n",
      "Batch: 345\n",
      "Batch: 346\n",
      "Batch: 347\n",
      "Batch: 348\n",
      "Batch: 349\n",
      "Batch: 350\n",
      "Batch: 351\n",
      "Batch: 352\n",
      "Batch: 353\n",
      "Batch: 354\n",
      "Batch: 355\n",
      "Batch: 356\n",
      "Batch: 357\n",
      "Batch: 358\n",
      "Batch: 359\n",
      "Batch: 360\n",
      "Batch: 361\n",
      "Batch: 362\n",
      "Batch: 363\n",
      "Batch: 364\n",
      "Batch: 365\n",
      "Batch: 366\n",
      "Batch: 367\n",
      "Batch: 368\n",
      "Batch: 369\n",
      "Batch: 370\n",
      "Batch: 371\n",
      "Batch: 372\n",
      "Batch: 373\n",
      "Batch: 374\n",
      "Batch: 375\n",
      "Batch: 376\n",
      "Batch: 377\n",
      "Batch: 378\n",
      "Batch: 379\n",
      "Batch: 380\n",
      "Batch: 381\n",
      "Batch: 382\n",
      "Batch: 383\n",
      "Batch: 384\n",
      "Batch: 385\n",
      "Batch: 386\n",
      "Batch: 387\n",
      "Batch: 388\n",
      "Batch: 389\n",
      "Batch: 390\n",
      "Batch: 391\n",
      "Batch: 392\n",
      "Batch: 393\n",
      "Batch: 394\n",
      "Batch: 395\n",
      "Batch: 396\n",
      "Batch: 397\n",
      "Batch: 398\n",
      "Batch: 399\n",
      "Batch: 400\n",
      "Batch: 401\n",
      "Batch: 402\n",
      "Batch: 403\n",
      "Batch: 404\n",
      "Batch: 405\n",
      "Batch: 406\n",
      "Batch: 407\n",
      "Batch: 408\n",
      "Batch: 409\n",
      "Batch: 410\n",
      "Batch: 411\n",
      "Batch: 412\n",
      "Batch: 413\n",
      "Batch: 414\n",
      "Batch: 415\n",
      "Batch: 416\n",
      "Batch: 417\n",
      "Batch: 418\n",
      "Batch: 419\n",
      "Batch: 420\n",
      "Batch: 421\n",
      "Batch: 422\n",
      "Batch: 423\n",
      "Batch: 424\n",
      "Batch: 425\n",
      "Batch: 426\n",
      "Batch: 427\n",
      "Batch: 428\n",
      "Batch: 429\n",
      "Batch: 430\n",
      "Batch: 431\n",
      "Batch: 432\n",
      "Batch: 433\n",
      "Batch: 434\n",
      "Batch: 435\n",
      "Batch: 436\n",
      "Batch: 437\n",
      "Batch: 438\n",
      "Batch: 439\n",
      "Batch: 440\n",
      "Batch: 441\n",
      "Batch: 442\n",
      "Batch: 443\n",
      "Batch: 444\n",
      "Batch: 445\n",
      "Batch: 446\n",
      "Batch: 447\n",
      "Batch: 448\n",
      "Batch: 449\n",
      "Batch: 450\n",
      "Batch: 451\n",
      "Batch: 452\n",
      "Batch: 453\n",
      "Batch: 454\n",
      "Batch: 455\n",
      "Batch: 456\n",
      "Batch: 457\n",
      "Batch: 458\n",
      "Batch: 459\n",
      "Batch: 460\n",
      "Batch: 461\n",
      "Batch: 462\n",
      "Batch: 463\n",
      "Batch: 464\n",
      "Batch: 465\n",
      "Batch: 466\n",
      "Batch: 467\n",
      "Batch: 468\n",
      "Batch: 469\n",
      "Batch: 470\n",
      "Batch: 471\n",
      "Batch: 472\n",
      "Batch: 473\n",
      "Batch: 474\n",
      "Batch: 475\n",
      "Batch: 476\n",
      "Batch: 477\n",
      "Batch: 478\n",
      "Batch: 479\n",
      "Batch: 480\n",
      "Batch: 481\n",
      "Batch: 482\n",
      "Batch: 483\n",
      "Batch: 484\n",
      "Batch: 485\n",
      "Batch: 486\n",
      "Batch: 487\n",
      "Batch: 488\n",
      "Batch: 489\n",
      "Batch: 490\n",
      "Batch: 491\n",
      "Batch: 492\n",
      "Batch: 493\n",
      "Batch: 494\n",
      "Batch: 495\n",
      "Batch: 496\n",
      "Batch: 497\n",
      "Batch: 498\n",
      "Batch: 499\n",
      "Batch: 500\n",
      "Batch: 501\n",
      "Batch: 502\n",
      "Batch: 503\n",
      "Batch: 504\n",
      "Batch: 505\n",
      "Batch: 506\n",
      "Batch: 507\n",
      "Batch: 508\n",
      "Batch: 509\n",
      "Batch: 510\n",
      "Batch: 511\n",
      "Batch: 512\n",
      "Batch: 513\n",
      "Batch: 514\n",
      "Batch: 515\n",
      "Batch: 516\n",
      "Batch: 517\n",
      "Batch: 518\n",
      "Batch: 519\n",
      "Batch: 520\n",
      "Batch: 521\n",
      "Batch: 522\n",
      "Batch: 523\n",
      "Batch: 524\n",
      "Batch: 525\n",
      "Batch: 526\n",
      "Batch: 527\n",
      "Batch: 528\n",
      "Batch: 529\n",
      "Batch: 530\n",
      "Batch: 531\n",
      "Batch: 532\n",
      "Batch: 533\n",
      "Batch: 534\n",
      "Batch: 535\n",
      "Batch: 536\n",
      "Batch: 537\n",
      "Batch: 538\n",
      "Batch: 539\n",
      "Batch: 540\n",
      "Batch: 541\n",
      "Batch: 542\n",
      "Batch: 543\n",
      "Batch: 544\n",
      "Batch: 545\n",
      "Batch: 546\n",
      "Batch: 547\n",
      "Batch: 548\n",
      "Batch: 549\n",
      "Batch: 550\n",
      "Batch: 551\n",
      "Batch: 552\n",
      "Batch: 553\n",
      "Batch: 554\n",
      "Batch: 555\n",
      "Batch: 556\n",
      "Batch: 557\n",
      "Batch: 558\n",
      "Batch: 559\n",
      "Batch: 560\n",
      "Batch: 561\n",
      "Batch: 562\n",
      "Batch: 563\n",
      "Batch: 564\n",
      "Batch: 565\n",
      "Batch: 566\n",
      "Batch: 567\n",
      "Batch: 568\n",
      "Batch: 569\n",
      "Batch: 570\n",
      "Batch: 571\n",
      "Batch: 572\n",
      "Batch: 573\n",
      "Batch: 574\n",
      "Batch: 575\n",
      "Batch: 576\n",
      "Batch: 577\n",
      "Batch: 578\n",
      "Batch: 579\n",
      "Batch: 580\n",
      "Batch: 581\n",
      "Batch: 582\n",
      "Batch: 583\n",
      "Batch: 584\n",
      "Batch: 585\n",
      "Batch: 586\n",
      "Batch: 587\n",
      "Batch: 588\n",
      "Batch: 589\n",
      "Batch: 590\n",
      "Batch: 591\n",
      "Batch: 592\n",
      "Batch: 593\n",
      "Batch: 594\n",
      "Batch: 595\n",
      "Batch: 596\n",
      "Batch: 597\n",
      "Batch: 598\n",
      "Batch: 599\n",
      "Batch: 600\n",
      "Batch: 601\n",
      "Batch: 602\n",
      "Batch: 603\n",
      "Batch: 604\n",
      "Batch: 605\n",
      "Batch: 606\n",
      "Batch: 607\n",
      "Batch: 608\n",
      "Batch: 609\n",
      "Batch: 610\n",
      "Batch: 611\n",
      "Batch: 612\n",
      "Batch: 613\n",
      "Batch: 614\n",
      "Batch: 615\n",
      "Batch: 616\n",
      "Batch: 617\n",
      "Batch: 618\n",
      "Batch: 619\n",
      "Batch: 620\n",
      "Batch: 621\n",
      "Batch: 622\n",
      "Batch: 623\n",
      "Batch: 624\n",
      "Batch: 625\n",
      "Batch: 626\n",
      "Batch: 627\n",
      "Batch: 628\n",
      "Batch: 629\n",
      "Batch: 630\n",
      "Batch: 631\n",
      "Batch: 632\n",
      "Batch: 633\n",
      "Batch: 634\n",
      "Batch: 635\n",
      "Batch: 636\n",
      "Batch: 637\n",
      "Batch: 638\n",
      "Batch: 639\n",
      "Batch: 640\n",
      "Batch: 641\n",
      "Batch: 642\n",
      "Batch: 643\n",
      "Batch: 644\n",
      "Batch: 645\n",
      "Batch: 646\n",
      "Batch: 647\n",
      "Batch: 648\n",
      "Batch: 649\n",
      "Batch: 650\n",
      "Batch: 651\n",
      "Batch: 652\n",
      "Batch: 653\n",
      "Batch: 654\n",
      "Batch: 655\n",
      "Batch: 656\n",
      "Batch: 657\n",
      "Batch: 658\n",
      "Batch: 659\n",
      "Batch: 660\n",
      "Batch: 661\n",
      "Batch: 662\n",
      "Batch: 663\n",
      "Batch: 664\n",
      "Batch: 665\n",
      "Batch: 666\n",
      "Batch: 667\n",
      "Batch: 668\n",
      "Batch: 669\n",
      "Batch: 670\n",
      "Batch: 671\n",
      "Batch: 672\n",
      "Batch: 673\n",
      "Batch: 674\n",
      "Batch: 675\n",
      "Batch: 676\n",
      "Batch: 677\n",
      "Batch: 678\n",
      "Batch: 679\n",
      "Batch: 680\n",
      "Batch: 681\n",
      "Batch: 682\n",
      "Batch: 683\n",
      "Batch: 684\n",
      "Batch: 685\n",
      "Batch: 686\n",
      "Batch: 687\n",
      "Batch: 688\n",
      "Batch: 689\n",
      "Batch: 690\n",
      "Batch: 691\n",
      "Batch: 692\n",
      "Batch: 693\n",
      "Batch: 694\n",
      "Batch: 695\n",
      "Batch: 696\n",
      "Batch: 697\n",
      "Batch: 698\n",
      "Batch: 699\n",
      "Batch: 700\n",
      "Batch: 701\n",
      "Batch: 702\n",
      "Batch: 703\n",
      "Batch: 704\n",
      "Batch: 705\n",
      "Batch: 706\n",
      "Batch: 707\n",
      "Batch: 708\n",
      "Batch: 709\n",
      "Batch: 710\n",
      "Batch: 711\n",
      "Batch: 712\n",
      "Batch: 713\n",
      "Batch: 714\n",
      "Batch: 715\n",
      "Batch: 716\n",
      "Batch: 717\n",
      "Batch: 718\n",
      "Batch: 719\n",
      "Batch: 720\n",
      "Batch: 721\n",
      "Batch: 722\n",
      "Batch: 723\n",
      "Batch: 724\n",
      "Batch: 725\n",
      "Batch: 726\n",
      "Batch: 727\n",
      "Batch: 728\n",
      "Batch: 729\n",
      "Batch: 730\n",
      "Batch: 731\n",
      "Batch: 732\n",
      "Batch: 733\n",
      "Batch: 734\n",
      "Batch: 735\n",
      "Batch: 736\n",
      "Batch: 737\n",
      "Batch: 738\n",
      "Batch: 739\n",
      "Batch: 740\n",
      "Batch: 741\n",
      "Batch: 742\n",
      "Batch: 743\n",
      "Batch: 744\n",
      "Batch: 745\n",
      "Batch: 746\n",
      "Batch: 747\n",
      "Batch: 748\n",
      "Batch: 749\n",
      "Batch: 750\n",
      "Batch: 751\n",
      "Batch: 752\n",
      "Batch: 753\n",
      "Batch: 754\n",
      "Batch: 755\n",
      "Batch: 756\n",
      "Batch: 757\n",
      "Batch: 758\n",
      "Batch: 759\n",
      "Batch: 760\n",
      "Batch: 761\n",
      "Batch: 762\n",
      "Batch: 763\n",
      "Batch: 764\n",
      "Batch: 765\n",
      "Batch: 766\n",
      "Batch: 767\n",
      "Batch: 768\n",
      "Batch: 769\n",
      "Batch: 770\n",
      "Batch: 771\n",
      "Batch: 772\n",
      "Batch: 773\n",
      "Batch: 774\n",
      "Batch: 775\n",
      "Batch: 776\n",
      "Batch: 777\n",
      "Batch: 778\n",
      "Batch: 779\n",
      "Batch: 780\n",
      "Batch: 781\n",
      "Batch: 782\n",
      "Batch: 783\n",
      "Batch: 784\n",
      "Batch: 785\n",
      "Batch: 786\n",
      "Batch: 787\n",
      "Batch: 788\n",
      "Batch: 789\n",
      "Batch: 790\n",
      "Batch: 791\n",
      "Batch: 792\n",
      "Batch: 793\n",
      "Batch: 794\n",
      "Batch: 795\n",
      "Batch: 796\n",
      "Batch: 797\n",
      "Batch: 798\n",
      "Batch: 799\n",
      "Batch: 800\n",
      "Batch: 801\n",
      "Batch: 802\n",
      "Batch: 803\n",
      "Batch: 804\n",
      "Batch: 805\n",
      "Batch: 806\n",
      "Batch: 807\n",
      "Batch: 808\n",
      "Batch: 809\n",
      "Batch: 810\n",
      "Batch: 811\n",
      "Batch: 812\n",
      "Batch: 813\n",
      "Batch: 814\n",
      "Batch: 815\n",
      "Batch: 816\n",
      "Batch: 817\n",
      "Batch: 818\n",
      "Batch: 819\n",
      "Batch: 820\n",
      "Batch: 821\n",
      "Batch: 822\n",
      "Batch: 823\n",
      "Batch: 824\n",
      "Batch: 825\n",
      "Batch: 826\n",
      "Batch: 827\n",
      "Batch: 828\n",
      "Batch: 829\n",
      "Batch: 830\n",
      "Batch: 831\n",
      "Batch: 832\n",
      "Batch: 833\n",
      "Batch: 834\n",
      "Batch: 835\n",
      "Batch: 836\n",
      "Batch: 837\n",
      "Batch: 838\n",
      "Batch: 839\n",
      "Batch: 840\n",
      "Batch: 841\n",
      "Batch: 842\n",
      "Batch: 843\n",
      "Batch: 844\n",
      "Batch: 845\n",
      "Batch: 846\n",
      "Batch: 847\n",
      "Batch: 848\n",
      "Batch: 849\n",
      "Batch: 850\n",
      "Batch: 851\n",
      "Batch: 852\n",
      "Batch: 853\n",
      "Batch: 854\n",
      "Batch: 855\n",
      "Batch: 856\n",
      "Batch: 857\n",
      "Batch: 858\n",
      "Batch: 859\n",
      "Batch: 860\n",
      "Batch: 861\n",
      "Batch: 862\n",
      "Batch: 863\n",
      "Batch: 864\n",
      "Batch: 865\n",
      "Batch: 866\n",
      "Batch: 867\n",
      "Batch: 868\n",
      "Batch: 869\n",
      "Batch: 870\n",
      "Batch: 871\n",
      "Batch: 872\n",
      "Batch: 873\n",
      "Batch: 874\n",
      "Batch: 875\n",
      "Batch: 876\n",
      "Batch: 877\n",
      "Batch: 878\n",
      "Batch: 879\n",
      "Batch: 880\n",
      "Batch: 881\n",
      "Batch: 882\n",
      "Batch: 883\n",
      "Batch: 884\n",
      "Batch: 885\n",
      "Batch: 886\n",
      "Batch: 887\n",
      "Batch: 888\n",
      "Batch: 889\n",
      "Batch: 890\n",
      "Batch: 891\n",
      "Batch: 892\n",
      "Batch: 893\n",
      "Batch: 894\n",
      "Batch: 895\n",
      "Batch: 896\n",
      "Batch: 897\n",
      "Batch: 898\n",
      "Batch: 899\n",
      "Batch: 900\n",
      "Batch: 901\n",
      "Batch: 902\n",
      "Batch: 903\n",
      "Batch: 904\n",
      "Batch: 905\n",
      "Batch: 906\n",
      "Batch: 907\n",
      "Batch: 908\n",
      "Batch: 909\n",
      "Batch: 910\n",
      "Batch: 911\n",
      "Batch: 912\n",
      "Batch: 913\n",
      "Batch: 914\n",
      "Batch: 915\n",
      "Batch: 916\n",
      "Batch: 917\n",
      "Batch: 918\n",
      "Batch: 919\n",
      "Batch: 920\n",
      "Batch: 921\n",
      "Batch: 922\n",
      "Batch: 923\n",
      "Batch: 924\n",
      "Batch: 925\n",
      "Batch: 926\n",
      "Batch: 927\n",
      "Batch: 928\n",
      "Batch: 929\n",
      "Batch: 930\n",
      "Batch: 931\n",
      "Batch: 932\n",
      "Batch: 933\n",
      "Batch: 934\n",
      "Batch: 935\n",
      "Batch: 936\n",
      "Batch: 937\n",
      "Batch: 938\n",
      "Batch: 939\n",
      "Batch: 940\n",
      "Batch: 941\n",
      "Batch: 942\n",
      "Batch: 943\n",
      "Batch: 944\n",
      "Batch: 945\n",
      "Batch: 946\n",
      "Batch: 947\n",
      "Batch: 948\n",
      "Batch: 949\n",
      "Batch: 950\n",
      "Batch: 951\n",
      "Batch: 952\n",
      "Batch: 953\n",
      "Batch: 954\n",
      "Batch: 955\n",
      "Batch: 956\n",
      "Batch: 957\n",
      "Batch: 958\n",
      "Batch: 959\n",
      "Batch: 960\n",
      "Batch: 961\n",
      "Batch: 962\n",
      "Batch: 963\n",
      "Batch: 964\n",
      "Batch: 965\n",
      "Batch: 966\n",
      "Batch: 967\n",
      "Batch: 968\n",
      "Batch: 969\n",
      "Batch: 970\n",
      "Batch: 971\n",
      "Batch: 972\n",
      "Batch: 973\n",
      "Batch: 974\n",
      "Batch: 975\n",
      "Batch: 976\n",
      "Batch: 977\n",
      "Batch: 978\n",
      "Batch: 979\n",
      "Batch: 980\n",
      "Batch: 981\n",
      "Batch: 982\n",
      "Batch: 983\n",
      "Batch: 984\n",
      "Batch: 985\n",
      "Batch: 986\n",
      "Batch: 987\n",
      "Batch: 988\n",
      "Batch: 989\n",
      "Batch: 990\n",
      "Batch: 991\n",
      "Batch: 992\n",
      "Batch: 993\n",
      "Batch: 994\n",
      "Batch: 995\n",
      "Batch: 996\n",
      "Batch: 997\n",
      "Batch: 998\n",
      "Batch: 999\n",
      "Batch: 1000\n",
      "Batch: 1001\n",
      "Batch: 1002\n",
      "Batch: 1003\n",
      "Batch: 1004\n",
      "Batch: 1005\n",
      "Batch: 1006\n",
      "Batch: 1007\n",
      "Batch: 1008\n",
      "Batch: 1009\n",
      "Batch: 1010\n",
      "Batch: 1011\n",
      "Batch: 1012\n",
      "Batch: 1013\n",
      "Batch: 1014\n",
      "Batch: 1015\n",
      "Batch: 1016\n",
      "Batch: 1017\n",
      "Batch: 1018\n",
      "Batch: 1019\n",
      "Batch: 1020\n",
      "Batch: 1021\n",
      "Batch: 1022\n",
      "Batch: 1023\n",
      "Batch: 1024\n",
      "Batch: 1025\n",
      "Batch: 1026\n",
      "Batch: 1027\n",
      "Batch: 1028\n",
      "Batch: 1029\n",
      "Batch: 1030\n",
      "Batch: 1031\n",
      "Batch: 1032\n",
      "Batch: 1033\n",
      "Batch: 1034\n",
      "Batch: 1035\n",
      "Batch: 1036\n",
      "Batch: 1037\n",
      "Batch: 1038\n",
      "Batch: 1039\n",
      "Batch: 1040\n",
      "Batch: 1041\n",
      "Batch: 1042\n",
      "Batch: 1043\n",
      "Batch: 1044\n",
      "Batch: 1045\n",
      "Batch: 1046\n",
      "Batch: 1047\n",
      "Batch: 1048\n",
      "Batch: 1049\n",
      "Batch: 1050\n",
      "Batch: 1051\n",
      "Batch: 1052\n",
      "Batch: 1053\n",
      "Batch: 1054\n",
      "Batch: 1055\n",
      "Batch: 1056\n",
      "Batch: 1057\n",
      "Batch: 1058\n",
      "Batch: 1059\n",
      "Batch: 1060\n",
      "Batch: 1061\n",
      "Batch: 1062\n",
      "Batch: 1063\n",
      "Batch: 1064\n",
      "Batch: 1065\n",
      "Batch: 1066\n",
      "Batch: 1067\n",
      "Batch: 1068\n",
      "Batch: 1069\n",
      "Batch: 1070\n",
      "Batch: 1071\n",
      "Batch: 1072\n",
      "Batch: 1073\n",
      "Batch: 1074\n",
      "Batch: 1075\n",
      "Batch: 1076\n",
      "Batch: 1077\n",
      "Batch: 1078\n",
      "Batch: 1079\n",
      "Batch: 1080\n",
      "Batch: 1081\n",
      "Batch: 1082\n",
      "Batch: 1083\n",
      "Batch: 1084\n",
      "Batch: 1085\n",
      "Batch: 1086\n",
      "Batch: 1087\n",
      "Batch: 1088\n",
      "Batch: 1089\n",
      "Batch: 1090\n",
      "Batch: 1091\n",
      "Batch: 1092\n",
      "Batch: 1093\n",
      "Batch: 1094\n",
      "Batch: 1095\n",
      "Batch: 1096\n",
      "Batch: 1097\n",
      "Batch: 1098\n",
      "Batch: 1099\n",
      "Batch: 1100\n",
      "Batch: 1101\n",
      "Batch: 1102\n",
      "Batch: 1103\n",
      "Batch: 1104\n",
      "Batch: 1105\n",
      "Batch: 1106\n",
      "Batch: 1107\n",
      "Batch: 1108\n",
      "Batch: 1109\n",
      "Batch: 1110\n",
      "Batch: 1111\n",
      "Batch: 1112\n",
      "Batch: 1113\n",
      "Batch: 1114\n",
      "Batch: 1115\n",
      "Batch: 1116\n",
      "Batch: 1117\n",
      "Batch: 1118\n",
      "Batch: 1119\n",
      "Batch: 1120\n",
      "Batch: 1121\n",
      "Batch: 1122\n",
      "Batch: 1123\n",
      "Batch: 1124\n",
      "Batch: 1125\n",
      "Batch: 1126\n",
      "Batch: 1127\n",
      "Batch: 1128\n",
      "Batch: 1129\n",
      "Batch: 1130\n",
      "Batch: 1131\n",
      "Batch: 1132\n",
      "Batch: 1133\n",
      "Batch: 1134\n",
      "Batch: 1135\n",
      "Batch: 1136\n",
      "Batch: 1137\n",
      "Batch: 1138\n",
      "Batch: 1139\n",
      "Batch: 1140\n",
      "Batch: 1141\n",
      "Batch: 1142\n",
      "Batch: 1143\n",
      "Batch: 1144\n",
      "Batch: 1145\n",
      "Batch: 1146\n",
      "Batch: 1147\n",
      "Batch: 1148\n",
      "Batch: 1149\n",
      "Batch: 1150\n",
      "Batch: 1151\n",
      "Batch: 1152\n",
      "Batch: 1153\n",
      "Batch: 1154\n",
      "Batch: 1155\n",
      "Batch: 1156\n",
      "Batch: 1157\n",
      "Batch: 1158\n",
      "Batch: 1159\n",
      "Batch: 1160\n",
      "Batch: 1161\n",
      "Batch: 1162\n",
      "Batch: 1163\n",
      "Batch: 1164\n",
      "Batch: 1165\n",
      "Batch: 1166\n",
      "Batch: 1167\n",
      "Batch: 1168\n",
      "Batch: 1169\n",
      "Batch: 1170\n",
      "Batch: 1171\n",
      "Batch: 1172\n",
      "Batch: 1173\n",
      "Batch: 1174\n",
      "Batch: 1175\n",
      "Batch: 1176\n",
      "Batch: 1177\n",
      "Batch: 1178\n",
      "Batch: 1179\n",
      "Batch: 1180\n",
      "Batch: 1181\n",
      "Batch: 1182\n",
      "Batch: 1183\n",
      "Batch: 1184\n",
      "Batch: 1185\n",
      "Batch: 1186\n",
      "Batch: 1187\n",
      "Batch: 1188\n",
      "Batch: 1189\n",
      "Batch: 1190\n",
      "Batch: 1191\n",
      "Batch: 1192\n",
      "Batch: 1193\n",
      "Batch: 1194\n",
      "Batch: 1195\n",
      "Batch: 1196\n",
      "Batch: 1197\n",
      "Batch: 1198\n",
      "Batch: 1199\n",
      "Batch: 1200\n",
      "Batch: 1201\n",
      "Batch: 1202\n",
      "Batch: 1203\n",
      "Batch: 1204\n",
      "Batch: 1205\n",
      "Batch: 1206\n",
      "Batch: 1207\n",
      "Batch: 1208\n",
      "Batch: 1209\n",
      "Batch: 1210\n",
      "Batch: 1211\n",
      "Batch: 1212\n",
      "Batch: 1213\n",
      "Batch: 1214\n",
      "Batch: 1215\n",
      "Batch: 1216\n",
      "Batch: 1217\n",
      "Batch: 1218\n",
      "Batch: 1219\n",
      "Batch: 1220\n",
      "Batch: 1221\n",
      "Batch: 1222\n",
      "Batch: 1223\n",
      "Batch: 1224\n",
      "Batch: 1225\n",
      "Batch: 1226\n",
      "Batch: 1227\n",
      "Batch: 1228\n",
      "Batch: 1229\n",
      "Batch: 1230\n",
      "Batch: 1231\n",
      "Batch: 1232\n",
      "Batch: 1233\n",
      "Batch: 1234\n",
      "Batch: 1235\n",
      "Batch: 1236\n",
      "Batch: 1237\n",
      "Batch: 1238\n",
      "Batch: 1239\n",
      "Batch: 1240\n",
      "Batch: 1241\n",
      "Batch: 1242\n",
      "Batch: 1243\n",
      "Batch: 1244\n",
      "Batch: 1245\n",
      "Batch: 1246\n",
      "Batch: 1247\n",
      "Batch: 1248\n",
      "Batch: 1249\n",
      "Batch: 1250\n",
      "Batch: 1251\n",
      "Batch: 1252\n",
      "Batch: 1253\n",
      "Batch: 1254\n",
      "Batch: 1255\n",
      "Batch: 1256\n",
      "Batch: 1257\n",
      "Batch: 1258\n",
      "Batch: 1259\n",
      "Batch: 1260\n",
      "Batch: 1261\n",
      "Batch: 1262\n",
      "Batch: 1263\n",
      "Batch: 1264\n",
      "Batch: 1265\n",
      "Batch: 1266\n",
      "Batch: 1267\n",
      "Batch: 1268\n",
      "Batch: 1269\n",
      "Batch: 1270\n",
      "Batch: 1271\n",
      "Batch: 1272\n",
      "Batch: 1273\n",
      "Batch: 1274\n",
      "Batch: 1275\n",
      "Batch: 1276\n",
      "Batch: 1277\n",
      "Batch: 1278\n",
      "Batch: 1279\n",
      "Batch: 1280\n",
      "Batch: 1281\n",
      "Batch: 1282\n",
      "Batch: 1283\n",
      "Batch: 1284\n",
      "Batch: 1285\n",
      "Batch: 1286\n",
      "Batch: 1287\n",
      "Batch: 1288\n",
      "Batch: 1289\n",
      "Batch: 1290\n",
      "Batch: 1291\n",
      "Batch: 1292\n",
      "Batch: 1293\n",
      "Batch: 1294\n",
      "Batch: 1295\n",
      "Batch: 1296\n",
      "Batch: 1297\n",
      "Batch: 1298\n",
      "Batch: 1299\n",
      "Batch: 1300\n",
      "Batch: 1301\n",
      "Batch: 1302\n",
      "Batch: 1303\n",
      "Batch: 1304\n",
      "Batch: 1305\n",
      "Batch: 1306\n",
      "Batch: 1307\n",
      "Batch: 1308\n",
      "Batch: 1309\n",
      "Batch: 1310\n",
      "Batch: 1311\n",
      "Batch: 1312\n",
      "Batch: 1313\n",
      "Batch: 1314\n",
      "Batch: 1315\n",
      "Batch: 1316\n",
      "Batch: 1317\n",
      "Batch: 1318\n",
      "Batch: 1319\n",
      "Batch: 1320\n",
      "Batch: 1321\n",
      "Batch: 1322\n",
      "Batch: 1323\n",
      "Batch: 1324\n",
      "Batch: 1325\n",
      "Batch: 1326\n",
      "Batch: 1327\n",
      "Batch: 1328\n",
      "Batch: 1329\n",
      "Batch: 1330\n",
      "Batch: 1331\n",
      "Batch: 1332\n",
      "Batch: 1333\n",
      "Batch: 1334\n",
      "Batch: 1335\n",
      "Batch: 1336\n",
      "Batch: 1337\n",
      "Batch: 1338\n",
      "Batch: 1339\n",
      "Batch: 1340\n",
      "Batch: 1341\n",
      "Batch: 1342\n",
      "Batch: 1343\n",
      "Batch: 1344\n",
      "Batch: 1345\n",
      "Batch: 1346\n",
      "Batch: 1347\n",
      "Batch: 1348\n",
      "Batch: 1349\n",
      "Batch: 1350\n",
      "Batch: 1351\n",
      "Batch: 1352\n",
      "Batch: 1353\n",
      "Batch: 1354\n",
      "Batch: 1355\n",
      "Batch: 1356\n",
      "Batch: 1357\n",
      "Batch: 1358\n",
      "Batch: 1359\n",
      "Batch: 1360\n",
      "Batch: 1361\n",
      "Batch: 1362\n",
      "Batch: 1363\n",
      "Batch: 1364\n",
      "Batch: 1365\n",
      "Batch: 1366\n",
      "Batch: 1367\n",
      "Batch: 1368\n",
      "Batch: 1369\n",
      "Batch: 1370\n",
      "Batch: 1371\n",
      "Batch: 1372\n",
      "Batch: 1373\n",
      "Batch: 1374\n",
      "Batch: 1375\n",
      "Batch: 1376\n",
      "Batch: 1377\n",
      "Batch: 1378\n",
      "Batch: 1379\n",
      "Batch: 1380\n",
      "Batch: 1381\n",
      "Batch: 1382\n",
      "Batch: 1383\n",
      "Batch: 1384\n",
      "Batch: 1385\n",
      "Batch: 1386\n",
      "Batch: 1387\n",
      "Batch: 1388\n",
      "Batch: 1389\n",
      "Batch: 1390\n",
      "Batch: 1391\n",
      "Batch: 1392\n",
      "Batch: 1393\n",
      "Batch: 1394\n",
      "Batch: 1395\n",
      "Batch: 1396\n",
      "Batch: 1397\n",
      "Batch: 1398\n",
      "Batch: 1399\n",
      "Batch: 1400\n",
      "Batch: 1401\n",
      "Batch: 1402\n",
      "Batch: 1403\n",
      "Batch: 1404\n",
      "Batch: 1405\n",
      "Batch: 1406\n",
      "Batch: 1407\n",
      "Batch: 1408\n",
      "Batch: 1409\n",
      "Batch: 1410\n",
      "Batch: 1411\n",
      "Batch: 1412\n",
      "Batch: 1413\n",
      "Batch: 1414\n",
      "Batch: 1415\n",
      "Batch: 1416\n",
      "Batch: 1417\n",
      "Batch: 1418\n",
      "Batch: 1419\n",
      "Batch: 1420\n",
      "Batch: 1421\n",
      "Batch: 1422\n",
      "Batch: 1423\n",
      "Batch: 1424\n",
      "Batch: 1425\n",
      "Batch: 1426\n",
      "Batch: 1427\n",
      "Batch: 1428\n",
      "Batch: 1429\n",
      "Batch: 1430\n",
      "Batch: 1431\n",
      "Batch: 1432\n",
      "Batch: 1433\n",
      "Batch: 1434\n",
      "Batch: 1435\n",
      "Batch: 1436\n",
      "Batch: 1437\n",
      "Batch: 1438\n",
      "Batch: 1439\n",
      "Batch: 1440\n",
      "Batch: 1441\n",
      "Batch: 1442\n",
      "Batch: 1443\n",
      "Batch: 1444\n",
      "Batch: 1445\n",
      "Batch: 1446\n",
      "Batch: 1447\n",
      "Batch: 1448\n",
      "Batch: 1449\n",
      "Batch: 1450\n",
      "Batch: 1451\n",
      "Batch: 1452\n",
      "Batch: 1453\n",
      "Batch: 1454\n",
      "Batch: 1455\n",
      "Batch: 1456\n",
      "Batch: 1457\n",
      "Batch: 1458\n",
      "Batch: 1459\n",
      "Batch: 1460\n",
      "Batch: 1461\n",
      "Batch: 1462\n",
      "Batch: 1463\n",
      "Batch: 1464\n",
      "Batch: 1465\n",
      "Batch: 1466\n",
      "Batch: 1467\n",
      "Batch: 1468\n",
      "Batch: 1469\n",
      "Batch: 1470\n",
      "Batch: 1471\n",
      "Batch: 1472\n",
      "Batch: 1473\n",
      "Batch: 1474\n",
      "Batch: 1475\n",
      "Batch: 1476\n",
      "Batch: 1477\n",
      "Batch: 1478\n",
      "Batch: 1479\n",
      "Batch: 1480\n",
      "Batch: 1481\n",
      "Batch: 1482\n",
      "Batch: 1483\n",
      "Batch: 1484\n",
      "Batch: 1485\n",
      "Batch: 1486\n",
      "Batch: 1487\n",
      "Batch: 1488\n",
      "Batch: 1489\n",
      "Batch: 1490\n",
      "Batch: 1491\n",
      "Batch: 1492\n",
      "Batch: 1493\n",
      "Batch: 1494\n",
      "Batch: 1495\n",
      "Batch: 1496\n",
      "Batch: 1497\n",
      "Batch: 1498\n",
      "Batch: 1499\n",
      "Batch: 1500\n",
      "Batch: 1501\n",
      "Batch: 1502\n",
      "Batch: 1503\n",
      "Batch: 1504\n",
      "Batch: 1505\n",
      "Batch: 1506\n",
      "Batch: 1507\n",
      "Batch: 1508\n",
      "Batch: 1509\n",
      "Batch: 1510\n",
      "Batch: 1511\n",
      "Batch: 1512\n",
      "Batch: 1513\n",
      "Batch: 1514\n",
      "Batch: 1515\n",
      "Batch: 1516\n",
      "Batch: 1517\n",
      "Batch: 1518\n",
      "Batch: 1519\n",
      "Batch: 1520\n",
      "Batch: 1521\n",
      "Batch: 1522\n",
      "Batch: 1523\n",
      "Batch: 1524\n",
      "Batch: 1525\n",
      "Batch: 1526\n",
      "Batch: 1527\n",
      "Batch: 1528\n",
      "Batch: 1529\n",
      "Batch: 1530\n",
      "Batch: 1531\n",
      "Batch: 1532\n",
      "Batch: 1533\n",
      "Batch: 1534\n",
      "Batch: 1535\n",
      "Batch: 1536\n",
      "Batch: 1537\n",
      "Batch: 1538\n",
      "Batch: 1539\n",
      "Batch: 1540\n",
      "Batch: 1541\n",
      "Batch: 1542\n",
      "Batch: 1543\n",
      "Batch: 1544\n",
      "Batch: 1545\n",
      "Batch: 1546\n",
      "Batch: 1547\n",
      "Batch: 1548\n",
      "Batch: 1549\n",
      "Batch: 1550\n",
      "Batch: 1551\n",
      "Batch: 1552\n",
      "Batch: 1553\n",
      "Batch: 1554\n",
      "Batch: 1555\n",
      "Batch: 1556\n",
      "Batch: 1557\n",
      "Batch: 1558\n",
      "Batch: 1559\n",
      "Batch: 1560\n",
      "Batch: 1561\n",
      "Batch: 1562\n",
      "Batch: 1563\n",
      "Batch: 1564\n",
      "Batch: 1565\n",
      "Batch: 1566\n",
      "Batch: 1567\n",
      "Batch: 1568\n",
      "Batch: 1569\n",
      "Batch: 1570\n",
      "Batch: 1571\n",
      "Batch: 1572\n",
      "Batch: 1573\n",
      "Batch: 1574\n",
      "Batch: 1575\n",
      "Batch: 1576\n",
      "Batch: 1577\n",
      "Batch: 1578\n",
      "Batch: 1579\n",
      "Batch: 1580\n",
      "Batch: 1581\n",
      "Batch: 1582\n",
      "Batch: 1583\n",
      "Batch: 1584\n",
      "Batch: 1585\n",
      "Batch: 1586\n",
      "Batch: 1587\n",
      "Batch: 1588\n",
      "Batch: 1589\n",
      "Batch: 1590\n",
      "Batch: 1591\n",
      "Batch: 1592\n",
      "Batch: 1593\n",
      "Batch: 1594\n",
      "Batch: 1595\n",
      "Batch: 1596\n",
      "Batch: 1597\n",
      "Batch: 1598\n",
      "Batch: 1599\n",
      "Batch: 1600\n",
      "Batch: 1601\n",
      "Batch: 1602\n",
      "Batch: 1603\n",
      "Batch: 1604\n",
      "Batch: 1605\n",
      "Batch: 1606\n",
      "Batch: 1607\n",
      "Batch: 1608\n",
      "Batch: 1609\n",
      "Batch: 1610\n",
      "Batch: 1611\n",
      "Batch: 1612\n",
      "Batch: 1613\n",
      "Batch: 1614\n",
      "Batch: 1615\n",
      "Batch: 1616\n",
      "Batch: 1617\n",
      "Batch: 1618\n",
      "Batch: 1619\n",
      "Batch: 1620\n",
      "Batch: 1621\n",
      "Batch: 1622\n",
      "Batch: 1623\n",
      "Batch: 1624\n",
      "Batch: 1625\n",
      "Batch: 1626\n",
      "Batch: 1627\n",
      "Batch: 1628\n",
      "Batch: 1629\n",
      "Batch: 1630\n",
      "Batch: 1631\n",
      "Batch: 1632\n",
      "Batch: 1633\n",
      "Batch: 1634\n",
      "Batch: 1635\n",
      "Batch: 1636\n",
      "Batch: 1637\n",
      "Batch: 1638\n",
      "Batch: 1639\n",
      "Batch: 1640\n",
      "Batch: 1641\n",
      "Batch: 1642\n",
      "Batch: 1643\n",
      "Batch: 1644\n",
      "Batch: 1645\n",
      "Batch: 1646\n",
      "Batch: 1647\n",
      "Batch: 1648\n",
      "Batch: 1649\n",
      "Batch: 1650\n",
      "Batch: 1651\n",
      "Batch: 1652\n",
      "Batch: 1653\n",
      "Batch: 1654\n",
      "Batch: 1655\n",
      "Batch: 1656\n",
      "Batch: 1657\n",
      "Batch: 1658\n",
      "Batch: 1659\n",
      "Batch: 1660\n",
      "Batch: 1661\n",
      "Batch: 1662\n",
      "Batch: 1663\n",
      "Batch: 1664\n",
      "Batch: 1665\n",
      "Batch: 1666\n",
      "Batch: 1667\n",
      "Batch: 1668\n",
      "Batch: 1669\n",
      "Batch: 1670\n",
      "Batch: 1671\n",
      "Batch: 1672\n",
      "Batch: 1673\n",
      "Batch: 1674\n",
      "Batch: 1675\n",
      "Batch: 1676\n",
      "Batch: 1677\n",
      "Batch: 1678\n",
      "Batch: 1679\n",
      "Batch: 1680\n",
      "Batch: 1681\n",
      "Batch: 1682\n",
      "Batch: 1683\n",
      "Batch: 1684\n",
      "Batch: 1685\n",
      "Batch: 1686\n",
      "Batch: 1687\n",
      "Batch: 1688\n",
      "Batch: 1689\n",
      "Batch: 1690\n",
      "Batch: 1691\n",
      "Batch: 1692\n",
      "Batch: 1693\n",
      "Batch: 1694\n",
      "Batch: 1695\n",
      "Batch: 1696\n",
      "Batch: 1697\n",
      "Batch: 1698\n",
      "Batch: 1699\n",
      "Batch: 1700\n",
      "Batch: 1701\n",
      "Batch: 1702\n",
      "Batch: 1703\n",
      "Batch: 1704\n",
      "Batch: 1705\n",
      "Batch: 1706\n",
      "Batch: 1707\n",
      "Batch: 1708\n",
      "Batch: 1709\n",
      "Batch: 1710\n",
      "Batch: 1711\n",
      "Batch: 1712\n",
      "Batch: 1713\n",
      "Batch: 1714\n",
      "Batch: 1715\n",
      "Batch: 1716\n",
      "Batch: 1717\n",
      "Batch: 1718\n",
      "Batch: 1719\n",
      "Batch: 1720\n",
      "Batch: 1721\n",
      "Batch: 1722\n",
      "Batch: 1723\n",
      "Batch: 1724\n",
      "Batch: 1725\n",
      "Batch: 1726\n",
      "Batch: 1727\n",
      "Batch: 1728\n",
      "Batch: 1729\n",
      "Batch: 1730\n",
      "Batch: 1731\n",
      "Batch: 1732\n",
      "Batch: 1733\n",
      "Batch: 1734\n",
      "Batch: 1735\n",
      "Batch: 1736\n",
      "Batch: 1737\n",
      "Batch: 1738\n",
      "Batch: 1739\n",
      "Batch: 1740\n",
      "Batch: 1741\n",
      "Batch: 1742\n",
      "Batch: 1743\n",
      "Batch: 1744\n",
      "Batch: 1745\n",
      "Batch: 1746\n",
      "Batch: 1747\n",
      "Batch: 1748\n",
      "Batch: 1749\n",
      "Batch: 1750\n",
      "Batch: 1751\n",
      "Batch: 1752\n",
      "Batch: 1753\n",
      "Batch: 1754\n",
      "Batch: 1755\n",
      "Batch: 1756\n",
      "Batch: 1757\n",
      "Batch: 1758\n",
      "Batch: 1759\n",
      "Batch: 1760\n",
      "Batch: 1761\n",
      "Batch: 1762\n",
      "Batch: 1763\n",
      "Batch: 1764\n",
      "Batch: 1765\n",
      "Batch: 1766\n",
      "Batch: 1767\n",
      "Batch: 1768\n",
      "Batch: 1769\n",
      "Batch: 1770\n",
      "Batch: 1771\n",
      "Batch: 1772\n",
      "Batch: 1773\n",
      "Batch: 1774\n",
      "Batch: 1775\n",
      "Batch: 1776\n",
      "Batch: 1777\n",
      "Batch: 1778\n",
      "Batch: 1779\n",
      "Batch: 1780\n",
      "Batch: 1781\n",
      "Batch: 1782\n",
      "Batch: 1783\n",
      "Batch: 1784\n",
      "Batch: 1785\n",
      "Batch: 1786\n",
      "Batch: 1787\n",
      "Batch: 1788\n",
      "Batch: 1789\n",
      "Batch: 1790\n",
      "Batch: 1791\n",
      "Batch: 1792\n",
      "Batch: 1793\n",
      "Batch: 1794\n",
      "Batch: 1795\n",
      "Batch: 1796\n",
      "Batch: 1797\n",
      "Batch: 1798\n",
      "Batch: 1799\n",
      "Batch: 1800\n",
      "Batch: 1801\n",
      "Batch: 1802\n",
      "Batch: 1803\n",
      "Batch: 1804\n",
      "Batch: 1805\n",
      "Batch: 1806\n",
      "Batch: 1807\n",
      "Batch: 1808\n",
      "Batch: 1809\n",
      "Batch: 1810\n",
      "Batch: 1811\n",
      "Batch: 1812\n",
      "Batch: 1813\n",
      "Batch: 1814\n",
      "Batch: 1815\n",
      "Batch: 1816\n",
      "Batch: 1817\n",
      "Batch: 1818\n",
      "Batch: 1819\n",
      "Batch: 1820\n",
      "Batch: 1821\n",
      "Batch: 1822\n",
      "Batch: 1823\n",
      "Batch: 1824\n",
      "Batch: 1825\n",
      "Batch: 1826\n",
      "Batch: 1827\n",
      "Batch: 1828\n",
      "Batch: 1829\n",
      "Batch: 1830\n",
      "Batch: 1831\n",
      "Batch: 1832\n",
      "Batch: 1833\n",
      "Batch: 1834\n",
      "Batch: 1835\n",
      "Batch: 1836\n",
      "Batch: 1837\n",
      "Batch: 1838\n",
      "Batch: 1839\n",
      "Batch: 1840\n",
      "Batch: 1841\n",
      "Batch: 1842\n",
      "Batch: 1843\n",
      "Batch: 1844\n",
      "Batch: 1845\n",
      "Batch: 1846\n",
      "Batch: 1847\n",
      "Batch: 1848\n",
      "Batch: 1849\n",
      "Batch: 1850\n",
      "Batch: 1851\n",
      "Batch: 1852\n",
      "Batch: 1853\n",
      "Batch: 1854\n",
      "Batch: 1855\n",
      "Batch: 1856\n",
      "Batch: 1857\n",
      "Batch: 1858\n",
      "Batch: 1859\n",
      "Batch: 1860\n",
      "Batch: 1861\n",
      "Batch: 1862\n",
      "Batch: 1863\n",
      "Batch: 1864\n",
      "Batch: 1865\n",
      "Batch: 1866\n",
      "Batch: 1867\n",
      "Batch: 1868\n",
      "Batch: 1869\n",
      "Batch: 1870\n",
      "Batch: 1871\n",
      "Batch: 1872\n",
      "Batch: 1873\n",
      "Batch: 1874\n",
      "Batch: 1875\n",
      "Batch: 1876\n",
      "Batch: 1877\n",
      "Batch: 1878\n",
      "Batch: 1879\n",
      "Batch: 1880\n",
      "Batch: 1881\n",
      "Batch: 1882\n",
      "Batch: 1883\n",
      "Batch: 1884\n",
      "Batch: 1885\n",
      "Batch: 1886\n",
      "Batch: 1887\n",
      "Batch: 1888\n",
      "Batch: 1889\n",
      "Batch: 1890\n",
      "Batch: 1891\n",
      "Batch: 1892\n",
      "Batch: 1893\n",
      "Batch: 1894\n",
      "Batch: 1895\n",
      "Batch: 1896\n",
      "Batch: 1897\n",
      "Batch: 1898\n",
      "Batch: 1899\n",
      "Batch: 1900\n",
      "Batch: 1901\n",
      "Batch: 1902\n",
      "Batch: 1903\n",
      "Batch: 1904\n",
      "Batch: 1905\n",
      "Batch: 1906\n",
      "Batch: 1907\n",
      "Batch: 1908\n",
      "Batch: 1909\n",
      "Batch: 1910\n",
      "Batch: 1911\n",
      "Batch: 1912\n",
      "Batch: 1913\n",
      "Batch: 1914\n",
      "Batch: 1915\n",
      "Batch: 1916\n",
      "Batch: 1917\n",
      "Batch: 1918\n",
      "Batch: 1919\n",
      "Batch: 1920\n",
      "Batch: 1921\n",
      "Batch: 1922\n",
      "Batch: 1923\n",
      "Batch: 1924\n",
      "Batch: 1925\n",
      "Batch: 1926\n",
      "Batch: 1927\n",
      "Batch: 1928\n",
      "Batch: 1929\n",
      "Batch: 1930\n",
      "Batch: 1931\n",
      "Batch: 1932\n",
      "Batch: 1933\n",
      "Batch: 1934\n",
      "Batch: 1935\n",
      "Batch: 1936\n",
      "Batch: 1937\n",
      "Batch: 1938\n",
      "Batch: 1939\n",
      "Batch: 1940\n",
      "Batch: 1941\n",
      "Batch: 1942\n",
      "Batch: 1943\n",
      "Batch: 1944\n",
      "Batch: 1945\n",
      "Batch: 1946\n",
      "Batch: 1947\n",
      "Batch: 1948\n",
      "Batch: 1949\n",
      "Batch: 1950\n",
      "Batch: 1951\n",
      "Batch: 1952\n",
      "Batch: 1953\n",
      "Batch: 1954\n",
      "Batch: 1955\n",
      "Batch: 1956\n",
      "Batch: 1957\n",
      "Batch: 1958\n",
      "Batch: 1959\n",
      "Batch: 1960\n",
      "Batch: 1961\n",
      "Batch: 1962\n",
      "Batch: 1963\n",
      "Batch: 1964\n",
      "Batch: 1965\n",
      "Batch: 1966\n",
      "Batch: 1967\n",
      "Batch: 1968\n",
      "Batch: 1969\n",
      "Batch: 1970\n",
      "Batch: 1971\n",
      "Batch: 1972\n",
      "Batch: 1973\n",
      "Batch: 1974\n",
      "Batch: 1975\n",
      "Batch: 1976\n",
      "Batch: 1977\n",
      "Batch: 1978\n",
      "Batch: 1979\n",
      "Batch: 1980\n",
      "Batch: 1981\n",
      "Batch: 1982\n",
      "Batch: 1983\n",
      "Batch: 1984\n",
      "Batch: 1985\n",
      "Batch: 1986\n",
      "Batch: 1987\n",
      "Batch: 1988\n",
      "Batch: 1989\n",
      "Batch: 1990\n",
      "Batch: 1991\n",
      "Batch: 1992\n",
      "Batch: 1993\n",
      "Batch: 1994\n",
      "Batch: 1995\n",
      "Batch: 1996\n",
      "Batch: 1997\n",
      "Batch: 1998\n",
      "Batch: 1999\n",
      "Batch: 2000\n",
      "Batch: 2001\n",
      "Batch: 2002\n",
      "Batch: 2003\n",
      "Batch: 2004\n",
      "Batch: 2005\n",
      "Batch: 2006\n",
      "Batch: 2007\n",
      "Batch: 2008\n",
      "Batch: 2009\n",
      "Batch: 2010\n",
      "Batch: 2011\n",
      "Batch: 2012\n",
      "Batch: 2013\n",
      "Batch: 2014\n",
      "Batch: 2015\n",
      "Batch: 2016\n",
      "Batch: 2017\n",
      "Batch: 2018\n",
      "Batch: 2019\n",
      "Batch: 2020\n",
      "Batch: 2021\n",
      "Batch: 2022\n",
      "Batch: 2023\n",
      "Batch: 2024\n",
      "Batch: 2025\n",
      "Batch: 2026\n",
      "Batch: 2027\n",
      "Batch: 2028\n",
      "Batch: 2029\n",
      "Batch: 2030\n",
      "Batch: 2031\n",
      "Batch: 2032\n",
      "Batch: 2033\n",
      "Batch: 2034\n",
      "Batch: 2035\n",
      "Batch: 2036\n",
      "Batch: 2037\n",
      "Batch: 2038\n",
      "Batch: 2039\n",
      "Batch: 2040\n",
      "Batch: 2041\n",
      "Batch: 2042\n",
      "Batch: 2043\n",
      "Batch: 2044\n",
      "Batch: 2045\n",
      "Batch: 2046\n",
      "Batch: 2047\n",
      "Batch: 2048\n",
      "Batch: 2049\n",
      "Batch: 2050\n",
      "Batch: 2051\n",
      "Batch: 2052\n",
      "Batch: 2053\n",
      "Batch: 2054\n",
      "Batch: 2055\n",
      "Batch: 2056\n",
      "Batch: 2057\n",
      "Batch: 2058\n",
      "Batch: 2059\n",
      "Batch: 2060\n",
      "Batch: 2061\n",
      "Batch: 2062\n",
      "Batch: 2063\n",
      "Batch: 2064\n",
      "Batch: 2065\n",
      "Batch: 2066\n",
      "Batch: 2067\n",
      "Batch: 2068\n",
      "Batch: 2069\n",
      "Batch: 2070\n",
      "Batch: 2071\n",
      "Batch: 2072\n",
      "Batch: 2073\n",
      "Batch: 2074\n",
      "Batch: 2075\n",
      "Batch: 2076\n",
      "Batch: 2077\n",
      "Batch: 2078\n",
      "Batch: 2079\n",
      "Batch: 2080\n",
      "Batch: 2081\n",
      "Batch: 2082\n",
      "Batch: 2083\n",
      "Batch: 2084\n",
      "Batch: 2085\n",
      "Batch: 2086\n",
      "Batch: 2087\n",
      "Batch: 2088\n",
      "Batch: 2089\n",
      "Batch: 2090\n",
      "Batch: 2091\n",
      "Batch: 2092\n",
      "Batch: 2093\n",
      "Batch: 2094\n",
      "Batch: 2095\n",
      "Batch: 2096\n",
      "Batch: 2097\n",
      "Batch: 2098\n",
      "Batch: 2099\n",
      "Batch: 2100\n",
      "Batch: 2101\n",
      "Batch: 2102\n",
      "Batch: 2103\n",
      "Batch: 2104\n",
      "Batch: 2105\n",
      "Batch: 2106\n",
      "Batch: 2107\n",
      "Batch: 2108\n",
      "Batch: 2109\n",
      "Batch: 2110\n",
      "Batch: 2111\n",
      "Batch: 2112\n",
      "Batch: 2113\n",
      "Batch: 2114\n",
      "Batch: 2115\n",
      "Batch: 2116\n",
      "Batch: 2117\n",
      "Batch: 2118\n",
      "Batch: 2119\n",
      "Batch: 2120\n",
      "Batch: 2121\n",
      "Batch: 2122\n",
      "Batch: 2123\n",
      "Batch: 2124\n",
      "Batch: 2125\n",
      "Batch: 2126\n",
      "Batch: 2127\n",
      "Batch: 2128\n",
      "Batch: 2129\n",
      "Batch: 2130\n",
      "Batch: 2131\n",
      "Batch: 2132\n",
      "Batch: 2133\n",
      "Batch: 2134\n",
      "Batch: 2135\n",
      "Batch: 2136\n",
      "Batch: 2137\n",
      "Batch: 2138\n",
      "Batch: 2139\n",
      "Batch: 2140\n",
      "Batch: 2141\n",
      "Batch: 2142\n",
      "Batch: 2143\n",
      "Batch: 2144\n",
      "Batch: 2145\n",
      "Batch: 2146\n",
      "Batch: 2147\n",
      "Batch: 2148\n",
      "Batch: 2149\n",
      "Batch: 2150\n",
      "Batch: 2151\n",
      "Batch: 2152\n",
      "Batch: 2153\n",
      "Batch: 2154\n",
      "Batch: 2155\n",
      "Batch: 2156\n",
      "Batch: 2157\n",
      "Batch: 2158\n",
      "Batch: 2159\n",
      "Batch: 2160\n",
      "Batch: 2161\n",
      "Batch: 2162\n",
      "Batch: 2163\n",
      "Batch: 2164\n",
      "Batch: 2165\n",
      "Batch: 2166\n",
      "Batch: 2167\n",
      "Batch: 2168\n",
      "Batch: 2169\n",
      "Batch: 2170\n",
      "Batch: 2171\n",
      "Batch: 2172\n",
      "Batch: 2173\n",
      "Batch: 2174\n",
      "Batch: 2175\n",
      "Batch: 2176\n",
      "Batch: 2177\n",
      "Batch: 2178\n",
      "Batch: 2179\n",
      "Batch: 2180\n",
      "Batch: 2181\n",
      "Batch: 2182\n",
      "Batch: 2183\n",
      "Batch: 2184\n",
      "Batch: 2185\n",
      "Batch: 2186\n",
      "Batch: 2187\n",
      "Batch: 2188\n",
      "Batch: 2189\n",
      "Batch: 2190\n",
      "Batch: 2191\n",
      "Batch: 2192\n",
      "Batch: 2193\n",
      "Batch: 2194\n",
      "Batch: 2195\n",
      "Batch: 2196\n",
      "Batch: 2197\n",
      "Batch: 2198\n",
      "Batch: 2199\n",
      "Batch: 2200\n",
      "Batch: 2201\n",
      "Batch: 2202\n",
      "Batch: 2203\n",
      "Batch: 2204\n",
      "Batch: 2205\n",
      "Batch: 2206\n",
      "Batch: 2207\n",
      "Batch: 2208\n",
      "Batch: 2209\n",
      "Batch: 2210\n",
      "Batch: 2211\n",
      "Batch: 2212\n",
      "Batch: 2213\n",
      "Batch: 2214\n",
      "Batch: 2215\n",
      "Batch: 2216\n",
      "Batch: 2217\n",
      "Batch: 2218\n",
      "Batch: 2219\n",
      "Batch: 2220\n",
      "Batch: 2221\n",
      "Batch: 2222\n",
      "Batch: 2223\n",
      "Batch: 2224\n",
      "Batch: 2225\n",
      "Batch: 2226\n",
      "Batch: 2227\n",
      "Batch: 2228\n",
      "Batch: 2229\n",
      "Batch: 2230\n",
      "Batch: 2231\n",
      "Batch: 2232\n",
      "Batch: 2233\n",
      "Batch: 2234\n",
      "Batch: 2235\n",
      "Batch: 2236\n",
      "Batch: 2237\n",
      "Batch: 2238\n",
      "Batch: 2239\n",
      "Batch: 2240\n",
      "Batch: 2241\n",
      "Batch: 2242\n",
      "Batch: 2243\n",
      "Batch: 2244\n",
      "Batch: 2245\n",
      "Batch: 2246\n",
      "Batch: 2247\n",
      "Batch: 2248\n",
      "Batch: 2249\n",
      "Batch: 2250\n",
      "Batch: 2251\n",
      "Batch: 2252\n",
      "Batch: 2253\n",
      "Batch: 2254\n",
      "Batch: 2255\n",
      "Batch: 2256\n",
      "Batch: 2257\n",
      "Batch: 2258\n",
      "Batch: 2259\n",
      "Batch: 2260\n",
      "Batch: 2261\n",
      "Batch: 2262\n",
      "Batch: 2263\n",
      "Batch: 2264\n",
      "Batch: 2265\n",
      "Batch: 2266\n",
      "Batch: 2267\n",
      "Batch: 2268\n",
      "Batch: 2269\n",
      "Batch: 2270\n",
      "Batch: 2271\n",
      "Batch: 2272\n",
      "Batch: 2273\n",
      "Batch: 2274\n",
      "Batch: 2275\n",
      "Batch: 2276\n",
      "Batch: 2277\n",
      "Batch: 2278\n",
      "Batch: 2279\n",
      "Batch: 2280\n",
      "Batch: 2281\n",
      "Batch: 2282\n",
      "Batch: 2283\n",
      "Batch: 2284\n",
      "Batch: 2285\n",
      "Batch: 2286\n",
      "Batch: 2287\n",
      "Batch: 2288\n",
      "Batch: 2289\n",
      "Batch: 2290\n",
      "Batch: 2291\n",
      "Batch: 2292\n",
      "Batch: 2293\n",
      "Batch: 2294\n",
      "Batch: 2295\n",
      "Batch: 2296\n",
      "Batch: 2297\n",
      "Batch: 2298\n",
      "Batch: 2299\n",
      "Batch: 2300\n",
      "Batch: 2301\n",
      "Batch: 2302\n",
      "Batch: 2303\n",
      "Batch: 2304\n",
      "Batch: 2305\n",
      "Batch: 2306\n",
      "Batch: 2307\n",
      "Batch: 2308\n",
      "Batch: 2309\n",
      "Batch: 2310\n",
      "Batch: 2311\n",
      "Batch: 2312\n",
      "Batch: 2313\n",
      "Batch: 2314\n",
      "Batch: 2315\n",
      "Batch: 2316\n",
      "Batch: 2317\n",
      "Batch: 2318\n",
      "Batch: 2319\n",
      "Batch: 2320\n",
      "Batch: 2321\n",
      "Batch: 2322\n",
      "Batch: 2323\n",
      "Batch: 2324\n",
      "Batch: 2325\n",
      "Batch: 2326\n",
      "Batch: 2327\n",
      "Batch: 2328\n",
      "Batch: 2329\n",
      "Batch: 2330\n",
      "Batch: 2331\n",
      "Batch: 2332\n",
      "Batch: 2333\n",
      "Batch: 2334\n",
      "Batch: 2335\n",
      "Batch: 2336\n",
      "Batch: 2337\n",
      "Batch: 2338\n",
      "Batch: 2339\n",
      "Batch: 2340\n",
      "Batch: 2341\n",
      "Batch: 2342\n",
      "Batch: 2343\n",
      "Batch: 2344\n",
      "Batch: 2345\n",
      "Batch: 2346\n",
      "Batch: 2347\n",
      "Batch: 2348\n",
      "Batch: 2349\n",
      "Batch: 2350\n",
      "Batch: 2351\n",
      "Batch: 2352\n",
      "Batch: 2353\n",
      "Batch: 2354\n",
      "Batch: 2355\n",
      "Batch: 2356\n",
      "Batch: 2357\n",
      "Batch: 2358\n",
      "Batch: 2359\n",
      "Batch: 2360\n",
      "Batch: 2361\n",
      "Batch: 2362\n",
      "Batch: 2363\n",
      "Batch: 2364\n",
      "Batch: 2365\n",
      "Batch: 2366\n",
      "Batch: 2367\n",
      "Batch: 2368\n",
      "Batch: 2369\n",
      "Batch: 2370\n",
      "Batch: 2371\n",
      "Batch: 2372\n",
      "Batch: 2373\n",
      "Batch: 2374\n",
      "Batch: 2375\n",
      "Batch: 2376\n",
      "Batch: 2377\n",
      "Batch: 2378\n",
      "Batch: 2379\n",
      "Batch: 2380\n",
      "Batch: 2381\n",
      "Batch: 2382\n",
      "Batch: 2383\n",
      "Batch: 2384\n",
      "Batch: 2385\n",
      "Batch: 2386\n",
      "Batch: 2387\n",
      "Batch: 2388\n",
      "Batch: 2389\n",
      "Batch: 2390\n",
      "Batch: 2391\n",
      "Batch: 2392\n",
      "Batch: 2393\n",
      "Batch: 2394\n",
      "Batch: 2395\n",
      "Batch: 2396\n",
      "Batch: 2397\n",
      "Batch: 2398\n",
      "Batch: 2399\n",
      "Batch: 2400\n",
      "Batch: 2401\n",
      "Batch: 2402\n",
      "Batch: 2403\n",
      "Batch: 2404\n",
      "Batch: 2405\n",
      "Batch: 2406\n",
      "Batch: 2407\n",
      "Batch: 2408\n",
      "Batch: 2409\n",
      "Batch: 2410\n",
      "Batch: 2411\n",
      "Batch: 2412\n",
      "Batch: 2413\n",
      "Batch: 2414\n",
      "Batch: 2415\n",
      "Batch: 2416\n",
      "Batch: 2417\n",
      "Batch: 2418\n",
      "Batch: 2419\n",
      "Batch: 2420\n",
      "Batch: 2421\n",
      "Batch: 2422\n",
      "Batch: 2423\n",
      "Batch: 2424\n",
      "Batch: 2425\n",
      "Batch: 2426\n",
      "Batch: 2427\n",
      "Batch: 2428\n",
      "Batch: 2429\n",
      "Batch: 2430\n",
      "Batch: 2431\n",
      "Batch: 2432\n",
      "Batch: 2433\n",
      "Batch: 2434\n",
      "Batch: 2435\n",
      "Batch: 2436\n",
      "Batch: 2437\n",
      "Batch: 2438\n",
      "Batch: 2439\n",
      "Batch: 2440\n",
      "Batch: 2441\n",
      "Batch: 2442\n",
      "Batch: 2443\n",
      "Batch: 2444\n",
      "Batch: 2445\n",
      "Batch: 2446\n",
      "Batch: 2447\n",
      "Batch: 2448\n",
      "Batch: 2449\n",
      "Batch: 2450\n",
      "Batch: 2451\n",
      "Batch: 2452\n",
      "Batch: 2453\n",
      "Batch: 2454\n",
      "Batch: 2455\n",
      "Batch: 2456\n",
      "Batch: 2457\n",
      "Batch: 2458\n",
      "Batch: 2459\n",
      "Batch: 2460\n",
      "Batch: 2461\n",
      "Batch: 2462\n",
      "Batch: 2463\n",
      "Batch: 2464\n",
      "Batch: 2465\n",
      "Batch: 2466\n",
      "Batch: 2467\n",
      "Batch: 2468\n",
      "Batch: 2469\n",
      "Batch: 2470\n",
      "Batch: 2471\n",
      "Batch: 2472\n",
      "Batch: 2473\n",
      "Batch: 2474\n",
      "Batch: 2475\n",
      "Batch: 2476\n",
      "Batch: 2477\n",
      "Batch: 2478\n",
      "Batch: 2479\n",
      "Batch: 2480\n",
      "Batch: 2481\n",
      "Batch: 2482\n",
      "Batch: 2483\n",
      "Batch: 2484\n",
      "Batch: 2485\n",
      "Batch: 2486\n",
      "Batch: 2487\n",
      "Batch: 2488\n",
      "Batch: 2489\n",
      "Batch: 2490\n",
      "Batch: 2491\n",
      "Batch: 2492\n",
      "Batch: 2493\n",
      "Batch: 2494\n",
      "Batch: 2495\n",
      "Batch: 2496\n",
      "Batch: 2497\n",
      "Batch: 2498\n",
      "Batch: 2499\n",
      "Batch: 2500\n",
      "Batch: 2501\n",
      "Batch: 2502\n",
      "Batch: 2503\n",
      "Batch: 2504\n",
      "Batch: 2505\n",
      "Batch: 2506\n",
      "Batch: 2507\n",
      "Batch: 2508\n",
      "Batch: 2509\n",
      "Batch: 2510\n",
      "Batch: 2511\n",
      "Batch: 2512\n",
      "Batch: 2513\n",
      "Batch: 2514\n",
      "Batch: 2515\n",
      "Batch: 2516\n",
      "Batch: 2517\n",
      "Batch: 2518\n",
      "Batch: 2519\n",
      "Batch: 2520\n",
      "Batch: 2521\n",
      "Batch: 2522\n",
      "Batch: 2523\n",
      "Batch: 2524\n",
      "Batch: 2525\n",
      "Batch: 2526\n",
      "Batch: 2527\n",
      "Batch: 2528\n",
      "Batch: 2529\n",
      "Batch: 2530\n",
      "Batch: 2531\n",
      "Batch: 2532\n",
      "Batch: 2533\n",
      "Batch: 2534\n",
      "Batch: 2535\n",
      "Batch: 2536\n",
      "Batch: 2537\n",
      "Batch: 2538\n",
      "Batch: 2539\n",
      "Batch: 2540\n",
      "Batch: 2541\n",
      "Batch: 2542\n",
      "Batch: 2543\n",
      "Batch: 2544\n",
      "Batch: 2545\n",
      "Batch: 2546\n",
      "Batch: 2547\n",
      "Batch: 2548\n",
      "Batch: 2549\n",
      "Batch: 2550\n",
      "Batch: 2551\n",
      "Batch: 2552\n",
      "Batch: 2553\n",
      "Batch: 2554\n",
      "Batch: 2555\n",
      "Batch: 2556\n",
      "Batch: 2557\n",
      "Batch: 2558\n",
      "Batch: 2559\n",
      "Batch: 2560\n",
      "Batch: 2561\n",
      "Batch: 2562\n",
      "Batch: 2563\n",
      "Batch: 2564\n",
      "Batch: 2565\n",
      "Batch: 2566\n",
      "Batch: 2567\n",
      "Batch: 2568\n",
      "Batch: 2569\n",
      "Batch: 2570\n",
      "Batch: 2571\n",
      "Batch: 2572\n",
      "Batch: 2573\n",
      "Batch: 2574\n",
      "Batch: 2575\n",
      "Batch: 2576\n",
      "Batch: 2577\n",
      "Batch: 2578\n",
      "Batch: 2579\n",
      "Batch: 2580\n",
      "Batch: 2581\n",
      "Batch: 2582\n",
      "Batch: 2583\n",
      "Batch: 2584\n",
      "Batch: 2585\n",
      "Batch: 2586\n",
      "Batch: 2587\n",
      "Batch: 2588\n",
      "Batch: 2589\n",
      "Batch: 2590\n",
      "Batch: 2591\n",
      "Batch: 2592\n",
      "Batch: 2593\n",
      "Batch: 2594\n",
      "Batch: 2595\n",
      "Batch: 2596\n",
      "Batch: 2597\n",
      "Batch: 2598\n",
      "Batch: 2599\n",
      "Batch: 2600\n",
      "Batch: 2601\n",
      "Batch: 2602\n",
      "Batch: 2603\n",
      "Batch: 2604\n",
      "Batch: 2605\n",
      "Batch: 2606\n",
      "Batch: 2607\n",
      "Batch: 2608\n",
      "Batch: 2609\n",
      "Batch: 2610\n",
      "Batch: 2611\n",
      "Batch: 2612\n",
      "Batch: 2613\n",
      "Batch: 2614\n",
      "Batch: 2615\n",
      "Batch: 2616\n",
      "Batch: 2617\n",
      "Batch: 2618\n",
      "Batch: 2619\n",
      "Batch: 2620\n",
      "Batch: 2621\n",
      "Batch: 2622\n",
      "Batch: 2623\n",
      "Batch: 2624\n",
      "Batch: 2625\n",
      "Batch: 2626\n",
      "Batch: 2627\n",
      "Batch: 2628\n",
      "Batch: 2629\n",
      "Batch: 2630\n",
      "Batch: 2631\n",
      "Batch: 2632\n",
      "Batch: 2633\n",
      "Batch: 2634\n",
      "Batch: 2635\n",
      "Batch: 2636\n",
      "Batch: 2637\n",
      "Batch: 2638\n",
      "Batch: 2639\n",
      "Batch: 2640\n",
      "Batch: 2641\n",
      "Batch: 2642\n",
      "Batch: 2643\n",
      "Batch: 2644\n",
      "Batch: 2645\n",
      "Batch: 2646\n",
      "Batch: 2647\n",
      "Batch: 2648\n",
      "Batch: 2649\n",
      "Batch: 2650\n",
      "Batch: 2651\n",
      "Batch: 2652\n",
      "Batch: 2653\n",
      "Batch: 2654\n",
      "Batch: 2655\n",
      "Batch: 2656\n",
      "Batch: 2657\n",
      "Batch: 2658\n",
      "Batch: 2659\n",
      "Batch: 2660\n",
      "Batch: 2661\n",
      "Batch: 2662\n",
      "Batch: 2663\n",
      "Batch: 2664\n",
      "Batch: 2665\n",
      "Batch: 2666\n",
      "Batch: 2667\n",
      "Batch: 2668\n",
      "Batch: 2669\n",
      "Batch: 2670\n",
      "Batch: 2671\n",
      "Batch: 2672\n",
      "Batch: 2673\n",
      "Batch: 2674\n",
      "Batch: 2675\n",
      "Batch: 2676\n",
      "Batch: 2677\n",
      "Batch: 2678\n",
      "Batch: 2679\n",
      "Batch: 2680\n",
      "Batch: 2681\n",
      "Batch: 2682\n",
      "Batch: 2683\n",
      "Batch: 2684\n",
      "Batch: 2685\n",
      "Batch: 2686\n",
      "Batch: 2687\n",
      "Batch: 2688\n",
      "Batch: 2689\n",
      "Batch: 2690\n",
      "Batch: 2691\n",
      "Batch: 2692\n",
      "Batch: 2693\n",
      "Batch: 2694\n",
      "Batch: 2695\n",
      "Batch: 2696\n",
      "Batch: 2697\n",
      "Batch: 2698\n",
      "Batch: 2699\n",
      "Batch: 2700\n",
      "Batch: 2701\n",
      "Batch: 2702\n",
      "Batch: 2703\n",
      "Batch: 2704\n",
      "Batch: 2705\n",
      "Batch: 2706\n",
      "Batch: 2707\n",
      "Batch: 2708\n",
      "Batch: 2709\n",
      "Batch: 2710\n",
      "Batch: 2711\n",
      "Batch: 2712\n",
      "Batch: 2713\n",
      "Batch: 2714\n",
      "Batch: 2715\n",
      "Batch: 2716\n",
      "Batch: 2717\n",
      "Batch: 2718\n",
      "Batch: 2719\n",
      "Batch: 2720\n",
      "Batch: 2721\n",
      "Batch: 2722\n",
      "Batch: 2723\n",
      "Batch: 2724\n",
      "Batch: 2725\n",
      "Batch: 2726\n",
      "Batch: 2727\n",
      "Batch: 2728\n",
      "Batch: 2729\n",
      "Batch: 2730\n",
      "Batch: 2731\n",
      "Batch: 2732\n",
      "Batch: 2733\n",
      "Batch: 2734\n",
      "Batch: 2735\n",
      "Batch: 2736\n",
      "Batch: 2737\n",
      "Batch: 2738\n",
      "Batch: 2739\n",
      "Batch: 2740\n",
      "Batch: 2741\n",
      "Batch: 2742\n",
      "Batch: 2743\n",
      "Batch: 2744\n",
      "Batch: 2745\n",
      "Batch: 2746\n",
      "Batch: 2747\n",
      "Batch: 2748\n",
      "Batch: 2749\n",
      "Batch: 2750\n",
      "Batch: 2751\n",
      "Batch: 2752\n",
      "Batch: 2753\n",
      "Batch: 2754\n",
      "Batch: 2755\n",
      "Batch: 2756\n",
      "Batch: 2757\n",
      "Batch: 2758\n",
      "Batch: 2759\n",
      "Batch: 2760\n",
      "Batch: 2761\n",
      "Batch: 2762\n",
      "Batch: 2763\n",
      "Batch: 2764\n",
      "Batch: 2765\n",
      "Batch: 2766\n",
      "Batch: 2767\n",
      "Batch: 2768\n",
      "Batch: 2769\n",
      "Batch: 2770\n",
      "Batch: 2771\n",
      "Batch: 2772\n",
      "Batch: 2773\n",
      "Batch: 2774\n",
      "Batch: 2775\n",
      "Batch: 2776\n",
      "Batch: 2777\n",
      "Batch: 2778\n",
      "Batch: 2779\n",
      "Batch: 2780\n",
      "Batch: 2781\n",
      "Batch: 2782\n",
      "Batch: 2783\n",
      "Batch: 2784\n",
      "Batch: 2785\n",
      "Batch: 2786\n",
      "Batch: 2787\n",
      "Batch: 2788\n",
      "Batch: 2789\n",
      "Batch: 2790\n",
      "Batch: 2791\n",
      "Batch: 2792\n",
      "Batch: 2793\n",
      "Batch: 2794\n",
      "Batch: 2795\n",
      "Batch: 2796\n",
      "Batch: 2797\n",
      "Batch: 2798\n",
      "Batch: 2799\n",
      "Batch: 2800\n",
      "Batch: 2801\n",
      "Batch: 2802\n",
      "Batch: 2803\n",
      "Batch: 2804\n",
      "Batch: 2805\n",
      "Batch: 2806\n",
      "Batch: 2807\n",
      "Batch: 2808\n",
      "Batch: 2809\n",
      "Batch: 2810\n",
      "Batch: 2811\n",
      "Batch: 2812\n",
      "Batch: 2813\n",
      "Batch: 2814\n",
      "Batch: 2815\n",
      "Batch: 2816\n",
      "Batch: 2817\n",
      "Batch: 2818\n",
      "Batch: 2819\n",
      "Batch: 2820\n",
      "Batch: 2821\n",
      "Batch: 2822\n",
      "Batch: 2823\n",
      "Batch: 2824\n",
      "Batch: 2825\n",
      "Batch: 2826\n",
      "Batch: 2827\n",
      "Batch: 2828\n",
      "Batch: 2829\n",
      "Batch: 2830\n",
      "Batch: 2831\n",
      "Batch: 2832\n",
      "Batch: 2833\n",
      "Batch: 2834\n",
      "Batch: 2835\n",
      "Batch: 2836\n",
      "Batch: 2837\n",
      "Batch: 2838\n",
      "Batch: 2839\n",
      "Batch: 2840\n",
      "Batch: 2841\n",
      "Batch: 2842\n",
      "Batch: 2843\n",
      "Batch: 2844\n",
      "Batch: 2845\n",
      "Batch: 2846\n",
      "Batch: 2847\n",
      "Batch: 2848\n",
      "Batch: 2849\n",
      "Batch: 2850\n",
      "Batch: 2851\n",
      "Batch: 2852\n",
      "Batch: 2853\n",
      "Batch: 2854\n",
      "Batch: 2855\n",
      "Batch: 2856\n",
      "Batch: 2857\n",
      "Batch: 2858\n",
      "Batch: 2859\n",
      "Batch: 2860\n",
      "Batch: 2861\n",
      "Batch: 2862\n",
      "Batch: 2863\n",
      "Batch: 2864\n",
      "Batch: 2865\n",
      "Batch: 2866\n",
      "Batch: 2867\n",
      "Batch: 2868\n",
      "Batch: 2869\n",
      "Batch: 2870\n",
      "Batch: 2871\n",
      "Batch: 2872\n",
      "Batch: 2873\n",
      "Batch: 2874\n",
      "Batch: 2875\n",
      "Batch: 2876\n",
      "Batch: 2877\n",
      "Batch: 2878\n",
      "Batch: 2879\n",
      "Batch: 2880\n",
      "Batch: 2881\n",
      "Batch: 2882\n",
      "Batch: 2883\n",
      "Batch: 2884\n",
      "Batch: 2885\n",
      "Batch: 2886\n",
      "Batch: 2887\n",
      "Batch: 2888\n",
      "Batch: 2889\n",
      "Batch: 2890\n",
      "Batch: 2891\n",
      "Batch: 2892\n",
      "Batch: 2893\n",
      "Batch: 2894\n",
      "Batch: 2895\n",
      "Batch: 2896\n",
      "Batch: 2897\n",
      "Batch: 2898\n",
      "Batch: 2899\n",
      "Batch: 2900\n",
      "Batch: 2901\n",
      "Batch: 2902\n",
      "Batch: 2903\n",
      "Batch: 2904\n",
      "Batch: 2905\n",
      "Batch: 2906\n",
      "Batch: 2907\n",
      "Batch: 2908\n",
      "Batch: 2909\n",
      "Batch: 2910\n",
      "Batch: 2911\n",
      "Batch: 2912\n",
      "Batch: 2913\n",
      "Batch: 2914\n",
      "Batch: 2915\n",
      "Batch: 2916\n",
      "Batch: 2917\n",
      "Batch: 2918\n",
      "Batch: 2919\n",
      "Batch: 2920\n",
      "Batch: 2921\n",
      "Batch: 2922\n",
      "Batch: 2923\n",
      "Batch: 2924\n",
      "Batch: 2925\n",
      "Batch: 2926\n",
      "Batch: 2927\n",
      "Batch: 2928\n",
      "Batch: 2929\n",
      "Batch: 2930\n",
      "Batch: 2931\n",
      "Batch: 2932\n",
      "Batch: 2933\n",
      "Batch: 2934\n",
      "Batch: 2935\n",
      "Batch: 2936\n",
      "Batch: 2937\n",
      "Batch: 2938\n",
      "Batch: 2939\n",
      "Batch: 2940\n",
      "Batch: 2941\n",
      "Batch: 2942\n",
      "Batch: 2943\n",
      "Batch: 2944\n",
      "Batch: 2945\n",
      "Batch: 2946\n",
      "Batch: 2947\n",
      "Batch: 2948\n",
      "Batch: 2949\n",
      "Batch: 2950\n",
      "Batch: 2951\n",
      "Batch: 2952\n",
      "Batch: 2953\n",
      "Batch: 2954\n",
      "Batch: 2955\n",
      "Batch: 2956\n",
      "Batch: 2957\n",
      "Batch: 2958\n",
      "Batch: 2959\n",
      "Batch: 2960\n",
      "Batch: 2961\n",
      "Batch: 2962\n",
      "Batch: 2963\n",
      "Batch: 2964\n",
      "Batch: 2965\n",
      "Batch: 2966\n",
      "Batch: 2967\n",
      "Batch: 2968\n",
      "Batch: 2969\n",
      "Batch: 2970\n",
      "Batch: 2971\n",
      "Batch: 2972\n",
      "Batch: 2973\n",
      "Batch: 2974\n",
      "Batch: 2975\n",
      "Batch: 2976\n",
      "Batch: 2977\n",
      "Batch: 2978\n",
      "Batch: 2979\n",
      "Batch: 2980\n",
      "Batch: 2981\n",
      "Batch: 2982\n",
      "Batch: 2983\n",
      "Batch: 2984\n",
      "Batch: 2985\n",
      "Batch: 2986\n",
      "Batch: 2987\n",
      "Batch: 2988\n",
      "Batch: 2989\n",
      "Batch: 2990\n",
      "Batch: 2991\n",
      "Batch: 2992\n",
      "Batch: 2993\n",
      "Batch: 2994\n",
      "Batch: 2995\n",
      "Batch: 2996\n",
      "Batch: 2997\n",
      "Batch: 2998\n",
      "Batch: 2999\n",
      "Batch: 3000\n",
      "Batch: 3001\n",
      "Batch: 3002\n",
      "Batch: 3003\n",
      "Batch: 3004\n",
      "Batch: 3005\n",
      "Batch: 3006\n",
      "Batch: 3007\n",
      "Batch: 3008\n",
      "Batch: 3009\n",
      "Batch: 3010\n",
      "Batch: 3011\n",
      "Batch: 3012\n",
      "Batch: 3013\n",
      "Batch: 3014\n",
      "Batch: 3015\n",
      "Batch: 3016\n",
      "Batch: 3017\n",
      "Batch: 3018\n",
      "Batch: 3019\n",
      "Batch: 3020\n",
      "Batch: 3021\n",
      "Batch: 3022\n",
      "Batch: 3023\n",
      "Batch: 3024\n",
      "Batch: 3025\n",
      "Batch: 3026\n",
      "Batch: 3027\n",
      "Batch: 3028\n",
      "Batch: 3029\n",
      "Batch: 3030\n",
      "Batch: 3031\n",
      "Batch: 3032\n",
      "Batch: 3033\n",
      "Batch: 3034\n",
      "Batch: 3035\n",
      "Batch: 3036\n",
      "Batch: 3037\n",
      "Batch: 3038\n",
      "Batch: 3039\n",
      "Batch: 3040\n",
      "Batch: 3041\n",
      "Batch: 3042\n",
      "Batch: 3043\n",
      "Batch: 3044\n",
      "Batch: 3045\n",
      "Batch: 3046\n",
      "Batch: 3047\n",
      "Batch: 3048\n",
      "Batch: 3049\n",
      "Batch: 3050\n",
      "Batch: 3051\n",
      "Batch: 3052\n",
      "Batch: 3053\n",
      "Batch: 3054\n",
      "Batch: 3055\n",
      "Batch: 3056\n",
      "Batch: 3057\n",
      "Batch: 3058\n",
      "Batch: 3059\n",
      "Batch: 3060\n",
      "Batch: 3061\n",
      "Batch: 3062\n",
      "Batch: 3063\n",
      "Batch: 3064\n",
      "Batch: 3065\n",
      "Batch: 3066\n",
      "Batch: 3067\n",
      "Batch: 3068\n",
      "Batch: 3069\n",
      "Batch: 3070\n",
      "Batch: 3071\n",
      "Batch: 3072\n",
      "Batch: 3073\n",
      "Batch: 3074\n",
      "Batch: 3075\n",
      "Batch: 3076\n",
      "Batch: 3077\n",
      "Batch: 3078\n",
      "Batch: 3079\n",
      "Batch: 3080\n",
      "Batch: 3081\n",
      "Batch: 3082\n",
      "Batch: 3083\n",
      "Batch: 3084\n",
      "Batch: 3085\n",
      "Batch: 3086\n",
      "Batch: 3087\n",
      "Batch: 3088\n",
      "Batch: 3089\n",
      "Batch: 3090\n",
      "Batch: 3091\n",
      "Batch: 3092\n",
      "Batch: 3093\n",
      "Batch: 3094\n",
      "Batch: 3095\n",
      "Batch: 3096\n",
      "Batch: 3097\n",
      "Batch: 3098\n",
      "Batch: 3099\n",
      "Batch: 3100\n",
      "Batch: 3101\n",
      "Batch: 3102\n",
      "Batch: 3103\n",
      "Batch: 3104\n",
      "Batch: 3105\n",
      "Batch: 3106\n",
      "Batch: 3107\n",
      "Batch: 3108\n",
      "Batch: 3109\n",
      "Batch: 3110\n",
      "Batch: 3111\n",
      "Batch: 3112\n",
      "Batch: 3113\n",
      "Batch: 3114\n",
      "Batch: 3115\n",
      "Batch: 3116\n",
      "Batch: 3117\n",
      "Batch: 3118\n",
      "Batch: 3119\n",
      "Batch: 3120\n",
      "Batch: 3121\n",
      "Batch: 3122\n",
      "Batch: 3123\n",
      "Batch: 3124\n",
      "Batch: 3125\n",
      "Batch: 3126\n",
      "Batch: 3127\n",
      "Batch: 3128\n",
      "Batch: 3129\n",
      "Batch: 3130\n",
      "Batch: 3131\n",
      "Batch: 3132\n",
      "Batch: 3133\n",
      "Batch: 3134\n",
      "Batch: 3135\n",
      "Batch: 3136\n",
      "Batch: 3137\n",
      "Batch: 3138\n",
      "Batch: 3139\n",
      "Batch: 3140\n",
      "Batch: 3141\n",
      "Batch: 3142\n",
      "Batch: 3143\n",
      "Batch: 3144\n",
      "Batch: 3145\n",
      "Batch: 3146\n",
      "Batch: 3147\n",
      "Batch: 3148\n",
      "Batch: 3149\n",
      "Batch: 3150\n",
      "Batch: 3151\n",
      "Batch: 3152\n",
      "Batch: 3153\n",
      "Batch: 3154\n",
      "Batch: 3155\n",
      "Batch: 3156\n",
      "Batch: 3157\n",
      "Batch: 3158\n",
      "Batch: 3159\n",
      "Batch: 3160\n",
      "Batch: 3161\n",
      "Batch: 3162\n",
      "Batch: 3163\n",
      "Batch: 3164\n",
      "Batch: 3165\n",
      "Batch: 3166\n",
      "Batch: 3167\n",
      "Batch: 3168\n",
      "Batch: 3169\n",
      "Batch: 3170\n",
      "Batch: 3171\n",
      "Batch: 3172\n",
      "Batch: 3173\n",
      "Batch: 3174\n",
      "Batch: 3175\n",
      "Batch: 3176\n",
      "Batch: 3177\n",
      "Batch: 3178\n",
      "Batch: 3179\n",
      "Batch: 3180\n",
      "Batch: 3181\n",
      "Batch: 3182\n",
      "Batch: 3183\n",
      "Batch: 3184\n",
      "Batch: 3185\n",
      "Batch: 3186\n",
      "Batch: 3187\n",
      "Batch: 3188\n",
      "Batch: 3189\n",
      "Batch: 3190\n",
      "Batch: 3191\n",
      "Batch: 3192\n",
      "Batch: 3193\n",
      "Batch: 3194\n",
      "Batch: 3195\n",
      "Batch: 3196\n",
      "Batch: 3197\n",
      "Batch: 3198\n",
      "Batch: 3199\n",
      "Batch: 3200\n",
      "Batch: 3201\n",
      "Batch: 3202\n",
      "Batch: 3203\n",
      "Batch: 3204\n",
      "Batch: 3205\n",
      "Batch: 3206\n",
      "Batch: 3207\n",
      "Batch: 3208\n",
      "Batch: 3209\n",
      "Batch: 3210\n",
      "Batch: 3211\n",
      "Batch: 3212\n",
      "Batch: 3213\n",
      "Batch: 3214\n",
      "Batch: 3215\n",
      "Batch: 3216\n",
      "Batch: 3217\n",
      "Batch: 3218\n",
      "Batch: 3219\n",
      "Batch: 3220\n",
      "Batch: 3221\n",
      "Batch: 3222\n",
      "Batch: 3223\n",
      "Batch: 3224\n",
      "Batch: 3225\n",
      "Batch: 3226\n",
      "Batch: 3227\n",
      "Batch: 3228\n",
      "Batch: 3229\n",
      "Batch: 3230\n",
      "Batch: 3231\n",
      "Batch: 3232\n",
      "Batch: 3233\n",
      "Batch: 3234\n",
      "Batch: 3235\n",
      "Batch: 3236\n",
      "Batch: 3237\n",
      "Batch: 3238\n",
      "Batch: 3239\n",
      "Batch: 3240\n",
      "Batch: 3241\n",
      "Batch: 3242\n",
      "Batch: 3243\n",
      "Batch: 3244\n",
      "Batch: 3245\n",
      "Batch: 3246\n",
      "Batch: 3247\n",
      "Batch: 3248\n",
      "Batch: 3249\n",
      "Batch: 3250\n",
      "Batch: 3251\n",
      "Batch: 3252\n",
      "Batch: 3253\n",
      "Batch: 3254\n",
      "Batch: 3255\n",
      "Batch: 3256\n",
      "Batch: 3257\n",
      "Batch: 3258\n",
      "Batch: 3259\n",
      "Batch: 3260\n",
      "Batch: 3261\n",
      "Batch: 3262\n",
      "Batch: 3263\n",
      "Batch: 3264\n",
      "Batch: 3265\n",
      "Batch: 3266\n",
      "Batch: 3267\n",
      "Batch: 3268\n",
      "Batch: 3269\n",
      "Batch: 3270\n",
      "Batch: 3271\n",
      "Batch: 3272\n",
      "Batch: 3273\n",
      "Batch: 3274\n",
      "Batch: 3275\n",
      "Batch: 3276\n",
      "Batch: 3277\n",
      "Batch: 3278\n",
      "Batch: 3279\n",
      "Batch: 3280\n",
      "Batch: 3281\n",
      "Batch: 3282\n",
      "Batch: 3283\n",
      "Batch: 3284\n",
      "Batch: 3285\n",
      "Batch: 3286\n",
      "Batch: 3287\n",
      "Batch: 3288\n",
      "Batch: 3289\n",
      "Batch: 3290\n",
      "Batch: 3291\n",
      "Batch: 3292\n",
      "Batch: 3293\n",
      "Batch: 3294\n",
      "Batch: 3295\n",
      "Batch: 3296\n",
      "Batch: 3297\n",
      "Batch: 3298\n",
      "Batch: 3299\n",
      "Batch: 3300\n",
      "Batch: 3301\n",
      "Batch: 3302\n",
      "Batch: 3303\n",
      "Batch: 3304\n",
      "Batch: 3305\n",
      "Batch: 3306\n",
      "Batch: 3307\n",
      "Batch: 3308\n",
      "Batch: 3309\n",
      "Batch: 3310\n",
      "Batch: 3311\n",
      "Batch: 3312\n",
      "Batch: 3313\n",
      "Batch: 3314\n",
      "Batch: 3315\n",
      "Batch: 3316\n",
      "Batch: 3317\n",
      "Batch: 3318\n",
      "Batch: 3319\n",
      "Batch: 3320\n",
      "Batch: 3321\n",
      "Batch: 3322\n",
      "Batch: 3323\n",
      "Batch: 3324\n",
      "Batch: 3325\n",
      "Batch: 3326\n",
      "Batch: 3327\n",
      "Batch: 3328\n",
      "Batch: 3329\n",
      "Batch: 3330\n",
      "Batch: 3331\n",
      "Batch: 3332\n",
      "Batch: 3333\n",
      "Batch: 3334\n",
      "Batch: 3335\n",
      "Batch: 3336\n",
      "Batch: 3337\n",
      "Batch: 3338\n",
      "Batch: 3339\n",
      "Batch: 3340\n",
      "Batch: 3341\n",
      "Batch: 3342\n",
      "Batch: 3343\n",
      "Batch: 3344\n",
      "Batch: 3345\n",
      "Batch: 3346\n",
      "Batch: 3347\n",
      "Batch: 3348\n",
      "Batch: 3349\n",
      "Batch: 3350\n",
      "Batch: 3351\n",
      "Batch: 3352\n",
      "Batch: 3353\n",
      "Batch: 3354\n",
      "Batch: 3355\n",
      "Batch: 3356\n",
      "Batch: 3357\n",
      "Batch: 3358\n",
      "Batch: 3359\n",
      "Batch: 3360\n",
      "Batch: 3361\n",
      "Batch: 3362\n",
      "Batch: 3363\n",
      "Batch: 3364\n",
      "Batch: 3365\n",
      "Batch: 3366\n",
      "Batch: 3367\n",
      "Batch: 3368\n",
      "Batch: 3369\n",
      "Batch: 3370\n",
      "Batch: 3371\n",
      "Batch: 3372\n",
      "Batch: 3373\n",
      "Batch: 3374\n",
      "Batch: 3375\n",
      "Batch: 3376\n",
      "Batch: 3377\n",
      "Batch: 3378\n",
      "Batch: 3379\n",
      "Batch: 3380\n",
      "Batch: 3381\n",
      "Batch: 3382\n",
      "Batch: 3383\n",
      "Batch: 3384\n",
      "Batch: 3385\n",
      "Batch: 3386\n",
      "Batch: 3387\n",
      "Batch: 3388\n",
      "Batch: 3389\n",
      "Batch: 3390\n",
      "Batch: 3391\n",
      "Batch: 3392\n",
      "Batch: 3393\n",
      "Batch: 3394\n",
      "Batch: 3395\n",
      "Batch: 3396\n",
      "Batch: 3397\n",
      "Batch: 3398\n",
      "Batch: 3399\n",
      "Batch: 3400\n",
      "Batch: 3401\n",
      "Batch: 3402\n",
      "Batch: 3403\n",
      "Batch: 3404\n",
      "Batch: 3405\n",
      "Batch: 3406\n",
      "Batch: 3407\n",
      "Batch: 3408\n",
      "Batch: 3409\n",
      "Batch: 3410\n",
      "Batch: 3411\n",
      "Batch: 3412\n",
      "Batch: 3413\n",
      "Batch: 3414\n",
      "Batch: 3415\n",
      "Batch: 3416\n",
      "Batch: 3417\n",
      "Batch: 3418\n",
      "Batch: 3419\n",
      "Batch: 3420\n",
      "Batch: 3421\n",
      "Batch: 3422\n",
      "Batch: 3423\n",
      "Batch: 3424\n",
      "Batch: 3425\n",
      "Batch: 3426\n",
      "Batch: 3427\n",
      "Batch: 3428\n",
      "Batch: 3429\n",
      "Batch: 3430\n",
      "Batch: 3431\n",
      "Batch: 3432\n",
      "Batch: 3433\n",
      "Batch: 3434\n",
      "Batch: 3435\n",
      "Batch: 3436\n",
      "Batch: 3437\n",
      "Batch: 3438\n",
      "Batch: 3439\n",
      "Batch: 3440\n",
      "Batch: 3441\n",
      "Batch: 3442\n",
      "Batch: 3443\n",
      "Batch: 3444\n",
      "Batch: 3445\n",
      "Batch: 3446\n",
      "Batch: 3447\n",
      "Batch: 3448\n",
      "Batch: 3449\n",
      "Batch: 3450\n",
      "Batch: 3451\n",
      "Batch: 3452\n",
      "Batch: 3453\n",
      "Batch: 3454\n",
      "Batch: 3455\n",
      "Batch: 3456\n",
      "Batch: 3457\n",
      "Batch: 3458\n",
      "Batch: 3459\n",
      "Batch: 3460\n",
      "Batch: 3461\n",
      "Batch: 3462\n",
      "Batch: 3463\n",
      "Batch: 3464\n",
      "Batch: 3465\n",
      "Batch: 3466\n",
      "Batch: 3467\n",
      "Batch: 3468\n",
      "Batch: 3469\n",
      "Batch: 3470\n",
      "Batch: 3471\n",
      "Batch: 3472\n",
      "Batch: 3473\n",
      "Batch: 3474\n",
      "Batch: 3475\n",
      "Batch: 3476\n",
      "Batch: 3477\n",
      "Batch: 3478\n",
      "Batch: 3479\n",
      "Batch: 3480\n",
      "Batch: 3481\n",
      "Batch: 3482\n",
      "Batch: 3483\n",
      "Batch: 3484\n",
      "Batch: 3485\n",
      "Batch: 3486\n",
      "Batch: 3487\n",
      "Batch: 3488\n",
      "Batch: 3489\n",
      "Batch: 3490\n",
      "Batch: 3491\n",
      "Batch: 3492\n",
      "Batch: 3493\n",
      "Batch: 3494\n",
      "Batch: 3495\n",
      "Batch: 3496\n",
      "Batch: 3497\n",
      "Batch: 3498\n",
      "Batch: 3499\n",
      "Batch: 3500\n",
      "Batch: 3501\n",
      "Batch: 3502\n",
      "Batch: 3503\n",
      "Batch: 3504\n",
      "Batch: 3505\n",
      "Batch: 3506\n",
      "Batch: 3507\n",
      "Batch: 3508\n",
      "Batch: 3509\n",
      "Batch: 3510\n",
      "Batch: 3511\n",
      "Batch: 3512\n",
      "Batch: 3513\n",
      "Batch: 3514\n",
      "Batch: 3515\n",
      "Batch: 3516\n",
      "Batch: 3517\n",
      "Batch: 3518\n",
      "Batch: 3519\n",
      "Batch: 3520\n",
      "Batch: 3521\n",
      "Batch: 3522\n",
      "Batch: 3523\n",
      "Batch: 3524\n",
      "Batch: 3525\n",
      "Batch: 3526\n",
      "Batch: 3527\n",
      "Batch: 3528\n",
      "Batch: 3529\n",
      "Batch: 3530\n",
      "Batch: 3531\n",
      "Batch: 3532\n",
      "Batch: 3533\n",
      "Batch: 3534\n",
      "Batch: 3535\n",
      "Batch: 3536\n",
      "Batch: 3537\n",
      "Batch: 3538\n",
      "Batch: 3539\n",
      "Batch: 3540\n",
      "Batch: 3541\n",
      "Batch: 3542\n",
      "Batch: 3543\n",
      "Batch: 3544\n",
      "Batch: 3545\n",
      "Batch: 3546\n",
      "Batch: 3547\n",
      "Batch: 3548\n",
      "Batch: 3549\n",
      "Batch: 3550\n",
      "Batch: 3551\n",
      "Batch: 3552\n",
      "Batch: 3553\n",
      "Batch: 3554\n",
      "Batch: 3555\n",
      "Batch: 3556\n",
      "Batch: 3557\n",
      "Batch: 3558\n",
      "Batch: 3559\n",
      "Batch: 3560\n",
      "Batch: 3561\n",
      "Batch: 3562\n",
      "Batch: 3563\n",
      "Batch: 3564\n",
      "Batch: 3565\n",
      "Batch: 3566\n",
      "Batch: 3567\n",
      "Batch: 3568\n",
      "Batch: 3569\n",
      "Batch: 3570\n",
      "Batch: 3571\n",
      "Batch: 3572\n",
      "Batch: 3573\n",
      "Batch: 3574\n",
      "Batch: 3575\n",
      "Batch: 3576\n",
      "Batch: 3577\n",
      "Batch: 3578\n",
      "Batch: 3579\n",
      "Batch: 3580\n",
      "Batch: 3581\n",
      "Batch: 3582\n",
      "Batch: 3583\n",
      "Batch: 3584\n",
      "Batch: 3585\n",
      "Batch: 3586\n",
      "Batch: 3587\n",
      "Batch: 3588\n",
      "Batch: 3589\n",
      "Batch: 3590\n",
      "Batch: 3591\n",
      "Batch: 3592\n",
      "Batch: 3593\n",
      "Batch: 3594\n",
      "Batch: 3595\n",
      "Batch: 3596\n",
      "Batch: 3597\n",
      "Batch: 3598\n",
      "Batch: 3599\n",
      "Batch: 3600\n",
      "Batch: 3601\n",
      "Batch: 3602\n",
      "Batch: 3603\n",
      "Batch: 3604\n",
      "Batch: 3605\n",
      "Batch: 3606\n",
      "Batch: 3607\n",
      "Batch: 3608\n",
      "Batch: 3609\n",
      "Batch: 3610\n",
      "Batch: 3611\n",
      "Batch: 3612\n",
      "Batch: 3613\n",
      "Batch: 3614\n",
      "Batch: 3615\n",
      "Batch: 3616\n",
      "Batch: 3617\n",
      "Batch: 3618\n",
      "Batch: 3619\n",
      "Batch: 3620\n",
      "Batch: 3621\n",
      "Batch: 3622\n",
      "Batch: 3623\n",
      "Batch: 3624\n",
      "Batch: 3625\n",
      "Batch: 3626\n",
      "Batch: 3627\n",
      "Batch: 3628\n",
      "Batch: 3629\n",
      "Batch: 3630\n",
      "Batch: 3631\n",
      "Batch: 3632\n",
      "Batch: 3633\n",
      "Batch: 3634\n",
      "Batch: 3635\n",
      "Batch: 3636\n",
      "Batch: 3637\n",
      "Batch: 3638\n",
      "Batch: 3639\n",
      "Batch: 3640\n",
      "Batch: 3641\n",
      "Batch: 3642\n",
      "Batch: 3643\n",
      "Batch: 3644\n",
      "Batch: 3645\n",
      "Batch: 3646\n",
      "Batch: 3647\n",
      "Batch: 3648\n",
      "Batch: 3649\n",
      "Batch: 3650\n",
      "Batch: 3651\n",
      "Batch: 3652\n",
      "Batch: 3653\n",
      "Batch: 3654\n",
      "Batch: 3655\n",
      "Batch: 3656\n",
      "Batch: 3657\n",
      "Batch: 3658\n",
      "Batch: 3659\n",
      "Batch: 3660\n",
      "Batch: 3661\n",
      "Batch: 3662\n",
      "Batch: 3663\n",
      "Batch: 3664\n",
      "Batch: 3665\n",
      "Batch: 3666\n",
      "Batch: 3667\n",
      "Batch: 3668\n",
      "Batch: 3669\n",
      "Batch: 3670\n",
      "Batch: 3671\n",
      "Batch: 3672\n",
      "Batch: 3673\n",
      "Batch: 3674\n",
      "Batch: 3675\n",
      "Batch: 3676\n",
      "Batch: 3677\n",
      "Batch: 3678\n",
      "Batch: 3679\n",
      "Batch: 3680\n",
      "Batch: 3681\n",
      "Batch: 3682\n",
      "Batch: 3683\n",
      "Batch: 3684\n",
      "Batch: 3685\n",
      "Batch: 3686\n",
      "Batch: 3687\n",
      "Batch: 3688\n",
      "Batch: 3689\n",
      "Batch: 3690\n",
      "Batch: 3691\n",
      "Batch: 3692\n",
      "Batch: 3693\n",
      "Batch: 3694\n",
      "Batch: 3695\n",
      "Batch: 3696\n",
      "Batch: 3697\n",
      "Batch: 3698\n",
      "Batch: 3699\n",
      "Batch: 3700\n",
      "Batch: 3701\n",
      "Batch: 3702\n",
      "Batch: 3703\n",
      "Batch: 3704\n",
      "Batch: 3705\n",
      "Batch: 3706\n",
      "Batch: 3707\n",
      "Batch: 3708\n",
      "Batch: 3709\n",
      "Batch: 3710\n",
      "Batch: 3711\n",
      "Batch: 3712\n",
      "Batch: 3713\n",
      "Batch: 3714\n",
      "Batch: 3715\n",
      "Batch: 3716\n",
      "Batch: 3717\n",
      "Batch: 3718\n",
      "Batch: 3719\n",
      "Batch: 3720\n",
      "Batch: 3721\n",
      "Batch: 3722\n",
      "Batch: 3723\n",
      "Batch: 3724\n",
      "Batch: 3725\n",
      "Batch: 3726\n",
      "Batch: 3727\n",
      "Batch: 3728\n",
      "Batch: 3729\n",
      "Batch: 3730\n",
      "Batch: 3731\n",
      "Batch: 3732\n",
      "Batch: 3733\n",
      "Batch: 3734\n",
      "Batch: 3735\n",
      "Batch: 3736\n",
      "Batch: 3737\n",
      "Batch: 3738\n",
      "Batch: 3739\n",
      "Batch: 3740\n",
      "Batch: 3741\n",
      "Batch: 3742\n",
      "Batch: 3743\n",
      "Batch: 3744\n",
      "Batch: 3745\n",
      "Batch: 3746\n",
      "Batch: 3747\n",
      "Batch: 3748\n",
      "Batch: 3749\n",
      "Batch: 3750\n",
      "Batch: 3751\n",
      "Batch: 3752\n",
      "Batch: 3753\n",
      "Batch: 3754\n",
      "Batch: 3755\n",
      "Batch: 3756\n",
      "Batch: 3757\n",
      "Batch: 3758\n",
      "Batch: 3759\n",
      "Batch: 3760\n",
      "Batch: 3761\n",
      "Batch: 3762\n",
      "Batch: 3763\n",
      "Batch: 3764\n",
      "Batch: 3765\n",
      "Batch: 3766\n",
      "Batch: 3767\n",
      "Batch: 3768\n",
      "Batch: 3769\n",
      "Batch: 3770\n",
      "Batch: 3771\n",
      "Batch: 3772\n",
      "Batch: 3773\n",
      "Batch: 3774\n",
      "Batch: 3775\n",
      "Batch: 3776\n",
      "Batch: 3777\n",
      "Batch: 3778\n",
      "Batch: 3779\n",
      "Batch: 3780\n",
      "Batch: 3781\n",
      "Batch: 3782\n",
      "Batch: 3783\n",
      "Batch: 3784\n",
      "Batch: 3785\n",
      "Batch: 3786\n",
      "Batch: 3787\n",
      "Batch: 3788\n",
      "Batch: 3789\n",
      "Batch: 3790\n",
      "Batch: 3791\n",
      "Batch: 3792\n",
      "Batch: 3793\n",
      "Batch: 3794\n",
      "Batch: 3795\n",
      "Batch: 3796\n",
      "Batch: 3797\n",
      "Batch: 3798\n",
      "Batch: 3799\n",
      "Batch: 3800\n",
      "Batch: 3801\n",
      "Batch: 3802\n",
      "Batch: 3803\n",
      "Batch: 3804\n",
      "Batch: 3805\n",
      "Batch: 3806\n",
      "Batch: 3807\n",
      "Batch: 3808\n",
      "Batch: 3809\n",
      "Batch: 3810\n",
      "Batch: 3811\n",
      "Batch: 3812\n",
      "Batch: 3813\n",
      "Batch: 3814\n",
      "Batch: 3815\n",
      "Batch: 3816\n",
      "Batch: 3817\n",
      "Batch: 3818\n",
      "Batch: 3819\n",
      "Batch: 3820\n",
      "Batch: 3821\n",
      "Batch: 3822\n",
      "Batch: 3823\n",
      "Batch: 3824\n",
      "Batch: 3825\n",
      "Batch: 3826\n",
      "Batch: 3827\n",
      "Batch: 3828\n",
      "Batch: 3829\n",
      "Batch: 3830\n",
      "Batch: 3831\n",
      "Batch: 3832\n",
      "Batch: 3833\n",
      "Batch: 3834\n",
      "Batch: 3835\n",
      "Batch: 3836\n",
      "Batch: 3837\n",
      "Batch: 3838\n",
      "Batch: 3839\n",
      "Batch: 3840\n",
      "Batch: 3841\n",
      "Batch: 3842\n",
      "Batch: 3843\n",
      "Batch: 3844\n",
      "Batch: 3845\n",
      "Batch: 3846\n",
      "Batch: 3847\n",
      "Batch: 3848\n",
      "Batch: 3849\n",
      "Batch: 3850\n",
      "Batch: 3851\n",
      "Batch: 3852\n",
      "Batch: 3853\n",
      "Batch: 3854\n",
      "Batch: 3855\n",
      "Batch: 3856\n",
      "Batch: 3857\n",
      "Batch: 3858\n",
      "Batch: 3859\n",
      "Batch: 3860\n",
      "Batch: 3861\n",
      "Batch: 3862\n",
      "Batch: 3863\n",
      "Batch: 3864\n",
      "Batch: 3865\n",
      "Batch: 3866\n",
      "Batch: 3867\n",
      "Batch: 3868\n",
      "Batch: 3869\n",
      "Batch: 3870\n",
      "Batch: 3871\n",
      "Batch: 3872\n",
      "Batch: 3873\n",
      "Batch: 3874\n",
      "Batch: 3875\n",
      "Batch: 3876\n",
      "Batch: 3877\n",
      "Batch: 3878\n",
      "Batch: 3879\n",
      "Batch: 3880\n",
      "Batch: 3881\n",
      "Batch: 3882\n",
      "Batch: 3883\n",
      "Batch: 3884\n",
      "Batch: 3885\n",
      "Batch: 3886\n",
      "Batch: 3887\n",
      "Batch: 3888\n",
      "Batch: 3889\n",
      "Batch: 3890\n",
      "Batch: 3891\n",
      "Batch: 3892\n",
      "Batch: 3893\n",
      "Batch: 3894\n",
      "Batch: 3895\n",
      "Batch: 3896\n",
      "Batch: 3897\n",
      "Batch: 3898\n",
      "Batch: 3899\n",
      "Batch: 3900\n",
      "Batch: 3901\n",
      "Batch: 3902\n",
      "Batch: 3903\n",
      "Batch: 3904\n",
      "Batch: 3905\n",
      "Batch: 3906\n",
      "Batch: 3907\n",
      "Batch: 3908\n",
      "Batch: 3909\n",
      "Batch: 3910\n",
      "Batch: 3911\n",
      "Batch: 3912\n",
      "Batch: 3913\n",
      "Batch: 3914\n",
      "Batch: 3915\n",
      "Batch: 3916\n",
      "Batch: 3917\n",
      "Batch: 3918\n",
      "Batch: 3919\n",
      "Batch: 3920\n",
      "Batch: 3921\n",
      "Batch: 3922\n",
      "Batch: 3923\n",
      "Batch: 3924\n",
      "Batch: 3925\n",
      "Batch: 3926\n",
      "Batch: 3927\n",
      "Batch: 3928\n",
      "Batch: 3929\n",
      "Batch: 3930\n",
      "Batch: 3931\n",
      "Batch: 3932\n",
      "Batch: 3933\n",
      "Batch: 3934\n",
      "Batch: 3935\n",
      "Batch: 3936\n",
      "Batch: 3937\n",
      "Batch: 3938\n",
      "Batch: 3939\n",
      "Batch: 3940\n",
      "Batch: 3941\n",
      "Batch: 3942\n",
      "Batch: 3943\n",
      "Batch: 3944\n",
      "Batch: 3945\n",
      "Batch: 3946\n",
      "Batch: 3947\n",
      "Batch: 3948\n",
      "Batch: 3949\n",
      "Batch: 3950\n",
      "Batch: 3951\n",
      "Batch: 3952\n",
      "Batch: 3953\n",
      "Batch: 3954\n",
      "Batch: 3955\n",
      "Batch: 3956\n",
      "Batch: 3957\n",
      "Batch: 3958\n",
      "Batch: 3959\n",
      "Batch: 3960\n",
      "Batch: 3961\n",
      "Batch: 3962\n",
      "Batch: 3963\n",
      "Batch: 3964\n",
      "Batch: 3965\n",
      "Batch: 3966\n",
      "Batch: 3967\n",
      "Batch: 3968\n",
      "Batch: 3969\n",
      "Batch: 3970\n",
      "Batch: 3971\n",
      "Batch: 3972\n",
      "Batch: 3973\n",
      "Batch: 3974\n",
      "Batch: 3975\n",
      "Batch: 3976\n",
      "Batch: 3977\n",
      "Batch: 3978\n",
      "Batch: 3979\n",
      "Batch: 3980\n",
      "Batch: 3981\n",
      "Batch: 3982\n",
      "Batch: 3983\n",
      "Batch: 3984\n",
      "Batch: 3985\n",
      "Batch: 3986\n",
      "Batch: 3987\n",
      "Batch: 3988\n",
      "Batch: 3989\n",
      "Batch: 3990\n",
      "Batch: 3991\n",
      "Batch: 3992\n",
      "Batch: 3993\n",
      "Batch: 3994\n",
      "Batch: 3995\n",
      "Batch: 3996\n",
      "Batch: 3997\n",
      "Batch: 3998\n",
      "Batch: 3999\n",
      "Batch: 4000\n",
      "Batch: 4001\n",
      "Batch: 4002\n",
      "Batch: 4003\n",
      "Batch: 4004\n",
      "Batch: 4005\n",
      "Batch: 4006\n",
      "Batch: 4007\n",
      "Batch: 4008\n",
      "Batch: 4009\n",
      "Batch: 4010\n",
      "Batch: 4011\n",
      "Batch: 4012\n",
      "Batch: 4013\n",
      "Batch: 4014\n",
      "Batch: 4015\n",
      "Batch: 4016\n",
      "Batch: 4017\n",
      "Batch: 4018\n",
      "Batch: 4019\n",
      "Batch: 4020\n",
      "Batch: 4021\n",
      "Batch: 4022\n",
      "Batch: 4023\n",
      "Batch: 4024\n",
      "Batch: 4025\n",
      "Batch: 4026\n",
      "Batch: 4027\n",
      "Batch: 4028\n",
      "Batch: 4029\n",
      "Batch: 4030\n",
      "Batch: 4031\n",
      "Batch: 4032\n",
      "Batch: 4033\n",
      "Batch: 4034\n",
      "Batch: 4035\n",
      "Batch: 4036\n",
      "Batch: 4037\n",
      "Batch: 4038\n",
      "Batch: 4039\n",
      "Batch: 4040\n",
      "Batch: 4041\n",
      "Batch: 4042\n",
      "Batch: 4043\n",
      "Batch: 4044\n",
      "Batch: 4045\n",
      "Batch: 4046\n",
      "Batch: 4047\n",
      "Batch: 4048\n",
      "Batch: 4049\n",
      "Batch: 4050\n",
      "Batch: 4051\n",
      "Batch: 4052\n",
      "Batch: 4053\n",
      "Batch: 4054\n",
      "Batch: 4055\n",
      "Batch: 4056\n",
      "Batch: 4057\n",
      "Batch: 4058\n",
      "Batch: 4059\n",
      "Batch: 4060\n",
      "Batch: 4061\n",
      "Batch: 4062\n",
      "Batch: 4063\n",
      "Batch: 4064\n",
      "Batch: 4065\n",
      "Batch: 4066\n",
      "Batch: 4067\n",
      "Batch: 4068\n",
      "Batch: 4069\n",
      "Batch: 4070\n",
      "Batch: 4071\n",
      "Batch: 4072\n",
      "Batch: 4073\n",
      "Batch: 4074\n",
      "Batch: 4075\n",
      "Batch: 4076\n",
      "Batch: 4077\n",
      "Batch: 4078\n",
      "Batch: 4079\n",
      "Batch: 4080\n",
      "Batch: 4081\n",
      "Batch: 4082\n",
      "Batch: 4083\n",
      "Batch: 4084\n",
      "Batch: 4085\n",
      "Batch: 4086\n",
      "Batch: 4087\n",
      "Batch: 4088\n",
      "Batch: 4089\n",
      "Batch: 4090\n",
      "Batch: 4091\n",
      "Batch: 4092\n",
      "Batch: 4093\n",
      "Batch: 4094\n",
      "Batch: 4095\n",
      "Batch: 4096\n",
      "Batch: 4097\n",
      "Batch: 4098\n",
      "Batch: 4099\n",
      "Batch: 4100\n",
      "Batch: 4101\n",
      "Batch: 4102\n",
      "Batch: 4103\n",
      "Batch: 4104\n",
      "Batch: 4105\n",
      "Batch: 4106\n",
      "Batch: 4107\n",
      "Batch: 4108\n",
      "Batch: 4109\n",
      "Batch: 4110\n",
      "Batch: 4111\n",
      "Batch: 4112\n",
      "Batch: 4113\n",
      "Batch: 4114\n",
      "Batch: 4115\n",
      "Batch: 4116\n",
      "Batch: 4117\n",
      "Batch: 4118\n",
      "Batch: 4119\n",
      "Batch: 4120\n",
      "Batch: 4121\n",
      "Batch: 4122\n",
      "Batch: 4123\n",
      "Batch: 4124\n",
      "Batch: 4125\n",
      "Batch: 4126\n",
      "Batch: 4127\n",
      "Batch: 4128\n",
      "Batch: 4129\n",
      "Batch: 4130\n",
      "Batch: 4131\n",
      "Batch: 4132\n",
      "Batch: 4133\n",
      "Batch: 4134\n",
      "Batch: 4135\n",
      "Batch: 4136\n",
      "Batch: 4137\n",
      "Batch: 4138\n",
      "Batch: 4139\n",
      "Batch: 4140\n",
      "Batch: 4141\n",
      "Batch: 4142\n",
      "Batch: 4143\n",
      "Batch: 4144\n",
      "Batch: 4145\n",
      "Batch: 4146\n",
      "Batch: 4147\n",
      "Batch: 4148\n",
      "Batch: 4149\n",
      "Batch: 4150\n",
      "Batch: 4151\n",
      "Batch: 4152\n",
      "Batch: 4153\n",
      "Batch: 4154\n",
      "Batch: 4155\n",
      "Batch: 4156\n",
      "Batch: 4157\n",
      "Batch: 4158\n",
      "Batch: 4159\n",
      "Batch: 4160\n",
      "Batch: 4161\n",
      "Batch: 4162\n",
      "Batch: 4163\n",
      "Batch: 4164\n",
      "Batch: 4165\n",
      "Batch: 4166\n",
      "Batch: 4167\n",
      "Batch: 4168\n",
      "Batch: 4169\n",
      "Batch: 4170\n",
      "Batch: 4171\n",
      "Batch: 4172\n",
      "Batch: 4173\n",
      "Batch: 4174\n",
      "Batch: 4175\n",
      "Batch: 4176\n",
      "Batch: 4177\n",
      "Batch: 4178\n",
      "Batch: 4179\n",
      "Batch: 4180\n",
      "Batch: 4181\n",
      "Batch: 4182\n",
      "Batch: 4183\n",
      "Batch: 4184\n",
      "Batch: 4185\n",
      "Batch: 4186\n",
      "Batch: 4187\n",
      "Batch: 4188\n",
      "Batch: 4189\n",
      "Batch: 4190\n",
      "Batch: 4191\n",
      "Batch: 4192\n",
      "Batch: 4193\n",
      "Batch: 4194\n",
      "Batch: 4195\n",
      "Batch: 4196\n",
      "Batch: 4197\n",
      "Batch: 4198\n",
      "Batch: 4199\n",
      "Batch: 4200\n",
      "Batch: 4201\n",
      "Batch: 4202\n",
      "Batch: 4203\n",
      "Batch: 4204\n",
      "Batch: 4205\n",
      "Batch: 4206\n",
      "Batch: 4207\n",
      "Batch: 4208\n",
      "Batch: 4209\n",
      "Batch: 4210\n",
      "Batch: 4211\n",
      "Batch: 4212\n",
      "Batch: 4213\n",
      "Batch: 4214\n",
      "Batch: 4215\n",
      "Batch: 4216\n",
      "Batch: 4217\n",
      "Batch: 4218\n",
      "Batch: 4219\n",
      "Batch: 4220\n",
      "Batch: 4221\n",
      "Batch: 4222\n",
      "Batch: 4223\n",
      "Batch: 4224\n",
      "Batch: 4225\n",
      "Batch: 4226\n",
      "Batch: 4227\n",
      "Batch: 4228\n",
      "Batch: 4229\n",
      "Batch: 4230\n",
      "Batch: 4231\n",
      "Batch: 4232\n",
      "Batch: 4233\n",
      "Batch: 4234\n",
      "Batch: 4235\n",
      "Batch: 4236\n",
      "Batch: 4237\n",
      "Batch: 4238\n",
      "Batch: 4239\n",
      "Batch: 4240\n",
      "Batch: 4241\n",
      "Batch: 4242\n",
      "Batch: 4243\n",
      "Batch: 4244\n",
      "Batch: 4245\n",
      "Batch: 4246\n",
      "Batch: 4247\n",
      "Batch: 4248\n",
      "Batch: 4249\n",
      "Batch: 4250\n",
      "Batch: 4251\n",
      "Batch: 4252\n",
      "Batch: 4253\n",
      "Batch: 4254\n",
      "Batch: 4255\n",
      "Batch: 4256\n",
      "Batch: 4257\n",
      "Batch: 4258\n",
      "Batch: 4259\n",
      "Batch: 4260\n",
      "Batch: 4261\n",
      "Batch: 4262\n",
      "Batch: 4263\n",
      "Batch: 4264\n",
      "Batch: 4265\n",
      "Batch: 4266\n",
      "Batch: 4267\n",
      "Batch: 4268\n",
      "Batch: 4269\n",
      "Batch: 4270\n",
      "Batch: 4271\n",
      "Batch: 4272\n",
      "Batch: 4273\n",
      "Batch: 4274\n",
      "Batch: 4275\n",
      "Batch: 4276\n",
      "Batch: 4277\n",
      "Batch: 4278\n",
      "Batch: 4279\n",
      "Batch: 4280\n",
      "Batch: 4281\n",
      "Batch: 4282\n",
      "Batch: 4283\n",
      "Batch: 4284\n",
      "Batch: 4285\n",
      "Batch: 4286\n",
      "Batch: 4287\n",
      "Batch: 4288\n",
      "Batch: 4289\n",
      "Batch: 4290\n",
      "Batch: 4291\n",
      "Batch: 4292\n",
      "Batch: 4293\n",
      "Batch: 4294\n",
      "Batch: 4295\n",
      "Batch: 4296\n",
      "Batch: 4297\n",
      "Batch: 4298\n",
      "Batch: 4299\n",
      "Batch: 4300\n",
      "Batch: 4301\n",
      "Batch: 4302\n",
      "Batch: 4303\n",
      "Batch: 4304\n",
      "Batch: 4305\n",
      "Batch: 4306\n",
      "Batch: 4307\n",
      "Batch: 4308\n",
      "Batch: 4309\n",
      "Batch: 4310\n",
      "Batch: 4311\n",
      "Batch: 4312\n",
      "Batch: 4313\n",
      "Batch: 4314\n",
      "Batch: 4315\n",
      "Batch: 4316\n",
      "Batch: 4317\n",
      "Batch: 4318\n",
      "Batch: 4319\n",
      "Batch: 4320\n",
      "Batch: 4321\n",
      "Batch: 4322\n",
      "Batch: 4323\n",
      "Batch: 4324\n",
      "Batch: 4325\n",
      "Batch: 4326\n",
      "Batch: 4327\n",
      "Batch: 4328\n",
      "Batch: 4329\n",
      "Batch: 4330\n",
      "Batch: 4331\n",
      "Batch: 4332\n",
      "Batch: 4333\n",
      "Batch: 4334\n",
      "Batch: 4335\n",
      "Batch: 4336\n",
      "Batch: 4337\n",
      "Batch: 4338\n",
      "Batch: 4339\n",
      "Batch: 4340\n",
      "Batch: 4341\n",
      "Batch: 4342\n",
      "Batch: 4343\n",
      "Batch: 4344\n",
      "Batch: 4345\n",
      "Batch: 4346\n",
      "Batch: 4347\n",
      "Batch: 4348\n",
      "Batch: 4349\n",
      "Batch: 4350\n",
      "Batch: 4351\n",
      "Batch: 4352\n",
      "Batch: 4353\n",
      "Batch: 4354\n",
      "Batch: 4355\n",
      "Batch: 4356\n",
      "Batch: 4357\n",
      "Batch: 4358\n",
      "Batch: 4359\n",
      "Batch: 4360\n",
      "Batch: 4361\n",
      "Batch: 4362\n",
      "Batch: 4363\n",
      "Batch: 4364\n",
      "Batch: 4365\n",
      "Batch: 4366\n",
      "Batch: 4367\n",
      "Batch: 4368\n",
      "Batch: 4369\n",
      "Batch: 4370\n",
      "Batch: 4371\n",
      "Batch: 4372\n",
      "Batch: 4373\n",
      "Batch: 4374\n",
      "Batch: 4375\n",
      "Batch: 4376\n",
      "Batch: 4377\n",
      "Batch: 4378\n",
      "Batch: 4379\n",
      "Batch: 4380\n",
      "Batch: 4381\n",
      "Batch: 4382\n",
      "Batch: 4383\n",
      "Batch: 4384\n",
      "Batch: 4385\n",
      "Batch: 4386\n",
      "Batch: 4387\n",
      "Batch: 4388\n",
      "Batch: 4389\n",
      "Batch: 4390\n",
      "Batch: 4391\n",
      "Batch: 4392\n",
      "Batch: 4393\n",
      "Batch: 4394\n",
      "Batch: 4395\n",
      "Batch: 4396\n",
      "Batch: 4397\n",
      "Batch: 4398\n",
      "Batch: 4399\n",
      "Batch: 4400\n",
      "Batch: 4401\n",
      "Batch: 4402\n",
      "Batch: 4403\n",
      "Batch: 4404\n",
      "Batch: 4405\n",
      "Batch: 4406\n",
      "Batch: 4407\n",
      "Batch: 4408\n",
      "Batch: 4409\n",
      "Batch: 4410\n",
      "Batch: 4411\n",
      "Batch: 4412\n",
      "Batch: 4413\n",
      "Batch: 4414\n",
      "Batch: 4415\n",
      "Batch: 4416\n",
      "Batch: 4417\n",
      "Batch: 4418\n",
      "Batch: 4419\n",
      "Batch: 4420\n",
      "Batch: 4421\n",
      "Batch: 4422\n",
      "Batch: 4423\n",
      "Batch: 4424\n",
      "Batch: 4425\n",
      "Batch: 4426\n",
      "Batch: 4427\n",
      "Batch: 4428\n",
      "Batch: 4429\n",
      "Batch: 4430\n",
      "Batch: 4431\n",
      "Batch: 4432\n",
      "Batch: 4433\n",
      "Batch: 4434\n",
      "Batch: 4435\n",
      "Batch: 4436\n",
      "Batch: 4437\n",
      "Batch: 4438\n",
      "Batch: 4439\n",
      "Batch: 4440\n",
      "Batch: 4441\n",
      "Batch: 4442\n",
      "Batch: 4443\n",
      "Batch: 4444\n",
      "Batch: 4445\n",
      "Batch: 4446\n",
      "Batch: 4447\n",
      "Batch: 4448\n",
      "Batch: 4449\n",
      "Batch: 4450\n",
      "Batch: 4451\n",
      "Batch: 4452\n",
      "Batch: 4453\n",
      "Batch: 4454\n",
      "Batch: 4455\n",
      "Batch: 4456\n",
      "Batch: 4457\n",
      "Batch: 4458\n",
      "Batch: 4459\n",
      "Batch: 4460\n",
      "Batch: 4461\n",
      "Batch: 4462\n",
      "Batch: 4463\n",
      "Batch: 4464\n",
      "Batch: 4465\n",
      "Batch: 4466\n",
      "Batch: 4467\n",
      "Batch: 4468\n",
      "Batch: 4469\n",
      "Batch: 4470\n",
      "Batch: 4471\n",
      "Batch: 4472\n",
      "Batch: 4473\n",
      "Batch: 4474\n",
      "Batch: 4475\n",
      "Batch: 4476\n",
      "Batch: 4477\n",
      "Batch: 4478\n",
      "Batch: 4479\n",
      "Batch: 4480\n",
      "Batch: 4481\n",
      "Batch: 4482\n",
      "Batch: 4483\n",
      "Batch: 4484\n",
      "Batch: 4485\n",
      "Batch: 4486\n",
      "Batch: 4487\n",
      "Batch: 4488\n",
      "Batch: 4489\n",
      "Batch: 4490\n",
      "Batch: 4491\n",
      "Batch: 4492\n",
      "Batch: 4493\n",
      "Batch: 4494\n",
      "Batch: 4495\n",
      "Batch: 4496\n",
      "Batch: 4497\n",
      "Batch: 4498\n",
      "Batch: 4499\n",
      "Batch: 4500\n",
      "Batch: 4501\n",
      "Batch: 4502\n",
      "Batch: 4503\n",
      "Batch: 4504\n",
      "Batch: 4505\n",
      "Batch: 4506\n",
      "Batch: 4507\n",
      "Batch: 4508\n",
      "Batch: 4509\n",
      "Batch: 4510\n",
      "Batch: 4511\n",
      "Batch: 4512\n",
      "Batch: 4513\n",
      "Batch: 4514\n",
      "Batch: 4515\n",
      "Batch: 4516\n",
      "Batch: 4517\n",
      "Batch: 4518\n",
      "Batch: 4519\n",
      "Batch: 4520\n",
      "Batch: 4521\n",
      "Batch: 4522\n",
      "Batch: 4523\n",
      "Batch: 4524\n",
      "Batch: 4525\n",
      "Batch: 4526\n",
      "Batch: 4527\n",
      "Batch: 4528\n",
      "Batch: 4529\n",
      "Batch: 4530\n",
      "Batch: 4531\n",
      "Batch: 4532\n",
      "Batch: 4533\n",
      "Batch: 4534\n",
      "Batch: 4535\n",
      "Batch: 4536\n",
      "Batch: 4537\n",
      "Batch: 4538\n",
      "Batch: 4539\n",
      "Batch: 4540\n",
      "Batch: 4541\n",
      "Batch: 4542\n",
      "Batch: 4543\n",
      "Batch: 4544\n",
      "Batch: 4545\n",
      "Batch: 4546\n",
      "Batch: 4547\n",
      "Batch: 4548\n",
      "Batch: 4549\n",
      "Batch: 4550\n",
      "Batch: 4551\n",
      "Batch: 4552\n",
      "Batch: 4553\n",
      "Batch: 4554\n",
      "Batch: 4555\n",
      "Batch: 4556\n",
      "Batch: 4557\n",
      "Batch: 4558\n",
      "Batch: 4559\n",
      "Batch: 4560\n",
      "Batch: 4561\n",
      "Batch: 4562\n",
      "Batch: 4563\n",
      "Batch: 4564\n",
      "Batch: 4565\n",
      "Batch: 4566\n",
      "Batch: 4567\n",
      "Batch: 4568\n",
      "Batch: 4569\n",
      "Batch: 4570\n",
      "Batch: 4571\n",
      "Batch: 4572\n",
      "Batch: 4573\n",
      "Batch: 4574\n",
      "Batch: 4575\n",
      "Batch: 4576\n",
      "Batch: 4577\n",
      "Batch: 4578\n",
      "Batch: 4579\n",
      "Batch: 4580\n",
      "Batch: 4581\n",
      "Batch: 4582\n",
      "Batch: 4583\n",
      "Batch: 4584\n",
      "Batch: 4585\n",
      "Batch: 4586\n",
      "Batch: 4587\n",
      "Batch: 4588\n",
      "Batch: 4589\n",
      "Batch: 4590\n",
      "Batch: 4591\n",
      "Batch: 4592\n",
      "Batch: 4593\n",
      "Batch: 4594\n",
      "Batch: 4595\n",
      "Batch: 4596\n",
      "Batch: 4597\n",
      "Batch: 4598\n",
      "Batch: 4599\n",
      "Batch: 4600\n",
      "Batch: 4601\n",
      "Batch: 4602\n",
      "Batch: 4603\n",
      "Batch: 4604\n",
      "Batch: 4605\n",
      "Batch: 4606\n",
      "Batch: 4607\n",
      "Batch: 4608\n",
      "Batch: 4609\n",
      "Batch: 4610\n",
      "Batch: 4611\n",
      "Batch: 4612\n",
      "Batch: 4613\n",
      "Batch: 4614\n",
      "Batch: 4615\n",
      "Batch: 4616\n",
      "Batch: 4617\n",
      "Batch: 4618\n",
      "Batch: 4619\n",
      "Batch: 4620\n",
      "Batch: 4621\n",
      "Batch: 4622\n",
      "Batch: 4623\n",
      "Batch: 4624\n",
      "Batch: 4625\n",
      "Batch: 4626\n",
      "Batch: 4627\n",
      "Batch: 4628\n",
      "Batch: 4629\n",
      "Batch: 4630\n",
      "Batch: 4631\n",
      "Batch: 4632\n",
      "Batch: 4633\n",
      "Batch: 4634\n",
      "Batch: 4635\n",
      "Batch: 4636\n",
      "Batch: 4637\n",
      "Batch: 4638\n",
      "Batch: 4639\n",
      "Batch: 4640\n",
      "Batch: 4641\n",
      "Batch: 4642\n",
      "Batch: 4643\n",
      "Batch: 4644\n",
      "Batch: 4645\n",
      "Batch: 4646\n",
      "Batch: 4647\n",
      "Batch: 4648\n",
      "Batch: 4649\n",
      "Batch: 4650\n",
      "Batch: 4651\n",
      "Batch: 4652\n",
      "Batch: 4653\n",
      "Batch: 4654\n",
      "Batch: 4655\n",
      "Batch: 4656\n",
      "Batch: 4657\n",
      "Batch: 4658\n",
      "Batch: 4659\n",
      "Batch: 4660\n",
      "Batch: 4661\n",
      "Batch: 4662\n",
      "Batch: 4663\n",
      "Batch: 4664\n",
      "Batch: 4665\n",
      "Batch: 4666\n",
      "Batch: 4667\n",
      "Batch: 4668\n",
      "Batch: 4669\n",
      "Batch: 4670\n",
      "Batch: 4671\n",
      "Batch: 4672\n",
      "Batch: 4673\n",
      "Batch: 4674\n",
      "Batch: 4675\n",
      "Batch: 4676\n",
      "Batch: 4677\n",
      "Batch: 4678\n",
      "Batch: 4679\n",
      "Batch: 4680\n",
      "Batch: 4681\n",
      "Batch: 4682\n",
      "Batch: 4683\n",
      "Batch: 4684\n",
      "Batch: 4685\n",
      "Batch: 4686\n",
      "Batch: 4687\n",
      "Batch: 4688\n",
      "Batch: 4689\n",
      "Batch: 4690\n",
      "Batch: 4691\n",
      "Batch: 4692\n",
      "Batch: 4693\n",
      "Batch: 4694\n",
      "Batch: 4695\n",
      "Batch: 4696\n",
      "Batch: 4697\n",
      "Batch: 4698\n",
      "Batch: 4699\n",
      "Batch: 4700\n",
      "Batch: 4701\n",
      "Batch: 4702\n",
      "Batch: 4703\n",
      "Batch: 4704\n",
      "Batch: 4705\n",
      "Batch: 4706\n",
      "Batch: 4707\n",
      "Batch: 4708\n",
      "Batch: 4709\n",
      "Batch: 4710\n",
      "Batch: 4711\n",
      "Batch: 4712\n",
      "Batch: 4713\n",
      "Batch: 4714\n",
      "Batch: 4715\n",
      "Batch: 4716\n",
      "Batch: 4717\n",
      "Batch: 4718\n",
      "Batch: 4719\n",
      "Batch: 4720\n",
      "Batch: 4721\n",
      "Batch: 4722\n",
      "Batch: 4723\n",
      "Batch: 4724\n",
      "Batch: 4725\n",
      "Batch: 4726\n",
      "Batch: 4727\n",
      "Batch: 4728\n",
      "Batch: 4729\n",
      "Batch: 4730\n",
      "Batch: 4731\n",
      "Batch: 4732\n",
      "Batch: 4733\n",
      "Batch: 4734\n",
      "Batch: 4735\n",
      "Batch: 4736\n",
      "Batch: 4737\n",
      "Batch: 4738\n",
      "Batch: 4739\n",
      "Batch: 4740\n",
      "Batch: 4741\n",
      "Batch: 4742\n",
      "Batch: 4743\n",
      "Batch: 4744\n",
      "Batch: 4745\n",
      "Batch: 4746\n",
      "Batch: 4747\n",
      "Batch: 4748\n",
      "Batch: 4749\n",
      "Batch: 4750\n",
      "Batch: 4751\n",
      "Batch: 4752\n",
      "Batch: 4753\n",
      "Batch: 4754\n",
      "Batch: 4755\n",
      "Batch: 4756\n",
      "Batch: 4757\n",
      "Batch: 4758\n",
      "Batch: 4759\n",
      "Batch: 4760\n",
      "Batch: 4761\n",
      "Batch: 4762\n",
      "Batch: 4763\n",
      "Batch: 4764\n",
      "Batch: 4765\n",
      "Batch: 4766\n",
      "Batch: 4767\n",
      "Batch: 4768\n",
      "Batch: 4769\n",
      "Batch: 4770\n",
      "Batch: 4771\n",
      "Batch: 4772\n",
      "Batch: 4773\n",
      "Batch: 4774\n",
      "Batch: 4775\n",
      "Batch: 4776\n",
      "Batch: 4777\n",
      "Batch: 4778\n",
      "Batch: 4779\n",
      "Batch: 4780\n",
      "Batch: 4781\n",
      "Batch: 4782\n",
      "Batch: 4783\n",
      "Batch: 4784\n",
      "Batch: 4785\n",
      "Batch: 4786\n",
      "Batch: 4787\n",
      "Batch: 4788\n",
      "Batch: 4789\n",
      "Batch: 4790\n",
      "Batch: 4791\n",
      "Batch: 4792\n",
      "Batch: 4793\n",
      "Batch: 4794\n",
      "Batch: 4795\n",
      "Batch: 4796\n",
      "Batch: 4797\n",
      "Batch: 4798\n",
      "Batch: 4799\n",
      "Batch: 4800\n",
      "Batch: 4801\n",
      "Batch: 4802\n",
      "Batch: 4803\n",
      "Batch: 4804\n",
      "Batch: 4805\n",
      "Batch: 4806\n",
      "Batch: 4807\n",
      "Batch: 4808\n",
      "Batch: 4809\n",
      "Batch: 4810\n",
      "Batch: 4811\n",
      "Batch: 4812\n",
      "Batch: 4813\n",
      "Batch: 4814\n",
      "Batch: 4815\n",
      "Batch: 4816\n",
      "Batch: 4817\n",
      "Batch: 4818\n",
      "Batch: 4819\n",
      "Batch: 4820\n",
      "Batch: 4821\n",
      "Batch: 4822\n",
      "Batch: 4823\n",
      "Batch: 4824\n",
      "Batch: 4825\n",
      "Batch: 4826\n",
      "Batch: 4827\n",
      "Batch: 4828\n",
      "Batch: 4829\n",
      "Batch: 4830\n",
      "Batch: 4831\n",
      "Batch: 4832\n",
      "Batch: 4833\n",
      "Batch: 4834\n",
      "Batch: 4835\n",
      "Batch: 4836\n",
      "Batch: 4837\n",
      "Batch: 4838\n",
      "Batch: 4839\n",
      "Batch: 4840\n",
      "Batch: 4841\n",
      "Batch: 4842\n",
      "Batch: 4843\n",
      "Batch: 4844\n",
      "Batch: 4845\n",
      "Batch: 4846\n",
      "Batch: 4847\n",
      "Batch: 4848\n",
      "Batch: 4849\n",
      "Batch: 4850\n",
      "Batch: 4851\n",
      "Batch: 4852\n",
      "Batch: 4853\n",
      "Batch: 4854\n",
      "Batch: 4855\n",
      "Batch: 4856\n",
      "Batch: 4857\n",
      "Batch: 4858\n",
      "Batch: 4859\n",
      "Batch: 4860\n",
      "Batch: 4861\n",
      "Batch: 4862\n",
      "Batch: 4863\n",
      "Batch: 4864\n",
      "Batch: 4865\n",
      "Batch: 4866\n",
      "Batch: 4867\n",
      "Batch: 4868\n",
      "Batch: 4869\n",
      "Batch: 4870\n",
      "Batch: 4871\n",
      "Batch: 4872\n",
      "Batch: 4873\n",
      "Batch: 4874\n",
      "Batch: 4875\n",
      "Batch: 4876\n",
      "Batch: 4877\n",
      "Batch: 4878\n",
      "Batch: 4879\n",
      "Batch: 4880\n",
      "Batch: 4881\n",
      "Batch: 4882\n",
      "Batch: 4883\n",
      "Batch: 4884\n",
      "Batch: 4885\n",
      "Batch: 4886\n",
      "Batch: 4887\n",
      "Batch: 4888\n",
      "Batch: 4889\n",
      "Batch: 4890\n",
      "Batch: 4891\n",
      "Batch: 4892\n",
      "Batch: 4893\n",
      "Batch: 4894\n",
      "Batch: 4895\n",
      "Batch: 4896\n",
      "Batch: 4897\n",
      "Batch: 4898\n",
      "Batch: 4899\n",
      "Batch: 4900\n",
      "Batch: 4901\n",
      "Batch: 4902\n",
      "Batch: 4903\n",
      "Batch: 4904\n",
      "Batch: 4905\n",
      "Batch: 4906\n",
      "Batch: 4907\n",
      "Batch: 4908\n",
      "Batch: 4909\n",
      "Batch: 4910\n",
      "Batch: 4911\n",
      "Batch: 4912\n",
      "Batch: 4913\n",
      "Batch: 4914\n",
      "Batch: 4915\n",
      "Batch: 4916\n",
      "Batch: 4917\n",
      "Batch: 4918\n",
      "Batch: 4919\n",
      "Batch: 4920\n",
      "Batch: 4921\n",
      "Batch: 4922\n",
      "Batch: 4923\n",
      "Batch: 4924\n",
      "Batch: 4925\n",
      "Batch: 4926\n",
      "Batch: 4927\n",
      "Batch: 4928\n",
      "Batch: 4929\n",
      "Batch: 4930\n",
      "Batch: 4931\n",
      "Batch: 4932\n",
      "Batch: 4933\n",
      "Batch: 4934\n",
      "Batch: 4935\n",
      "Batch: 4936\n",
      "Batch: 4937\n",
      "Batch: 4938\n",
      "Batch: 4939\n",
      "Batch: 4940\n",
      "Batch: 4941\n",
      "Batch: 4942\n",
      "Batch: 4943\n",
      "Batch: 4944\n",
      "Batch: 4945\n",
      "Batch: 4946\n",
      "Batch: 4947\n",
      "Batch: 4948\n",
      "Batch: 4949\n",
      "Batch: 4950\n",
      "Batch: 4951\n",
      "Batch: 4952\n",
      "Batch: 4953\n",
      "Batch: 4954\n",
      "Batch: 4955\n",
      "Batch: 4956\n",
      "Batch: 4957\n",
      "Batch: 4958\n",
      "Batch: 4959\n",
      "Batch: 4960\n",
      "Batch: 4961\n",
      "Batch: 4962\n",
      "Batch: 4963\n",
      "Batch: 4964\n",
      "Batch: 4965\n",
      "Batch: 4966\n",
      "Batch: 4967\n",
      "Batch: 4968\n",
      "Batch: 4969\n",
      "Batch: 4970\n",
      "Batch: 4971\n",
      "Batch: 4972\n",
      "Batch: 4973\n",
      "Batch: 4974\n",
      "Batch: 4975\n",
      "Batch: 4976\n",
      "Batch: 4977\n",
      "Batch: 4978\n",
      "Batch: 4979\n",
      "Batch: 4980\n",
      "Batch: 4981\n",
      "Batch: 4982\n",
      "Batch: 4983\n",
      "Batch: 4984\n",
      "Batch: 4985\n",
      "Batch: 4986\n",
      "Batch: 4987\n",
      "Batch: 4988\n",
      "Batch: 4989\n",
      "Batch: 4990\n",
      "Batch: 4991\n",
      "Batch: 4992\n",
      "Batch: 4993\n",
      "Batch: 4994\n",
      "Batch: 4995\n",
      "Batch: 4996\n",
      "Batch: 4997\n",
      "Batch: 4998\n",
      "Batch: 4999\n",
      "Batch: 5000\n",
      "Batch: 5001\n",
      "Batch: 5002\n",
      "Batch: 5003\n",
      "Batch: 5004\n",
      "Batch: 5005\n",
      "Batch: 5006\n",
      "Batch: 5007\n",
      "Batch: 5008\n",
      "Batch: 5009\n",
      "Batch: 5010\n",
      "Batch: 5011\n",
      "Batch: 5012\n",
      "Batch: 5013\n",
      "Batch: 5014\n",
      "Batch: 5015\n",
      "Batch: 5016\n",
      "Batch: 5017\n",
      "Batch: 5018\n",
      "Batch: 5019\n",
      "Batch: 5020\n",
      "Batch: 5021\n",
      "Batch: 5022\n",
      "Batch: 5023\n",
      "Batch: 5024\n",
      "Batch: 5025\n",
      "Batch: 5026\n",
      "Batch: 5027\n",
      "Batch: 5028\n",
      "Batch: 5029\n",
      "Batch: 5030\n",
      "Batch: 5031\n",
      "Batch: 5032\n",
      "Batch: 5033\n",
      "Batch: 5034\n",
      "Batch: 5035\n",
      "Batch: 5036\n",
      "Batch: 5037\n",
      "Batch: 5038\n",
      "Batch: 5039\n",
      "Batch: 5040\n",
      "Batch: 5041\n",
      "Batch: 5042\n",
      "Batch: 5043\n",
      "Batch: 5044\n",
      "Batch: 5045\n",
      "Batch: 5046\n",
      "Batch: 5047\n",
      "Batch: 5048\n",
      "Batch: 5049\n",
      "Batch: 5050\n",
      "Batch: 5051\n",
      "Batch: 5052\n",
      "Batch: 5053\n",
      "Batch: 5054\n",
      "Batch: 5055\n",
      "Batch: 5056\n",
      "Batch: 5057\n",
      "Batch: 5058\n",
      "Batch: 5059\n",
      "Batch: 5060\n",
      "Batch: 5061\n",
      "Batch: 5062\n",
      "Batch: 5063\n",
      "Batch: 5064\n",
      "Batch: 5065\n",
      "Batch: 5066\n",
      "Batch: 5067\n",
      "Batch: 5068\n",
      "Batch: 5069\n",
      "Batch: 5070\n",
      "Batch: 5071\n",
      "Batch: 5072\n",
      "Batch: 5073\n",
      "Batch: 5074\n",
      "Batch: 5075\n",
      "Batch: 5076\n",
      "Batch: 5077\n",
      "Batch: 5078\n",
      "Batch: 5079\n",
      "Batch: 5080\n",
      "Batch: 5081\n",
      "Batch: 5082\n",
      "Batch: 5083\n",
      "Batch: 5084\n",
      "Batch: 5085\n",
      "Batch: 5086\n",
      "Batch: 5087\n",
      "Batch: 5088\n",
      "Batch: 5089\n",
      "Batch: 5090\n",
      "Batch: 5091\n",
      "Batch: 5092\n",
      "Batch: 5093\n",
      "Batch: 5094\n",
      "Batch: 5095\n",
      "Batch: 5096\n",
      "Batch: 5097\n",
      "Batch: 5098\n",
      "Batch: 5099\n",
      "Batch: 5100\n",
      "Batch: 5101\n",
      "Batch: 5102\n",
      "Batch: 5103\n",
      "Batch: 5104\n",
      "Batch: 5105\n",
      "Batch: 5106\n",
      "Batch: 5107\n",
      "Batch: 5108\n",
      "Batch: 5109\n",
      "Batch: 5110\n",
      "Batch: 5111\n",
      "Batch: 5112\n",
      "Batch: 5113\n",
      "Batch: 5114\n",
      "Batch: 5115\n",
      "Batch: 5116\n",
      "Batch: 5117\n",
      "Batch: 5118\n",
      "Batch: 5119\n",
      "Batch: 5120\n",
      "Batch: 5121\n",
      "Batch: 5122\n",
      "Batch: 5123\n",
      "Batch: 5124\n",
      "Batch: 5125\n",
      "Batch: 5126\n",
      "Batch: 5127\n",
      "Batch: 5128\n",
      "Batch: 5129\n",
      "Batch: 5130\n",
      "Batch: 5131\n",
      "Batch: 5132\n",
      "Batch: 5133\n",
      "Batch: 5134\n",
      "Batch: 5135\n",
      "Batch: 5136\n",
      "Batch: 5137\n",
      "Batch: 5138\n",
      "Batch: 5139\n",
      "Batch: 5140\n",
      "Batch: 5141\n",
      "Batch: 5142\n",
      "Batch: 5143\n",
      "Batch: 5144\n",
      "Batch: 5145\n",
      "Batch: 5146\n",
      "Batch: 5147\n",
      "Batch: 5148\n",
      "Batch: 5149\n",
      "Batch: 5150\n",
      "Batch: 5151\n",
      "Batch: 5152\n",
      "Batch: 5153\n",
      "Batch: 5154\n",
      "Batch: 5155\n",
      "Batch: 5156\n",
      "Batch: 5157\n",
      "Batch: 5158\n",
      "Batch: 5159\n",
      "Batch: 5160\n",
      "Batch: 5161\n",
      "Batch: 5162\n",
      "Batch: 5163\n",
      "Batch: 5164\n",
      "Batch: 5165\n",
      "Batch: 5166\n",
      "Batch: 5167\n",
      "Batch: 5168\n",
      "Batch: 5169\n",
      "Batch: 5170\n",
      "Batch: 5171\n",
      "Batch: 5172\n",
      "Batch: 5173\n",
      "Batch: 5174\n",
      "Batch: 5175\n",
      "Batch: 5176\n",
      "Batch: 5177\n",
      "Batch: 5178\n",
      "Batch: 5179\n",
      "Batch: 5180\n",
      "Batch: 5181\n",
      "Batch: 5182\n",
      "Batch: 5183\n",
      "Batch: 5184\n",
      "Batch: 5185\n",
      "Batch: 5186\n",
      "Batch: 5187\n",
      "Batch: 5188\n",
      "Batch: 5189\n",
      "Batch: 5190\n",
      "Batch: 5191\n",
      "Batch: 5192\n",
      "Batch: 5193\n",
      "Batch: 5194\n",
      "Batch: 5195\n",
      "Batch: 5196\n",
      "Batch: 5197\n",
      "Batch: 5198\n",
      "Batch: 5199\n",
      "Batch: 5200\n",
      "Batch: 5201\n",
      "Batch: 5202\n",
      "Batch: 5203\n",
      "Batch: 5204\n",
      "Batch: 5205\n",
      "Batch: 5206\n",
      "Batch: 5207\n",
      "Batch: 5208\n",
      "Batch: 5209\n",
      "Batch: 5210\n",
      "Batch: 5211\n",
      "Batch: 5212\n",
      "Batch: 5213\n",
      "Batch: 5214\n",
      "Batch: 5215\n",
      "Batch: 5216\n",
      "Batch: 5217\n",
      "Batch: 5218\n",
      "Batch: 5219\n",
      "Batch: 5220\n",
      "Batch: 5221\n",
      "Batch: 5222\n",
      "Batch: 5223\n",
      "Batch: 5224\n",
      "Batch: 5225\n",
      "Batch: 5226\n",
      "Batch: 5227\n",
      "Batch: 5228\n",
      "Batch: 5229\n",
      "Batch: 5230\n",
      "Batch: 5231\n",
      "Batch: 5232\n",
      "Batch: 5233\n",
      "Batch: 5234\n",
      "Batch: 5235\n",
      "Batch: 5236\n",
      "Batch: 5237\n",
      "Batch: 5238\n",
      "Batch: 5239\n",
      "Batch: 5240\n",
      "Batch: 5241\n",
      "Batch: 5242\n",
      "Batch: 5243\n",
      "Batch: 5244\n",
      "Batch: 5245\n",
      "Batch: 5246\n",
      "Batch: 5247\n",
      "Batch: 5248\n",
      "Batch: 5249\n",
      "Batch: 5250\n",
      "Batch: 5251\n",
      "Batch: 5252\n",
      "Batch: 5253\n",
      "Batch: 5254\n",
      "Batch: 5255\n",
      "Batch: 5256\n",
      "Batch: 5257\n",
      "Batch: 5258\n",
      "Batch: 5259\n",
      "Batch: 5260\n",
      "Batch: 5261\n",
      "Batch: 5262\n",
      "Batch: 5263\n",
      "Batch: 5264\n",
      "Batch: 5265\n",
      "Batch: 5266\n",
      "Batch: 5267\n",
      "Batch: 5268\n",
      "Batch: 5269\n",
      "Batch: 5270\n",
      "Batch: 5271\n",
      "Batch: 5272\n",
      "Batch: 5273\n",
      "Batch: 5274\n",
      "Batch: 5275\n",
      "Batch: 5276\n",
      "Batch: 5277\n",
      "Batch: 5278\n",
      "Batch: 5279\n",
      "Batch: 5280\n",
      "Batch: 5281\n",
      "Batch: 5282\n",
      "Batch: 5283\n",
      "Batch: 5284\n",
      "Batch: 5285\n",
      "Batch: 5286\n",
      "Batch: 5287\n",
      "Batch: 5288\n",
      "Batch: 5289\n",
      "Batch: 5290\n",
      "Batch: 5291\n",
      "Batch: 5292\n",
      "Batch: 5293\n",
      "Batch: 5294\n",
      "Batch: 5295\n",
      "Batch: 5296\n",
      "Batch: 5297\n",
      "Batch: 5298\n",
      "Batch: 5299\n",
      "Batch: 5300\n",
      "Batch: 5301\n",
      "Batch: 5302\n",
      "Batch: 5303\n",
      "Batch: 5304\n",
      "Batch: 5305\n",
      "Batch: 5306\n",
      "Batch: 5307\n",
      "Batch: 5308\n",
      "Batch: 5309\n",
      "Batch: 5310\n",
      "Batch: 5311\n",
      "Batch: 5312\n",
      "Batch: 5313\n",
      "Batch: 5314\n",
      "Batch: 5315\n",
      "Batch: 5316\n",
      "Batch: 5317\n",
      "Batch: 5318\n",
      "Batch: 5319\n",
      "Batch: 5320\n",
      "Batch: 5321\n",
      "Batch: 5322\n",
      "Batch: 5323\n",
      "Batch: 5324\n",
      "Batch: 5325\n",
      "Batch: 5326\n",
      "Batch: 5327\n",
      "Batch: 5328\n",
      "Batch: 5329\n",
      "Batch: 5330\n",
      "Batch: 5331\n",
      "Batch: 5332\n",
      "Batch: 5333\n",
      "Batch: 5334\n",
      "Batch: 5335\n",
      "Batch: 5336\n",
      "Batch: 5337\n",
      "Batch: 5338\n",
      "Batch: 5339\n",
      "Batch: 5340\n",
      "Batch: 5341\n",
      "Batch: 5342\n",
      "Batch: 5343\n",
      "Batch: 5344\n",
      "Batch: 5345\n",
      "Batch: 5346\n",
      "Batch: 5347\n",
      "Batch: 5348\n",
      "Batch: 5349\n",
      "Batch: 5350\n",
      "Batch: 5351\n",
      "Batch: 5352\n",
      "Batch: 5353\n",
      "Batch: 5354\n",
      "Batch: 5355\n",
      "Batch: 5356\n",
      "Batch: 5357\n",
      "Batch: 5358\n",
      "Batch: 5359\n",
      "Batch: 5360\n",
      "Batch: 5361\n",
      "Batch: 5362\n",
      "Batch: 5363\n",
      "Batch: 5364\n",
      "Batch: 5365\n",
      "Batch: 5366\n",
      "Batch: 5367\n",
      "Batch: 5368\n",
      "Batch: 5369\n",
      "Batch: 5370\n",
      "Batch: 5371\n",
      "Batch: 5372\n",
      "Batch: 5373\n",
      "Batch: 5374\n",
      "Batch: 5375\n",
      "Batch: 5376\n",
      "Batch: 5377\n",
      "Batch: 5378\n",
      "Batch: 5379\n",
      "Batch: 5380\n",
      "Batch: 5381\n",
      "Batch: 5382\n",
      "Batch: 5383\n",
      "Batch: 5384\n",
      "Batch: 5385\n",
      "Batch: 5386\n",
      "Batch: 5387\n",
      "Batch: 5388\n",
      "Batch: 5389\n",
      "Batch: 5390\n",
      "Batch: 5391\n",
      "Batch: 5392\n",
      "Batch: 5393\n",
      "Batch: 5394\n",
      "Batch: 5395\n",
      "Batch: 5396\n",
      "Batch: 5397\n",
      "Batch: 5398\n",
      "Batch: 5399\n",
      "Batch: 5400\n",
      "Batch: 5401\n",
      "Batch: 5402\n",
      "Batch: 5403\n",
      "Batch: 5404\n",
      "Batch: 5405\n",
      "Batch: 5406\n",
      "Batch: 5407\n",
      "Batch: 5408\n",
      "Batch: 5409\n",
      "Batch: 5410\n",
      "Batch: 5411\n",
      "Batch: 5412\n",
      "Batch: 5413\n",
      "Batch: 5414\n",
      "Batch: 5415\n",
      "Batch: 5416\n",
      "Batch: 5417\n",
      "Batch: 5418\n",
      "Batch: 5419\n",
      "Batch: 5420\n",
      "Batch: 5421\n",
      "Batch: 5422\n",
      "Batch: 5423\n",
      "Batch: 5424\n",
      "Batch: 5425\n",
      "Batch: 5426\n",
      "Batch: 5427\n",
      "Batch: 5428\n",
      "Batch: 5429\n",
      "Batch: 5430\n",
      "Batch: 5431\n",
      "Batch: 5432\n",
      "Batch: 5433\n",
      "Batch: 5434\n",
      "Batch: 5435\n",
      "Batch: 5436\n",
      "Batch: 5437\n",
      "Batch: 5438\n",
      "Batch: 5439\n",
      "Batch: 5440\n",
      "Batch: 5441\n",
      "Batch: 5442\n",
      "Batch: 5443\n",
      "Batch: 5444\n",
      "Batch: 5445\n",
      "Batch: 5446\n",
      "Batch: 5447\n",
      "Batch: 5448\n",
      "Batch: 5449\n",
      "Batch: 5450\n",
      "Batch: 5451\n",
      "Batch: 5452\n",
      "Batch: 5453\n",
      "Batch: 5454\n",
      "Batch: 5455\n",
      "Batch: 5456\n",
      "Batch: 5457\n",
      "Batch: 5458\n",
      "Batch: 5459\n",
      "Batch: 5460\n",
      "Batch: 5461\n",
      "Batch: 5462\n",
      "Batch: 5463\n",
      "Batch: 5464\n",
      "Batch: 5465\n",
      "Batch: 5466\n",
      "Batch: 5467\n",
      "Batch: 5468\n",
      "Batch: 5469\n",
      "Batch: 5470\n",
      "Batch: 5471\n",
      "Batch: 5472\n",
      "Batch: 5473\n",
      "Batch: 5474\n",
      "Batch: 5475\n",
      "Batch: 5476\n",
      "Batch: 5477\n",
      "Batch: 5478\n",
      "Batch: 5479\n",
      "Batch: 5480\n",
      "Batch: 5481\n",
      "Batch: 5482\n",
      "Batch: 5483\n",
      "Batch: 5484\n",
      "Batch: 5485\n",
      "Batch: 5486\n",
      "Batch: 5487\n",
      "Batch: 5488\n",
      "Batch: 5489\n",
      "Batch: 5490\n",
      "Batch: 5491\n",
      "Batch: 5492\n",
      "Batch: 5493\n",
      "Batch: 5494\n",
      "Batch: 5495\n",
      "Batch: 5496\n",
      "Batch: 5497\n",
      "Batch: 5498\n",
      "Batch: 5499\n",
      "Batch: 5500\n",
      "Batch: 5501\n",
      "Batch: 5502\n",
      "Batch: 5503\n",
      "Batch: 5504\n",
      "Batch: 5505\n",
      "Batch: 5506\n",
      "Batch: 5507\n",
      "Batch: 5508\n",
      "Batch: 5509\n",
      "Batch: 5510\n",
      "Batch: 5511\n",
      "Batch: 5512\n",
      "Batch: 5513\n",
      "Batch: 5514\n",
      "Batch: 5515\n",
      "Batch: 5516\n",
      "Batch: 5517\n",
      "Batch: 5518\n",
      "Batch: 5519\n",
      "Batch: 5520\n",
      "Batch: 5521\n",
      "Batch: 5522\n",
      "Batch: 5523\n",
      "Batch: 5524\n",
      "Batch: 5525\n",
      "Batch: 5526\n",
      "Batch: 5527\n",
      "Batch: 5528\n",
      "Batch: 5529\n",
      "Batch: 5530\n",
      "Batch: 5531\n",
      "Batch: 5532\n",
      "Batch: 5533\n",
      "Batch: 5534\n",
      "Batch: 5535\n",
      "Batch: 5536\n",
      "Batch: 5537\n",
      "Batch: 5538\n",
      "Batch: 5539\n",
      "Batch: 5540\n",
      "Batch: 5541\n",
      "Batch: 5542\n",
      "Batch: 5543\n",
      "Batch: 5544\n",
      "Batch: 5545\n",
      "Batch: 5546\n",
      "Batch: 5547\n",
      "Batch: 5548\n",
      "Batch: 5549\n",
      "Batch: 5550\n",
      "Batch: 5551\n",
      "Batch: 5552\n",
      "Batch: 5553\n",
      "Batch: 5554\n",
      "Batch: 5555\n",
      "Batch: 5556\n",
      "Batch: 5557\n",
      "Batch: 5558\n",
      "Batch: 5559\n",
      "Batch: 5560\n",
      "Batch: 5561\n",
      "Batch: 5562\n",
      "Batch: 5563\n",
      "Batch: 5564\n",
      "Batch: 5565\n",
      "Batch: 5566\n",
      "Batch: 5567\n",
      "Batch: 5568\n",
      "Batch: 5569\n",
      "Batch: 5570\n",
      "Batch: 5571\n",
      "Batch: 5572\n",
      "Batch: 5573\n",
      "Batch: 5574\n",
      "Batch: 5575\n",
      "Batch: 5576\n",
      "Batch: 5577\n",
      "Batch: 5578\n",
      "Batch: 5579\n",
      "Batch: 5580\n",
      "Batch: 5581\n",
      "Batch: 5582\n",
      "Batch: 5583\n",
      "Batch: 5584\n",
      "Batch: 5585\n",
      "Batch: 5586\n",
      "Batch: 5587\n",
      "Batch: 5588\n",
      "Batch: 5589\n",
      "Batch: 5590\n",
      "Batch: 5591\n",
      "Batch: 5592\n",
      "Batch: 5593\n",
      "Batch: 5594\n",
      "Batch: 5595\n",
      "Batch: 5596\n",
      "Batch: 5597\n",
      "Batch: 5598\n",
      "Batch: 5599\n",
      "Batch: 5600\n",
      "Batch: 5601\n",
      "Batch: 5602\n",
      "Batch: 5603\n",
      "Batch: 5604\n",
      "Batch: 5605\n",
      "Batch: 5606\n",
      "Batch: 5607\n",
      "Batch: 5608\n",
      "Batch: 5609\n",
      "Batch: 5610\n",
      "Batch: 5611\n",
      "Batch: 5612\n",
      "Batch: 5613\n",
      "Batch: 5614\n",
      "Batch: 5615\n",
      "Batch: 5616\n",
      "Batch: 5617\n",
      "Batch: 5618\n",
      "Batch: 5619\n",
      "Batch: 5620\n",
      "Batch: 5621\n",
      "Batch: 5622\n",
      "Batch: 5623\n",
      "Batch: 5624\n",
      "Batch: 5625\n",
      "Batch: 5626\n",
      "Batch: 5627\n",
      "Batch: 5628\n",
      "Batch: 5629\n",
      "Batch: 5630\n",
      "Batch: 5631\n",
      "Batch: 5632\n",
      "Batch: 5633\n",
      "Batch: 5634\n",
      "Batch: 5635\n",
      "Batch: 5636\n",
      "Batch: 5637\n",
      "Batch: 5638\n",
      "Batch: 5639\n",
      "Batch: 5640\n",
      "Batch: 5641\n",
      "Batch: 5642\n",
      "Batch: 5643\n",
      "Batch: 5644\n",
      "Batch: 5645\n",
      "Batch: 5646\n",
      "Batch: 5647\n",
      "Batch: 5648\n",
      "Batch: 5649\n",
      "Batch: 5650\n",
      "Batch: 5651\n",
      "Batch: 5652\n",
      "Batch: 5653\n",
      "Batch: 5654\n",
      "Batch: 5655\n",
      "Batch: 5656\n",
      "Batch: 5657\n",
      "Batch: 5658\n",
      "Batch: 5659\n",
      "Batch: 5660\n",
      "Batch: 5661\n",
      "Batch: 5662\n",
      "Batch: 5663\n",
      "Batch: 5664\n",
      "Batch: 5665\n",
      "Batch: 5666\n",
      "Batch: 5667\n",
      "Batch: 5668\n",
      "Batch: 5669\n",
      "Batch: 5670\n",
      "Batch: 5671\n",
      "Batch: 5672\n",
      "Batch: 5673\n",
      "Batch: 5674\n",
      "Batch: 5675\n",
      "Batch: 5676\n",
      "Batch: 5677\n",
      "Batch: 5678\n",
      "Batch: 5679\n",
      "Batch: 5680\n",
      "Batch: 5681\n",
      "Batch: 5682\n",
      "Batch: 5683\n",
      "Batch: 5684\n",
      "Batch: 5685\n",
      "Batch: 5686\n",
      "Batch: 5687\n",
      "Batch: 5688\n",
      "Batch: 5689\n",
      "Batch: 5690\n",
      "Batch: 5691\n",
      "Batch: 5692\n",
      "Batch: 5693\n",
      "Batch: 5694\n",
      "Batch: 5695\n",
      "Batch: 5696\n",
      "Batch: 5697\n",
      "Batch: 5698\n",
      "Batch: 5699\n",
      "Batch: 5700\n",
      "Batch: 5701\n",
      "Batch: 5702\n",
      "Batch: 5703\n",
      "Batch: 5704\n",
      "Batch: 5705\n",
      "Batch: 5706\n",
      "Batch: 5707\n",
      "Batch: 5708\n",
      "Batch: 5709\n",
      "Batch: 5710\n",
      "Batch: 5711\n",
      "Batch: 5712\n",
      "Batch: 5713\n",
      "Batch: 5714\n",
      "Batch: 5715\n",
      "Batch: 5716\n",
      "Batch: 5717\n",
      "Batch: 5718\n",
      "Batch: 5719\n",
      "Batch: 5720\n",
      "Batch: 5721\n",
      "Batch: 5722\n",
      "Batch: 5723\n",
      "Batch: 5724\n",
      "Batch: 5725\n",
      "Batch: 5726\n",
      "Batch: 5727\n",
      "Batch: 5728\n",
      "Batch: 5729\n",
      "Batch: 5730\n",
      "Batch: 5731\n",
      "Batch: 5732\n",
      "Batch: 5733\n",
      "Batch: 5734\n",
      "Batch: 5735\n",
      "Batch: 5736\n",
      "Batch: 5737\n",
      "Batch: 5738\n",
      "Batch: 5739\n",
      "Batch: 5740\n",
      "Batch: 5741\n",
      "Batch: 5742\n",
      "Batch: 5743\n",
      "Batch: 5744\n",
      "Batch: 5745\n",
      "Batch: 5746\n",
      "Batch: 5747\n",
      "Batch: 5748\n",
      "Batch: 5749\n",
      "Batch: 5750\n",
      "Batch: 5751\n",
      "Batch: 5752\n",
      "Batch: 5753\n",
      "Batch: 5754\n",
      "Batch: 5755\n",
      "Batch: 5756\n",
      "Batch: 5757\n",
      "Batch: 5758\n",
      "Batch: 5759\n",
      "Batch: 5760\n",
      "Batch: 5761\n",
      "Batch: 5762\n",
      "Batch: 5763\n",
      "Batch: 5764\n",
      "Batch: 5765\n",
      "Batch: 5766\n",
      "Batch: 5767\n",
      "Batch: 5768\n",
      "Batch: 5769\n",
      "Batch: 5770\n",
      "Batch: 5771\n",
      "Batch: 5772\n",
      "Batch: 5773\n",
      "Batch: 5774\n",
      "Batch: 5775\n",
      "Batch: 5776\n",
      "Batch: 5777\n",
      "Batch: 5778\n",
      "Batch: 5779\n",
      "Batch: 5780\n",
      "Batch: 5781\n",
      "Batch: 5782\n",
      "Batch: 5783\n",
      "Batch: 5784\n",
      "Batch: 5785\n",
      "Batch: 5786\n",
      "Batch: 5787\n",
      "Batch: 5788\n",
      "Batch: 5789\n",
      "Batch: 5790\n",
      "Batch: 5791\n",
      "Batch: 5792\n",
      "Batch: 5793\n",
      "Batch: 5794\n",
      "Batch: 5795\n",
      "Batch: 5796\n",
      "Batch: 5797\n",
      "Batch: 5798\n",
      "Batch: 5799\n",
      "Batch: 5800\n",
      "Batch: 5801\n",
      "Batch: 5802\n",
      "Batch: 5803\n",
      "Batch: 5804\n",
      "Batch: 5805\n",
      "Batch: 5806\n",
      "Batch: 5807\n",
      "Batch: 5808\n",
      "Batch: 5809\n",
      "Batch: 5810\n",
      "Batch: 5811\n",
      "Batch: 5812\n",
      "Batch: 5813\n",
      "Batch: 5814\n",
      "Batch: 5815\n",
      "Batch: 5816\n",
      "Batch: 5817\n",
      "Batch: 5818\n",
      "Batch: 5819\n",
      "Batch: 5820\n",
      "Batch: 5821\n",
      "Batch: 5822\n",
      "Batch: 5823\n",
      "Batch: 5824\n",
      "Batch: 5825\n",
      "Batch: 5826\n",
      "Batch: 5827\n",
      "Batch: 5828\n",
      "Batch: 5829\n",
      "Batch: 5830\n",
      "Batch: 5831\n",
      "Batch: 5832\n",
      "Batch: 5833\n",
      "Batch: 5834\n",
      "Batch: 5835\n",
      "Batch: 5836\n",
      "Batch: 5837\n",
      "Batch: 5838\n",
      "Batch: 5839\n",
      "Batch: 5840\n",
      "Batch: 5841\n",
      "Batch: 5842\n",
      "Batch: 5843\n",
      "Batch: 5844\n",
      "Batch: 5845\n",
      "Batch: 5846\n",
      "Batch: 5847\n",
      "Batch: 5848\n",
      "Batch: 5849\n",
      "Batch: 5850\n",
      "Batch: 5851\n",
      "Batch: 5852\n",
      "Batch: 5853\n",
      "Batch: 5854\n",
      "Batch: 5855\n",
      "Batch: 5856\n",
      "Batch: 5857\n",
      "Batch: 5858\n",
      "Batch: 5859\n",
      "Batch: 5860\n",
      "Batch: 5861\n",
      "Batch: 5862\n",
      "Batch: 5863\n",
      "Batch: 5864\n",
      "Batch: 5865\n",
      "Batch: 5866\n",
      "Batch: 5867\n",
      "Batch: 5868\n",
      "Batch: 5869\n",
      "Batch: 5870\n",
      "Batch: 5871\n",
      "Batch: 5872\n",
      "Batch: 5873\n",
      "Batch: 5874\n",
      "Batch: 5875\n",
      "Batch: 5876\n",
      "Batch: 5877\n",
      "Batch: 5878\n",
      "Batch: 5879\n",
      "Batch: 5880\n",
      "Batch: 5881\n",
      "Batch: 5882\n",
      "Batch: 5883\n",
      "Batch: 5884\n",
      "Batch: 5885\n",
      "Batch: 5886\n",
      "Batch: 5887\n",
      "Batch: 5888\n",
      "Batch: 5889\n",
      "Batch: 5890\n",
      "Batch: 5891\n",
      "Batch: 5892\n",
      "Batch: 5893\n",
      "Batch: 5894\n",
      "Batch: 5895\n",
      "Batch: 5896\n",
      "Batch: 5897\n",
      "Batch: 5898\n",
      "Batch: 5899\n",
      "Batch: 5900\n",
      "Batch: 5901\n",
      "Batch: 5902\n",
      "Batch: 5903\n",
      "Batch: 5904\n",
      "Batch: 5905\n",
      "Batch: 5906\n",
      "Batch: 5907\n",
      "Batch: 5908\n",
      "Batch: 5909\n",
      "Batch: 5910\n",
      "Batch: 5911\n",
      "Batch: 5912\n",
      "Batch: 5913\n",
      "Batch: 5914\n",
      "Batch: 5915\n",
      "Batch: 5916\n",
      "Batch: 5917\n",
      "Batch: 5918\n",
      "Batch: 5919\n",
      "Batch: 5920\n",
      "Batch: 5921\n",
      "Batch: 5922\n",
      "Batch: 5923\n",
      "Batch: 5924\n",
      "Batch: 5925\n",
      "Batch: 5926\n",
      "Batch: 5927\n",
      "Batch: 5928\n",
      "Batch: 5929\n",
      "Batch: 5930\n",
      "Batch: 5931\n",
      "Batch: 5932\n",
      "Batch: 5933\n",
      "Batch: 5934\n",
      "Batch: 5935\n",
      "Batch: 5936\n",
      "Batch: 5937\n",
      "Batch: 5938\n",
      "Batch: 5939\n",
      "Batch: 5940\n",
      "Batch: 5941\n",
      "Batch: 5942\n",
      "Batch: 5943\n",
      "Batch: 5944\n",
      "Batch: 5945\n",
      "Batch: 5946\n",
      "Batch: 5947\n",
      "Batch: 5948\n",
      "Batch: 5949\n",
      "Batch: 5950\n",
      "Batch: 5951\n",
      "Batch: 5952\n",
      "Batch: 5953\n",
      "Batch: 5954\n",
      "Batch: 5955\n",
      "Batch: 5956\n",
      "Batch: 5957\n",
      "Batch: 5958\n",
      "Batch: 5959\n",
      "Batch: 5960\n",
      "Batch: 5961\n",
      "Batch: 5962\n",
      "Batch: 5963\n",
      "Batch: 5964\n",
      "Batch: 5965\n",
      "Batch: 5966\n",
      "Batch: 5967\n",
      "Batch: 5968\n",
      "Batch: 5969\n",
      "Batch: 5970\n",
      "Batch: 5971\n",
      "Batch: 5972\n",
      "Batch: 5973\n",
      "Batch: 5974\n",
      "Batch: 5975\n",
      "Batch: 5976\n",
      "Batch: 5977\n",
      "Batch: 5978\n",
      "Batch: 5979\n",
      "Batch: 5980\n",
      "Batch: 5981\n",
      "Batch: 5982\n",
      "Batch: 5983\n",
      "Batch: 5984\n",
      "Batch: 5985\n",
      "Batch: 5986\n",
      "Batch: 5987\n",
      "Batch: 5988\n",
      "Batch: 5989\n",
      "Batch: 5990\n",
      "Batch: 5991\n",
      "Batch: 5992\n",
      "Batch: 5993\n",
      "Batch: 5994\n",
      "Batch: 5995\n",
      "Batch: 5996\n",
      "Batch: 5997\n",
      "Batch: 5998\n",
      "Batch: 5999\n",
      "Batch: 6000\n",
      "Batch: 6001\n",
      "Batch: 6002\n",
      "Batch: 6003\n",
      "Batch: 6004\n",
      "Batch: 6005\n",
      "Batch: 6006\n",
      "Batch: 6007\n",
      "Batch: 6008\n",
      "Batch: 6009\n",
      "Batch: 6010\n",
      "Batch: 6011\n",
      "Batch: 6012\n",
      "Batch: 6013\n",
      "Batch: 6014\n",
      "Batch: 6015\n",
      "Batch: 6016\n",
      "Batch: 6017\n",
      "Batch: 6018\n",
      "Batch: 6019\n",
      "Batch: 6020\n",
      "Batch: 6021\n",
      "Batch: 6022\n",
      "Batch: 6023\n",
      "Batch: 6024\n",
      "Batch: 6025\n",
      "Batch: 6026\n",
      "Batch: 6027\n",
      "Batch: 6028\n",
      "Batch: 6029\n",
      "Batch: 6030\n",
      "Batch: 6031\n",
      "Batch: 6032\n",
      "Batch: 6033\n",
      "Batch: 6034\n",
      "Batch: 6035\n",
      "Batch: 6036\n",
      "Batch: 6037\n",
      "Batch: 6038\n",
      "Batch: 6039\n",
      "Batch: 6040\n",
      "Batch: 6041\n",
      "Batch: 6042\n",
      "Batch: 6043\n",
      "Batch: 6044\n",
      "Batch: 6045\n",
      "Batch: 6046\n",
      "Batch: 6047\n",
      "Batch: 6048\n",
      "Batch: 6049\n",
      "Batch: 6050\n",
      "Batch: 6051\n",
      "Batch: 6052\n",
      "Batch: 6053\n",
      "Batch: 6054\n",
      "Batch: 6055\n",
      "Batch: 6056\n",
      "Batch: 6057\n",
      "Batch: 6058\n",
      "Batch: 6059\n",
      "Batch: 6060\n",
      "Batch: 6061\n",
      "Batch: 6062\n",
      "Batch: 6063\n",
      "Batch: 6064\n",
      "Batch: 6065\n",
      "Batch: 6066\n",
      "Batch: 6067\n",
      "Batch: 6068\n",
      "Batch: 6069\n",
      "Batch: 6070\n",
      "Batch: 6071\n",
      "Batch: 6072\n",
      "Batch: 6073\n",
      "Batch: 6074\n",
      "Batch: 6075\n",
      "Batch: 6076\n",
      "Batch: 6077\n",
      "Batch: 6078\n",
      "Batch: 6079\n",
      "Batch: 6080\n",
      "Batch: 6081\n",
      "Batch: 6082\n",
      "Batch: 6083\n",
      "Batch: 6084\n",
      "Batch: 6085\n",
      "Batch: 6086\n",
      "Batch: 6087\n",
      "Batch: 6088\n",
      "Batch: 6089\n",
      "Batch: 6090\n",
      "Batch: 6091\n",
      "Batch: 6092\n",
      "Batch: 6093\n",
      "Batch: 6094\n",
      "Batch: 6095\n",
      "Batch: 6096\n",
      "Batch: 6097\n",
      "Batch: 6098\n",
      "Batch: 6099\n",
      "Batch: 6100\n",
      "Batch: 6101\n",
      "Batch: 6102\n",
      "Batch: 6103\n",
      "Batch: 6104\n",
      "Batch: 6105\n",
      "Batch: 6106\n",
      "Batch: 6107\n",
      "Batch: 6108\n",
      "Batch: 6109\n",
      "Batch: 6110\n",
      "Batch: 6111\n",
      "Batch: 6112\n",
      "Batch: 6113\n",
      "Batch: 6114\n",
      "Batch: 6115\n",
      "Batch: 6116\n",
      "Batch: 6117\n",
      "Batch: 6118\n",
      "Batch: 6119\n",
      "Batch: 6120\n",
      "Batch: 6121\n",
      "Batch: 6122\n",
      "Batch: 6123\n",
      "Batch: 6124\n",
      "Batch: 6125\n",
      "Batch: 6126\n",
      "Batch: 6127\n",
      "Batch: 6128\n",
      "Batch: 6129\n",
      "Batch: 6130\n",
      "Batch: 6131\n",
      "Batch: 6132\n",
      "Batch: 6133\n",
      "Batch: 6134\n",
      "Batch: 6135\n",
      "Batch: 6136\n",
      "Batch: 6137\n",
      "Batch: 6138\n",
      "Batch: 6139\n",
      "Batch: 6140\n",
      "Batch: 6141\n",
      "Batch: 6142\n",
      "Batch: 6143\n",
      "Batch: 6144\n",
      "Batch: 6145\n",
      "Batch: 6146\n",
      "Batch: 6147\n",
      "Batch: 6148\n",
      "Batch: 6149\n",
      "Batch: 6150\n",
      "Batch: 6151\n",
      "Batch: 6152\n",
      "Batch: 6153\n",
      "Batch: 6154\n",
      "Batch: 6155\n",
      "Batch: 6156\n",
      "Batch: 6157\n",
      "Batch: 6158\n",
      "Batch: 6159\n",
      "Batch: 6160\n",
      "Batch: 6161\n",
      "Batch: 6162\n",
      "Batch: 6163\n",
      "Batch: 6164\n",
      "Batch: 6165\n",
      "Batch: 6166\n",
      "Batch: 6167\n",
      "Batch: 6168\n",
      "Batch: 6169\n",
      "Batch: 6170\n",
      "Batch: 6171\n",
      "Batch: 6172\n",
      "Batch: 6173\n",
      "Batch: 6174\n",
      "Batch: 6175\n",
      "Batch: 6176\n",
      "Batch: 6177\n",
      "Batch: 6178\n",
      "Batch: 6179\n",
      "Batch: 6180\n",
      "Batch: 6181\n",
      "Batch: 6182\n",
      "Batch: 6183\n",
      "Batch: 6184\n",
      "Batch: 6185\n",
      "Batch: 6186\n",
      "Batch: 6187\n",
      "Batch: 6188\n",
      "Batch: 6189\n",
      "Batch: 6190\n",
      "Batch: 6191\n",
      "Batch: 6192\n",
      "Batch: 6193\n",
      "Batch: 6194\n",
      "Batch: 6195\n",
      "Batch: 6196\n",
      "Batch: 6197\n",
      "Batch: 6198\n",
      "Batch: 6199\n",
      "Batch: 6200\n",
      "Batch: 6201\n",
      "Batch: 6202\n",
      "Batch: 6203\n",
      "Batch: 6204\n",
      "Batch: 6205\n",
      "Batch: 6206\n",
      "Batch: 6207\n",
      "Batch: 6208\n",
      "Batch: 6209\n",
      "Batch: 6210\n",
      "Batch: 6211\n",
      "Batch: 6212\n",
      "Batch: 6213\n",
      "Batch: 6214\n",
      "Batch: 6215\n",
      "Batch: 6216\n",
      "Batch: 6217\n",
      "Batch: 6218\n",
      "Batch: 6219\n",
      "Batch: 6220\n",
      "Batch: 6221\n",
      "Batch: 6222\n",
      "Batch: 6223\n",
      "Batch: 6224\n",
      "Batch: 6225\n",
      "Batch: 6226\n",
      "Batch: 6227\n",
      "Batch: 6228\n",
      "Batch: 6229\n",
      "Batch: 6230\n",
      "Batch: 6231\n",
      "Batch: 6232\n",
      "Batch: 6233\n",
      "Batch: 6234\n",
      "Batch: 6235\n",
      "Batch: 6236\n",
      "Batch: 6237\n",
      "Batch: 6238\n",
      "Batch: 6239\n",
      "Batch: 6240\n",
      "Batch: 6241\n",
      "Batch: 6242\n",
      "Batch: 6243\n",
      "Batch: 6244\n",
      "Batch: 6245\n",
      "Batch: 6246\n",
      "Batch: 6247\n",
      "Batch: 6248\n",
      "Batch: 6249\n",
      "Batch: 6250\n",
      "Batch: 6251\n",
      "Batch: 6252\n",
      "Batch: 6253\n",
      "Batch: 6254\n",
      "Batch: 6255\n",
      "Batch: 6256\n",
      "Batch: 6257\n",
      "Batch: 6258\n",
      "Batch: 6259\n",
      "Batch: 6260\n",
      "Batch: 6261\n",
      "Batch: 6262\n",
      "Batch: 6263\n",
      "Batch: 6264\n",
      "Batch: 6265\n",
      "Batch: 6266\n",
      "Batch: 6267\n",
      "Batch: 6268\n",
      "Batch: 6269\n",
      "Batch: 6270\n",
      "Batch: 6271\n",
      "Batch: 6272\n",
      "Batch: 6273\n",
      "Batch: 6274\n",
      "Batch: 6275\n",
      "Batch: 6276\n",
      "Batch: 6277\n",
      "Batch: 6278\n",
      "Batch: 6279\n",
      "Batch: 6280\n",
      "Batch: 6281\n",
      "Batch: 6282\n",
      "Batch: 6283\n",
      "Batch: 6284\n",
      "Batch: 6285\n",
      "Batch: 6286\n",
      "Batch: 6287\n",
      "Batch: 6288\n",
      "Batch: 6289\n",
      "Batch: 6290\n",
      "Batch: 6291\n",
      "Batch: 6292\n",
      "Batch: 6293\n",
      "Batch: 6294\n",
      "Batch: 6295\n",
      "Batch: 6296\n",
      "Batch: 6297\n",
      "Batch: 6298\n",
      "Batch: 6299\n",
      "Batch: 6300\n",
      "Batch: 6301\n",
      "Batch: 6302\n",
      "Batch: 6303\n",
      "Batch: 6304\n",
      "Batch: 6305\n",
      "Batch: 6306\n",
      "Batch: 6307\n",
      "Batch: 6308\n",
      "Batch: 6309\n",
      "Batch: 6310\n",
      "Batch: 6311\n",
      "Batch: 6312\n",
      "Batch: 6313\n",
      "Batch: 6314\n",
      "Batch: 6315\n",
      "Batch: 6316\n",
      "Batch: 6317\n",
      "Batch: 6318\n",
      "Batch: 6319\n",
      "Batch: 6320\n",
      "Batch: 6321\n",
      "Batch: 6322\n",
      "Batch: 6323\n",
      "Batch: 6324\n",
      "Batch: 6325\n",
      "Batch: 6326\n",
      "Batch: 6327\n",
      "Batch: 6328\n",
      "Batch: 6329\n",
      "Batch: 6330\n",
      "Batch: 6331\n",
      "Batch: 6332\n",
      "Batch: 6333\n",
      "Batch: 6334\n",
      "Batch: 6335\n",
      "Batch: 6336\n",
      "Batch: 6337\n",
      "Batch: 6338\n",
      "Batch: 6339\n",
      "Batch: 6340\n",
      "Batch: 6341\n",
      "Batch: 6342\n",
      "Batch: 6343\n",
      "Batch: 6344\n",
      "Batch: 6345\n",
      "Batch: 6346\n",
      "Batch: 6347\n",
      "Batch: 6348\n",
      "Batch: 6349\n",
      "Batch: 6350\n",
      "Batch: 6351\n",
      "Batch: 6352\n",
      "Batch: 6353\n",
      "Batch: 6354\n",
      "Batch: 6355\n",
      "Batch: 6356\n",
      "Batch: 6357\n",
      "Batch: 6358\n",
      "Batch: 6359\n",
      "Batch: 6360\n",
      "Batch: 6361\n",
      "Batch: 6362\n",
      "Batch: 6363\n",
      "Batch: 6364\n",
      "Batch: 6365\n",
      "Batch: 6366\n",
      "Batch: 6367\n",
      "Batch: 6368\n",
      "Batch: 6369\n",
      "Batch: 6370\n",
      "Batch: 6371\n",
      "Batch: 6372\n",
      "Batch: 6373\n",
      "Batch: 6374\n",
      "Batch: 6375\n",
      "Batch: 6376\n",
      "Batch: 6377\n",
      "Batch: 6378\n",
      "Batch: 6379\n",
      "Batch: 6380\n",
      "Batch: 6381\n",
      "Batch: 6382\n",
      "Batch: 6383\n",
      "Batch: 6384\n",
      "Batch: 6385\n",
      "Batch: 6386\n",
      "Batch: 6387\n",
      "Batch: 6388\n",
      "Batch: 6389\n",
      "Batch: 6390\n",
      "Batch: 6391\n",
      "Batch: 6392\n",
      "Batch: 6393\n",
      "Batch: 6394\n",
      "Batch: 6395\n",
      "Batch: 6396\n",
      "Batch: 6397\n",
      "Batch: 6398\n",
      "Batch: 6399\n",
      "Batch: 6400\n",
      "Batch: 6401\n",
      "Batch: 6402\n",
      "Batch: 6403\n",
      "Batch: 6404\n",
      "Batch: 6405\n",
      "Batch: 6406\n",
      "Batch: 6407\n",
      "Batch: 6408\n",
      "Batch: 6409\n",
      "Batch: 6410\n",
      "Batch: 6411\n",
      "Batch: 6412\n",
      "Batch: 6413\n",
      "Batch: 6414\n",
      "Batch: 6415\n",
      "Batch: 6416\n",
      "Batch: 6417\n",
      "Batch: 6418\n",
      "Batch: 6419\n",
      "Batch: 6420\n",
      "Batch: 6421\n",
      "Batch: 6422\n",
      "Batch: 6423\n",
      "Batch: 6424\n",
      "Batch: 6425\n",
      "Batch: 6426\n",
      "Batch: 6427\n",
      "Batch: 6428\n",
      "Batch: 6429\n",
      "Batch: 6430\n",
      "Batch: 6431\n",
      "Batch: 6432\n",
      "Batch: 6433\n",
      "Batch: 6434\n",
      "Batch: 6435\n",
      "Batch: 6436\n",
      "Batch: 6437\n",
      "Batch: 6438\n",
      "Batch: 6439\n",
      "Batch: 6440\n",
      "Batch: 6441\n",
      "Batch: 6442\n",
      "Batch: 6443\n",
      "Batch: 6444\n",
      "Batch: 6445\n",
      "Batch: 6446\n",
      "Batch: 6447\n",
      "Batch: 6448\n",
      "Batch: 6449\n",
      "Batch: 6450\n",
      "Batch: 6451\n",
      "Batch: 6452\n",
      "Batch: 6453\n",
      "Batch: 6454\n",
      "Batch: 6455\n",
      "Batch: 6456\n",
      "Batch: 6457\n",
      "Batch: 6458\n",
      "Batch: 6459\n",
      "Batch: 6460\n",
      "Batch: 6461\n",
      "Batch: 6462\n",
      "Batch: 6463\n",
      "Batch: 6464\n",
      "Batch: 6465\n",
      "Batch: 6466\n",
      "Batch: 6467\n",
      "Batch: 6468\n",
      "Batch: 6469\n",
      "Batch: 6470\n",
      "Batch: 6471\n",
      "Batch: 6472\n",
      "Batch: 6473\n",
      "Batch: 6474\n",
      "Batch: 6475\n",
      "Batch: 6476\n",
      "Batch: 6477\n",
      "Batch: 6478\n",
      "Batch: 6479\n",
      "Batch: 6480\n",
      "Batch: 6481\n",
      "Batch: 6482\n",
      "Batch: 6483\n",
      "Batch: 6484\n",
      "Batch: 6485\n",
      "Batch: 6486\n",
      "Batch: 6487\n",
      "Batch: 6488\n",
      "Batch: 6489\n",
      "Batch: 6490\n",
      "Batch: 6491\n",
      "Batch: 6492\n",
      "Batch: 6493\n",
      "Batch: 6494\n",
      "Batch: 6495\n",
      "Batch: 6496\n",
      "Batch: 6497\n",
      "Batch: 6498\n",
      "Batch: 6499\n",
      "Batch: 6500\n",
      "Batch: 6501\n",
      "Batch: 6502\n",
      "Batch: 6503\n",
      "Batch: 6504\n",
      "Batch: 6505\n",
      "Batch: 6506\n",
      "Batch: 6507\n",
      "Batch: 6508\n",
      "Batch: 6509\n",
      "Batch: 6510\n",
      "Batch: 6511\n",
      "Batch: 6512\n",
      "Batch: 6513\n",
      "Batch: 6514\n",
      "Batch: 6515\n",
      "Batch: 6516\n",
      "Batch: 6517\n",
      "Batch: 6518\n",
      "Batch: 6519\n",
      "Batch: 6520\n",
      "Batch: 6521\n",
      "Batch: 6522\n",
      "Batch: 6523\n",
      "Batch: 6524\n",
      "Batch: 6525\n",
      "Batch: 6526\n",
      "Batch: 6527\n",
      "Batch: 6528\n",
      "Batch: 6529\n",
      "Batch: 6530\n",
      "Batch: 6531\n",
      "Batch: 6532\n",
      "Batch: 6533\n",
      "Batch: 6534\n",
      "Batch: 6535\n",
      "Batch: 6536\n",
      "Batch: 6537\n",
      "Batch: 6538\n",
      "Batch: 6539\n",
      "Batch: 6540\n",
      "Batch: 6541\n",
      "Batch: 6542\n",
      "Batch: 6543\n",
      "Batch: 6544\n",
      "Batch: 6545\n",
      "Batch: 6546\n",
      "Batch: 6547\n",
      "Batch: 6548\n",
      "Batch: 6549\n",
      "Batch: 6550\n",
      "Batch: 6551\n",
      "Batch: 6552\n",
      "Batch: 6553\n",
      "Batch: 6554\n",
      "Batch: 6555\n",
      "Batch: 6556\n",
      "Batch: 6557\n",
      "Batch: 6558\n",
      "Batch: 6559\n",
      "Batch: 6560\n",
      "Batch: 6561\n",
      "Batch: 6562\n",
      "Batch: 6563\n",
      "Batch: 6564\n",
      "Batch: 6565\n",
      "Batch: 6566\n",
      "Batch: 6567\n",
      "Batch: 6568\n",
      "Batch: 6569\n",
      "Batch: 6570\n",
      "Batch: 6571\n",
      "Batch: 6572\n",
      "Batch: 6573\n",
      "Batch: 6574\n",
      "Batch: 6575\n",
      "Batch: 6576\n",
      "Batch: 6577\n",
      "Batch: 6578\n",
      "Batch: 6579\n",
      "Batch: 6580\n",
      "Batch: 6581\n",
      "Batch: 6582\n",
      "Batch: 6583\n",
      "Batch: 6584\n",
      "Batch: 6585\n",
      "Batch: 6586\n",
      "Batch: 6587\n",
      "Batch: 6588\n",
      "Batch: 6589\n",
      "Batch: 6590\n",
      "Batch: 6591\n",
      "Batch: 6592\n",
      "Batch: 6593\n",
      "Batch: 6594\n",
      "Batch: 6595\n",
      "Batch: 6596\n",
      "Batch: 6597\n",
      "Batch: 6598\n",
      "Batch: 6599\n",
      "Batch: 6600\n",
      "Batch: 6601\n",
      "Batch: 6602\n",
      "Batch: 6603\n",
      "Batch: 6604\n",
      "Batch: 6605\n",
      "Batch: 6606\n",
      "Batch: 6607\n",
      "Batch: 6608\n",
      "Batch: 6609\n",
      "Batch: 6610\n",
      "Batch: 6611\n",
      "Batch: 6612\n",
      "Batch: 6613\n",
      "Batch: 6614\n",
      "Batch: 6615\n",
      "Batch: 6616\n",
      "Batch: 6617\n",
      "Batch: 6618\n",
      "Batch: 6619\n",
      "Batch: 6620\n",
      "Batch: 6621\n",
      "Batch: 6622\n",
      "Batch: 6623\n",
      "Batch: 6624\n",
      "Batch: 6625\n",
      "Batch: 6626\n",
      "Batch: 6627\n",
      "Batch: 6628\n",
      "Batch: 6629\n",
      "Batch: 6630\n",
      "Batch: 6631\n",
      "Batch: 6632\n",
      "Batch: 6633\n",
      "Batch: 6634\n",
      "Batch: 6635\n",
      "Batch: 6636\n",
      "Batch: 6637\n",
      "Batch: 6638\n",
      "Batch: 6639\n",
      "Batch: 6640\n",
      "Batch: 6641\n",
      "Batch: 6642\n",
      "Batch: 6643\n",
      "Batch: 6644\n",
      "Batch: 6645\n",
      "Batch: 6646\n",
      "Batch: 6647\n",
      "Batch: 6648\n",
      "Batch: 6649\n",
      "Batch: 6650\n",
      "Batch: 6651\n",
      "Batch: 6652\n",
      "Batch: 6653\n",
      "Batch: 6654\n",
      "Batch: 6655\n",
      "Batch: 6656\n",
      "Batch: 6657\n",
      "Batch: 6658\n",
      "Batch: 6659\n",
      "Batch: 6660\n",
      "Batch: 6661\n",
      "Batch: 6662\n",
      "Batch: 6663\n",
      "Batch: 6664\n",
      "Batch: 6665\n",
      "Batch: 6666\n",
      "Batch: 6667\n",
      "Batch: 6668\n",
      "Batch: 6669\n",
      "Batch: 6670\n",
      "Batch: 6671\n",
      "Batch: 6672\n",
      "Batch: 6673\n",
      "Batch: 6674\n",
      "Batch: 6675\n",
      "Batch: 6676\n",
      "Batch: 6677\n",
      "Batch: 6678\n",
      "Batch: 6679\n",
      "Batch: 6680\n",
      "Batch: 6681\n",
      "Batch: 6682\n",
      "Batch: 6683\n",
      "Batch: 6684\n",
      "Batch: 6685\n",
      "Batch: 6686\n",
      "Batch: 6687\n",
      "Batch: 6688\n",
      "Batch: 6689\n",
      "Batch: 6690\n",
      "Batch: 6691\n",
      "Batch: 6692\n",
      "Batch: 6693\n",
      "Batch: 6694\n",
      "Batch: 6695\n",
      "Batch: 6696\n",
      "Batch: 6697\n",
      "Batch: 6698\n",
      "Batch: 6699\n",
      "Batch: 6700\n",
      "Batch: 6701\n",
      "Batch: 6702\n",
      "Batch: 6703\n",
      "Batch: 6704\n",
      "Batch: 6705\n",
      "Batch: 6706\n",
      "Batch: 6707\n",
      "Batch: 6708\n",
      "Batch: 6709\n",
      "Batch: 6710\n",
      "Batch: 6711\n",
      "Batch: 6712\n",
      "Batch: 6713\n",
      "Batch: 6714\n",
      "Batch: 6715\n",
      "Batch: 6716\n",
      "Batch: 6717\n",
      "Batch: 6718\n",
      "Batch: 6719\n",
      "Batch: 6720\n",
      "Batch: 6721\n",
      "Batch: 6722\n",
      "Batch: 6723\n",
      "Batch: 6724\n",
      "Batch: 6725\n",
      "Batch: 6726\n",
      "Batch: 6727\n",
      "Batch: 6728\n",
      "Batch: 6729\n",
      "Batch: 6730\n",
      "Batch: 6731\n",
      "Batch: 6732\n",
      "Batch: 6733\n",
      "Batch: 6734\n",
      "Batch: 6735\n",
      "Batch: 6736\n",
      "Batch: 6737\n",
      "Batch: 6738\n",
      "Batch: 6739\n",
      "Batch: 6740\n",
      "Batch: 6741\n",
      "Batch: 6742\n",
      "Batch: 6743\n",
      "Batch: 6744\n",
      "Batch: 6745\n",
      "Batch: 6746\n",
      "Batch: 6747\n",
      "Batch: 6748\n",
      "Batch: 6749\n",
      "Batch: 6750\n",
      "Batch: 6751\n",
      "Batch: 6752\n",
      "Batch: 6753\n",
      "Batch: 6754\n",
      "Batch: 6755\n",
      "Batch: 6756\n",
      "Batch: 6757\n",
      "Batch: 6758\n",
      "Batch: 6759\n",
      "Batch: 6760\n",
      "Batch: 6761\n",
      "Batch: 6762\n",
      "Batch: 6763\n",
      "Batch: 6764\n",
      "Batch: 6765\n",
      "Batch: 6766\n",
      "Batch: 6767\n",
      "Batch: 6768\n",
      "Batch: 6769\n",
      "Batch: 6770\n",
      "Batch: 6771\n",
      "Batch: 6772\n",
      "Batch: 6773\n",
      "Batch: 6774\n",
      "Batch: 6775\n",
      "Batch: 6776\n",
      "Batch: 6777\n",
      "Batch: 6778\n",
      "Batch: 6779\n",
      "Batch: 6780\n",
      "Batch: 6781\n",
      "Batch: 6782\n",
      "Batch: 6783\n",
      "Batch: 6784\n",
      "Batch: 6785\n",
      "Batch: 6786\n",
      "Batch: 6787\n",
      "Batch: 6788\n",
      "Batch: 6789\n",
      "Batch: 6790\n",
      "Batch: 6791\n",
      "Batch: 6792\n",
      "Batch: 6793\n",
      "Batch: 6794\n",
      "Batch: 6795\n",
      "Batch: 6796\n",
      "Batch: 6797\n",
      "Batch: 6798\n",
      "Batch: 6799\n",
      "Batch: 6800\n",
      "Batch: 6801\n",
      "Batch: 6802\n",
      "Batch: 6803\n",
      "Batch: 6804\n",
      "Batch: 6805\n",
      "Batch: 6806\n",
      "Batch: 6807\n",
      "Batch: 6808\n",
      "Batch: 6809\n",
      "Batch: 6810\n",
      "Batch: 6811\n",
      "Batch: 6812\n",
      "Batch: 6813\n",
      "Batch: 6814\n",
      "Batch: 6815\n",
      "Batch: 6816\n",
      "Batch: 6817\n",
      "Batch: 6818\n",
      "Batch: 6819\n",
      "Batch: 6820\n",
      "Batch: 6821\n",
      "Batch: 6822\n",
      "Batch: 6823\n",
      "Batch: 6824\n",
      "Batch: 6825\n",
      "Batch: 6826\n",
      "Batch: 6827\n",
      "Batch: 6828\n",
      "Batch: 6829\n",
      "Batch: 6830\n",
      "Batch: 6831\n",
      "Batch: 6832\n",
      "Batch: 6833\n",
      "Batch: 6834\n",
      "Batch: 6835\n",
      "Batch: 6836\n",
      "Batch: 6837\n",
      "Batch: 6838\n",
      "Batch: 6839\n",
      "Batch: 6840\n",
      "Batch: 6841\n",
      "Batch: 6842\n",
      "Batch: 6843\n",
      "Batch: 6844\n",
      "Batch: 6845\n",
      "Batch: 6846\n",
      "Batch: 6847\n",
      "Batch: 6848\n",
      "Batch: 6849\n",
      "Batch: 6850\n",
      "Batch: 6851\n",
      "Batch: 6852\n",
      "Batch: 6853\n",
      "Batch: 6854\n",
      "Batch: 6855\n",
      "Batch: 6856\n",
      "Batch: 6857\n",
      "Batch: 6858\n",
      "Batch: 6859\n",
      "Batch: 6860\n",
      "Batch: 6861\n",
      "Batch: 6862\n",
      "Batch: 6863\n",
      "Batch: 6864\n",
      "Batch: 6865\n",
      "Batch: 6866\n",
      "Batch: 6867\n",
      "Batch: 6868\n",
      "Batch: 6869\n",
      "Batch: 6870\n",
      "Batch: 6871\n",
      "Batch: 6872\n",
      "Batch: 6873\n",
      "Batch: 6874\n",
      "Batch: 6875\n",
      "Batch: 6876\n",
      "Batch: 6877\n",
      "Batch: 6878\n",
      "Batch: 6879\n",
      "Batch: 6880\n",
      "Batch: 6881\n",
      "Batch: 6882\n",
      "Batch: 6883\n",
      "Batch: 6884\n",
      "Batch: 6885\n",
      "Batch: 6886\n",
      "Batch: 6887\n",
      "Batch: 6888\n",
      "Batch: 6889\n",
      "Batch: 6890\n",
      "Batch: 6891\n",
      "Batch: 6892\n",
      "Batch: 6893\n",
      "Batch: 6894\n",
      "Batch: 6895\n",
      "Batch: 6896\n",
      "Batch: 6897\n",
      "Batch: 6898\n",
      "Batch: 6899\n",
      "Batch: 6900\n",
      "Batch: 6901\n",
      "Batch: 6902\n",
      "Batch: 6903\n",
      "Batch: 6904\n",
      "Batch: 6905\n",
      "Batch: 6906\n",
      "Batch: 6907\n",
      "Batch: 6908\n",
      "Batch: 6909\n",
      "Batch: 6910\n",
      "Batch: 6911\n",
      "Batch: 6912\n",
      "Batch: 6913\n",
      "Batch: 6914\n",
      "Batch: 6915\n",
      "Batch: 6916\n",
      "Batch: 6917\n",
      "Batch: 6918\n",
      "Batch: 6919\n",
      "Batch: 6920\n",
      "Batch: 6921\n",
      "Batch: 6922\n",
      "Batch: 6923\n",
      "Batch: 6924\n",
      "Batch: 6925\n",
      "Batch: 6926\n",
      "Batch: 6927\n",
      "Batch: 6928\n",
      "Batch: 6929\n",
      "Batch: 6930\n",
      "Batch: 6931\n",
      "Batch: 6932\n",
      "Batch: 6933\n",
      "Batch: 6934\n",
      "Batch: 6935\n",
      "Batch: 6936\n",
      "Batch: 6937\n",
      "Batch: 6938\n",
      "Batch: 6939\n",
      "Batch: 6940\n",
      "Batch: 6941\n",
      "Batch: 6942\n",
      "Batch: 6943\n",
      "Batch: 6944\n",
      "Batch: 6945\n",
      "Batch: 6946\n",
      "Batch: 6947\n",
      "Batch: 6948\n",
      "Batch: 6949\n",
      "Batch: 6950\n",
      "Batch: 6951\n",
      "Batch: 6952\n",
      "Batch: 6953\n",
      "Batch: 6954\n",
      "Batch: 6955\n",
      "Batch: 6956\n",
      "Batch: 6957\n",
      "Batch: 6958\n",
      "Batch: 6959\n",
      "Batch: 6960\n",
      "Batch: 6961\n",
      "Batch: 6962\n",
      "Batch: 6963\n",
      "Batch: 6964\n",
      "Batch: 6965\n",
      "Batch: 6966\n",
      "Batch: 6967\n",
      "Batch: 6968\n",
      "Batch: 6969\n",
      "Batch: 6970\n",
      "Batch: 6971\n",
      "Batch: 6972\n",
      "Batch: 6973\n",
      "Batch: 6974\n",
      "Batch: 6975\n",
      "Batch: 6976\n",
      "Batch: 6977\n",
      "Batch: 6978\n",
      "Batch: 6979\n",
      "Batch: 6980\n",
      "Batch: 6981\n",
      "Batch: 6982\n",
      "Batch: 6983\n",
      "Batch: 6984\n",
      "Batch: 6985\n",
      "Batch: 6986\n",
      "Batch: 6987\n",
      "Batch: 6988\n",
      "Batch: 6989\n",
      "Batch: 6990\n",
      "Batch: 6991\n",
      "Batch: 6992\n",
      "Batch: 6993\n",
      "Batch: 6994\n",
      "Batch: 6995\n",
      "Batch: 6996\n",
      "Batch: 6997\n",
      "Batch: 6998\n",
      "Batch: 6999\n",
      "Batch: 7000\n",
      "Batch: 7001\n",
      "Batch: 7002\n",
      "Batch: 7003\n",
      "Batch: 7004\n",
      "Batch: 7005\n",
      "Batch: 7006\n",
      "Batch: 7007\n",
      "Batch: 7008\n",
      "Batch: 7009\n",
      "Batch: 7010\n",
      "Batch: 7011\n",
      "Batch: 7012\n",
      "Batch: 7013\n",
      "Batch: 7014\n",
      "Batch: 7015\n",
      "Batch: 7016\n",
      "Batch: 7017\n",
      "Batch: 7018\n",
      "Batch: 7019\n",
      "Batch: 7020\n",
      "Batch: 7021\n",
      "Batch: 7022\n",
      "Batch: 7023\n",
      "Batch: 7024\n",
      "Batch: 7025\n",
      "Batch: 7026\n",
      "Batch: 7027\n",
      "Batch: 7028\n",
      "Batch: 7029\n",
      "Batch: 7030\n",
      "Batch: 7031\n",
      "Batch: 7032\n",
      "Batch: 7033\n",
      "Batch: 7034\n",
      "Batch: 7035\n",
      "Batch: 7036\n",
      "Batch: 7037\n",
      "Batch: 7038\n",
      "Batch: 7039\n",
      "Batch: 7040\n",
      "Batch: 7041\n",
      "Batch: 7042\n",
      "Batch: 7043\n",
      "Batch: 7044\n",
      "Batch: 7045\n",
      "Batch: 7046\n",
      "Batch: 7047\n",
      "Batch: 7048\n",
      "Batch: 7049\n",
      "Batch: 7050\n",
      "Batch: 7051\n",
      "Batch: 7052\n",
      "Batch: 7053\n",
      "Batch: 7054\n",
      "Batch: 7055\n",
      "Batch: 7056\n",
      "Batch: 7057\n",
      "Batch: 7058\n",
      "Batch: 7059\n",
      "Batch: 7060\n",
      "Batch: 7061\n",
      "Batch: 7062\n",
      "Batch: 7063\n",
      "Batch: 7064\n",
      "Batch: 7065\n",
      "Batch: 7066\n",
      "Batch: 7067\n",
      "Batch: 7068\n",
      "Batch: 7069\n",
      "Batch: 7070\n",
      "Batch: 7071\n",
      "Batch: 7072\n",
      "Batch: 7073\n",
      "Batch: 7074\n",
      "Batch: 7075\n",
      "Batch: 7076\n",
      "Batch: 7077\n",
      "Batch: 7078\n",
      "Batch: 7079\n",
      "Batch: 7080\n",
      "Batch: 7081\n",
      "Batch: 7082\n",
      "Batch: 7083\n",
      "Batch: 7084\n",
      "Batch: 7085\n",
      "Batch: 7086\n",
      "Batch: 7087\n",
      "Batch: 7088\n",
      "Batch: 7089\n",
      "Batch: 7090\n",
      "Batch: 7091\n",
      "Batch: 7092\n",
      "Batch: 7093\n",
      "Batch: 7094\n",
      "Batch: 7095\n",
      "Batch: 7096\n",
      "Batch: 7097\n",
      "Batch: 7098\n",
      "Batch: 7099\n",
      "Batch: 7100\n",
      "Batch: 7101\n",
      "Batch: 7102\n",
      "Batch: 7103\n",
      "Batch: 7104\n",
      "Batch: 7105\n",
      "Batch: 7106\n",
      "Batch: 7107\n",
      "Batch: 7108\n",
      "Batch: 7109\n",
      "Batch: 7110\n",
      "Batch: 7111\n",
      "Batch: 7112\n",
      "Batch: 7113\n",
      "Batch: 7114\n",
      "Batch: 7115\n",
      "Batch: 7116\n",
      "Batch: 7117\n",
      "Batch: 7118\n",
      "Batch: 7119\n",
      "Batch: 7120\n",
      "Batch: 7121\n",
      "Batch: 7122\n",
      "Batch: 7123\n",
      "Batch: 7124\n",
      "Batch: 7125\n",
      "Batch: 7126\n",
      "Batch: 7127\n",
      "Batch: 7128\n",
      "Batch: 7129\n",
      "Batch: 7130\n",
      "Batch: 7131\n",
      "Batch: 7132\n",
      "Batch: 7133\n",
      "Batch: 7134\n",
      "Batch: 7135\n",
      "Batch: 7136\n",
      "Batch: 7137\n",
      "Batch: 7138\n",
      "Batch: 7139\n",
      "Batch: 7140\n",
      "Batch: 7141\n",
      "Batch: 7142\n",
      "Batch: 7143\n",
      "Batch: 7144\n",
      "Batch: 7145\n",
      "Batch: 7146\n",
      "Batch: 7147\n",
      "Batch: 7148\n",
      "Batch: 7149\n",
      "Batch: 7150\n",
      "Batch: 7151\n",
      "Batch: 7152\n",
      "Batch: 7153\n",
      "Batch: 7154\n",
      "Batch: 7155\n",
      "Batch: 7156\n",
      "Batch: 7157\n",
      "Batch: 7158\n",
      "Batch: 7159\n",
      "Batch: 7160\n",
      "Batch: 7161\n",
      "Batch: 7162\n",
      "Batch: 7163\n",
      "Batch: 7164\n",
      "Batch: 7165\n",
      "Batch: 7166\n",
      "Batch: 7167\n",
      "Batch: 7168\n",
      "Batch: 7169\n",
      "Batch: 7170\n",
      "Batch: 7171\n",
      "Batch: 7172\n",
      "Batch: 7173\n",
      "Batch: 7174\n",
      "Batch: 7175\n",
      "Batch: 7176\n",
      "Batch: 7177\n",
      "Batch: 7178\n",
      "Batch: 7179\n",
      "Batch: 7180\n",
      "Batch: 7181\n",
      "Batch: 7182\n",
      "Batch: 7183\n",
      "Batch: 7184\n",
      "Batch: 7185\n",
      "Batch: 7186\n",
      "Batch: 7187\n",
      "Batch: 7188\n",
      "Batch: 7189\n",
      "Batch: 7190\n",
      "Batch: 7191\n",
      "Batch: 7192\n",
      "Batch: 7193\n",
      "Batch: 7194\n",
      "Batch: 7195\n",
      "Batch: 7196\n",
      "Batch: 7197\n",
      "Batch: 7198\n",
      "Batch: 7199\n",
      "Batch: 7200\n",
      "Batch: 7201\n",
      "Batch: 7202\n",
      "Batch: 7203\n",
      "Batch: 7204\n",
      "Batch: 7205\n",
      "Batch: 7206\n",
      "Batch: 7207\n",
      "Batch: 7208\n",
      "Batch: 7209\n",
      "Batch: 7210\n",
      "Batch: 7211\n",
      "Batch: 7212\n",
      "Batch: 7213\n",
      "Batch: 7214\n",
      "Batch: 7215\n",
      "Batch: 7216\n",
      "Batch: 7217\n",
      "Batch: 7218\n",
      "Batch: 7219\n",
      "Batch: 7220\n",
      "Batch: 7221\n",
      "Batch: 7222\n",
      "Batch: 7223\n",
      "Batch: 7224\n",
      "Batch: 7225\n",
      "Batch: 7226\n",
      "Batch: 7227\n",
      "Batch: 7228\n",
      "Batch: 7229\n",
      "Batch: 7230\n",
      "Batch: 7231\n",
      "Batch: 7232\n",
      "Batch: 7233\n",
      "Batch: 7234\n",
      "Batch: 7235\n",
      "Batch: 7236\n",
      "Batch: 7237\n",
      "Batch: 7238\n",
      "Batch: 7239\n",
      "Batch: 7240\n",
      "Batch: 7241\n",
      "Batch: 7242\n",
      "Batch: 7243\n",
      "Batch: 7244\n",
      "Batch: 7245\n",
      "Batch: 7246\n",
      "Batch: 7247\n",
      "Batch: 7248\n",
      "Batch: 7249\n",
      "Batch: 7250\n",
      "Batch: 7251\n",
      "Batch: 7252\n",
      "Batch: 7253\n",
      "Batch: 7254\n",
      "Batch: 7255\n",
      "Batch: 7256\n",
      "Batch: 7257\n",
      "Batch: 7258\n",
      "Batch: 7259\n",
      "Batch: 7260\n",
      "Batch: 7261\n",
      "Batch: 7262\n",
      "Batch: 7263\n",
      "Batch: 7264\n",
      "Batch: 7265\n",
      "Batch: 7266\n",
      "Batch: 7267\n",
      "Batch: 7268\n",
      "Batch: 7269\n",
      "Batch: 7270\n",
      "Batch: 7271\n",
      "Batch: 7272\n",
      "Batch: 7273\n",
      "Batch: 7274\n",
      "Batch: 7275\n",
      "Batch: 7276\n",
      "Batch: 7277\n",
      "Batch: 7278\n",
      "Batch: 7279\n",
      "Batch: 7280\n",
      "Batch: 7281\n",
      "Batch: 7282\n",
      "Batch: 7283\n",
      "Batch: 7284\n",
      "Batch: 7285\n",
      "Batch: 7286\n",
      "Batch: 7287\n",
      "Batch: 7288\n",
      "Batch: 7289\n",
      "Batch: 7290\n",
      "Batch: 7291\n",
      "Batch: 7292\n",
      "Batch: 7293\n",
      "Batch: 7294\n",
      "Batch: 7295\n",
      "Batch: 7296\n",
      "Batch: 7297\n",
      "Batch: 7298\n",
      "Batch: 7299\n",
      "Batch: 7300\n",
      "Batch: 7301\n",
      "Batch: 7302\n",
      "Batch: 7303\n",
      "Batch: 7304\n",
      "Batch: 7305\n",
      "Batch: 7306\n",
      "Batch: 7307\n",
      "Batch: 7308\n",
      "Batch: 7309\n",
      "Batch: 7310\n",
      "Batch: 7311\n",
      "Batch: 7312\n",
      "Batch: 7313\n",
      "Batch: 7314\n",
      "Batch: 7315\n",
      "Batch: 7316\n",
      "Batch: 7317\n",
      "Batch: 7318\n",
      "Batch: 7319\n",
      "Batch: 7320\n",
      "Batch: 7321\n",
      "Batch: 7322\n",
      "Batch: 7323\n",
      "Batch: 7324\n",
      "Batch: 7325\n",
      "Batch: 7326\n",
      "Batch: 7327\n",
      "Batch: 7328\n",
      "Batch: 7329\n",
      "Batch: 7330\n",
      "Batch: 7331\n",
      "Batch: 7332\n",
      "Batch: 7333\n",
      "Batch: 7334\n",
      "Batch: 7335\n",
      "Batch: 7336\n",
      "Batch: 7337\n",
      "Batch: 7338\n",
      "Batch: 7339\n",
      "Batch: 7340\n",
      "Batch: 7341\n",
      "Batch: 7342\n",
      "Batch: 7343\n",
      "Batch: 7344\n",
      "Batch: 7345\n",
      "Batch: 7346\n",
      "Batch: 7347\n",
      "Batch: 7348\n",
      "Batch: 7349\n",
      "Batch: 7350\n",
      "Batch: 7351\n",
      "Batch: 7352\n",
      "Batch: 7353\n",
      "Batch: 7354\n",
      "Batch: 7355\n",
      "Batch: 7356\n",
      "Batch: 7357\n",
      "Batch: 7358\n",
      "Batch: 7359\n",
      "Batch: 7360\n",
      "Batch: 7361\n",
      "Batch: 7362\n",
      "Batch: 7363\n",
      "Batch: 7364\n",
      "Batch: 7365\n",
      "Batch: 7366\n",
      "Batch: 7367\n",
      "Batch: 7368\n",
      "Batch: 7369\n",
      "Batch: 7370\n",
      "Batch: 7371\n",
      "Batch: 7372\n",
      "Batch: 7373\n",
      "Batch: 7374\n",
      "Batch: 7375\n",
      "Batch: 7376\n",
      "Batch: 7377\n",
      "Batch: 7378\n",
      "Batch: 7379\n",
      "Batch: 7380\n",
      "Batch: 7381\n",
      "Batch: 7382\n",
      "Batch: 7383\n",
      "Batch: 7384\n",
      "Batch: 7385\n",
      "Batch: 7386\n",
      "Batch: 7387\n",
      "Batch: 7388\n",
      "Batch: 7389\n",
      "Batch: 7390\n",
      "Batch: 7391\n",
      "Batch: 7392\n",
      "Batch: 7393\n",
      "Batch: 7394\n",
      "Batch: 7395\n",
      "Batch: 7396\n",
      "Batch: 7397\n",
      "Batch: 7398\n",
      "Batch: 7399\n",
      "Batch: 7400\n",
      "Batch: 7401\n",
      "Batch: 7402\n",
      "Batch: 7403\n",
      "Batch: 7404\n",
      "Batch: 7405\n",
      "Batch: 7406\n",
      "Batch: 7407\n",
      "Batch: 7408\n",
      "Batch: 7409\n",
      "Batch: 7410\n",
      "Batch: 7411\n",
      "Batch: 7412\n",
      "Batch: 7413\n",
      "Batch: 7414\n",
      "Batch: 7415\n",
      "Batch: 7416\n",
      "Batch: 7417\n",
      "Batch: 7418\n",
      "Batch: 7419\n",
      "Batch: 7420\n",
      "Batch: 7421\n",
      "Batch: 7422\n",
      "Batch: 7423\n",
      "Batch: 7424\n",
      "Batch: 7425\n",
      "Batch: 7426\n",
      "Batch: 7427\n",
      "Batch: 7428\n",
      "Batch: 7429\n",
      "Batch: 7430\n",
      "Batch: 7431\n",
      "Batch: 7432\n",
      "Batch: 7433\n",
      "Batch: 7434\n",
      "Batch: 7435\n",
      "Batch: 7436\n",
      "Batch: 7437\n",
      "Batch: 7438\n",
      "Batch: 7439\n",
      "Batch: 7440\n",
      "Batch: 7441\n",
      "Batch: 7442\n",
      "Batch: 7443\n",
      "Batch: 7444\n",
      "Batch: 7445\n",
      "Batch: 7446\n",
      "Batch: 7447\n",
      "Batch: 7448\n",
      "Batch: 7449\n",
      "Batch: 7450\n",
      "Batch: 7451\n",
      "Batch: 7452\n",
      "Batch: 7453\n",
      "Batch: 7454\n",
      "Batch: 7455\n",
      "Batch: 7456\n",
      "Batch: 7457\n",
      "Batch: 7458\n",
      "Batch: 7459\n",
      "Batch: 7460\n",
      "Batch: 7461\n",
      "Batch: 7462\n",
      "Batch: 7463\n",
      "Batch: 7464\n",
      "Batch: 7465\n",
      "Batch: 7466\n",
      "Batch: 7467\n",
      "Batch: 7468\n",
      "Batch: 7469\n",
      "Batch: 7470\n",
      "Batch: 7471\n",
      "Batch: 7472\n",
      "Batch: 7473\n",
      "Batch: 7474\n",
      "Batch: 7475\n",
      "Batch: 7476\n",
      "Batch: 7477\n",
      "Batch: 7478\n",
      "Batch: 7479\n",
      "Batch: 7480\n",
      "Batch: 7481\n",
      "Batch: 7482\n",
      "Batch: 7483\n",
      "Batch: 7484\n",
      "Batch: 7485\n",
      "Batch: 7486\n",
      "Batch: 7487\n",
      "Batch: 7488\n",
      "Batch: 7489\n",
      "Batch: 7490\n",
      "Batch: 7491\n",
      "Batch: 7492\n",
      "Batch: 7493\n",
      "Batch: 7494\n",
      "Batch: 7495\n",
      "Batch: 7496\n",
      "Batch: 7497\n",
      "Batch: 7498\n",
      "Batch: 7499\n",
      "Batch: 7500\n",
      "Batch: 7501\n",
      "Batch: 7502\n",
      "Batch: 7503\n",
      "Batch: 7504\n",
      "Batch: 7505\n",
      "Batch: 7506\n",
      "Batch: 7507\n",
      "Batch: 7508\n",
      "Batch: 7509\n",
      "Batch: 7510\n",
      "Batch: 7511\n",
      "Batch: 7512\n",
      "Batch: 7513\n",
      "Batch: 7514\n",
      "Batch: 7515\n",
      "Batch: 7516\n",
      "Batch: 7517\n",
      "Batch: 7518\n",
      "Batch: 7519\n",
      "Batch: 7520\n",
      "Batch: 7521\n",
      "Batch: 7522\n",
      "Batch: 7523\n",
      "Batch: 7524\n",
      "Batch: 7525\n",
      "Batch: 7526\n",
      "Batch: 7527\n",
      "Batch: 7528\n",
      "Batch: 7529\n",
      "Batch: 7530\n",
      "Batch: 7531\n",
      "Batch: 7532\n",
      "Batch: 7533\n",
      "Batch: 7534\n",
      "Batch: 7535\n",
      "Batch: 7536\n",
      "Batch: 7537\n",
      "Batch: 7538\n",
      "Batch: 7539\n",
      "Batch: 7540\n",
      "Batch: 7541\n",
      "Batch: 7542\n",
      "Batch: 7543\n",
      "Batch: 7544\n",
      "Batch: 7545\n",
      "Batch: 7546\n",
      "Batch: 7547\n",
      "Batch: 7548\n",
      "Batch: 7549\n",
      "Batch: 7550\n",
      "Batch: 7551\n",
      "Batch: 7552\n",
      "Batch: 7553\n",
      "Batch: 7554\n",
      "Batch: 7555\n",
      "Batch: 7556\n",
      "Batch: 7557\n",
      "Batch: 7558\n",
      "Batch: 7559\n",
      "Batch: 7560\n",
      "Batch: 7561\n",
      "Batch: 7562\n",
      "Batch: 7563\n",
      "Batch: 7564\n",
      "Batch: 7565\n",
      "Batch: 7566\n",
      "Batch: 7567\n",
      "Batch: 7568\n",
      "Batch: 7569\n",
      "Batch: 7570\n",
      "Batch: 7571\n",
      "Batch: 7572\n",
      "Batch: 7573\n",
      "Batch: 7574\n",
      "Batch: 7575\n",
      "Batch: 7576\n",
      "Batch: 7577\n",
      "Batch: 7578\n",
      "Batch: 7579\n",
      "Batch: 7580\n",
      "Batch: 7581\n",
      "Batch: 7582\n",
      "Batch: 7583\n",
      "Batch: 7584\n",
      "Batch: 7585\n",
      "Batch: 7586\n",
      "Batch: 7587\n",
      "Batch: 7588\n",
      "Batch: 7589\n",
      "Batch: 7590\n",
      "Batch: 7591\n",
      "Batch: 7592\n",
      "Batch: 7593\n",
      "Batch: 7594\n",
      "Batch: 7595\n",
      "Batch: 7596\n",
      "Batch: 7597\n",
      "Batch: 7598\n",
      "Batch: 7599\n",
      "Batch: 7600\n",
      "Batch: 7601\n",
      "Batch: 7602\n",
      "Batch: 7603\n",
      "Batch: 7604\n",
      "Batch: 7605\n",
      "Batch: 7606\n",
      "Batch: 7607\n",
      "Batch: 7608\n",
      "Batch: 7609\n",
      "Batch: 7610\n",
      "Batch: 7611\n",
      "Batch: 7612\n",
      "Batch: 7613\n",
      "Batch: 7614\n",
      "Batch: 7615\n",
      "Batch: 7616\n",
      "Batch: 7617\n",
      "Batch: 7618\n",
      "Batch: 7619\n",
      "Batch: 7620\n",
      "Batch: 7621\n",
      "Batch: 7622\n",
      "Batch: 7623\n",
      "Batch: 7624\n",
      "Batch: 7625\n",
      "Batch: 7626\n",
      "Batch: 7627\n",
      "Batch: 7628\n",
      "Batch: 7629\n",
      "Batch: 7630\n",
      "Batch: 7631\n",
      "Batch: 7632\n",
      "Batch: 7633\n",
      "Batch: 7634\n",
      "Batch: 7635\n",
      "Batch: 7636\n",
      "Batch: 7637\n",
      "Batch: 7638\n",
      "Batch: 7639\n",
      "Batch: 7640\n",
      "Batch: 7641\n",
      "Batch: 7642\n",
      "Batch: 7643\n",
      "Batch: 7644\n",
      "Batch: 7645\n",
      "Batch: 7646\n",
      "Batch: 7647\n",
      "Batch: 7648\n",
      "Batch: 7649\n",
      "Batch: 7650\n",
      "Batch: 7651\n",
      "Batch: 7652\n",
      "Batch: 7653\n",
      "Batch: 7654\n",
      "Batch: 7655\n",
      "Batch: 7656\n",
      "Batch: 7657\n",
      "Batch: 7658\n",
      "Batch: 7659\n",
      "Batch: 7660\n",
      "Batch: 7661\n",
      "Batch: 7662\n",
      "Batch: 7663\n",
      "Batch: 7664\n",
      "Batch: 7665\n",
      "Batch: 7666\n",
      "Batch: 7667\n",
      "Batch: 7668\n",
      "Batch: 7669\n",
      "Batch: 7670\n",
      "Batch: 7671\n",
      "Batch: 7672\n",
      "Batch: 7673\n",
      "Batch: 7674\n",
      "Batch: 7675\n",
      "Batch: 7676\n",
      "Batch: 7677\n"
     ]
    }
   ],
   "source": [
    "Towers.eval()  # Set model to evaluation mode\n",
    "encodedDouments = []\n",
    "with torch.no_grad():  # No need to track gradients for testing\n",
    "    i=0\n",
    "    for batch in docsEmbeddingsDataloader:\n",
    "        i+=1\n",
    "        encodedDoumentsBatch = Towers.docEncoder(batch).cpu().numpy()\n",
    "        encodedDouments.extend(encodedDoumentsBatch)\n",
    "        print(f'Batch: {i}')\n",
    "        # print(batch)\n",
    "        # print(encodedDoumentsBatch)\n",
    "        # if(i >= 2):\n",
    "        #     break\n",
    "encodedDouments = pd.DataFrame({'encoders': [array for array in encodedDouments]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(767675, 1)\n",
      "(767675, 1)\n",
      "(767675, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(libriary.shape)\n",
    "print(encodedDouments.shape)\n",
    "\n",
    "libWithEncoders = pd.DataFrame({\n",
    "    'document': libriary['document'],\n",
    "    'encoders': encodedDouments['encoders'],\n",
    "})\n",
    "\n",
    "print(libWithEncoders.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Random element from Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what does a wolf spider look like\n"
     ]
    }
   ],
   "source": [
    "def getRandomQuery(dataframe):\n",
    "    available_indices = list(dataframe.index)\n",
    "    random_index = np.random.choice(available_indices)\n",
    "    query = dataframe.iloc[random_index]['query']\n",
    "    return query\n",
    "query = getRandomQuery(validate)\n",
    "\n",
    "print(query)\n",
    "\n",
    "def to_w2v_embedding(sp, text):\n",
    "    tokens = sp.encode_as_pieces(text.lower())\n",
    "\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if (token in w2v_model.wv): \n",
    "            embeddings.append(w2v_model.wv[token])\n",
    "\n",
    "    return np.stack(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.99999493  0.99999994 -1.          0.99805367  0.99999994 -0.99435025\n",
      " -1.         -1.          0.99999994 -1.         -1.          0.99999994\n",
      "  0.99999994  0.9009006   0.99999994  0.99995136]\n"
     ]
    }
   ],
   "source": [
    "Towers.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # No need to track gradients for testing\n",
    "    # query_embedding = torch.tensor(to_w2v_embedding(sp, ))\n",
    "    query_embedding = torch.tensor([to_w2v_embedding(sp, query)], dtype=torch.float, device=device)\n",
    "    encodedQuery = Towers.docEncoder(query_embedding).cpu().numpy()\n",
    "print(encodedQuery[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Closest documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Compute the cosine similarity between two vectors.\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "libWithEncoders['distance'] = libWithEncoders['encoders'].apply(lambda x: (1- cosine_similarity(encodedQuery[0], x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what does a wolf spider look like\n",
      "                                                 document  \\\n",
      "742498  There are many varieties of sweet potatoes, wh...   \n",
      "714125  Click here to get exclusive, professional tips...   \n",
      "186734  (BPM). Processes of the same nature are classi...   \n",
      "205084  Wolf Spiders live in both coastal and inland h...   \n",
      "476959  There are some people who have seen good resul...   \n",
      "\n",
      "                                                 encoders  distance  \n",
      "742498  [-0.99999356, 0.99999994, -1.0, 0.9864725, 0.9...  0.012050  \n",
      "714125  [-1.0, 0.99999994, -0.9999061, 0.99999994, 0.9...  0.102515  \n",
      "186734  [-0.99971503, 0.99999994, -0.99999994, 0.79861...  0.107043  \n",
      "205084  [-1.0, 0.99999994, -1.0, 0.9999977, 0.99999994...  0.113631  \n",
      "476959  [-1.0, 0.99999994, -0.9526948, 0.99965733, 0.9...  0.119708  \n"
     ]
    }
   ],
   "source": [
    "libWithEncodersSorted = libWithEncoders.sort_values(by='distance', ascending=True)\n",
    "results = libWithEncodersSorted.head(5)\n",
    "print(query)\n",
    "print(results)\n",
    "\n",
    "csv_file_path = 'results.csv'\n",
    "results.to_csv(csv_file_path, index=False)\n",
    "\n",
    "with open(csv_file_path, 'a') as f:\n",
    "    f.write('\\n\\nQuery:\\n')\n",
    "    f.write(query + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
